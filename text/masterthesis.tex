\documentclass[
a4paper, 							% Papierformat
%10pt,								% Schriftgröße (12pt, 11pt (Standard))
%twoside,							% Doppelseiten
titlepage,						% Titelei auf eigener Seite
%normalheadings,			% Überschriften etwas kleiner (smallheadings)
%idxtotoc,						% Index im Inhaltsverzeichnis
%liststotoc,					% Abb.- und Tab.verzeichnis im Inhalt
%bibtotoc,						% Literaturverzeichnis im Inhalt
%leqno,   						% Nummerierung von Gleichungen links
%fleqn,								% Ausgabe von Gleichungen linksbündig
%draft								% überlangen Zeilen in Ausgabe gekennzeichnet
]
{scrreprt}
\usepackage[ngerman]{babel}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tipa}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm,includeheadfoot]{geometry}
\usepackage{marvosym}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{listings} \lstset{numbers=left, numberstyle=\tiny, numbersep=5pt, basicstyle=\fontsize{9}{13}\selectfont, xleftmargin=1cm, xrightmargin=1cm, frame=topline} \lstset{language=Java}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}


\begin{document}



\thispagestyle{empty}
\begin{titlepage}
\begin{figure}[t]
	\centering
  \includegraphics[width=80mm]{images/HsKaLogoKlein.png}
	\vspace{2.5cm}
\end{figure}
\begin{center}
\title{Master-Thesis}
\textbf{\huge{Master-Thesis}} \\[0.5cm]
\textbf{Visual Studio Erweiterung zur statischen Code-Analyse} \\[4cm]
\textbf{andrena objetcs ag} \\[0.25cm]
\author{Manuel Naujoks} Manuel Naujoks\\[2.5cm]
Betreut durch \\[0.25cm] 
Prof. Dr. Thomas Fuchß \\[2.5cm]
Bischweier, den \today
\end{center}
\end{titlepage}



\pagenumbering{roman}
\setcounter{page}{1}
\begin{center}\textbf{\large Erklärung}\\[1cm]\end{center}
Hiermit versichere ich, dass ich die vorliegende Arbeit selbstständig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe, dass alle Stellen der Arbeit, die wörtlich oder sinngemäß aus anderen Quellen übernommen wurden, als solche kenntlich gemacht sind und dass die Arbeit in gleicher oder ähnlicher Form noch keiner Prüfungsbehörde vorgelegt wurde.
\\[4\baselineskip]
Bischweier, den \today \\
Manuel Naujoks
\newpage



\chapter*{Zusammenfassung}
Im Rahmen dieser Master-Thesis soll eine Visual Studio Erweiterung entwickelt werden, die direktes Entwickler-Feedback anhand von Software-Metriken geben kann. Dabei dient das Plugin Usus für Eclipse als Vorlage, welches bereits existiert. Die zu erstellende Erweiterung soll eine statische Code-Analyse von .NET-Projekten in Visual Stuido 2010 durchführen und für andrena relevante Code-Metriken berechnen können.
\newline
Die zu entwickelnde Erweiterung soll genutzt werden können, um Software-Entwickler aktiv zu unterstützen "`Clean code"' zu schreiben. Eine ähnliche Lösung zu Microsofts Achievements Extension mit Achievements in Bezug auf clean code best practices wäre denkbar. Dazu soll eine Evaluierung anhand von Beispielaufgaben aus einem andrena-Kurs zum Thema Refaktorisierung bearbeitet und die Veränderung in den Metriken entsprechend erfasst und dokumentiert werden.
\newline
Weiterhin soll in einer Metrik-Analyse nach Heuristiken oder Regeln mit statischer Signifikanz gesucht werden, die eventuell guten von schlechtem Code unterscheiden können. Lassen sich hier Muster beziehungsweise Strukturen aufzeigen? Ein Indiz hierfür ist, dass die Metriken oft einer Exponentialverteilung folgen. Dabei soll untersucht werden, ob und wenn möglich wie sich dies auf den Software Qualitäts Index (SQI) von andrena abbilden lässt.
\newpage



\chapter*{Abstract}
Objective of this master thesis is the development of a Visual Studio Extension that is capable of providing direct development feedback based on software metrics. The Eclipse plugin Usus, which already exists, is going to be used as orientation. The extension that is developed shall be able to perform static code analysis of .NET projects in Visual Studio 2010 in order to calculate the code metrics that are relevant for andrena.
\newline
As far as feedback is concerned, the extension shall be able to actively support developers to write "`clean code"'. A similar solution to Microsofts Achievements Extension could likely be found with achievements based on common clean code best practices. Therefore an evaluation with sample exercises of an andrena course on the topic of refactoring is done and the variation in the metrics is detected and documented.
\newline
Another metric analysis is performed in order to find heuristics or rules with static significance, which might be able to distinguish good code from bad code. Are there detectable patterns? One thing might be that metrics often follow an exponential distribution. An analysis shall show whether it is possible and if yes, how this can be mapped to the Software Quality Index (SQI) of andrena.
\newpage




\tableofcontents




\chapter{Einführung}
\pagenumbering{arabic}
\setcounter{page}{1}
bla bla bla Softwarequalität
bla bla bla Metriken
bla bla bla Entwicklerfeedback
bla bla bla Übersicht über Codebasis
bla bla bla direkt in Visual Studio
bla bla bla

\section{andrena objects ag}
Diese Master-Thesis wird bei dem Software-Unternehmen andrena objects ag durchgeführt. bla bla bla.

\section{Aufbau der Thesis}
bla bla bla.




\chapter{Grundlagen}
\label{chap:basics}
In diesem Kapitel sollen die Grundlagen vermittelt werden, die für ein Verständnis einer mit Quellcode arbeitenden Erweiterung für Visual Studio erforderlich sind. Dazu wird in Abschnitt \ref{sec:generalbasics} zunächst auf allgemeine Grundlagen wie Quellcode, sowie Entwicklungsumgebungen eingegangen. Anschließend werden in Abschnitt \ref{sec:technicalbasics} die technischen Grundlagen vorgestellt.


\section{Allgemeine Grundlagen}
In diesem Abschnitt wird in Unterabschnitt \ref{subsec:cleancode} zunächst auf die Clean Code Idee sowie manche Prinzipien eingegangen. Anschließend wird in Unterabschnitt \ref{subsec:eclipse} das Programm Eclipse vorgestellt. In Unterabschnitt \ref{subsec:visualstudio} wird abschließend auf das Umfeld der Erweiterung eingegangen wird, die im Rahmen dieser Master-Thesis entwickelt werden soll. Dabei handelt es sich um das Entwicklungswerkzeug Visual Studio.
\label{sec:generalbasics}

\subsection{Clean Code}
\label{subsec:cleancode}
Ein Softwaresystem wird in Form von Quellcode erstellt. Dieser Code wird anschließend kompiliert um eine ausführbares Programm zu erhalten. Robert C. Martin beschreibt Code in seinem Clean Code Buch als Sprache, in der wir die Anforderungen an die Software maschinenlesbar zum Ausdruck bringen \cite{CleanCode}. Weiter beschreibt er in seinem Buch Prinzipien und "`Best Practices"', die das Erstellen von verständlicherem und wartbareren Quellcode unterstützen. Die selben Prinzipien wurden auch von Ralf Westphal und Stefan Lieser aufgegriffen und im Rahmen eines Wertesystems mit sieben Graden vorgestellt \cite{CleanCodeDeveloper}. Martin's Clean Code Buch bleibt auch für Westphal und Lieser die grundlegende Lektüre.
\paragraph{}
Die Prinzipien und Best Practices der Clean Code Bewegung umfassen viele Aspekte, die bereits durch Kent Beck in seinem Buch über die Methodik \textit{Extreme Programming} (XP) \cite{XP} eingeführt wurden. Drei wichtige Bestandteile von XP, die ebenfalls in den Graden des Clean Code Wertesystems von Westphal und Lieser auftreten, sind die folgenden.
\begin{description}
\item[Automatisiertes Testen] ist eine der wichtigsten Praktiken in der Clean Code Bewegung. Nach Robert C. Martin ist es die Aufgabe eines Entwicklers keinen Schaden in einem Softwaresystem anzurichten. Damit meint er Schaden an der Funktionalität und Schaden an der Struktur der Anwendung. Beides kann mit automatisierten Testfällen sichergestellt werden.
\item[Ständiges Refactoring] ist der effektivste Schutz gegen Schaden an der Struktur eines Softwaresystems bedingt durch evolutionäres Wachstum und vielen Anpassungen. Durch Tests kann dabei sichergestellt werden, dass Umstrukturierungen den Funktionsumfang nicht beeinträchtigen. Martin Fowler beschreibt solches Refactoring in seinem Buch \cite{Refactoring}
\item[Schnelle Code Reviews] sind eine weitere Voraussetzung um Clean Code entwickeln zu können. Der entscheidende Punkt ist das Feedback. Je schneller der Entwickler Feedback bekommt um so früher können Probleme im Quellcode erkannt und mit relativ wenig Aufwand korrigiert werden.
\end{description}

\subsection{Eclipse}
\label{subsec:eclipse}
Eclipse\footnote[1]{"`Eclipse - The Eclipse Foundation open source community website"' \url{http://www.eclipse.org/}} ist eine integrierte Entwicklungsumgebung (IDE) der Eclipse Foundation. Die Anwendung ist eine kostenfreies open source Programm und wird hauptsächlich für die Entwicklung von Software mit der Programmiersprache Java\footnote[2]{"`Oracle and Java"' \url{http://www.oracle.com/us/technologies/java/index.html}} verwendet. Eclipse unterstützt externe Erweiterungen in Form von Plugins.

\subsection{Visual Studio}
\label{subsec:visualstudio}
Visual Studio\footnote[3]{"`Die Microsoft Visual Studio 2010 Produktfamilie"' \url{http://www.microsoft.com/germany/visualstudio/products/default.aspx}} ist eine integrierte Entwicklungsumgebung von Microsoft. Im Gegensatz zu Eclipse ist Visual Studio ab der Professional Version ein kommerzielles Produkt. Die Entwicklung für das .NET-Framework\footnote[4]{"`Microsoft .NET Framework"' \url{http://www.microsoft.com/net}} von Microsoft kann mit Visual Studio durchgeführt werden, wobei mehrere Programmiersprachen unterstützt werden. Zu den bekanntesten und am weitesten verbreiteten Sprachen für das .NET-Framework zählen C\# und Viusal Basic.NET.
\paragraph{}
Visual Studio erlaubt die Installation von externen Erweiterungen als Addin oder Erweiterung ab der Professional Version. Die kostenfreie Express Edition besitzt einen sehr eingeschränkten Funktionsumfang. Der Unterschied zwischen einem Visual Studio Addin und einer Visual Studio Erweiterung ist der, dass Addins bereits in früheren Versionen unterstützt wurden und ein Entwickler die Schnittstellen in Visual Studio direkt anprogrammieren kann. Die Erweiterungen werden ab Visual Studio 2010 unterstützt und benötigen zur Entwicklung das \textit{Visual Studio 2010 SDK}\footnote[5]{Download: "`Visual Studio 2010 SP1 SDK"'\url{http://www.microsoft.com/download/en/details.aspx?id=21835}}, erlauben aber eine modernere Klassenbibliothek. Aaron Marten beschreibt in seinem Artikel \cite{VSCustomExtensions} die Möglichkeiten, wie mit der neuen Erweiterungstechnologie (VSIX) Addin-ähnliche Erweiterungen erstellt werden können.


\section{Technische Grundlagen}
\label{sec:technicalbasics}
In diesem Abschnitt werden die technischen Grundlagen erläutert. Dazu wird in Unterabschnitt \ref{subsec:oo} zunächst der Begriff der Objektorientierung eingeführt, bevor in Unterabschnitt \ref{subsec:graphs} auf Graphen näher eingegangen wird. Abschließend wird in Unterabschnitt \ref{subsec:staticcodeanalysis} das Konzept der statischen Code-Analyse vorgestellt.

\subsection{Objektorientierung}
\label{subsec:oo}
Die Objektorientierung als Methode ermöglicht laut Benrd Oestereich die hohe Komplexität von Softwaresystemen zu beherrschen \cite{OOSE}. Das ist möglich, da diese Methode die Dinge der realen Welt als Objekte sieht und dadurch die Problemdomäne verständlich und anschaulich macht. Ein objektorientiertes Softwaresystem besteht aus den folgenden vier wesentlichen Komponenten.
\begin{description}
\item[Klasse] kommt aus dem lateinischen von \textit{classis} und bedeutet "`Aufgebot"'. Damit ist laut Oestereich eine Teilmenge von Objekten der gleichen Struktur gemeint. Eine Klasse ist folglich auch der Typ aller seiner Objekte. Klassen können auch abstrakt sein. Eine abstrakte Klasse, oder auch genannt Schnittstelle, kann nicht als Objekt erzeugt werden. Eine nicht abstrakte Klasse, also eine konkrete Klasse, muss von dieser Klasse eine Vererbung der Struktur und des Verhaltens durchführen. Von dieser erbenden und konkreten Klasse kann dann ein Objekt erzeugt werden, das sowohl vom Typ der konkreten Klasse als auch vom Typ der abstrakten Klasse ist.
\item[Objekt] kommt ebenfalls aus dem lateinischen von \textit{obicere} und bedeutet "`entgegenhalten"'. Bernd Oestereich beschreibt es als "`Gegenstand der Erkenntnis und Wahrnehmung, des Denkens und Handelns"' und bezieht sich dabei auf das Brockhaus Lexikon. Ein Objekt ist eine Instanz einer Klasse.
\item[Attribut] kommt auch aus dem lateinischen von \textit{attributum} und bedeutet "`das Beigefügte"', was einer Eigenschaft oder einem Kennzeichen einer Sache entspricht. Die Daten, die ein Objekt ausmachen, werden anhand von Attributen gespeichert, auf die von den Operationen des Objekts aus zugegriffen werden kann. Attribute werden auch als Felder bezeichnet und lassen sich in Klassen-Felder und Instanz-Felder unterscheiden. Klassen-Felder können von allen Objekten der Klasse gemeinsam genutzt werden, während Instanz-Felder unterschiedliche Werte für konkrete Objekte haben können.
\item[Operation] kommt aus dem lateinischen von \textit{operatio} und bedeutet "`Handlung"'. Eine konkrete Aktion, die anhand einer definierten Vorschrift durchgeführt wird bezeichnet Oestereich in diesem Sinne als Operation. Das Verhalten von Objekten wird anhand ihrer Operationen festgelegt. Andere Bezeichnungen für Operation ist Funktion oder Methode. Methoden lassen sich in Klassen-Methoden und Instanz-Methoden aufteilen. Klassen-Methoden können nicht auf die Instanz-Felder sondern nur auf die Klassen-Felder zugreifen. Instanz-Methoden können auf Instanz-Felder und auf Klassenfelder zugreifen.
\item[Paket] wird von Oestereich als eine Ansammlung von Modellelementen bezeichnet. Dabei sind Modellelemente Klassen oder andere Pakete und dienen der besseren Strukturierung des Systems. Pakete werden auch als Namensräume bezeichnet, da sie eine benannte Zusammenfassung von Klassen und anderen Namensräumen sind.
\end{description}
Zusätzlich beschreibt Oerstereich zwei weitere Mittel von objektorientierten Softwaresystemen, die der Abstraktion dienen und die es erlauben irrelevant Dinge wegzulassen.
\begin{description}
\item[Assoziation] kommt aus dem lateinischen von \textit{associare} und bedeutet "`verbinden"'. Nach Oestereich entspricht dies einer \textit{Hat-eine-Beziehung} und gibt an, dass eine Klasse mit einer anderen Klasse zusammenarbeitet. Objekte der Klasse können auf Objekte der verbundenen Klasse zugreifen. Damit ist die Klasse, von der die Assoziation ausgeht, von der anderen Klasse abhängig. Anders ausgedrückt hat diese Klasse eine Abhängigkeit von der anderen.
\item[Vererbung] entspricht einer \textit{Ist-ein-Beziehung} und gibt an, dass eine Klasse das Verhalten und die Struktur einer anderen Klasse erbt oder spezialisiert. Ein Objekt der erbenden Klasse ist damit auch ein Objekt der gerbten Klasse und hat somit auch eine Abhängigkeit von ihr.
\end{description}
Mit diesen sieben Konzepten kann eine Softwaresystem objektorientiert beschrieben werden.

\subsection{Graphentheorie}
\label{subsec:graphs}
Heiko Körner beschreibt einen Graph in seinem Skript \cite{GraphAlgorithms} als Zweiertupel \begin{math}G = (V, E)\end{math}. Der erste Wert, $V$, ist eine endliche Menge an Knoten und der zweite, $E$, ist eine endliche Menge an Kanten zwischen diesen Knoten. Eine Kante ist ein Paar aus \begin{math}V \times V\end{math} und beinhaltet die beiden Knoten, die sie verbindet. Körner unterscheidet in gerichtete und ungerichtete Graphen. Bei letzterem verbindet eine Kante die Knoten in beiden Richtungen, wobei eine gerichtete Kante die Verbindungsrichtung anhand der Knoten-Reihenfolge im Kanten-Tupel vorgibt. Weiter definiert Körner einen Baum als zusammenhängenden azyklischen Graph, indem jeder Knoten von einem Wurzelknoten aus erreichbar ist.

\subsection{Statische Code-Analyse}
\label{subsec:staticcodeanalysis}
Artur Wagner beschreibt in seiner Ausarbeitung \cite{IntroStaticCodeAnalysis} die statische Codeanalyse als Prozess, der von einem Programm ähnlich einem Compiler gestartet wird. Dieses Programm führt den Code nicht aus und erzeugt auch keinen ausführbaren Code, sondern ein nimmt eine Analyse vor. Wagner erwähnt noch, das eine statische Code-Analyse keinen Korrektheitsnachweis liefert sondern lediglich eine Art Systemzusammenfassung erzeugt. Eine solche Analyse des Codes findet dabei automatisiert statt. Christof Ebert, Reiner Dumke, Manfred Bundschuh und Andreas Schmietendorf stellen ebenfalls den Vergleich mit einem Compiler an. In ihrem Buch \cite{BPSoftwareMeasurement} erwähnen sie zusätzlich noch ein Qualitätsmodell, das mit dem Analyseergebnis in Verbindung gebracht wird und so eine einfache Interpretierbarkeit des analysierten Systems ermöglicht. Zusätzlich beschreiben sie den Vorgang als Sammeln von Metriken und deren Bewertung anhand von Kriterien.
\paragraph{}
Nadine Vehring beschreibt eine \textit{Metrik} in ihrer Ausarbeitung \cite{TestabilityMetrics} als Maß dafür, wie sehr eine \textit{Entität} ein \textit{Attribut} erfüllt. Als \textit{Entität} bezeichnet Vehring einen Teil des analysierten Systems, also beispielsweise eine Methode, Klasse oder eine Menge von Klassen. Weiterhin beschreibt sie ein \textit{Attribut} als Eigenschaft, die im betrachteten System, also bei den \textit{Entitäten} gemessen werden soll. In dieser Thesis wird der Metrik-Begriff wie folgt differenziert.
\begin{description}
\item[Metrik] ist der Begriff für eine bestimmte und tatsächlich gemessene Eigenschaft die Methoden, Klassen, Paketen oder Mengen von Klassen im zu analysierenden System besitzen. Er entspricht damit dem direkten Ergebnis einer statischen Code-Analyse. Dieser Begriff wird manchmal Synonym für die Eigenschaft verwendet, die gemessen werden soll.
\item[Statistik der Metrik] ist die Bezeichnung für die zusammengefassten Werte aller Komponenten im System, für die eine bestimmte Metrik ausgerechnet werden kann. Zusätzlich können Metriken vor und nach der Aggregation gewichtet und bewertet werden. Ob ein Wert in einer Statistik berücksichtigt wird kann ebenfalls festgelegt werden. Marc Philipp und Nicole Rauch unterscheiden Metrik und Statistik in ihrem Artikel \cite{EclipseMagUsus} ebenfalls.
\end{description}
Die Metriken eines Systems können auch manuell bestimmt werden. In dieser Master-Thesis werden Metriken aber immer als automatisiert bestimmbar und damit als Ergebnis einer automatisierten statischen Code-Analyse betrachtet. Das Konzept der statische Code-Analyse kann auch genutzt werden, um subjektive explizite Probleme im Code zu lokalisieren, wie beispielsweise die Verwendung von obsoleten Klassen und Methoden, sowie fehlende Klassenkommentare. In dieser Master-Thesis wird die statische Code-Analyse ausschließlich für die Bestimmung der Metriken genutzt.




\chapter{Anforderungen}
\label{chap:requirements}
In diesem Kapitel werden die Anforderungen an die Visual Studio Erweiterung zur statischen Code-Anaylse beschrieben, die im Rahmen dieser Master-Thesis entwickelt werden soll. Dabei werden die Anforderungen in einem agilen Kontext bestimmt und in Form von Sprint 0 wie in Scrum\footnote[1]{\url{http://www.pmscrum.com/blog/2011/06/10-things-do-sprint-0}} definiert. Dieses Kapitel gibt damit eine Antwort auf die Frage, was gemacht werden soll.


\section{Interessenvertreter}
\label{sec:stakeholder}
Die Interessenvertreter (engl. \textit{Stakeholder}) im Kontext dieser Master-Thesis sind Gruppen von Personen, die einen Einfluss auf Anforderungen des Systems haben können. Die folgenden vier Gruppen wurden dafür identifiziert.
\begin{description}
\item[andrena objects ag] als Arbeitgeber stellt das Umfeld dar, indem das Projekt durchgeführt und das System implementiert wird. Sie legt Wert auf agile Softwareentwicklung und möchte Entwicklungsprozesse und Praktiken gewinnbringend einsetzen. Die andrena objects ag hat bereits ein Plugin zur statischen Code-Analyse für Java und Eclipse entwickelt und möchte ihren Entwicklern ein ähnliches Programm auch für die .NET-Umgebung zur Verfügung stellen können.
\item[Leser dieser Thesis] haben ebenfalls ein Interesse an dem zu entwickelnden Produkt, das hauptsächlich theoretischer Natur ist. Sie haben einen Informatik-artigen Hintergrund und möchten einen Einblick in die Algorithmen und die Implementierungsdetails sämtlicher implementierten Aspekte des Systems erhalten.
\item[.NET-Entwickler mit wenig Erfahrung] arbeiten an kleineren Codebasen und wollen auf einfache Weise einen Überblick über Problemfälle des Systems behalten. Mithilfe des Systems wollen sie diese rechtzeitig beseitigen und sicherstellen, dass dadurch keine neuen Probleme entstehen.
\item[.NET-Entwickler mit viel Erfahrung] arbeiten an großen und komplizierten Codebasen und möchten das System einsetzen um Tendenzen im System zu erkennen und Spezialfälle zu analysieren. Auch sie wollen einen besseren Überblick erhalten und das System aus möglichst vielen verschiedenen Perspektiven sehen.
\item[.NET-Entwickler (Clean Coder)] legen sehr viel Wert auf Quellcode, der möglichst einfach zu verstehen ist und damit schnell an neue Anforderungen angepasst werden kann. Sie erwarten von dem System Feedback und Unterstützung bei der Entwicklung von sauberem Code. Außerdem möchten sie auf Stellen im Code hingewiesen werden, die nicht ihren Vorstellungen entsprechen.
\end{description}
Die Beschreibungen der Interessengruppen sind grob und allgemein gehalten, während versucht wurde, die direkten Bedürfnisse der jeweiligen Gruppe zu benennen. Natürlich ist die Erklärung damit nicht vollständig oder exklusiv. So kann beispielsweise auch ein erfahrener .NET-Entwickler ein Interesse an Clean Code haben.


\section{Ziele}
\label{sec:goals}
Nachdem die beteiligten Interessengruppen definiert wurden, werden in diesem Abschnitt die Ziele des zu entwickelnden Systems beschrieben. Peter Hruschka und Chris Rupp erklären in ihrem Buch \cite{AgileSEUML} ein Ziel als "`ein erstrebenswerter Zustand"' in der Zukunft, den es zu erreichen gilt. Damit ist ein Ziel eine abstrakte Form einer Anforderung an das System, die sich auch in einem agilen Projekt nicht so schnell ändert wie spezielle Anforderungen.

\subsection{Einsicht in die Codebasis}
Große Entwicklungsprojekte haben eine große Codebasis, die es den Entwicklern erschwert Aussagen über den Quellcode des Systems zu machen. Mithilfe statischer Code-Analyse kann eine Einsicht in diesen Quellcode gewährleistet und so zum Vorteil aller Interessenvertreter genutzt werden. Eigenschaften des Quellcodes werden als können als Metriken berechnet und bewertet werden. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Eigenschaften des Codes erkennen und darauf reagieren kann.

\subsection{Erkennen von Problemfällen}
In einer vorhandenen Codebasis besteht die Gefahr, den Überblick über Problemfälle zu verlieren. Ein Problem kann beispielsweise eine Klasse sein, die zu viele Abhängigkeiten zu anderen Klassen hat, oder eine Methode, die zu viel Funktionalität besitzt. Das Erkennen und Anzeigen dieser Stellen ist ein Vorteil, von dem alle Interessenvertreter profitieren können, und der es ermöglicht, Schwachstellen systematisch zu entfernen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Probleme im Code erkennen und darauf reagieren kann.

\subsection{Förderung von Clean Code}
Das Entwickeln von Code kann auf eine sehr rücksichtslose Art und Weise geschehen, sodass spätere Anpassungen nur schwer vorzunehmen sind. Durch Feedback und Unterstützung während der Programmierung kann die Entwicklung von Clean Code gefördert werden, was zu einer Codebasis führt, die flexibler auf Anpassungen reagieren kann. Dieses Ziel ist erreicht, sobald ein Entwickler mehr Clean Code Praktiken beachtet und einhält, als er dies ohne Unterstützung des Systems getan hätte.

\subsection{Interpretation der Software-Qualität}
Eine bestehende Codebasis zu bewerten erfordert detaillierte Kenntnis über alle Klassen, deren Interaktionen und vielem mehr. Außerdem muss eine menschliche Bewertung manuell jedes mal neu erfolgen, ist subjektiv und fehleranfällig. Eine teilweise automatisierte Interpretation anhand von Regeln und Gewichtungen, die auf Erfahrungen basieren, kann die menschliche Bewertung optimieren und einem Entwickler jederzeit mit verhältnismäßig geringem Aufwand eine Qualitätsinterpretation ermöglichen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, die Qualität des Quellcodes durch Interpretation einschätzen und mit anderen Systemen vergleichen kann.


\section{Architektur}
In diesem Abschnitt wird die grundlegende Architektur des zu entwickelnden Systems erläutert. Im Rahmen dieser Master-Thesis soll ein System entwickelt werden, dass die in Abschnitt \ref{sec:goals} genannten Ziele erreicht. Zusätzlich soll dieses System als Erweiterung in Visual Studio laufen und den Quelltext (kompiliert und/oder unkompiliert) in einer .NET-Sprache, wie beispielsweise C\#, analysieren. Abbildung \ref{fig:architecture} zeigt die beiden Komponenten \textit{Visualisierung} und \textit{statische Code-Analyse}, um die es sich im weiteren Verlauf handeln wird.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/architektur.jpg}
	\caption{Grobe Architektur des Systems}
	\label{fig:architecture}
\end{figure}
Die Komponente, die die statische Code-Analyse durchführt, verwendet drei Aktionen, die einem kompletten Analyse-Prozess entsprechen. Die schwarzen Pfeile symbolisieren dabei Zugriffe auf Daten. Die Aktion \textit{Berechnung} betrachtet das Softwaresystem und kann dafür auf den Quellcode und das erzeugte Kompilat zugreifen. Das Ergebnis dieser Betrachtung wird in Form von Metriken in einer Datenbank gespeichert und stellt Daten für die Aktion \textit{Gewichtung} bereit. Diese gewichtet die Daten und erzeugt Statistiken, die ebenfalls in der Datenbank hinterlegt werden. Die Aktion \textit{Bewertung} versucht anhand der gewichteten Daten eine Aussage über die Qualität des Softwaresystems zu treffen. Nachdem diese drei Aktionen abgelaufen sind, ist der Analyse-Prozess beendet. Die Komponente \textit{Visualisierung}, die in Visual Studio ausgeführt wird, kann diesen Analyse-Prozess starten und auf dessen Daten zugreifen. Sie zeigt die berechneten Metriken in geeigneten Kontexten an und gibt basierend auf der Bewertung ein entsprechendes Entwickler-Feedback. Dieses Feedback entsteht dabei genau dort, wo der Quellcode entstanden ist, der von dem Analyse-Prozess verarbeitet wurde. Nach einer entsprechenden Veränderung des Quelltext kann der Prozess erneut gestartet werden, um auch diese Veränderung zu analysieren. So entsteht theoretisch ein kontinuierlicher Verbesserungskreislauf. Dieser Zyklus wird durch die breiten transparenten Pfeile angezeigt und entspricht dem Informationsfluss in dieser Umgebung.


\section{Use Cases}
Aus den in Abschnitt \ref{sec:goals} definierten Zielen dieses Projekts lassen sich zunächst vier Anwendungsfälle bestimmen, die in Abbildung \ref{fig:usecases} dargestellt sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/usecases.jpg}
	\caption{Anwendungsfälle des Systems}
	\label{fig:usecases}
\end{figure}
Die Akteure entsprechen ungefähr den in Abschnitt \ref{sec:stakeholder} definierten Interessenvertretern. Der Akteur \textit{.NET-Entwickler} entspricht dem Interessenvertreter mit wenig .NET Erfahrung und dessen Interaktionen mit dem System werden von dem Entwickler mit viel Erfahrung, beziehungsweise Clean Code Interessen, erweitert. Die Interessenvertreter \textit{andrena objects ag} und \textit{Leser des Thesis} haben keine direkte Interaktion mit dem System und werden bei der Betrachtung der Use Cases ignoriert. Es ist ebenfalls zu sehen, dass der Anwendungsfall \textit{Code-Metriken bestimmen} alle anderen Anwendungsfälle direkt oder indirekt ergänzt. Damit ist er ein entscheidender Bestandteil des Systems, wenn nicht sogar der wichtigste.


\section{Produkt-Backlog}
\label{sec:productbacklog}
Die Anwendungsfälle lassen sich in User Stories (\textit{Anwendererzählungen}) unterteilen. Abbildung \ref{fig:productbacklog} zeit diese Aufteilung in der horizontalen und die Verteilung auf geplante Sprints in der vertikalen Dimension. Dieses zwei-dimensionale Backlog stellt die konkreten Anforderungen aus Benutzersicht an das komplette System dar.
\begin{figure}[h]
	\centering
		\includegraphics[width=17cm]{images/backlog.jpg}
	\caption{Produkt-Backlog des Systems}
	\label{fig:productbacklog}
\end{figure}
Die User Stories sind allgemein gehalten, da auf ein großes Design vor der Implementierung aus Agilitätsgründen verzichtet wurde. Pro Sprint werden die User Stories dann in konkrete Entwicklungs-Aufgaben unterteilt. Die Begründung jeder Story wurde nicht explizit aufgeschrieben, da die Beziehung zu den Use Cases und damit den Zielen aus Abschnitt \ref{sec:goals} erhalten und somit offensichtlich geblieben ist. Eine Priorisierung ist ebenfalls implizit durch das Aufteilen auf die Sprints entstanden, sodass eine explizite Business Value Analyse nicht notwendig ist. Da die Entwicklungsgeschwindigkeit noch nicht bekannt ist, ist die Sprint-Planung vorläufig. Eine Änderung kann also jederzeit erfolgen, wenn neue Use Cases und User Stories dazukommen, andere wegfallen oder nicht alle in einem Sprint geschafft werden. Zum Zeitpunkt dieser Planung lassen sich die bereits gefunden User Stories in schätzungswiese fünf Sprints implementieren. 
\paragraph{}
Was die Abnahmekriterien jeder Anwendererzählung betrifft, so wurde auch hier kein Mehrwert in der expliziten Definition gesehen. Pro Story kann ohne viel Aufwand ein exemplarischer manueller Akzeptanztest durchgeführt werden, der zeigt, ob das Ziel erreicht wurde. Zusätzlich können automatisierte Akzeptanztests zu Beginn des jeweiligen Sprints festgelegt werden.




\chapter{Vorgehensweise}
Nach dem die Anforderungen an das System, das in dieser Masther-Thesis entwickelt werden soll, in Kapitel \ref{chap:requirements} definiert wurden, wird in diesem Kapitel die grobe Vorgehensweise beschrieben. Dabei wird eine grobe Zeitplanung vorgestellt. Dieses Kapitel gibt damit eine Antwort auf die Frage, wie die Anforderungen realisiert werden sollen. Abbildung \ref{fig:plan_table} zeigt die zeitliche Aufteilung der Master-Thesis, während Abbildung \ref{fig:plan_gantt} das dazugehörige Gant-Chart darstellt. Die Thesis besteht aus einem praktischen und einen theoretischen Teil. Beide Teile überlagern sich, sodass eine Dokumentation der Implementierung zeitnah erfolgen kann und keine große Schreibphase gegen Ende des sechsmonatigen Zeitrahmen notwendig ist.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planningTable.png}
	\caption{Projektplan Tabelle}
	\label{fig:plan_table}
\end{figure}
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planningGantt.png}
	\caption{Projektplan Gantt-Chart}
	\label{fig:plan_gantt}
\end{figure}


\section{Praktischer Teil}
Der praktische Teil besteht aus einer Evaluationsphase und der eigentlichen Implementierungsphase. Während der Evaluierung werden verschiedene Technologien betrachtet, mit denen eine statische Code-Analyse durchgeführt werden kann. Das Ergebnis der Evaluierung wird die Grundlage der nächsten Phase darstellen. In der zweiten Phase werden die User Stories aus Abschnitt \ref{sec:productbacklog} im Rahmen der Visual Studio-Erweiterung zur statischen Code-Analyse in fünf zweiwöchigen (10 Tage) Sprints implementiert.


\section{Theoretischer Teil}
Der theoretische Teil entspricht hauptsächlich der Dokumentation aller Ergebnisse und deren Beschreibung in Form der schriftlichen Ausarbeitung dieser Master-Thesis. So werden in einer Planungsphase zunächst Grundlagen (Kapitel \ref{chap:basics}) beschrieben, sowie eine agile Anforderungsanalyse (Kapitel \ref{chap:requirements}) durchgeführt. Außerdem wird das Usus-Programm, dessen Funktionsumfang einen maßgeblichen Einfluss auf das zu entwickelnde System haben soll, näher betrachtet und dessen Metriken beschrieben (Kapitel \ref{chap:usus}). Anschließend soll das Ergebnis der Evaluierungsphase beschrieben werden (Kapitel \ref{chap:techeval}), bevor die tatsächlichen Sprints in Form von zwei-tägigen schriftlichen Zusammenfassungen abgeschlossen werden. Nach der Zusammenfassung des  vierten Sprints soll eine Fallstudio auf Basis eines andrena Kurs zum Thema Refactoring durchgeführt werden. Bei diesem Kurs soll das in dem praktischen Teil zu entwickelnde System eingesetzt und ermittelt werden, wie gut das Werkzeug einen Entwickler unterstützen kann. Unmittelbar vor dem fünften und vorläufig letzten Sprint soll eine Analyse von statischen Verteilungen der Metrik-Werte sowie deren Bedeutung erfolgen. Aufgrund dieser Verteilungen soll geprüft und beschrieben werden, ob und wenn ja, wie eine Aussage über den andrena Software Quality Index (SQI) anhand der Metriken möglich ist.




\chapter{Usus}
\label{chap:usus}
Das Wort \textit{usus} kommt aus dem lateinischen und bedeutet "`das, was üblich ist"'. In diesem Kapitel wird das Usus-Plugin für die Java Entwicklungsumgebung Eclipse \cite{UsusEclipsePlugin} vorgestellt, sowie auf die Metriken, die es berechnet, eingegangen. Usus entspricht im Groben dem Werkzeug für Eclipse und Java, das im Rahmen dieser Master-Thesis auch für Visual Studio und .NET entwickelt werden soll. Aus diesem Grund wird dessen Funktionsumfang an dieser Stelle betrachtet um ihn besser in nachimplementieren zu können. Eine direkte Portierung ist anhand der Technologieunterschiede von Visual Studio und Eclipse, sowie .NET und Java wahrscheinlich nicht möglich, sodass diese Option hier nicht in weiter verfolgt wird.


\section{Eclipse Plugin}
Das Usus-Plugin für Eclipse lässt sich über den Menü-Eintrag \texttt{Help / Install New Software} installieren, indem eine neue Software Site mit der Url \url{http://projectusus.googlecode.com/svn/updates/} hinzugefügt und anschließend \emph{Project Usus} ausgewählt wird. Nach der Installation steht die \emph{Project Usus perspective} zur Verfügung, die die folgenden Fenster enthält.

\subsection{Usus Cockpit}
In diesem Fenster werden die Usus Metriken angezeigt, die für alle Projekte, die Usus betrachtet, gelten. Zusätzlich wird der Trend pro Metrik dargestellt, also ob sich die Ausprägung der Metrik verbessert oder verschlechtert hat. Die Verbesserung wird dabei zwischen zwei erstellten Snapshots gemessen, die entweder manuell oder durch einen neuen Speichervorgang ausgelöst werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_cockpit.png}
	\caption{Usus Cockpit zeigt Übersicht über alle Projekte}
	\label{fig:usus_cockpit}
\end{figure}
Die in Abbildung \ref{fig:usus_cockpit} dargestellten Statistiken der Metriken errechnen sich aus der Aggregation der Paket-, Klassen- oder Methoden-Eigenschaften.

\subsection{Usus Info}
Dieses Fenster lässt sich im Kontext einer Methode oder einer Klasse öffnen und zeigt Metriken, die anhand der Eigenschaften des Kontextes ermittelt werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_info.png}
	\caption{Usus Info zeigt Übersicht über eine Methode oder Klasse}
	\label{fig:usus_info}
\end{figure}
Das in Abbildung \ref{fig:usus_info} gezeigte Info-Fenster lässt sich mit \texttt{Ctrl-U} öffnen und mit \texttt{Esc} wieder schließen.

\subsection{Usus Hotspots}
\label{subsec:usushotspots}
Dieses Fenster zeigt sogenannte Hotspots, also Stellen im Quellcode, dessen Metriken definierte Grenze oder einen Schwellwert überschreiten. Hotspots lassen sich für jede Metrik definieren, die im Usus Cockpit angezeigt wird. Zusätzlich wird der Trend pro Hotspot gezeigt, also ob sich der Hotspot verbessert oder verschlechtert.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_hotspots.png}
	\caption{Usus Hotspots zeigt die Stellen im Code, die eine besondere Metrikausprägung haben}
	\label{fig:usus_hotspots}
\end{figure}
Das in Abbildung \ref{fig:usus_hotspots} gezeigte Hotspot-Fenster zeigt Hotspots immer nur für eine Metrik an. Der Wechsel zu einer anderen Hotspot-Metrik erfolgt über einen Doppelklick auf die Metrikanzeige im Usus Cockpit. Über einen Doppelklick auf einen Hotspot lässt sich entweder zu der dazugehörigen Methode im Quelltext oder dem entsprechende Paket oder der Klasse in einem der beiden Usus Graph Ansichten navigieren.

\subsection{Usus Histogram}
Dieses Fenster zeigt die absolute Häufigkeitsverteilung der Ausprägungen einer Metrik über alle Projekte an, die Usus betrachtet. Die verwendete Metrik wird dabei auf der der x-Achse angezeigt, während die Anzahl der Ausprägungen auf der y-Achse dargestellt wird. Die Verteilung lässt sich für eine der Metriken definieren, die im Usus Cockpit angezeigt werden.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_histogram.png}
	\caption{Usus Histogram zeigt die statistische Verteilung der Ausprägungen der definierten Metrik}
	\label{fig:usus_histogram}
\end{figure}
Das in Abbildung \ref{fig:usus_histogram} gezeigte Histogramm-Fenster zeigt die Verteilung der Metrik an, die zuvor über einen Einfachklick im Usus Cockpit markiert wurde. Es zeigt immer nur die Daten für eine Metrik an. Die Ansicht kann vergrößert, verkleinert, skaliert und als Grafik gespeichert werden.

\subsection{Usus Class Graph \& Usus Package Graph}
\label{subsec:ususgraphs}
Dieses Fenster zeigt die Abhängigkeiten der betrachteten Projekte entweder auf Klassenebene oder auf Paketebene an. Auf Paketebene lassen sich optional nur die Pakete anzeigen, die sich in einem Zyklus von Abhängigkeiten zu anderen Paketen befinden. Auf Klassenebene lassen sich optional nur die Klassen anzeigen, die über eine Abhängigkeit über Paketgrenzen hinweg verfügen. Dabei werden auch nur eben diese Paketübergreifenden Abhängigkeiten angezeigt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_graph.png}
	\caption{Usus Graph Schaubilder zeigen die Abhängigkeiten der Klassen oder Pakete voneinander an}
	\label{fig:usus_graph}
\end{figure}
Das in Abbildung \ref{fig:usus_graph} dargestellte Fenster besteht aus zwei Karteikarten. Eine Karteikarte zeigt den Usus Class Graph, während die andere den Usus Package Graph darstellt. Zwischen den beiden Ansichten kann beliebig gewechselt werden. Die Knoten in den Graphen lassen sich mit der Maus frei positionieren. Zusätzlich lassen sich die Graphen-Darstellungen auch automatisch anordnen.


\section{Metriken}
In den Fenstern Usus Cockpit und Usus Info zeit das Eclipse Plugin die Werte verschiedener Metriken an. Das Usus Info Fenster zeigt im Kontext einer Methode neben den Metriken, die es zusätzlich für die Klasse anzeigt auch Methoden-Metriken. In diesem Abschnitt wird daher zuerst auf die Metriken eingegangen, die das Usus-Plugin für Methoden berechnet, bevor die Klassen-Metriken näher betrachtet werden. Abschließend werden die Usus Cockpit Metriken beschrieben.

\subsection{Pro Methode}
Wenn das Usus Info Fenster im Kontext einer Methode geöffnet wird, wird die zyklomatische Komplexität sowie die Länge der Methode dargestellt.
\subsubsection{Zyklomatische Komplexität}
\label{subsubsec:cyclomaticcomplexity}
Die Metrik \textit{Cyclomatic Complexity} wurde von Thomas J. McCabe vorgestellt \cite{AComplexityMeasure} um Methoden anhand von linear unabhängigen Ablaufpfaden in Bezug auf Komplexität zu bewerten. McCabe bezieht sich in seinem Artikel auf die Graphentheorie und errechnet die Komplexität eines Ablaufgraphen wie folgt.
\begin{equation}
v(G) = e - n + 2p
\label{eq:cyclomaticcomplexity1}
\end{equation}
\begin{eqnarray*}
G&=&\text{Ablaufgraph}\\
v(G)&=&\text{zyklomatische Komplexität von $G$}\\
e&=&\text{Anzahl Kanten im Ablaufgraphen $G$}\\
n&=&\text{Anzahl Knoten im Ablaufgraphen $G$}\\
p&=&\text{Anzahl Zusammenhangskomponenten in $G$}\\
\label{eq:cyclomaticcomplexity1agenda}
\end{eqnarray*}
Ernest Wallmüller beschreibt die zyklomatische Komplexität in seinem Buch \cite{SoftwareQMPraxis} auch als Anzahl aller entscheidungstreffenden Stellen in der Methode. Im Falle einer Verkettung von binären Entscheidungen zu logischen Ausdrücken zählt jede Entscheidung als eine solche Stelle. Diese einfachere Rechnung ergibt sich als
\begin{equation}
	v(G) = 1 + \Big( \sum_{\displaystyle b \in Bs(G)} 1 \Big)
\label{eq:cyclomaticcomplexity2}
\end{equation}
wobei $Bs(G)$ die Menge aller binären Entscheidungen im Ablaufgraphen $G$ darstellt. Voraussetzung für diese Rechnung ist, das die Methode nur einen Eingang und nur einen Ausgang besitzt. Der Quellcode in Listing \ref{listing:simpleifs} soll die Grundlage für eine demonstrative Berechnung der zyklomatischen Komplexität darstellen.
\begin{lstlisting}[caption={Einfache if-Verschachtelung},label={listing:simpleifs}]
public void doSomething() {
   if (condition1) {
      if (condition2 || condition3)
         do1();
   }
}
\end{lstlisting}
Nach Formel \ref{eq:cyclomaticcomplexity2} ergeben sich drei Entscheidungsstellen, welche durch die drei binären Bedingungen dargestellt werden. Die zyklomatische Komplexität entspricht damit \begin{math}v(G) = 1 + 3 = 4\end{math}.
\begin{figure}[h]
	\centering
		\includegraphics[width=9cm]{images/cc.jpg}
	\caption{Ablaufgraph G des Quellcodes \ref{listing:simpleifs}}
	\label{fig:ccsamplegraph}
\end{figure}
Die Berechnung anhand Formel \ref{eq:cyclomaticcomplexity1} basiert auf der Struktur des Ablaufgraphen, der in Abbildung \ref{fig:ccsamplegraph} dargestellt ist. Hier entspricht die zyklomatische Komplexität \begin{math}v(G) = 10 - 8 + 2 * 1 = 4\end{math}. Die Ergebnisse beider Rechnungen sind identisch. Die Eigenschaften einer Methode, die für die Berechnung der \textit{Cyclomatic Complexity}-Metrik erforderlich sind, sind also entweder die Anzahl der binären Entscheidungen oder der vollständige Ablaufgraph.
\subsubsection{Methodenlänge}
\label{subsubsec:methodlength}
Die Länge einer Methode kann auf unterschiedliche Weise ermittelt werden. Eine Unterscheidung der Möglichkeiten wird von Mark Lorenz und Jeff Kidds in \cite{OOSMetrics} vorgenommen.
\begin{description}
\item[Anzahl Code-Zeilen] (engl. Lines of code) entspricht der tatsächlichen Anzahl an Zeilenumbrüchen ohne leere Zeilen und Kommentarzeilen. Diese Längenangabe ist stark vom Entwicklerstil abhängig und kann sich daher unterschiedlich ausprägen, je nachdem wie beispielsweise eine Parameterliste umgebrochen wird.
\item[Anzahl der Anweisungen] (engl. Number of statements) entspricht nach Lorenz und Kidds einer stabileren Längenangabe. Eine Anweisung ist jeder durch ein Semikolon abgeschlossene Ausdruck sowie Bedingungs- und Wiederholungsanweisungen.
\end{description} 
Die im Usus Info Fenster angezeigte Methodenlänge entspricht der Anzahl der Anweisungen der Methode. Eine Berechnung kann daher über die Aufsummierung der Semikola und der if-, switch-, for-, while- und try-catch-Anweisungen erfolgen.

\subsection{Pro Klasse}
\label{subsec:perclass}
Wenn das Usus Info Fenster im Kontext einer Klasse geöffnet wird, wird die Klassengröße sowie die kumulierte Komponentenabhängigkeit der Klasse dargestellt.
\subsubsection{Klassengröße}
\label{subsubsec:classsize}
Ähnlich der Methodenlänge lässt sich auch die Größe einer Klasse auf verschiedene Weise berechnen. Lorenz und Jeff unterscheiden auch hier mehrere Möglichkeiten \cite{OOSMetrics}.
\begin{description}
\item[Anzahl der Methoden] erlaubt es Klassen zu erkennen, die zu viel oder zu wenig Funktionen erfüllen. Weitere Unterscheidungsmöglichkeiten sind Methoden in Klassen- und Instanz-Methoden aufzuteilen oder Methoden anhand der Sichtbarkeit zu klassifizieren. Ein Konstruktor würde sich wie eine statische Methode, also eine Klassen-Methode, verhalten.
\item[Anzahl der Felder] erlaubt es Klassen zu erkennen, die zu viel Informationen verwalten. Auch hier ist eine weitere Unterteilung in Klassen- und Instanz-Felder möglich. Die Sichtbarkeit der Felder erlaubt eine weitere Einschränkung.
\end{description} 
Das Usus Info Fenster zeigt als Klassengröße die Anzahl der Instanz-Methoden, der Klassen-Methoden sowie der Konstruktoren an. Dabei wird die Sichtbarkeit der Methode oder des Konstruktors nicht berücksichtigt. Das Usus-Plugin fokussiert damit auf die Funktion der Klassen und nicht auf die Information und das Wissen einer Klasse, welches in den Feldern liegt. Die Klassengröße kann also berechnet werden, wenn alle Methoden und Konstruktoren einer Klasse ermittelt werden können.
\subsubsection{Kumulierte Komponentenabhängigkeit}
\label{subsubsec:ccd}
Die Metrik \textit{Cumulative Component Dependency} ist laut Peter Grogono \cite{SoftwareQControl} eine Metrik, die für Systeme und Untersysteme ermittelt wird. Dabei werden für jede Klasse (Komponente) in diesem System die Anzahl der Klassen ermittelt, von denen die betrachtete Klasse direkt und indirekt abhängt. Eine Klasse ist immer auch von sich selber abhängig. Marc Philipp und Nicole Rauch bezeichnen diese Abhängigkeiten in ihrem Artikel \cite{EclipseMagUsus} als reflexsiv und transitiv. Anschließend werden die Abhängigkeiten aller betrachteten Klassen aufsummiert und ergeben den CCD-Wert des Systems. In dem Usus Info Fenster wird der Abhängigkeitswert einer betrachteten Klasse als \textit{CCD (of class)} bezeichnet. Um die Anzahl der Klassen zu bestimmen, von denen eine betrachtete Klasse abhängig ist, ist mindestens der vollständige Abhängigkeitsgraph der Klasse erforderlich. Mit einem Durchmusterungsalgorithmus kann die Erreichbarkeitsmenge (Reach-Menge) der Klasse (Startknoten) in diesem Abhängigkeitsgraph ermittelt werden. Heiko Körner beschreibt in seinem Skript \cite{GraphAlgorithms} die beiden Algorithmen \textit{BFS} (Breadth First Search) und \textit{DFS} (Depth First Search) für diesen Zweck.
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/ccd.jpg}
	\caption{Abhängigkeitsgraph einer Klasse mit aufsummierten Abhängigkeiten}
	\label{fig:ccd}
\end{figure}
Abbildung \ref{fig:ccd} zeigt sieben Klassen, die in einer hierarchischen Abhängigkeitsstruktur stehen. Offensichtlich ist Klasse A von allen anderen Klassen abhängig und hat damit den CCD-Wert sieben. Dies entspricht der Kardinalität der Reach-Menge von A, \begin{math}\{A,B,C,D,E,F,G\}\end{math}, die ermittelt wird, indem BFS oder DFS mit Klasse A als Startknoten im Abhängigkeitsgraph gestartet wird. Dabei werden die durch den Algorithmus markierten Knoten als Ergebnis des Algorithmus behandelt. Bei dem Abhängigkeitsgraph muss es sich nicht um einen Baum handeln.
\begin{equation}
	ccd(c) = | DFS(dG, c) |
\label{eq:cumulativecomponentdependencyofclass}
\end{equation}
\begin{eqnarray*}
dG&=&\text{Abhängigkeitsgraph des Systems}\\
c&=&\text{Klasse im System}\in dG\\
ccd(c)&=&\text{CCD-Wert der Klasse } c\\
\label{eq:cumulativecomponentdependencyofclassagenda}
\end{eqnarray*}
Formel \ref{eq:cumulativecomponentdependencyofclass} zeigt die Berechnungsvorschrift unter Verwendung des \textit{DFS}-Algorithmus. Die Berechnung des CCD-Werts einer Klasse kann also durchgeführt werden, sobald ein Abhängigkeitsgraph erzeugt werden kann. Um einen solchen Graphen zu erzeugen müssen die direkten Abhängigkeiten einer Klasse ermittelt werden können. Jede Klasse wird dann einem Knoten zugeordnet und jede Abhängigkeit einer gerichteten Kante. Eine grafische Darstellung (siehe Unterabschnitt \ref{subsec:ususgraphs}) ist dann ebenfalls möglich. Die direkten Abhängigkeiten einer Klasse können bestimmt werden, wenn die Typen aller Felder, Methodenparameter, Oberklasse und Interfaces sowie sämtlicher Methodenaufrufe entfernter Klassen identifiziert werden können. Abhängigkeiten zu Klassen, wie beispielsweise \texttt{String} oder \texttt{Object}, die im Basis-Framework definiert sind, können ignoriert werden.

\subsection{Projektübergreifend}
Neben den Metriken, die Usus für Methoden und Klassen berechnet, werden im Usus Cockpit Statistiken zu der Codebasis angezeigt. Dafür werden die ermittelten Metriken bewertet, wie es Marc Philipp und Nicole Rauch in ihrem Artikel \cite{EclipseMagUsus} beschreiben. In diesem Unterabschnitt werden die verscheiden Statistiken vorgestellt und auf ihre Bewertung eingegangen. Weiterhin werden die Schwellwerte der Statistiken definiert, anhand derer eine Klasse, Methode oder Paket als Hotspot (siehe Unter-Unterabschnitt \ref{subsec:usushotspots}) eingestuft wird.
\subsubsection{Durchschnittliche kumulierte Komponentenabhängigkeit}
Die Metrik \textit{Average Component Dependency} ist laut Peter Grogono \cite{SoftwareQControl} wie \textit{Cumulative Component Dependency} eine Metrik, die für Systeme und Untersysteme ermittelt wird. Dabei wird der Mittelwert des CCD-Werts des Systems wie in Formel \ref{eq:averagecomponentdependency1} berechnet, wobei $n$ die Anzahl der Klassen im System ist.
\begin{equation}
	acd = \frac{ccd}{n}
\label{eq:averagecomponentdependency1}
\end{equation}
Da Usus die CCD-Werte nicht für Systeme oder Untersysteme ermittelt, sondern die CCD-Werte der Klassen bestimmt ohne sie aufzusummieren (siehe Unter-Unterabschnitt \ref{subsubsec:ccd}), kann der ACD-Wert anhand einer Menge von Klassen $Cs$ berechnet werden, wie in Formel \ref{eq:averagecomponentdependency2} dargestellt. Die Rechnung ist äquivalent zu Formel \ref{eq:averagecomponentdependency1}.
\begin{equation}
	acd(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} ccd(C)}{|Cs|}
\label{eq:averagecomponentdependency2}
\end{equation}
Peter Grogono beschreibt die Bedeutung des ACD-Werts als durchschnittliche Anzahl an Komponenten, die durch eine Änderung einer Komponente betroffen sind und eventuell ebenfalls geändert werden müssen. Der ACD-Wert wird im Usus Cockpit als Statistik in Prozent angezeigt. Dazu wird nochmal der Mittelwert über die betrachteten Klassen gebildet, wie in Formel \ref{eq:averagecomponentdependency3} zu sehen ist und der Bewertungsfunktion von Philipp und Rauch entspricht.
\begin{equation}
	acd'(Cs) = \frac{acd(Cs)}{|Cs|}
\label{eq:averagecomponentdependency3}
\end{equation}
Eine Klasse wird von Usus dann als Hotspot betrachtet, wenn ihr CCD-Wert über einer Schwelle liegt, die von der Projektgröße abhängig ist. Die Projektgröße wird dabei an der Anzahl der Klassen festgelegt. Anhand der Tooltip-Erklärung im Usus Cockpit liegt diese Schwelle für kleine Projekte bei 15\% der Klassenanzahl, während bei großen Projekten 5\% der Klassenanzahl verwendet wird. Dafür haben Philipp und Rauch Formel \ref{eq:averagecomponentdependency4} mithilfe von Erfahrungswerten definiert um die Berechnung des CCD-Schwellwert $L_{ccd}$ anhand der Menge aller Klassen $Cs$ im System durchführen zu können.
\begin{equation}
	L_{ccd}(Cs) = \frac{1,5}{2^{\displaystyle (\log_{5} |Cs|)}}
\label{eq:averagecomponentdependency4}
\end{equation}
\subsubsection{Durchschnittliche Klassengröße}
Eine Klasse wird von Usus als Hotspot gesehen, sobald die in Unter-Unterabschnitt \ref{subsubsec:classsize} beschriebene Klassengröße den Schwellwert 12 übersteigt. Das haben Philipp und Rauch festgelegt. Die im Usus Cockpit angezeigte durchschnittliche Klassengröße betrachtet nur die Klassen, die bereits als Hotspot markiert wurden. Das liegt an der Bewertungsfunktion $rating_{cs}$ von Philipp und Rauch, die in Formel \ref{eq:averageclasssize1} angegeben ist.
\begin{equation}
	rating_{cs}(cs) = 
	\begin{cases}
		\displaystyle	\frac{1}{12 * cs} - 1, & \text{wenn }cs > 12\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averageclasssize1}
\end{equation}
Die Bewertungsfunktion der Klassengröße $cs$ ist direkt von dem Schwellwert 12 abhängig und bewertet alle Klassen, dessen Größe 12 oder weniger beträgt mit 0. Um die durchschnittliche Klassengröße $acs$ einer Menge von Klassen $Cs$ zu berechnen, bildet Usus den Mittelwert aller bewerteter Klassengrößen. Dazu wird die Formel \ref{eq:averageclasssize2} verwendet.
\begin{equation}
	acs(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} rating_{cs}(c)}{|Cs|}
\label{eq:averageclasssize2}
\end{equation}
Dabei gehen die mit 0 bewerteten Klassengrößen ebenfalls in die Durchschnittsberechnung ein.
\subsubsection{Durchschnittliche zyklomatische Komplexität}
Die Berechnung der durchschnittlichen zyklomatischen Komplexität findet auf ähnliche Weise statt. Philipp und Rauch haben hier den Schwellwert 4 gewählt. Damit werden Methoden ignoriert, die vier oder weniger unabhängige Ablaufpfade besitzen oder anders ausgedrückt, weniger als vier verschiedene Entscheidungen treffen. Die Bewertungsfunktion $rating_{cc}$ eines wie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} berechneten zyklomatischen Komplexitäts-Wert sieht damit folgendermaßen aus.
\begin{equation}
	rating_{cc}(cc) = 
	\begin{cases}
		\displaystyle	\frac{1}{4 * cc} - 1, & \text{wenn }cc > 4\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagecyclomaticcomplexity}
\end{equation}
Anschließend kann der Mittelwert der bewerteten Komplexitäten gebildet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Durchschnittliche Methodenlänge}
Auch die Berechnung der durchschnittlichen Methodenlänge findet ähnlich statt. Der Schwellwert für die in Unter-Unterabschnitt \ref{subsubsec:methodlength} berechnete Metrik wurde hier auf 9 festgelegt. Methoden mit 9 oder weniger Anweisungen werden damit ignoriert. Die Bewertungsfunktion $rating_{ml}$ sieht dann folgendermaßen aus.
\begin{equation}
	rating_{ml}(ml) = 
	\begin{cases}
		\displaystyle	\frac{1}{9 * ml} - 1, & \text{wenn }ml > 9\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagemethodlength}
\end{equation}
Aus den bewerteten Längen kann dann wieder der Mittelwert berechnet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Anzahl nicht-statischer öffentlicher Felder}
Wenn eine Klasse mindestens ein öffentliches Feld hat, das nicht statisch oder eine Konstante ist, dann betrachtet Usus diese Klasse als einen Hotspot. Dabei wird jede Klasse mit 1 bewertet, die mindestens eines dieser Felder besitzt. Der Schwellwert ist ebenfalls 1. Die Anzahl der betroffenen Klassen wird wie jede andere Metrik im Usus Cockpit über die Anzahl aller Klassen gemittelt und somit als Prozent dargestellt.
\subsubsection{Pakete mit zyklischen Abhängigkeiten}
Für Klassen wurde in Unter-Unterabschnitt \ref{subsubsec:ccd} ein Abhängigkeitsgraph unabhängig vom Paket ermittelt, in dem sich die betrachtete Klasse befindet. Um Pakete mit zyklischen Abhängigkeiten zu identifizieren, müssen alle Klassen-Knoten eines Paket in dem Abhängigkeitsgraph zu einem Paket-Knoten in einem neuen Abhängigkeitsgraph auf Paketebene zusammengefasst werden. Die Kanten zwischen den Klassen werden auf Kanten zwischen den übertragen. Anschließend können alle trivialen Kreise im Paket-Abhängigkeitsgraph entfernt und Zyklen gesucht werden. Heiko Körner beschreibt in seinem Skript \cite{GraphAlgorithms} die beiden Algorithmen \textit{Gegenseitige Erreichbarkeit} und \textit{Starke Zusammenhangskomponenten} für diesen Zweck. Mit den Algorithmen können alle starken Zusammenhangskomponenten (engl. \textit{strongly connected components} (SCC)) ermittelt werden. Alle starken Zusammanhangskomponenten, die mehr als eine Paket beinhalten entsprechen dann Paketen, die auf einem Kreis im Abhängigkeitsgraph liegen.
\begin{equation}
	cyclicPackages(pdG) = \sum_{\displaystyle scc \in SCCs(pdG)}
	\begin{cases}
		| scc |, & \text{wenn }|scc| > 1\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:packageswithcyclicdependencies}
\end{equation}
\begin{eqnarray*}
pdG&=&\text{Paket-Abhängigkeitsgraph}\\
SCCs(pdG)&=&\text{Menge aller starken Zusammenhangskomponenten in }pdG\\
scc&=&\text{Starke Zusammenhangskomponente als Menge von Paketen}\\
cyclicPackages(pdG)&=&\text{Anzahl aller Pakete in allen starken Zusammenhangskomponenten in }pdG\\
\label{eq:packageswithcyclicdependenciesagenda}
\end{eqnarray*}
Formel \ref{eq:packageswithcyclicdependencies} zeigt dabei die Aufsummierung aller Pakete in nicht-trivialen starken Zusammenhangskomponenten eines Paket-Abhängigkeitsgraph. Abschließend kann der $cyclicPackages$-Wert durch die Anzahl der betrachteten Pakete dividiert werden, um einen durchschnittlichen Paket-Zyklus-Wert zu bestimmen, der im Usus Cockpit angezeigt wird.




\chapter{Andere Tools}
Nachdem in dem vorherigen Kapitel das Eclipse Plugin Usus vorgestellt wurde, werden in diesem Kapitel einige andere Werkzeuge beschrieben, die ebenfalls eine statische Code-Analyse durchführen. Während Usus die direkte Inspiration für das in dieser Master-Thesis zu entwickelnde Tool darstellt, werden in diesem Kapitel einige Visual Studio Erweiterungen behandelt. Diese Erweiterungen versuchen bereits, die in Kapitel \ref{chap:requirements} definierten Anforderungen zu erfüllen und sind dabei auf Projekte spezialisiert, die für das .NET-Framework entwickelt werden.


\section{Visual Studio Metrics}
In diesem Abschnitt sollen die Möglichkeiten beschrieben werden, die Visual Studio von Haus aus bietet um Software zu analysieren. Ab Visual Studio 2010 Premium können zu jeder Solution (Menge von Projekten) verschiedene Code-Metriken direkt berechnet werden. Die Ergebnis-Anzeige ist in Abbildung \ref{fig:vsmetricsresult} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/vsmetricsresult.png}
	\caption{Code-Metriken Ergebnis-Fenster in Visual Studio 2010 Premium}
	\label{fig:vsmetricsresult}
\end{figure}
Bei den berechneten Metriken handelt es sich um \textit{Lines of Code} (eigentlich \textit{Number of Statements}), \textit{Class Coupling} (direkte Klassen-Abhängigkeiten), \textit{Cyclomatic Complexity} und \textit{Maintainability Index} (Microsofts Indikator für Wartbarkeit). Jede dieser Metriken wird auf Methoden-Ebene erhoben und Zusammenfassend in der hierarchischen Struktur nach oben (Klasse, Paket, Assembly) propagiert. Zusätzlich wird die Metrik \textit{Depth of Inheritance} (Anzahl an direkten und indirekten Oberklassen ohne Interfaces) auf Klassenebene bestimmt und ebenfalls nach oben aggregiert. Der Wartbarkeits-Index sowie dessen Berechnung wird von Zain Naboulsi in seinem Artikel \cite{VSMaintainabilityIndex} umfangreich erläutert. Neben der einfachen Darstellung erlaubt Visual Studio das Filtern der Methoden und Klassen anhand der Metriken und zeigt neben der Ausprägung des Wartbarkeits-Indexes eine Ampel an, die nach Microsofts Empfinden die Methode/Klasse als gut wartbar, weniger gut wartbar und nicht so gut wartbar klassifiziert.
\paragraph{}
In Visual Studio 2010 Ultimate können zudem mehrere grafische Funktionen genutzt werden. So lassen sich zum Beispiel Methoden automatisch als Sequenz-Diagramme darstellen, was einen Hinweis auf deren Komplexität und Abhängigkeiten geben kann. Zusätzlich kann der Abhängigkeitsgraph einer Solution mithilfe des Architektur-Explorer visualisiert und so zyklische Abhängigkeiten von Klassen und Pakten schnell gefunden werden. Abbildung \ref{fig:vsarchitecturenamespaces} zeigt das Ergebnis der Visualisierung, die neben der Graphen-Form auch in Form einer Matrix dargestellt werden kann.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/vsarchitecturenamespaces.png}
	\caption{Architektur-Diagramm in Visual Studio 2010 Ultimate auf Basis von Paketen, aufklappbar bis Methoden-Ebene}
	\label{fig:vsarchitecturenamespaces}
\end{figure}
Leider sind diese Funktion zur Metrik-Berechnung und zur Visualisierung in der am weitesten verbreiten Professional Version von Visual Studio nicht verfügbar. Zwei kostenlose Programme, die das Bestimmen der gleichen Menge von Code-Metriken erlauben werden in den folgenden Unterabschnitten vorgestellt.

\subsection{Visual Studio Code Metrics Power Tool}
\label{subsec:vscodemetricspowertool}
Das Kommandozeilenwerkzeug \textit{Visual Studio Code Metrics Power Tool}\footnote[1]{Download: "`Visual Studio Code Metrics PowerTool 10.0"' \url{http://www.microsoft.com/download/en/details.aspx?id=9422}} wird kostenfrei von Microsoft zum Download angeboten. Es erlaubt die Berechnung der gleichen Metriken wie die in Visual Studio 2010 Premium integrierte Funktionalität und erzeugt eine XML-Datei. Diese Datei enthält die Metriken für Projekte, Namensräume, Typen und Methoden in hierarchischer Form.

\subsection{Code Metrics Viewer}
Die Erweiterung \textit{Code Metrics Viewer}\footnote[2]{Download: "`Code Metrics Viewer extension"' \url{http://visualstudiogallery.msdn.microsoft.com/9f35524b-a784-4dbc-bd7b-6babd7a5a3b3}} für Visual Studio 2010 wird von Matthias Friedrich zum kostenlosen Download angeboten. Das Tool nutzt das Kommandozeilenwerkzeug \textit{Visual Studio Code Metrics Power Tool} um Metriken direkt in der Entwicklungsumgebung grafisch anzeigen zu können. In einem Visual Studio-Fenster, das dem aus Abbildung \ref{fig:vsmetricsresult} nachempfunden ist, wird der Inhalt der durch das Power Tool erzeugten XML-Datei visualisiert. Es lassen sich ebenfalls verschiedene Filter einstellen. Der Hauptunterschied zu der integrierten Funktionalität besteht darin, das die Ampel zu jeder Metrik angezeigt wird.


\section{NDepend}
Für die grafische Darstellung des Abhängigkeitsgraphen kann das kommerzielle Werkzeug NDepend\footnote[1]{"`Tutorial with explanations and screenshots"' \url{http://www.ndepend.com/GettingStarted.aspx\#Tuto}} (299\EUR für eine Einzelplatz-Lizenz) genutzt werden. Dieses Tool ist neben der umfangreichen Darstellung von Zusammenhängen und Abhängigkeiten in der Lage, viele verschiedene Metriken auf Anwendungs-, Projekt-, Namesraum-, Klassen- und Methoden-Ebene zu berechnen. Die Abhängigkeiten können, wie im Architektur-Explorer in Visual Studio Ultimate, in Form einer Matrix oder in Form eines Diagrams veranschaulicht werden. Dafür analysiert NDepend genau wie das Code Metrics Power Tool die pro Projekt von dem Compiler erzeugten Assembly-Dateien (exe oder dll). Das Programm ist neben .NET auch für Java und C++ erhältlich und kann als eigenständige Anwendung oder als Visual Studio Addin verwendet werden.

\subsection{Code Query Language}
Abhängig von der Metrik- und Abhängigkeitsberechnung kann NDepend Warnungen und Hinweise anzeigen, die den Programmierer rechtzeitig auf schwierige Stellen im Code hinweisen und es ihm erlauben, dort gezielt einzugreifen. Es lassen sich auch eigene Warnungen und Berichte mithilfe der deklarativen Sprache CQL (Code Query Language) erstellen und ausführen.

\subsection{Abstraktheit und Instabilität}
Eine sehr interessante Metrik im NDepend Metrik-Portfolio ist "`Abstraktheit und Instabilität"'. Diese Metrik-Kombination geht auf einen Artikel von Robert C. Martin \cite{OODesignMetrics} zurück. In diesem Artikel beschreibt Martin verschiedene Metriken zum Messen von Abhängigkeiten in Bezug auf eine Klassen-Kategorie. Eine Kategorie definiert er als Gruppe zusammenhängender Klassen, die gemeinsam benutzt werden. Diese Definition kann somit auf Pakete (Namensräume) oder auf Assemblies (Projekte) angewendet werden. Als erste Metrik stellt Martin \textit{Afferent Couplings} (hinführende Kupplungen $Ca(k)$) einer Kategorie $k$ als Anzahl der Klassen vor, die nicht in der Kategorie sind und eine Abhängigkeit von Klassen in der Kategorie haben. Daraus ergibt sich Formel \ref{eq:afferentcouplings}.
\begin{equation}
	Ca(k) = \sum_{\displaystyle c_o \in Cs \setminus Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_o, c_i) \in dG \mid c_i \in Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:afferentcouplings}
\end{equation}
\begin{eqnarray*}
Cs&=&\text{Menge aller Klassen im System}\\
Cs(k)&=&\text{Menge aller Klassen in der Kategorie }k\\
dG&=&\text{Abhängigkeitsgraph des Systems}\\
\label{eq:afferentcouplingsagenda}
\end{eqnarray*}
Martin bezieht sich auf die Abhängigkeiten zwischen Kategorien. In Formel \ref{eq:afferentcouplings} und den folgenden Formeln wird der bereits aus Unterabschnitt \ref{subsec:perclass} bekannte Abhängigkeitsgraph $dG$ auf Klassen-Ebene verwendet um die Abhängigkeiten abzubilden. Die Kategorie-Grenze einer Kategorie $k$ wird in Bezug auf die Klassen-Abhängigkeiten durch die Funktion $Cs(k)$ bestimmt. Während Formel \ref{eq:afferentcouplings} alle Abhängigkeiten in Richtung der betrachteten Kategorie beschreibt, definiert Formel \ref{eq:efferentcouplings} alle Abhängigkeiten aus der Richtung der betrachteten Kategorie. Die Metrik \textit{Efferent Couplings} (wegführende Kupplungen $Ce(k)$) bezeichnet die Anzahl der Klassen innerhalb einer Kategorie $k$, die Abhängigkeiten zu Klassen außerhalb der Kategorie besitzen.
\begin{equation}
	Ce(k) = \sum_{\displaystyle c_i \in Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_i, c_o) \in dG \mid c_o \in Cs \setminus Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:efferentcouplings}
\end{equation}
Die Formeln \ref{eq:afferentcouplings} und \ref{eq:efferentcouplings} besitzen die gleiche Struktur und unterscheiden sich nur durch die Richtung der gesuchten Kante im Abhängigkeitsgraph $dG$ und der Menge der Klassen, die gezählt werden soll.
\paragraph{}
Mit der Anzahl der hinführenden und wegführenden Abhängigkeiten kann jetzt die Metrik \textit{Instability} (Instabilität $I(k)$) einer Kategorie $k$ wie in Formel \ref{eq:instability} bestimmt werden. Martin beschreibt diese Metrik als Maß dafür, wie sich die betrachtete Kategorie anpassen muss, wenn sich das restliche System ändert.
\begin{equation}
	I(k) = \frac{Ce(k)}{Ca(k) + Ce(k)}
\label{eq:instability}
\end{equation}
Eine Instabilität von 1.0 bedeutet maximale Instabilität und wird erreicht, wenn nur wegführende Abhängigkeiten vorhanden sind, also die Klassen innerhalb der Kategorie von Klassen außerhalb abhängig sind. Im Falle einer Änderung im restlichen System ist diese Kategorie sehr wahrscheinlich ebenfalls betroffen. Eine Instabilität von 0.0 bedeutet maximale Stabilität, da keine wegführenden Abhängigkeiten vorhanden sind und Abhängigkeiten nur von Klassen außerhalb der Kategorie zu Klassen in der Kategorie bestehen. Eine Änderung des restlichen Systems hätte also keinen Einfluss auf die betrachtete Kategorie. Instabilität kann nur bestimmt werden, wenn mindestens ein Abhängigkeit (wegführend oder hinführend) vorhanden ist.
\paragraph{}
Robert C. Martin erläutert in seinem Artikel zudem den Zusammenhang von Instabilität und Abstraktheit. Dafür schreibt er, dass Abhängigkeiten von instabilen Kategorien zu vermeiden sind. Da Kategorien mit abstrakten Klassen und Schnittstellen hinführende Abhängigkeit einer externen Klasse motivieren, empfiehlt er keine abstrakten Typen innerhalb einer instabilen Kategorie zu positionieren. Um den Grad der Abstraktheit $A(k)$ einer Kategorie $k$ zu bestimmen, hat Martin die Metrik \textit{Abstractness} als Verhältnis zwischen abstrakten Klassen und Schnittstellen zu konkreten Klassen beschrieben. Dieses Verhältnis kann mit Formel \ref{eq:abstractness} berechnet werden.
\begin{equation}
	A(k) = \frac{|aCs(k)|}{|Cs(kp)|}
\label{eq:abstractness}
\end{equation}
\begin{eqnarray*}
aCs(k)&=&\text{Menge der abstrakten Klassen und Schnittstellen in der Kategorie }k\\
\label{eq:abstractnessagenda}
\end{eqnarray*}
Genau wie bei der Instabilität liegt auch die Ausprägung der Abstraktheit zwischen 0.0 und 1.0. Eine Abstraktheit von 0.0 entspricht einer konkreten Kategorie ohne abstrakte Typen, während eine Abstraktheit von 1.0 für eine Kategorie mit ausschließlich abstrakten Typen steht.
\paragraph{}
Die Abstraktheit und die Instabilität können kombiniert werden. NDepend greift die Idee von Martin auf und trägt jede Assembly der betrachteten Projektumgebung in einem Diagramm ähnlich Abbildung \ref{fig:abstractnessinstability} entsprechend ein.
\begin{figure}[h]
	\centering
		\includegraphics[width=7cm]{images/abstractnessinstability.jpg}
	\caption{Schematische Darstellung des "`Abstraktheit und Instabilität"'-Diagramm in NDepend}
	\label{fig:abstractnessinstability}
\end{figure}
Robert C. Martin beschreibt eine Kategorie, die in der Haupt-Sequenz liegt, als ausgeglichen, da sie zum Teil erweiterbar und zum Teil stabil ist. Laut Martin sind die beiden Endpunkte der Haupt-Sequenz die optimalen Punkte. Nach seiner Erfahrung können nur ungefähr die Hälfte der Kategorien in einem System diese optimalen Positionen einnehmen. Die andere Hälfte sollte möglichst nah an der Haupt-Sequenz liegen, was durch eine weitere Metrik in Form einer Abstandsberechnung festgehalten werden könnte.


\section{CCD-Addin}
In Kapitel \ref{chap:requirements} wurde im Rahmen der Anforderungsanalyse der Anwendungsfall "`Clean Code Hilfe bekommen"' identifiziert. Das Visual Studio Addin \textit{CcdAddIn}\footnote[1]{"`CcdAddIn is a visual Studio Add-In that displays the CCD values according to your current CCD Grade"' \url{https://github.com/AlexZeitler/CcdAddIn}} von Alexander Zeitler versucht eine solche Hilfestellung in passiver Form zu geben. In Unterabschnitt \ref{subsec:cleancode} wurde die Idee von Clean Code bereits erläutert und auf das sieben-Grade-System von Ralf Westphal und Stefan Lieser \cite{CleanCodeDeveloper} eingegangen. Das Programm integriert sich in die IDE und zeigt zu jedem Grad die entsprechenden Prinzipien und Praktiken an, sodass der Entwickler immer an seinen aktuellen Grad und an die damit verbundenen "`Regeln"' erinnert wird. Jede Praktik und jedes Prinzip ist anklickbar, sodass das Addin weitere Informationen anzeigen kann. Leider zeigt das Addin die Informationen nur an und bietet sonst kein weitere Hilfestellung.

\subsection{Prinzipien}
In diesem Unterabschnitt werden die einzelnen Grade vorgestellt. Da der \textit{schwarze} Grad lediglich einer Interessenbekundung entspricht und der \textit{weiße} Grad das komplette Spektrum abdeckt, werden im Folgenden nur die verbleibenden fünf Grade erwähnt. Die folgenden Prinzipien wurden direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen.
\begin{description}
	\item[Rot] \textit{Don´t Repeat Yourself} (DRY), \textit{Keep it simple, stupid} (KISS), Vorsicht vor Optimierungen!, \textit{Favour Composition over Inheritance} (FCoI)
	\item[Orange] \textit{Single Level of Abstraction} (SLA), \textit{Single Responsibility Principle} (SRP), \textit{Separation of Concerns} (SoC), Source Code Konventionen
	\item[Gelb] \textit{Interface Segregation Principle} (ISP), \textit{Dependency Inversion Principle} (DIP), \textit{Liskov Substitution Principle} (LSP), \textit{Principle of Least Astonishment} (PLA), \textit{Information Hiding Principle} (IHP)
	\item[Grün] \textit{Open Closed Principle} (OCP), \textit{Tell, don´t ask} (TDA), \textit{Law of Demeter} (LD)
	\item[Blau] Entwurf und Implementation überlappen nicht, Implementation spiegelt Entwurf, \textit{You Ain´t Gonna Need It} (YAGNI)
\end{description}

\subsection{Praktiken}
Neben den Prinzipien existieren zu jedem Grad auf Praktiken, die ebenfalls direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen wurden.
\begin{description}
	\item[Rot] die Pfadfinderregel beachten, \textit{Root Cause Analysis}, ein Versionskontrollsystem einsetzen, einfache Refaktorisierungsmuster anwenden, Täglich reflektieren
	\item[Orange] Issue Tracking, Automatisierte Integrationstests, Reviews, Lesen, Lesen, Lesen
	\item[Gelb] Automatisierte Unit Tests, Mockups (Testattrappen), Code Coverage Analyse, Teilnahme an Fachveranstaltungen, Komplexe Refaktorisierungen
	\item[Grün] Continuous Integration, Statische Codeanalyse (Metriken), \textit{Inversion of Control} (IOC) Container, Erfahrung weitergeben, Messen von Fehlern
	\item[Blau] Continuous Delivery, Iterative Entwicklung, Komponentenorientierung, Test first
\end{description}




\chapter{Technologie Evaluierung}
\label{chap:techeval}
Nachdem in Kapitel \ref{chap:requirements} die Anforderungen an die zu entwickelnde Visual Studio Erweiterung beschrieben wurden, werden in diesem Kapitel verschiedene Technologien in Betracht gezogen um ein Werkzeug zu entwickeln, das einen ähnlichen Funktionsumfang wie das in Kapitel \ref{chap:usus} beschrieben Usus-Plugin besitzt. Der Schwerpunkt in diesem Kapitel liegt auf der statischen Code-Analyse, die durchgeführt werden muss um Metriken und alles weitere Feedback zu berechnen. Zu diesem Zweck werden Möglichkeiten untersucht um Quellcode zu analysieren und um die Rohdaten zu ermitteln, die für die Berechnung der vorgestellten Metriken benötigt werden. Dieser Analyse-Schritt wird auch von Artur Wagner in seiner Ausarbeitung \cite{IntroStaticCodeAnalysis} auch mit den Analyse-Schritten eines Compilers verglichen. Allerdings ist es möglich eine statische Code-Analyse auch nach dem Kompilieren durchzuführen, indem das Kompilat betrachtet wird. Dies ist im Fall von Java und .NET möglich, da es sich bei dem erzeugten Format um eine Zwischensprache handelt, die erst unmittelbar vor dem Ausführen in Maschinensprache übersetzt wird. Die Technologien, die in diesem Kapitel behandelt werden, nutzen entweder den Quellcode oder das Compiler-Ergebnis um eine statische Code-Analyse durchzuführen.
\paragraph{}
Um die Technologien anhand ihrer Eignung zu evaluieren, wird die Bewertung nach verschiedenen Kriterien vorgenommen. Die Kriterien sind in Form von Fragen so formuliert, dass eine bejahende Antwort als positiv gilt. Die Kriterien sind nach Wichtigkeit absteigend sortiert.
\begin{enumerate} 
\item Können alle Informationen gesammelt werden, die benötigt werden um die von Usus berechneten Metriken ebenfalls zu berechnen?
\item Ist die Technologie verfügbar, kostenfrei nutzbar und kann veröffentlicht werden?
\item Unterstützt die Technologie alle .NET Laufzeitumgebungen unter Windows?
\item Ist die Technologie unabhängig von anderen Laufzeitumgebungen und anderen externen Komponenten?
\item Kann die Technologie ein System verarbeiten, das Klassen und Pakete verwendet, die nicht im betrachteten System definiert sind?
\item Ist die Technologie in der Lage ein System zu analysieren, dass nicht nur mit C$\#$ entwickelt wurde?
\item Kann die Technologie mit dem Code und dem Kompilat arbeiten?
\item Ist die Technologie einfach und performant einsetzbar?
\end{enumerate}
Anhand dieser Kriterien werden die verschiedenen Technologien, die in den folgenden Abschnitten beschrieben werden, evaluiert. Das Ergebnis wird dann abschließend im letzten Abschnitt in diesem Kapitel in Form einer Zusammenfassung vorgestellt.


\section{FxCop}
\label{sec:fxcop}
Jason Kresowaty beschreibt \textit{FxCop} in seiner Ausarbeitung \cite{FxCopCustomRules} als Werkzeug zur statischen Code-Analyse für Assemblies, die mit C\#, VB.NET und allen anderen .NET-Sprachen entwickelt wurden. \textit{FxCop} analysiert die vom Compiler erzeugten Binärdateien in \textit{Common Intermediate Language} (CIL) und führt Regeln aus, die nach Problemen im Sinne von Verletzungen von Konventionen und Richtlinien suchen.

\subsection{Umgebung}
Die \textit{FxCop}-Technologie besteht aus zwei Teilen. Der erste Teil ist die \textit{Microsoft FxCop} Anwendung und der zweite Teil sind die Regeln, die genutzt werden um die statische Analyse zu nutzen. Microsoft veröffentlicht mit dem Programm eine Menge von Regeln, um Assemblies anhand den von Krzysztof Cwalina und Brad Abrams veröffentlichten Konventionen und Richtlinien \cite{FrameworkDesignGuidelines} zu untersuchen. Eine Regel, die eine Berechnung von Metriken zur späteren Verwendung durchführt ist nicht vorhanden. Es lassen sich allerdings eigene Regeln definieren, die \textit{FxCop} genauso ausführen kann, und mit der das Programm beliebig erweitert werden kann. Eine solche eigene Regel könnte alle notwendigen Informationen sammeln um ein Programm mit einem Usus-ähnlichen Funktionsumfang zu entwickeln. Kresowaty beschreibt in seiner Ausarbeitung \cite{FxCopCustomRules} wie so eine Regel erstellt werden kann. Regeln lassen sich auch automatisiert ausführen, wenn eine Analyse mit der grafischen Oberfläche, die in Abbildung \ref{fig:fxcoprunner} dargestellt ist, nicht sinnvoll ist. Abbildung \ref{fig:fxcopcmdrunner} zeigt die Kommandozeilenversion des \textit{FxCop} Runners.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/fxcoprunner.png}
	\caption{FxCop Runner}
	\label{fig:fxcoprunner}
\end{figure}
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/fxcopcmdrunner.png}
	\caption{FxCop Kommandozeilen Runner}
	\label{fig:fxcopcmdrunner}
\end{figure}
\paragraph{}
Eine \textit{FxCop} Regel entspricht einer Klassenbibliothek, die eine Regel-Klasse und eine Regel-Konfigurationsdatei enthält. Während \textit{FxCop} den Code analysiert, erzeugt es Instanzen der Regel-Klasse und nutzt diese um in der Codebasis Problemfälle zu finden. Problemfälle können dann von der Regel-Klasse in Problem-Listen eingetragen werden, die \textit{FxCop} entweder grafisch anzeigt oder in Form einer Report-Datei erzeugt. Zusätzlich können Problemfälle als kritisch gekennzeichnet und mit verschiedenen Texten und Beschreibungen versehen werden um eine möglichst detaillierte Beschreibung der Schwierigkeit zu ermöglichen. \textit{FxCop} ist also auf das Finden von Problemen und nicht auf objektive Datensammlung spezialisiert. Um eine Assembly möglichst schnell analysieren zu können, erzeugt \textit{FxCop} mehrere Instanzen einer Regel und führt diese in mehreren Threads parallel aus. Jason Kresowaty betont in seiner Ausarbeitung \cite{FxCopCustomRules}, dass sich die Regeln nicht Thread-sicher verhalten. Damit mit \textit{FxCop} weiterverwendbare Daten gesammelt werden können, müssen diese auf eine geeignete Weise exportiert werden. Entweder können diese Daten in Form von Zeichenketten als Probleme verpackt oder direkt an ein Ziel gespeichert werden. Diese beiden Lösungen sind umständlich und nicht intuitiv und werden von der Nebenläufigkeit von \textit{FxCop} noch erschwert.

\subsection{API}
Regeln für \textit{FxCop} können mit C$\#$ in Form einer Klassenbibliothek entwickelt, wie es Jason Kresowaty in seiner Ausarbeitung \cite{FxCopCustomRules} vorstellt, und als \textit{Dynamic Link Library} (DLL) von \textit{FxCop} verwendet werden. Dazu muss die DLL über eine spezielle Metadaten-Datei als eingebettete Ressource verfügen, die die Regel dem Runner bekanntmacht. Die Regel selbst wird in einer Klasse implementiert, die von einer abstrakten Regel-Oberklasse abgeleitet ist und somit Analyse-Methoden überladen kann. Mit diesen Methoden kann das Objektmodell der zu analysierenden Assembly untersucht werden. Alle Basisklassen und Klassen, die das Objektmodell repräsentieren befinden sich im Namensraum \texttt{Microsoft.FxCop.Sdk}. Das \textit{Application Programming Interface} (API) um \textit{FxCop}-Regeln zu programmieren enthält Teile die dem in das .NET-Framework integrierten \texttt{System.Reflection} API ähnlich sind. Beide enthalten Klassen um das Objektmodell zu repräsentieren.
\paragraph{}
Um Operationen von einer Datenstruktur zu trennen, beschreiben Erich Gamma, Richard Helm, Ralph E. Johnson und John Vlissidest das Besuchermuster (Visitor Pattern) in \cite{DesignPatterns}. Mit dem Besuchermuster ermöglicht die \textit{FxCop} API die gleiche Datenstruktur (Objektmodell) mit vielen Regeln (Besuchern) zu analysieren. In der Regel-Klasse, die von \texttt{BaseIntrospectionRule} abgeleitet ist können oberflächliche Besuchermethoden überladen werden. Diese oberflächlichen Methoden bestimmen, an welcher Stelle im Objektmodell eine weitere Überprüfung vorgenommen werden soll. Zum Beispiel wird die \texttt{Check(Member)}-Methode in Listing \ref{listing:fxcopapisample} für jedes Property oder Methode in jeder Klasse aufgerufen. Die \texttt{Check(TypeNode)}-Methode wird zusätzlich für jede Klasse oder Interface ausgeführt.
\begin{lstlisting}[caption={FxCop API Beipiele},label={listing:fxcopapisample}]
ProblemCollection Check(Member member) {...}
ProblemCollection Check(TypeNode type) {...}
void VisitMemberBinding(MemberBinding memberBinding) {...}
void VisitBranch(Branch branch) {...}
void VisitAssignmentStatement(AssignmentStatement assignment) {...}
\end{lstlisting}
Nachdem sich die Regel mit einer dieser oberflächlichen \texttt{Check}-Methoden an dem Kontrollfluss der Analyse beteiligt, kann eine tiefgehende Analyse von der oberflächlichen Stelle ausgehend erfolgen. Dazu wird ein weiterer Besucher beispielsweise vom Typ \texttt{BinaryReadOnlyVisitor} erstellt, der die aktuelle Stelle im Objektmodell detaillierter besuchen kann. In einer von \texttt{BinaryReadOnlyVisitor} abgeleiteten Unterklasse können jetzt \texttt{Visit}-Methoden überladen werden, die ebenfalls in Listing \ref{listing:fxcopapisample} dargestellt sind. Beispielsweise kann in der Methode \texttt{VisitMemberBinding} jeder Methodenaufruf und mit \texttt{VisitAssignmentStatement} jede Zuweisung analysiert werden. Auf diese Weise und mit sämtlichen Parameter- und Rückgabetypen kann aus dem Objektmodell der für die zu berechnenden Metriken erforderliche Abhängigkeitsgraph erstellt werden. Die Anzahl der Anweisungen pro Methode kann entweder im Sinne der \textit{Common Intermediate Language} (CIL, die vom Compiler erzeugte Zwischensprache) oder im Sinne von einem \textit{FxCop} \texttt{Statement} erfolgen. Während die CIL-Anweisungen die C$\#$-Anweisungen sehr viel granulärer abbilden, entsprechen die FxCop-Anweisungen zusammengefassten CIL-Anweisungen. Eine Entsprechung der C$\#$-Anweisungen konnte ohne detaillierte Betrachtung der konkreten \texttt{Statement}-Typen nicht ermittelt werden. Die Anzahl der Zeilen kann dafür auf eine sehr einfach Weise bestimmt werden, da jedes \texttt{Statement} über einen \texttt{SourceContext} und dort über Start- und Endzeilennummern verfügt. Anhand der Liste aller Anweisungen kann die erste Zeile als kleinste Startzeile und die letzte als größte Endzeile gesucht und mittels der Differenz die Methodenlänge berechnet werden. Die zyklomatische Komplexität kann bestimmt werden, da jede Verzweigung im Code von der \texttt{VisitBranch}-Methode besucht wird.


\section{Common Compiler Infrastracture}
Die \textit{Common Compiler Infrastructure} (CCI) ist eine Sammlung von Bibliotheken, die Compiler-ähnliche Funktionen bereitstellen und von Microsoft Research entwickelt wurde \cite{CCI}. Auf Codeplex lässt sich die Komponente \textit{CCI Metadata} finden. Guy Smith beschreibt sie als Obermenge von \texttt{System.Reflection}, \texttt{System.Reflection.Emit} und \texttt{System.CodeDom}, also den Reflektions- und Code-Erzeugungs-Mechanismen des .NET-Framework zur Laufzeit \cite{CCIMetadata}. Smith beschreibt \textit{CCI Metadata} als Werkzeug, das mir den vom Compiler erzeugten CIL-Anweisungen arbeitet. Um einfacher mit Methoden zu arbeiten, stellt Smith mit \textit{CCI Code and AST Components} eine weitere Komponente vor \cite{CCICode}. \textit{CCI Code} erleichtert das Arbeiten mit Methoden, da es von den CIL-Anweisungen abstrahiert und Quellcode-ähnliche Bäume nutzt. Beide Komponenten sind unter der Microsoft Public License veröffentlicht. Die CCI wird in einer ähnlichen Variante unter anderem von dem Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} und FxCop aus Abschnitt \ref{sec:fxcop} genutzt. Die Assembly Microsoft.Cci.dll, die mit diesen Tools ausgeliefert wird, besitzt viele Funktionen nur intern oder von erlaubten Assemblies aufrufbar sind. Funktionen, die beispielsweise konkrete Methoden-Metriken berechnen, sind nur von Programmen aufrufbar, die in der CCI-Assembly aufgelistet sind, wie in Abbildung \ref{fig:cciinternalsvisible} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=14cm]{images/cciinternalsvisible.png}
	\caption{Micorsoft.Cci.dll \texttt{InternalsVisibleTo}-Attribute}
	\label{fig:cciinternalsvisible}
\end{figure}

\subsection{CCI Metadata}
Im Gegensatz zu der \textit{FxCop} API kann eine .NET-Assembly mit CCI direkt untersucht werden, ohne das die Analyse in Form einer einschränkenden Regel parallelisiert erfolgt. CCI überlässt dem Verwender der Bibliothek ob und wie die Untersuchung stattfinden soll. Mit einem \texttt{PeReader.DefaultHost} können PE-Dateien (\textit{Portable Executables} also dll- oder exe-Dateien) eingelesen werden. Zusätzlich kann die vom Compiler erzeugte pdb-Datei mit einem \texttt{PdbReader} importiert werden. Die pdb-Datei (\textit{Program Database}) enthält laut Microsoft \cite{PDBFile} Debug- und Projekt-Information wie beispielsweise die Datei- und Zeilenzuordnung der erzeugten Typen und Funktionen. Mit der \texttt{IAssembly.GetAllTypes()}-Methode können alle Typen ermittelt werden. Alle Methoden und Properties eines Typs, können mit \texttt{INamedTypeDefinition.Methods} bestimmt werden. Der Inhalt von Methoden und Properties kann in Form von CIL-Anweisungen mit \texttt{IMethodBody.Operations} genauer betrachtet werden. So lassen sich beispielsweise alle lokalen Variablen und Methodenaufrufe lokalisieren, um Abhängigkeiten der Methode zu anderen Typen zu finden. Zusammen mit Attributen, Parametern und Rückgabewerten kann der Abhängigkeitsgraph eines Typs ermittelt werden. Die zyklomatische Komplexität einer Methode kann ebenfalls über die CIL-Anweisungen bestimmt werden, was durch das Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} sowie Steve Gilham \cite{CCperCIL} demonstriert wird. Um die Methodenlänge einer Funktion aus den CIL-Anweisungen zu ermitteln, kann auch hier die Funktionalität durch das Code Metrics Power Tool inspiriert werden. Wenn zu der .NET-Assembly zusätzlich eine pdb-Datei existiert, kann außerdem die Start- und Endzeile jeder Anweisung auf die Methode bezogen werden, ähnlich der Lösung für die \textit{FxCop} Regel.

\subsection{CCI Code and AST Components}
Soweit wurden nur Funktionen von \textit{CCI Metadata} betrachtet. \textit{CCI Code and AST Components} erlaubt es das Quellcode-Modell einer Methode in Form eines abstrakten Syntax-Baums (AST) zu analysieren. Philip Newcomb beschreibt einen AST in seinem Tutorial über den AST Metamodel Standard \cite{ASTMetamodel} als formale Repräsentation der syntaktischen Struktur einer Software auch innerhalb Methoden. Um einen solchen Baum zu betrachten, können Besucher verwendet werden. Beispielsweise erlaubt eine Objekt vom Typ \texttt{CodeTraverser} jede strukturelle Stelle der Assembly mit überladbaren Methoden, von denen einige in Listing \ref{listing:ccicodeastsample} aufgeführt sind, zu besuchen.
\begin{lstlisting}[caption={\textit{CCI Code and AST Components} \texttt{CodeTraverser}-Methoden},label={listing:ccicodeastsample}]
TraverseChildren(IConditionalStatement conditionalStatement) {...}//if
TraverseChildren(IConditional conditional) {...}//bool expression
TraverseChildren(IForStatement forStatement) {...}
TraverseChildren(ISwitchStatement switchStatement) {...}
\end{lstlisting}
Für jede Stelle im Code leitet \texttt{CodeTraverser} den Aufruf an Objekte vom Typ \texttt{ICodeVisitor} weiter, und ermöglicht so einfache Erweiterungen auf mehrere Weisen vorzunehmen. \texttt{ICodeVisitor} besitzt für jede \texttt{Traverse}-Methode eine entsprechende \texttt{Visit}-Methode. Da \texttt{CodeTraverser} das Code-Modell von links nach rechts und "`Depth First"' besucht, können zwei Besucher registriert werden. Einer wird aufgerufen bevor ein Syntax-Element im Baum besucht wird und der andere wird aufgerufen nachdem der Besuch beendet ist. 
\paragraph{}
\textit{CCI Code and AST Components} ermöglicht das syntaktische besuchen von Sprachelementen, indem von CIL abstrahiert wird. Es existieren Besucher-Methoden für alle Sprachelemente, die aus C$\#$ 4.0 bekannt sind, wie beispielsweise Lambda-Ausdrücke, Generics, Attribute und vielen mehr. Die herunterladbare \textit{CCI Code and AST Components} Visual Studio Solution enthält ein Beispiel (PeToTextViaCodeModel), das sämtliche Strukturelemente einer dll- oder exe-Datei besucht und wieder C$\#$-Quelltext erzeugt. Das Ergebnis entspricht Code, der dem Original sehr ähnlich ist und an professionelle Decompiler erinnert. Die CCI erlaubt es außerdem eine geladene Assembly zu verändern und anschließend wieder zu exportieren.


\section{NRefactory}
Auch in der Mono-Welt existieren Werkzeuge für Compiler-ähnliche Funktionen. Das Team hinter Mono beschreibt Mono als Implementierung des .NET-Frameworks für Windows, Linux, Mac OS und verschiedene mobile Plattformen \cite{Mono}. In diesem Umfeld ist \textit{NRefactory} Teil der freien .NET-Entwicklungsumgebung SharpDevelop\footnote[1]{"`The Open Source Development Environment for .NET"' \url{http://www.icsharpcode.net/OpenSource/SD/}} und arbeitet im Gegensatz zur CCI und FxCop nicht nur auf Assembly-Ebene, sondern hauptsächlich mit Quellcode.

\subsection{AST aus Quellcode}
Mit \textit{NRefactory} ist es möglich einen AST aus C$\#$-Quelltext zu erzeugen. VB.net wird noch nicht unterstützt. Anschließend können AST-Besucher als direkte Implementierung der \texttt{IAstVisitor}-Schnittstelle oder als Ableitung von \texttt{DepthFirstAstVisitor} erstellt werden und mit dem abstrakten Syntax-Baum arbeiten. Listing \ref{listing:nrefacastsample} zeigt einige wenige Methoden, die in \texttt{IAstVisitor} definiert sind.
\begin{lstlisting}[caption={\textit{NRefactory} \texttt{IAstVisitor}-Methoden},label={listing:nrefacastsample}]
VisitIfElseStatement(IfElseStatement ifElseStatement) {...}
VisitBinaryOperatorExpression(BinaryOperatorExpression binaryOperatorExpression) {...}
VisitPrimitiveExpression(PrimitiveExpression primitiveExpression) {...}
VisitNewLine(NewLineNode newLineNode) {...}
VisitInvocationExpression(InvocationExpression invocationExpression) {...}
\end{lstlisting}
Mit einem solchen Besucher können strukturelle Code-Elemente wie if-Anweisungen sehr gut besucht werden, was die Berechnung der zyklomatischen Komplexität ermöglicht, ohne kompiliern zu müssen. Wie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben, brauchen dafür nur alle Entscheidungsstellen besucht und aufsummiert werden. Die Methodenlänge kann ebenfalls einfach bestimmt werden. Es ist möglich entweder alle Statements oder alle Zeilenumbrüche zu besuchen und aufzusummieren. Der AST kann auch verändert und anschließend neuer Code erzeugt werden. Allerdings kann der Abhängigkeitsgraph nicht durch die alleinige Erzeugung des AST erstellt werden.

\subsection{Mono.Cecil}
\textit{NRefactory} ordnet Methodenaufrufe in Form von \texttt{InvocationExpression}-Objekten erst dann der definierenden Stelle zu, wenn alle Typen und Methoden im AST mit einem \texttt{CSharpAstResolver} komplett aufgelöst werden. Dazu verwendet \textit{NRefactory} die \textit{Mono.Cecil}-Bibliothek, die Jean-Baptiste Evain als API zum Erzeugen, Analysieren und Verändern von .NET-Assemblies beschreibt \cite{MonoCecil}. Die Assemblies, in denen sich die Typen befinden auf die der Code zugreift, werden von \textit{Mono.Cecil} geladen. Listing \ref{listing:nrefacastresolvercreation} zeigt wie ein \texttt{CSharpAstResolver}-Objekt zur Auflösung des abstrakten Syntaxbaums erzeugt werden kann.
\begin{lstlisting}[caption={\textit{NRefactory} Erzeugung von \texttt{CSharpAstResolver}},label={listing:nrefacastresolvercreation}]
CSharpAstResolver CreateResolver(CompilationUnit parsed, params Type[] types)
{
    IProjectContent project = new CSharpProjectContent();
    CSharpParsedFile parsedFile = parsed.ToTypeSystem();
    project = project.UpdateProjectContent(null, parsedFile);
    project = project.AddAssemblyReferences(LoadAssemblies(types));
    return new CSharpAstResolver(project.CreateCompilation(), parsed, parsedFile);
}
\end{lstlisting}
Der Code orientiert sich an dem Demo Beispiel von Daniel Grunwald in dem \textit{NRefactory}-Repository \cite{NRefacRepo}. Das übergebene \texttt{CompilationUnit}-Objekt ist der Wurzelknoten eines \textit{NRefactory}-AST, der aus Quellcode-Fragment erstellt wurde. Dieser AST wird für die Typ-Zuordnung vorbereitet und gemeinsam mit allen anderen Assemblies, die für die Auflösung von externen Typen verwendet werden sollen, in Form eines \texttt{CSharpProjectContent}-Objekts zusammengefasst. Um diese Assemblies zu finden, wird jede durch einen in ihr enthaltenen, nicht weiter relevanten Typ identifiziert. Für die Erzeugung des \texttt{CSharpAstResolver}-Objekts, wird der unvorbereitete AST, der vorbereitete AST und das Kompilat des \texttt{CSharpProjectContent}-Objekts übergeben. Die eigentliche Auflösung wird dann über einen Aufruf der Methode \texttt{CSharpAstResolver.ApplyNavigator} synchron durchgeführt. Diese Funktion erwartet ein Objekt vom Typ \texttt{IResolveVisitorNavigator} und teilt diesem alle aufgelösten Details zu allen Knoten im AST mit. Ähnlich wie die CCI erlaubt auch \textit{Mono.Cecil} das manuelle Einlesen von Assemblies und \textit{Program Database}-Dateien um diese anhand der CIL-Anweisungen zu analysieren. Assemblies und pdb-Dateien können verändert und gespeichert werden.


\section{Codename "`Roslyn"'}
Karen Ng, Matt Warren, Peter Golde und Anders Hejlsberg beschreiben in ihrem Dokument \cite{RoslynOverview} ein Projekt um den C$\#$- und den VB.net-Compiler als Dienst zur Verfügung zu stellen. Sie beschreiben das Problem, dass Compiler viel isoliertes und ungeteiltes Wissen über die zu kompilierende Sprache besitzten. Dieses Wissen ist auch für andere Anwendungen, wie beispielsweise Entwicklungsumgebungen, Refactoring-Werkzeuge und Code-Analyse-Tools von bedeutung. Momentan müssen diese Programme das Wissen der Compiler neu erfinden und Teile des Compilers neu implementieren. Im Rahmen des Projekt \textit{Roslyn} sollen die Compiler ihr Wissen teilen können. Dazu werden sie als Dienste zur Verfügung gestellt und bieten APIs an. Diese APIs können dann von sämtlichen Code-orientierten Werkzeugen genutzt werden. Kirill Osenkov stellt in seinem Blog-Post \cite{RoslynCTPIntro} die CTP\footnote[1]{"`Microsoft Roslyn October 2011 CTP"' \url{http://msdn.com/roslyn}} (Community Technology Preview) von \textit{Roslyn} vor und erwähnt ein weiteres Ziel. Die bisherigen Compiler sollen in einer Sprache, die auf der CLR (Common Language Runtime) ausgeführt wird, neu geschrieben werden. Auf diese Weise soll das Team hinter Visual Studio schneller und bessere Features entwickeln können.

\subsection{Schichten}
In dem Dokument \cite{RoslynOverview} beschreiben Hejlsberg und co die traditionelle Compiler Pipeline der .net-Umgebung. Die \texttt{Roslyn}-Compiler werden diese Pipeline ebenfalls haben. Ein Parser erzeugt einen Syntax-Baum anhand der Grammatik der Sprache. Darauf folgt die Deklarierungsphase. In dieser Phase werden die Deklarierungen im Code zusammen mit importierten Metadaten in Form von benannten Einheiten, sogenannten Symbols, erstellt. Danach folgt die Binder-Phase, in der Typen im Syntax Baum den Symbols zugeordnet werden. In der letzten Phase wird alle vom Compiler angesammelte Information in Form von CIL-Anweisungen in eine Assembly-Datei exportiert. Project \textit{Roslyn} bietet für jede dieser Phasen eine entsprechende API im Rahmen einer Compiler API Schicht, die auf der Compiler Pipeline aufbaut. Auf diese Compiler API Schicht setzt \textit{Roslyn} noch eine Language Service Schicht, die mit dem Objektmodell der Compiler Phasen arbeitet und beispielsweise Refactorings unterstützt.
\paragraph{}
Hejlsberg und co unterscheiden noch zwischen verschiedenen Architekturschichten, die getrennt von den oben beschrieben Schichten über der Compiler Pipeline beschrieben werden. Die Compiler APIs erlauben den Zugriff auf das syntaktische und semantische Objektmodell, das durch die Compiler Pipeline zur Verfügung gestellt wird. Die nächste Schicht ist die Scripting API. Sie bietet eine Umgebung für das Ausführen von Code-Schnippseln in Form von Ausdrücken und Anweisungen. Mit dieser Umgebung kann ein REPL (Read Eval Print Loop) realisiert werden. Die Workspace API stellt die nächste Schicht dar und ermöglicht eine Analyse auf der Basis von kompletten Visual Studio Solutions. Die letzte Schicht ist die Services API. Sie ist die einzige, die eine Abhängigkeit von Visual Studio hat. Sämtliche Funktionen wie Visual Studio \texttt{IntelliSense}, Refactorings und Fomratierungsfunktionen befinden sich in dieser Schicht.

\subsection{Syntax Tree}
\label{subsec:roslynsyntaxtree}
In diesem Unterabschnitt werden die Möglichkeiten beschrieben, wie der Syntax-Baum der Compiler API verwendet werden kann. Interessant ist zu sehen, dass \textit{Roslyn} im Gegensatz zu \textit{NRefactory} die Datenstruktur nicht als abstrakten Syntax-Baum bezeichnet, sondern lediglich als Syntax-Baum. Philip Newcomb beschreibt in seiner Präsentation über den "`AST Metamodel Standard"' \cite{ASTMetamodel} den Unterschied als Nähe zum tatsächlichen Quellcode. Der Syntax Tree von \textit{Roslyn} orientiert sich sehr am Quellcode. Hejlsberg und co legen in ihrem Dokument \cite{RoslynOverview} besonderen Wert auf die Vollständigkeit des Baums, in dem jedes Leerzeichen und sogar synatktische Fehler Bestandteil des Syntax-Baum sind.
\paragraph{}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt die Erzeugung eines Syntax-Baum aus einem Quellcode-Ausschnitt, der in der Variable \texttt{sourceText} enthalten ist. Ähnlich wie \textit{NRefactory} bietet auch \textit{Roslyn} die Möglichkeit den Baum mit LINQ-Abfragen zu analysieren, da \texttt{DescendentNodes} ein \texttt{IEnumerable} zurückliefert. LINQ\footnote[1]{"`LINQ (Language-Integrated Query, sprachintegrierte Abfrage)"' \url{http://msdn.microsoft.com/de-de/library/bb397926.aspx}} ist ein Sprachkonstrukt, das es erlaubt mit Keywords wie beispielsweise \texttt{from}, \texttt{where} und \texttt{select} SQL-ähnliche Abfragen direkt in C$\#$ oder VB.net zu schreiben.
\begin{lstlisting}[caption={Erzeugung eines Syntax Tree mit der \textit{Rosyln} Compiler API},label={listing:roslynsyntaxtreecreation}]
SyntaxTree tree = SyntaxTree.ParseCompilationUnit(sourceText);
var methods = tree.Root.DescendentNodes().OfType<MethodDeclarationSyntax>();
...
var ifs = method.DescendentNodes().OfType<IfStatementSyntax>();
var invocations = method.DescendentNodes().OfType<InvocationExpressionSyntax>();
\end{lstlisting}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt ebenfalls wie alle Methoden, die in \texttt{sourceText} deklariert werden gefunden werden. In jeder dieser Methoden kann anschließend nach \texttt{if}-Anweisungen und ähnlichen Entscheidungsträgern gesucht werden, um die zyklomatische Komplexität, wie sie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben wurde, auszurechnen. Um die Typen zu finden, von denen eine Methode abhängig ist, können neben sämtlichen Variablen alle Methodenaufrufe gefunden werden. Daraus kann anschließend der Abhängigkeitsgraph bestimmt werden. Ähnlich zu \textit{NRefactory} kann auch für den \textit{Roslyn}-Baum ein Besucher als Ableitung von \texttt{SyntaxWalker} erstellt werden. Über entsprechende Überladungen kann dann auf alle Knoten im Syntax-Baum reagiert werden. Leerzeichen, Zeilenumbrüche und andere Elemente, die keine nicht syntaktische Relevanz haben, sind im Baum in Form von \texttt{Trivia}-Objekten vorhanden und lassen sich ebenfalls finden. Eine Manipulation des Code-Baums ist auch möglich indem ein neuer Baum erzeugt wird. Bestehende Bäume sind laut Hejlsberg und co unveränderlich.

\subsection{Semantik}
\label{subsec:roslynsemanticmodel}
In diesem Unterabschnitt wird beschrieben, wie die Compiler API die Semantik von Code verwaltet. Nach der Erzeugung der syntaktischen Repräsentation von Code, dem Syntax Tree, werden beispielsweise die Methodenaufrufe nicht automatisch der Stelle zugeordnet, die sie deklarieren. Ähnlich wie bei \textit{NRefactory} wird dazu eine Auflösung benötigt, die den Baum mit den Symbols verbindet. Listing \ref{listing:rosylnsemanticmodelcreation} zeigt wie ein Syntax-Baum kompiliert werden kann. Durch die Kompilierung werden alle Verweise, die sich wie im Beispiel auf die \texttt{mscorlib} (Bibliothek der Basistypen wie \texttt{object}, \texttt{string}, \texttt{DateTime}, usw) beziehen, aufgelöst.
\begin{lstlisting}[caption={Erzeugung eines semantischen Modells aus Syntax-Bäumen},label={listing:rosylnsemanticmodelcreation}]
Compilation compilation = Compilation.Create(name)
				.AddReferences(mscorlib)
				.AddSyntaxTrees(tree);
SemanticModel semanticModel = compilation.GetSemanticModel(tree);
\end{lstlisting}
Das Kompilieren findet im Speicher statt und das Ergebnis wird nicht in Form einer Assembly in eine Datei geschrieben. Aus dem Kompilat kann das semantische Modell erzeugt werden. Dieses Modell kann anschließend genutzt werden um zu sämtlichen syntaktischen Elementen im Syntax Tree semantische Eigenschaften zu erhalten.
\begin{lstlisting}[caption={Ermitteln der semantischen Information eines Methodenaufrufs},label={listing:roslynsemanticmodelusage}]
SemanticInfo invocationSymbols = semanticModel.GetSemanticInfo(invocation);
string typeName = invocationSymbols.Symbol.ContainingType.Name;
\end{lstlisting}
Dafür kann die \texttt{GetSemanticInfo}-Methode mit dem entsprechenden Element aufgerufen werden, wie in Lisiting \ref{listing:roslynsemanticmodelusage} dargestellt. Das semantische Modell enthält alle Symbols des Kompilats und nicht nur die, die für die Auflösung der Typen benötigt werden die im Syntax-Baum deklariert wurden. Wenn also über alle Typen im semantischen Modell iteriert wird, werden nicht nur die Typen aus dem Baum, sondern auch alle Typen aller Referenz-Assemblies, betrachtet.

\subsection{Workspace}
In diesem Unterabschnitt werden die Möglichkeiten der Compiler API in Bezug auf die Analyse von ganzen Visual Stuido Solutions beschrieben. Eine Solution ist eine Datei, die es Visual Studio ermöglicht mehrere Projekte mit mehreren Quellcode-Dateien zu verwalten und zu kompilieren. In einer Solution sind in der Regel alle Abhängigkeiten der beinhalteten Projekte entweder durch andere beinhaltete Projekte oder durch Referenz-Assemblies auflösbar. Die \textit{Roslyn} Services API erlaubt es im Kontext einer laufenden Visual Studio Instanz einen sogenannten Workspace zu verwenden, der die Visual Studio Umgebung Repräsentiert und den Syntax-Baum ändert, sobald der Quellcode ändert. Ein Workspace kann auch ohne Abhängigkeit von Visual Studio erzeugt werden, indem die Solution-Datei direkt geladen wird, wie in Listing \ref{listing:roslynsolutionworkspacecreation} zu sehen ist.
\begin{lstlisting}[caption={Erzeugung eines Workspace aus einer Visual Studio Solution-Datei},label={listing:roslynsolutionworkspacecreation}]
IWorkspace workSpace = Workspace.LoadSolution(solutionFile);
ISolution solution = ws.CurrentSolution;
...
SyntaxTree tree = document.GetSyntaxTree();
SemanticModel semantic = document.GetSemanticModel();
\end{lstlisting}
In einem \texttt{ISolution}-Objekt kann über alle enthaltenen Projekte iteriert werden. In jedem Projekt können alle Dokumente als \texttt{IDocument}-Objekte betrachtet werden. Zu jedem Dokument kann der zugehörige Syntax-Baum und das semantische Modell bestimmt werden. Da die Workspace-Repräsentation das Erzeugen und Kompilieren der Dateien übernimmt, kann die Code-Analyse direkt auf Solution-Ebene erfolgen, indem das Syntax-Baum und das semantische Modell wie in den Unterabschnitten \ref{subsec:roslynsyntaxtree} und \ref{subsec:roslynsemanticmodel} beschrieben wurde.


\section{Zusammenfassung}
Als Ergebnis einer formalen Nutzwert-Analyse, die hier noch erfolgt, und durch die Beantwortung der anfangs gestellten Fragen wird die folgende Technologie für die statische Code-Analyse in Usus.net verwendet:
\newline
CCI in Verbindung mit \textit{NRefactory}
\newline
\textsl{FxCop} leider nicht geeignet
\textit{Roslyn} leider nur als CTP verfügbar mit eigenem Compiler (allerdings langfristig die Lösung)
\newline
\newline
TODO! Tabelle mit Fragen als Zeilen und Technologien als Spalten:
\begin{enumerate} 
\item Können alle Informationen gesammelt werden, die benötigt werden um die von Usus berechneten Metriken ebenfalls zu berechnen?
\item Ist die Technologie verfügbar, kostenfrei nutzbar und kann veröffentlicht werden?
\item Unterstützt die Technologie alle .NET Laufzeitumgebungen unter Windows?
\item Ist die Technologie unabhängig von anderen Laufzeitumgebungen und anderen externen Komponenten?
\item Kann die Technologie ein System verarbeiten, das Klassen und Pakete verwendet, die nicht im betrachteten System definiert sind?
\item Ist die Technologie in der Lage ein System zu analysieren, dass nicht nur mit C$\#$ entwickelt wurde?
\item Kann die Technologie mit dem Code und dem Kompilat arbeiten?
\item Ist die Technologie einfach und performant einsetzbar?
\end{enumerate}













\chapter{Usus.net Objektmodell}
todo


\section{Struktur}
todo


\section{Metrikberechnung}
todo




\chapter{Visual Studio Erweiterung}
todo




\chapter{Clean Code Unterstützung}
todo


\section{Achievements System}
todo


\section{Fallbeispiel Andrena-Kurs}
todo




\chapter{Code-Qualität Bewertung}
todo


\section{Histogram}
todo


\section{Exponentialverteilungen}
todo


\section{Heuristiken}
todo


\section{Andrena Software Qualitäts Index}
todo




\chapter{Zusammenfassung}
todo




\chapter{Fazit}
todo









\bibliography{masterthesis}
\bibliographystyle{alpha}

\end{document}
