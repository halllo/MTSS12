\documentclass[
a4paper, 							% Papierformat
%10pt,								% Schriftgröße (12pt, 11pt (Standard))
twoside,							% Doppelseiten
titlepage,						% Titelei auf eigener Seite
%normalheadings,			% Überschriften etwas kleiner (smallheadings)
%idxtotoc,						% Index im Inhaltsverzeichnis
%liststotoc,					% Abb.- und Tab.verzeichnis im Inhalt
%bibtotoc,						% Literaturverzeichnis im Inhalt
%leqno,   						% Nummerierung von Gleichungen links
%fleqn,								% Ausgabe von Gleichungen linksbündig
%draft								% überlangen Zeilen in Ausgabe gekennzeichnet
]
{scrbook}


\usepackage[ngerman]{babel,translator}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tipa}
\usepackage[left=2.25cm,right=2.25cm,top=2cm,bottom=2cm,bindingoffset=1.5cm,includeheadfoot]{geometry}
\usepackage{marvosym}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=[rgb]{0,0,0.4},
    urlcolor=blue
}
\usepackage{mathtools}
\usepackage{listings} \lstset{numbers=left, numberstyle=\tiny, numbersep=5pt, basicstyle=\fontsize{9}{13}\selectfont, xleftmargin=5mm, xrightmargin=5mm, frame=topline} \lstset{language=Java}
\usepackage{shadethm}
\usepackage[table]{xcolor}
\usepackage[nonumberlist]{glossaries}
%\usepackage{glossaries}
\makeglossaries
\include{gloassary}
\usepackage{fancyhdr}


\newshadetheorem{definition}{Definition}
\newshadetheorem{stakeholder}{Interessenvertreter}
\newshadetheorem{goal}{Ziel}
\definecolor{shadethmcolor}{rgb}{.85,.85,.85}   % Farbe des Hintergrundes
\definecolor{shaderulecolor}{rgb}{.8,.8,.8}   % Farbe des Rahmens
\setlength{\shadeboxrule}{1.0pt}   % Breite des Rahmens

\newcommand{\blankpage}{
	\newpage
	\thispagestyle{empty}
	\mbox{}
	\newpage
}

\begin{document}



\begin{titlepage}
\begin{figure}[t]
	\centering
  \includegraphics[width=80mm]{images/HsKaLogoKlein.png}
	\vspace{2.5cm}
\end{figure}
\begin{center}
\title{Master-Thesis}
\textbf{\huge{Master-Thesis}} \\[0.5cm]
\textbf{Visual Studio-Erweiterung zur statischen Code-Analyse} \\[4cm]
\textbf{andrena objects ag} \\[0.25cm]
\author{Manuel Naujoks} Manuel Naujoks\\[2.5cm]
Betreut durch \\[0.25cm] 
Prof. Dr. Thomas Fuchß \\[2.5cm]
Karlsruhe, den \today
\end{center}
\end{titlepage}


\blankpage
\pagenumbering{roman}
\setcounter{page}{1}
\begin{center}\textbf{\large Erklärung}\\[1cm]\end{center}
Hiermit versichere ich, dass ich die vorliegende Arbeit selbstständig verfasst und das darin beschriebene Programm Usus.NET selbstständig programmiert und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe, dass alle Stellen der Arbeit, die wörtlich oder sinngemäß aus anderen Quellen übernommen wurden, als solche kenntlich gemacht sind und dass die Arbeit in gleicher oder ähnlicher Form noch keiner Prüfungsbehörde vorgelegt wurde.
\\[4\baselineskip]
Karlsruhe, den \today \\
Manuel Naujoks




\chapter*{Zusammenfassung}
Das Ziel dieser Arbeit war die Entwicklung und Dokumentation einer Visual Studio-Erweiterung, die dem Entwickler direktes Feedback anhand von \glslink{Metrik}{Softwaremetriken} und daraus abgeleiteten Qualitätskenngrößen gibt. Die Arbeit wurde im Rahmen einer Master-Thesis bei dem Softwareentwicklungshaus andrena objects ag durchgeführt. Dabei diente das Plugin Usus für Eclipse als Vorlage. Die erstellte Erweiterung kann eine \glslink{SCA}{statische Code-Analyse} von .NET-Projekten in Visual Studio 2010 durchführen. Dabei werden bestimmte \glslink{Metrik}{Codemetriken} berechnet, die bei andrena zum Einsatz kommen. Für die Berechnung werden die \glslink{ASM}{Assemblies}, die der Compiler bei jedem Kompiliervorgang erzeugt, mit der \gls{CCI} analysiert. Ein wesentliches Feature der Erweiterung ist die nahtlose Integration in Visual Studio, die es ermöglicht, die \glslink{Metrik}{Metriken} und Qualitätskenngrößen direkt in der Entwicklungsumgebung anzuzeigen.
\paragraph{}
Die entwickelte Erweiterung ist in der Lage, Softwareentwickler bei der Entwicklung von \gls{CleanCode} zu unterstützen. \gls{CleanCode} wurde von Robert C. Martin in seinem Buch "`\gls{CleanCode}"' vorgestellt und verfolgt das Ziel Quellcode besser verstehen und warten zu können. Das automatisierte Feedback erlaubt dem Entwickler, sich über Problemfälle in seinem Code zu informieren und diese schnell zu lokalisieren. Um eine Einschätzung bezüglich der Merkmale von \gls{CleanCode} vorzunehmen, nutzt die Erweiterung die \glslink{Verteilung}{statistischen Verteilungen} der \glslink{Metrik}{Metriken}. Die Analyse dieser \glslink{Verteilung}{Verteilungen} hat zu der Definition einer neuen \gls{CleanCode}-\gls{Metrik} geführt. Zusätzlich kann das Tool andrena's \gls{SQI} berechnen, der eine weitere Interpretation der inneren Qualität der Software ermöglicht. Die Erweiterung protokolliert die Veränderung dieses \gls{SQI} über die Zeit und stellt sie in einem Schaubild dar.
\paragraph{}
Um die entwickelte Erweiterung und dessen Möglichkeiten der Entwicklerunterstützung zu evaluieren, wurde eine Refactoring-Beispielaufgabe aus dem andrena-Kurs "`Agile Software Engineering"' analysiert. Diese Untersuchung bestätigt, dass die Erweiterung die Veränderungen des Quellcodes erkennt und dass die Refactorings zu Veränderungen der \glslink{Metrik}{Metriken}, Qualitätskenngrößen und besonders der neuen \gls{CleanCode}-\gls{Metrik} führen. Um die Leistungsfähigkeit des Werkzeugs zu messen, wurden die \glslink{SCA}{statischen Code-Analysen} einiger Industrie- und Open-Source-Projekte durchgeführt, deren Laufzeit erfasst und die Ergebnisse dokumentiert.
\paragraph{}
Die entwickelte Visual Studio-Erweiterung trägt den Namen Usus.NET und ist als Open-Source-Projekt unter \url{https://github.com/usus/Usus.NET} veröffentlicht. Die innere Softwarequalität des Usus.NET-Projekts wird von Usus.NET mit einen andrena-\gls{SQI} von 82,2\% als sehr positiv bewertet. Die neue \gls{CleanCode}-\gls{Metrik} der Methoden bestätigt dies. Damit stellt Usus.NET eine Grundlage dar, auf dessen Basis weitere Entwicklungen zur Verbesserung der Codequalität vorgenommen werden können.
\newpage



\chapter*{Abstract}
The aim of this thesis was to develop and document a Visual Studio extension that is capable of providing direct development feedback based on \glslink{Metrik}{software metrics} and quality indicators. The extension was developed during a postgraduate internship at the software company andrena objects ag. The Eclipse plugin Usus was used as a guide in terms of project orientation. The developed extension can perform a \glslink{SCA}{static code analysis} of .NET projects inside Visual Studio 2010. Several \glslink{Metrik}{code metrics} that are used in daily business at andrena, are calculated from the compiler generated \glslink{ASM}{assemblies} using the \gls{CCI}. One major feature is the seamless integration into Visual Studio, that enables the display of the \glslink{Metrik}{metrics} and indicators directly within the integrated development environment.
\paragraph{}
The developed extension helps developers to write \glslink{CleanCode}{clean code}. \glslink{CleanCode}{Clean code} was introduced by Robert C. Martins book "'\gls{CleanCode}"' and aims at improving readability and maintainability of source code. Automated feedback allows the developer to localize problematic areas within the code. For assessment of the code concerning the characteristics of \glslink{CleanCode}{clean code}, the extension makes use of the \glslink{Verteilung}{statistical distributions} of the \glslink{Metrik}{metric results}. An analysis of these \glslink{Verteilung}{distributions} has led to the definition of a new \glslink{CleanCode}{clean code} \glslink{Metrik}{metric}. Additionally, the tool can calculate andrena's \glslink{SQI}{software quality index}, which enables further interpretation of inner software quality. The extension records the changes of this \glslink{SQI}{software quality index} and visualizes them in a diagram.
\paragraph{}
The developed extension and its opportunities to support the developer are evaluated. A refactoring exercise of the andrena course "'Agile Software Engineering"' is analyzed to verify that changes in the code are picked up by the extension and lead to changes in the different \glslink{Metrik}{metrics}, indicators and especially in the new \glslink{CleanCode}{clean code} \glslink{Metrik}{metric}. In order to measure the performance of the tool, the \glslink{SCA}{static code analyses} of a number of real-world projects are timed and documented.
\paragraph{}
The developed Visual Studio extension is referred to as Usus.NET and is published as an open source project at \url{https://github.com/usus/Usus.NET}. The inner quality of the Usus.NET project is rated with an andrena \glslink{SQI}{software quality index} of 82,2\%, which is an excellent rating. The new \glslink{CleanCode}{clean code} \glslink{Metrik}{metric} of the methods confirms this. Usus.NET is a foundation and allows for further work on improvement of code quality.
\newpage



\tableofcontents

\listoffigures

\listoftables



\pagestyle{fancy}
\fancyhf{}
\fancyhead[CE]{Visual Studio-Erweiterung zur statischen Code-Analyse} 
\fancyhead[LO]{\tiny{\leftmark}}
\fancyhead[RO]{\small{\rightmark}}
\fancyfoot[LE,RO]{\thepage}




\chapter{Einleitung}
\label{chap:intro}
\pagenumbering{arabic}
\setcounter{page}{1}
Als vor ungefähr 50 Jahren der erste Computer gebaut wurde \cite{ENIAC}, konnte sich wahrscheinlich niemand vorstellen, wie schnell sich diese Rechenmaschinen verbreiten und weiterentwickeln würden. Die technischen Fortschritte, unter anderem in der Prozessortechnologie, haben dafür gesorgt, dass Ende 2008 weltweit mehr als eine Milliarde PCs tatsächlich verwendet wurden \cite{PCsWorldWide}. Dank Moore's Law\footnote[1]{Mehr Informationen: "`Moore's Law Inspires Intel Innovation"' \url{http://www.intel.com/content/www/us/en/silicon-innovations/moores-law-technology.html}} besitzen sogar heutige Smartphones eine erstaunliche Rechenleistung, die wahrscheinlich auch weiterhin steigen wird. Doch mit der rasanten Entwicklung immer fähigerer Hardware, entstehen auch immer neue Möglichkeiten für Software. Aus diesem Grund mussten sich auch die Programmiersprachen weiterentwickeln. Der O'REILLY-Verlag hat dazu ein Poster erstellt, das zeigt, wie Programmiersprachen andere Programmiersprachen beeinflusst haben \cite{ProgrammingLanguages}.
\paragraph{}
Immer umfangreichere Programmiersprachen und Frameworks stellen die Entwickler vor neue Herausforderungen. Diese neuen Möglichkeiten und die damit in Verbindung stehenden Erwartungen der Nutzer, gestalten die Softwareentwicklung zunehmend schwieriger. Die Anforderungen an die moderne Softwareentwicklung sind sogar so hoch, dass viele Projekte scheitern. Die Standish Group veröffentlicht mit dem CHAOS Report\footnote[2]{Mehr Informationen: "`CHAOS Knowledge Center"' \url{http://blog.standishgroup.com/pmresearch}} einen jährlichen Bericht, der die Erfolge und die Fehlschläge von IT-Projekten statistisch aufbereitet. Stefan Hagen interpretiert den CHAOS Report in seinem Blog-Post \cite{ChaosReport} und vergleicht diesen mit anderen Statistiken, um die Ursachen der Fehlschläge zu finden. Um die Probleme zu lösen, wurden verschiedene Modelle von Entwicklungsprozessen formalisiert und angewendet, die beispielsweise auch von Walt Scacchi in seiner Veröffentlichung beschrieben werden \cite{ProcessModels}.
\paragraph{}
Eine Lösung ist das agile Projektmanagement. Mike Cohn zitiert in seinem Blog-Post \cite{AgileIsBetter} den CHAOS Report von 2011 und beschreibt agile Projekte im Durchschnitt als dreimal so erfolgreich wie nicht-agile Projekte. Für die Entwickler bedeutet das konkret, dass sie schneller auf Änderungen der Anforderungen reagieren müssen. Dabei ist die Gefahr groß, dass die Entwickler Schaden an der äußeren und der inneren Qualität der Software anrichten. Mit der äußeren Qualität ist der Funktionsumfang gemeint. Die innere Qualität bezieht sich auf die Struktur und die Form des Quelltext. Während die Verschlechterung der äußeren Qualität in Form von Bugs relativ schnell offensichtlich wird, ist die Verschlechterung der inneren Qualität subtiler. Das kann dazu führen, dass zukünftige Änderungen komplizierter und langsamer vorgenommen werden können. Um dem entgegen zu wirken, haben berühmte Entwickler Bücher geschrieben, die Hilfestellungen enthalten. Zwei der bekanntesten Werke sind Robert C. Martin's Bücher "`Clean Code"' \cite{CleanCode} und "`Clean Coder"' \cite{CleanCoder}. Diese Hilfestellungen adressieren jeden Entwickler und versuchen ihn zu motivieren, verantwortungsbewusst mit Quellcode zu arbeiten. Um diese Hilfestellungen auf den eigentlichen Gegenstand der Softwareentwicklung, nämlich den Quellcode selber, zu übertragen, kann eine \glslink{SCA}{statische Code-Analyse} genutzt werden. Die \glslink{SCA}{statische Code-Analyse} berechnet \glslink{Metrik}{Metriken} des System, die einen Teil der inneren Qualität reflektieren. Moderne Entwicklungsumgebungen bieten momentan nur wenig Möglichkeiten den Quelltext zu analysieren und zu interpretieren. Einige separate Werkzeuge bieten etwas mehr Unterstützung und versuchen, dem Entwicklern so viele Informationen zu liefern, dass er eine bessere Einsicht in das Projekt bekommt.


\section{Aufgabenstellung}
Genau an dieser Stelle setzt diese Master-Thesis an. Es soll ein Werkzeug für .NET-Code entwickelt werden, dass dem Entwickler mehr relevante Informationen über eine Codebasis liefert, als anderen Werkzeuge dies tun. Diese Informationen sollen den Entwickler unterstützen, den Quellcode verantwortungsbewusster zu verändern, sodass der Code eher dem von Robert C. Martin beschriebenen \gls{CleanCode} entspricht. Das zu entwickelnde Tool soll außerdem direkt in Visual Studio integriert sein, sodass der Entwickler das Feedback automatisiert erhält und kein weiteres Werkzeug starten muss. Bei der Entwicklung der Visual Studio-Erweiterung soll ein Programm aus der Java-Welt als Orientierung dienen. Die Eclipse-Erweiterung Usus analysiert den Code und berechnet und gewichtet Kennzahlen, die dem Entwickler helfen können, eine bessere Einsicht in seinen Code zu bekommen. In dieser Master-Thesis soll ein Tool entwickelt werden, das einen vergleichbarem Funktionsumfang hat und zusätzliche Interpretationsmöglichkeiten bietet. Dabei soll die \gls{Verteilung} der \glslink{Metrik}{Metriken} untersucht und mit \gls{CleanCode} in Verbindung gebracht werden. Zusätzlich soll der andrena-\gls{SQI} berechnet werden, um eine Codebasis noch schneller einschätzen zu können.


\section{andrena objects ag}
\label{sec:andrena}
Diese Master-Thesis wird bei dem Unternehmen andrena objects ag in Karlsruhe durchgeführt. andrena ist ein Softwareentwicklungs- und beratungshaus, das keine eigenen Produkte vertreibt, sondern sein Know How in der agilen Softwareentwicklung in Form von Projektunterstützung, Lösungen (Auftragsarbeiten) und Training an seine Kunden weitergibt. Dabei spielen die in Unterabschnitt \ref{subsec:cleancode} beschriebenen Konzepte, Extreme Programming und \gls{CleanCode}, eine besondere Rolle. Um die moderne Softwareentwicklung immer weiter zu verbessern, ist andrena daran interessiert, sowohl die Fähigkeiten der Entwickler als auch die Fähigkeiten der eingesetzten Werkzeuge weiterzuentwickeln. Aus diesem Grund soll diese Master-Thesis die technologische Weiterentwicklung der agilen Entwicklung unterstützen. Jedes Projekt, an dem andrena beteiligt war, konnte, laut eigenen Angaben, bisher erfolgreich beendet werden \cite{andrena}. Diesen außergewöhnlichen Erfolg begründet andrena mit dem Konzept des \emph{agilen Software Engineering} und genau dieses Konzept soll, durch das in dieser Master-Thesis zu entwickelnde Programm, weiter unterstützt werden.


\section{Aufbau dieses Dokuments}
Die vorliegende Master-Thesis beschreibt die Entwicklung einer Visual Studio-Erweiterung zur \glslink{SCA}{statischen Code-Analyse}. Mit einer agilen Anforderungsanalyse werden zuerst die Anforderungen an das System und eine Planung der Entwicklungsaufgaben dokumentiert. Dadurch entsteht eine konkretere Vorstellung der Software, die im Folgenden entwickelt werden soll. Anschließend wird die zeitliche Planung und nachträglich die tatsächliche Durchführung beschrieben. Anhand bereits bestehender Werkzeuge und theoretischen Ideen wird analysiert, wie diese Software die definierten Anforderungen realisieren kann. Dadurch werden die grundlegenden Funktionen des Systems spezifiziert. Nach dieser Analysephase wird die Entwicklung des Programms beschrieben, indem zuerst auf die zentralen Komponenten eingegangen wird, die die eigentlichen Berechnungen anstellen. Danach wird die Integration dieser zentralen Komponenten in Visual Studio dokumentiert. Bis zu dieser Stelle wurde dann also ein System beschrieben, welches eine \glslink{SCA}{statische Code-Analyse} direkt in Visual Studio durchführen kann. Auf dieser Grundlage aufbauend, können dann weitere Funktionen konzipiert und implementiert werden. Es werden dann Funktionen spezifiziert, die das \gls{CleanCode}-Level und den \gls{SQI} einer Codebasis berechnen. In diesem Zusammenhang wird dann auch die dafür nötige Implementierung beschrieben. Abschließend wird die entwickelte Software evaluiert, indem zum Einen die Laufzeit der \glslink{SCA}{Analyse} verschiedener Projekte gemessen wird. Zum anderen wird ein Refactoring-Beispiel von andrena analysiert, bevor die Ergebnisse beider Evaluierungen beschrieben werden. Das Dokument endet mit einer Zusammenfassung und einem Ausblick, indem mögliche Weiterentwicklungen des Systems vorgeschlagen werden. 
\paragraph{}
In diesem Dokument sind Querverweise farbig dargestellt. Adressen zu Websites und Verweise auf Quellen des Literaturverzeichnis sind dabei \textcolor[rgb]{0,0,1}{blau} hervorgehoben. Verweise auf Kapitel, Abschnitte, Abbildungen, Tabellen, Listings, Formeln, Definitionen und Bezeichnungen im Glossar sind \textcolor[rgb]{0,0,0.4}{dunkelblau} gekennzeichnet. In dem Glossar werden häufig auftretende Bezeichnungen, die in dieser Master-Thesis von hoher Bedeutung sind, zusätzlich an einer zentralen Stelle beschrieben. Durch die farbige Hervorhebung wird auf diese Bedeutung explizit hingewiesen. Die digitale Version dieser Master-Thesis erlaubt es, über einen Klick auf diese farbigen Stellen direkt zu der Position der referenzierten Stelle zu springen. Wörter in \emph{kursiver} Form haben eine implizite Bedeutung und beziehen sich auf einen besonderen Kontext. Um auf externe Informationen hinzuweisen, wurden Fussnoten und das Literaturverzeichnis verwendet. Im Literaturverzeichnis werden essentielle und häufig mehrfach referenzierte Quellen aufgeführt, die für den Zusammenhang wichtig sind. Die Fussnoten dagegen beschreiben weniger wichtige Quellen, die nur an der Stelle interessant sind, an der sie verwendet werden. Zusätzlich werden Definitionsblöcke verwendet, um Begriffe mit einer besonderen Bedeutung kurz zu beschreiben. Wenn die besonderen Begriffe eine umfangreichere Beschreibung erfordern, wird diese Beschreibung in einem eigenen Abschnitt vorgenommen.




\chapter{Grundlagen}
\label{chap:basics}
In diesem Kapitel sollen die Grundlagen vermittelt werden, die für ein Verständnis einer mit Quellcode arbeitenden Erweiterung für Visual Studio erforderlich sind. Dazu wird in Abschnitt \ref{sec:generalbasics} zunächst auf allgemeine Grundlagen wie Quellcode, sowie Entwicklungsumgebungen eingegangen. Anschließend werden in Abschnitt \ref{sec:technicalbasics} die technischen Grundlagen vorgestellt.


\section{Allgemeine Grundlagen}
\label{sec:generalbasics}
In diesem Abschnitt wird zunächst auf die \gls{CleanCode}-Idee von Robert C. Martin sowie einige seiner Prinzipien eingegangen. Anschließend werden die beiden Entwicklungsumgebungen Eclipse und Visual Studio vorgestellt. Beide Programme sind in dieser Master-Thesis von Bedeutung, da die zu entwickelnde Erweiterung in ähnlicher Form bereits für Eclipse existiert und für Visual Studio ebenfalls erstellt werden soll.

\subsection{Clean Code}
\label{subsec:cleancode}
Ein Softwaresystem wird in Form von Quellcode erstellt. Dieser Code wird anschließend kompiliert um eine ausführbares Programm zu erhalten. Robert C. Martin beschreibt Code in seinem Buch "`Clean Code"' als Sprache, in der die Entwickler die Anforderungen an die Software maschinenlesbar zum Ausdruck bringen \cite{CleanCode}. Weiter beschreibt er in seinem Buch auch Prinzipien und Best Practices, die das Erstellen von verständlicherem und wartbareren Quellcode unterstützen. Die selben Prinzipien wurden auch von Ralf Westphal und Stefan Lieser aufgegriffen und im Rahmen eines Wertesystems mit sieben Graden vorgestellt \cite{CleanCodeDeveloper}. Martin's Buch "`Clean Code"' bleibt auch für Westphal und Lieser die grundlegende Lektüre. Die Prinzipien und Best Practices der \gls{CleanCode}-Bewegung umfassen viele Aspekte, die bereits durch Kent Beck in seinem Buch über die Methodik \emph{Extreme Programming} (XP) \cite{XP} eingeführt wurden. Drei wichtige Bestandteile von XP, die ebenfalls in den Graden des \gls{CleanCode}-Wertesystems von Westphal und Lieser auftreten, werden jetzt wie folgt definiert.
\begin{definition}[Automatisiertes Testen]
\emph{Automatisiertes Testen} ist eine der wichtigsten Praktiken in der \gls{CleanCode}-Bewegung. Dabei werden Testfälle in Verbindung mit dem Code implementiert. Diese Testfälle sind per Knopfdruck ausführbar und informieren den Entwickler darüber, ob das System noch alle spezifizierten Funktionen erfüllt.
\end{definition}
Laut Robert C. Martin ist es die Aufgabe eines Entwicklers, keinen Schaden in einem Softwaresystem anzurichten \cite{CleanCoder}. Damit meint er Schaden an der Funktionalität der Anwendung (äußere Qualität) und Schaden an der Struktur und Form des Quelltext (innere Qualität). Beides kann mit automatisierten Testfällen verhindert werden.
\begin{definition}[Ständiges Refactoring]
\emph{Ständiges Refactoring} ist der effektivste Schutz gegen Schäden an der Struktur und der damit verbundenen inneren Qualität eines Softwaresystems. Durch evolutionäres Wachstum und viele Anpassungen kann es vorgenommen, dass die Struktur einer Codebasis neue Anpassungen nicht optimal unterstützt. Dieses Ändern der Struktur, damit Anpassungen wieder besser unterstützt werden, wird als Refactoring bezeichnet. 
\end{definition}
Durch Tests kann sichergestellt werden, dass Refactorings den Funktionsumfang und damit die äußere Qualität nicht beeinträchtigen. Martin Fowler beschreibt solche Refactorings und deren Vorteile in seinem Buch \cite{Refactoring}.
\begin{definition}[Schnelle Codereviews]
\emph{Schnelle Codereviews} sind eine weitere Voraussetzung um Code entwickeln zu können, der wirklich lesbar, verständlich und wartbar ist. Der entscheidende Punkt ist das Feedback. Je schneller der Entwickler Feedback bekommt, um so früher können Probleme im Quellcode erkannt und mit relativ wenig Aufwand korrigiert werden.
\end{definition}

\subsection{Eclipse}
\label{subsec:eclipse}
Eclipse\footnote[1]{Download und mehr Informationen: "`Eclipse Foundation"' \url{http://www.eclipse.org/}} ist eine \emph{integrierte Entwicklungsumgebung} (engl. Integrated Development Environment, IDE) der Eclipse Foundation. Die Anwendung ist ein kostenfreies Open-Source-Programm und wird hauptsächlich für die Entwicklung von Software mit der Programmiersprache Java\footnote[2]{Download und mehr Informationen: "`Java"' \url{http://www.oracle.com/us/technologies/java/index.html}} verwendet. Eclipse unterstützt externe Erweiterungen in Form von Plugins.

\subsection{Visual Studio}
\label{subsec:visualstudio}
Visual Studio\footnote[3]{Mehr Informationen: "`Microsoft Visual Studio 2010 Produktfamilie"' \url{http://www.microsoft.com/germany/visualstudio/products/default.aspx}} ist eine integrierte Entwicklungsumgebung von Microsoft. Im Gegensatz zu Eclipse ist Visual Studio ab der Professional-Version ein kommerzielles Produkt. Die Entwicklung für das .NET Framework\footnote[4]{Download und mehr Informationen: "`Microsoft .NET Framework"' \url{http://www.microsoft.com/net}} von Microsoft kann mit Visual Studio durchgeführt werden, wobei mehrere Programmiersprachen unterstützt werden. Zu den bekanntesten und am weitesten verbreiteten Sprachen des .NET Frameworks zählen C$^\sharp$ und Visual Basic.NET.
\paragraph{}
Visual Studio erlaubt die Installation von externen Erweiterungen als Addin oder Erweiterung ab der Professional-Version. Die kostenfreie Express Edition besitzt einen sehr eingeschränkten Funktionsumfang. Der Unterschied zwischen einem Visual Studio-Addin und einer Visual Studio-Erweiterung ist der, dass Addins bereits in früheren Versionen unterstützt wurden und ein Entwickler die Schnittstellen in Visual Studio direkt anprogrammieren kann. Die Erweiterungen werden ab Visual Studio 2010 unterstützt und benötigen zur Entwicklung das Visual Studio 2010 SDK\footnote[5]{Download: "`Visual Studio 2010 SP1 SDK"' \url{http://www.microsoft.com/download/en/details.aspx?id=21835}}, erlauben aber eine modernere Nutzung der Automatisierung-API. Aaron Marten beschreibt in seinem Artikel \cite{VSCustomExtensions} die Möglichkeiten, wie mit der neuen Erweiterungstechnologie (VSIX) Addin-ähnliche Erweiterungen erstellt werden können.


\section{Technische Grundlagen}
\label{sec:technicalbasics}
In diesem Abschnitt werden die technischen Grundlagen erläutert. Dazu wird zunächst der Begriff der Objektorientierung eingeführt, da sämtliche Softwaresysteme, die in dieser Master-Thesis betrachtet werden, objektorientiert sind. Anschließend werden Graphen und Bäume beschrieben, da verschiedene \glslink{Metrik}{Softwaremetriken} anhand dieser Datenstruktur berechnet werden können. Abschließend wird das Konzept der statischen Code-Analyse vorgestellt, da die zu entwickelnde Erweiterung eben diese durchführen können soll.

\subsection{Objektorientierung}
\label{subsec:oo}
Die Objektorientierung ermöglicht laut Grady Booch, die hohe Komplexität von Softwaresystemen zu beherrschen \cite{OOAnalysisDesign}. Das ist möglich, da diese Methode die Dinge der realen Welt als Objekte sieht und dadurch die Problemdomäne verständlich und anschaulich macht. Ein objektorientiertes Softwaresystem besteht aus fünf wesentlichen Komponenten, die jetzt wie folgt definiert werden. Die lateinischen Übersetzungen sind aus dem Buch von Bernd Oestereich übernommen \cite{OOSE}.
\begin{definition}[Klasse]
\emph{Klasse} kommt aus dem lateinischen von \emph{classis} und bedeutet "`Aufgebot"'. Eine Klasse der Typ aller seiner Objekte. Klassen können abstrakt sein. Eine abstrakte Klasse, oder auch Schnittstelle genannt, kann nicht als Objekt erzeugt werden. Eine nicht-abstrakte Klasse, also eine konkrete Klasse, muss von dieser Klasse eine Vererbung der Struktur und des Verhaltens durchführen. Von dieser erbenden konkreten Klasse kann dann ein Objekt erzeugt werden, das sowohl vom Typ der konkreten Klasse als auch vom Typ der abstrakten Klasse ist.
\end{definition}
Grady Booch bezeichnet eine Klasse auch als Menge von Objekten der gleichen Struktur und des gleichen Verhaltens. 
\begin{definition}[Objekt]
\emph{Objekt} kommt ebenfalls aus dem lateinischen von \emph{obicere} und bedeutet "`entgegenhalten"'. Ein Objekt ist eine Instanz einer Klasse und stellt die Funktionen und Daten einer logischen Einheit in einem Softwaresystem dar.
\end{definition}
Grady Booch beschreibt ein Objekt als ein Etwas, das einen Zustand, ein Verhalten und eine Identität hat \cite{OOAnalysisDesign}. Laut Bertrand Meyer kann auf ein Objekt per Referenz zugegriffen werden \cite{OOSoftwareConst}.
\begin{definition}[Attribut]
\emph{Attribut} kommt auch aus dem lateinischen von \emph{attributum} und bedeutet "`das Beigefügte"', was einer Eigenschaft oder einem Kennzeichen einer Sache entspricht. Die Daten, die ein Objekt ausmachen, werden anhand von Attributen gespeichert. Auf die Attribute kann von den Operationen des Objekts aus zugegriffen werden kann. Attribute werden auch als Felder bezeichnet und lassen sich in Klassenfelder und Instanzfelder unterscheiden. Klassenfelder können von allen Objekten der Klasse gemeinsam genutzt werden, während Instanzfelder unterschiedliche Werte für konkrete Objekte haben können.
\end{definition}
\begin{definition}[Operation]
\emph{Operation} kommt aus dem lateinischen von \emph{operatio} und bedeutet "`Handlung"'. Eine konkrete Aktion, die anhand einer definierten Vorschrift durchgeführt wird, bezeichnet Oestereich in diesem Sinne als Operation. Das Verhalten von Objekten wird anhand ihrer Operationen festgelegt. Andere Bezeichnungen für Operation ist Funktion oder Methode. Methoden lassen sich in Klassenmethoden und Instanzmethoden aufteilen. Klassenmethoden können nicht auf die Instanzfelder sondern nur auf die Klassenfelder zugreifen. Instanzmethoden können auf Instanzfelder und auf Klassenfelder zugreifen.
\end{definition}
\begin{definition}[Paket]
\emph{Paket} ist ein hierarchisches Gruppierungskonstrukt, dass es erlaubt Klassen und andere Pakete zu gruppieren. Pakete werden auch als Namespaces bezeichnet, da sie eine benannte Zusammenfassung von Klassen und anderen Namespaces sind.
\end{definition}
Ein Paket wird von Bernd Oestereich als eine Ansammlung von Modellelementen bezeichnet \cite{OOSE}. Dabei sind Modellelemente Klassen oder andere Pakete und dienen der besseren Strukturierung des Systems. Grady Booch beschreibt zwei weitere Mittel von objektorientierten Softwaresystemen \cite{OOAnalysisDesign}, die der Abstraktion dienen und die es erlauben, Verantwortlichkeiten einfacher zu organisieren. Beide Konzepte werden jetzt ebenfalls definiert.
\begin{definition}[Assoziation]
\emph{Assoziation} kommt aus dem lateinischen von \emph{associare} und bedeutet "`verbinden"'. Eine Assoziation verbindet zwei Klassen, sodass Objekte der einen Klasse auf Objekte der verbundenen Klasse zugreifen können. Damit ist die Klasse, von der die Assoziation ausgeht, von der anderen Klasse abhängig. Anders ausgedrückt hat diese Klasse eine Abhängigkeit von der anderen.
\end{definition}
Bernd Oestereich beschreibt eine Assoziation als eine \emph{Hat-eine-Beziehung}, die angibt, dass eine Klasse mit einer anderen Klasse zusammenarbeitet. Grady Booch bezeichnet diese Zusammenarbeit auch als semantische Verbindung.
\begin{definition}[Vererbung]
\emph{Vererbung} erlaubt es Klassen, das Verhalten und die Struktur anderer Klassen zu erben oder zu spezialisieren. Ein Objekt der erbenden Klasse hat dabei erstmal die gleiche Struktur und das gleiche Verhalten, wie ein Objekt der vererbenden Klasse oder Oberklasse genannt. Diese Struktur und das Verhalten können von der erbenden Klasse verändert werden. Die erbende Klasse hat eine Abhängigkeit von der Oberklasse.
\end{definition}
Vererbung wird von Grady Booch auch als eine \emph{Ist-ein-Beziehung} beschrieben. Mit diesen sieben Konzepten kann ein objektorientiertes Softwaresystem vollständig beschrieben werden.

\subsection{Graphentheorie}
\label{subsec:graphs}
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben einen Graph in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} als Tupel \begin{math}G = (V, E)\end{math}. Der erste Wert, $V$, ist eine endliche Menge an Knoten und der zweite, $E$, ist eine endliche Menge an Kanten zwischen diesen Knoten. Eine Kante ist ein Paar aus \begin{math}V \times V\end{math} und beinhaltet die beiden Knoten, die sie verbindet. Cormen und co unterscheiden in gerichtete und ungerichtete Graphen. Bei Letzterem verbindet eine Kante die Knoten in beiden Richtungen, wobei eine gerichtete Kante die Verbindungsrichtung anhand der Knoten-Reihenfolge im Kanten-Tupel vorgibt. Ein gerichteter Graph wird auch als Digraph bezeichnet. Weiter definieren Cormen und seine Koautoren einen Baum als zusammenhängenden azyklischen Graph, indem jeder Knoten von einem Wurzelknoten aus erreichbar ist. %Seite 1168, 1173

\subsection{Statische Code-Analyse}
\label{subsec:staticcodeanalysis}
Artur Wagner beschreibt in seiner Seminar-Ausarbeitung \cite{IntroStaticCodeAnalysis} die \glslink{SCA}{statische Code-Analyse} als Prozess, der von einem Compiler-ähnlichen Programm gestartet wird. Dieses Programm führt den Code nicht aus und erzeugt auch keinen ausführbaren Code, sondern nimmt eine \glslink{SCA}{Analyse} des Codes vor. Wagner erwähnt noch, dass eine \glslink{SCA}{statische Code-Analyse} keinen Korrektheitsnachweis liefert sondern lediglich eine Art Systemzusammenfassung erzeugt. Eine solche \glslink{SCA}{Analyse} findet dabei automatisiert statt. Christof Ebert, Reiner Dumke, Manfred Bundschuh und Andreas Schmietendorf stellen ebenfalls den Vergleich mit einem Compiler an. In ihrem Buch \cite{BPSoftwareMeasurement} erwähnen sie zusätzlich noch ein Qualitätsmodell, das mit dem Ergebnis der \glslink{SCA}{Analyse} in Verbindung gebracht wird und so eine einfache Interpretierbarkeit des analysierten Systems ermöglicht. Zusätzlich beschreiben sie den Vorgang als Sammeln von \glslink{Metrik}{Metriken} und deren Bewertung anhand von Kriterien.
\paragraph{}
Nadine Vehring beschreibt eine \emph{\gls{Metrik}} in ihrer Seminar-Ausarbeitung \cite{TestabilityMetrics} als Maß dafür, wie sehr eine "`Entität"' ein "`Attribut"' erfüllt. Als "`Entität"' bezeichnet Vehring einen Teil des analysierten Systems, also beispielsweise eine Methode, Klasse oder eine Menge von Klassen. Weiterhin beschreibt sie ein "`Attribut"' als Eigenschaft, die im betrachteten System, also bei den "`Entitäten"' gemessen werden soll. In der vorliegenden Master-Thesis wird eine \gls{Metrik} wie folgt definiert.
\begin{definition}[Metrik]
\emph{\gls{Metrik}} ist der Begriff für eine bestimmte und tatsächlich gemessene Eigenschaft, die Methoden, Klassen, Paketen, oder Mengen von diesen, im zu analysierenden System besitzen. Damit sind die \glslink{Metrik}{Metriken} das direkte Ergebnis einer \glslink{SCA}{statischen Code-Analyse}. Der Begriff wird häufig auch synonym für die Eigenschaft verwendet, die gemessen werden soll.
\end{definition}
\begin{definition}[Statistik der Metrik]
Die \emph{Statistik der \gls{Metrik}} ist die Bezeichnung für die zusammengefassten Werte einer \glslink{Metrik}{Metrik} in einem System. Diese Werte können vor und nach der Aggregation gewichtet und bewertet werden.
\end{definition}
Das einzelne Methoden oder Klassen in einer Statistik nicht berücksichtigt werden, kann bei der Berechnung der Statistik ebenfalls festgelegt werden. Marc Philipp und Nicole Rauch unterscheiden in ihrem Artikel \cite{EclipseMagUsus} ebenfalls zwischen \gls{Metrik} und Statistik. Die \glslink{Metrik}{Metriken} eines Systems können auch manuell bestimmt werden. In dieser Master-Thesis werden \glslink{Metrik}{Metriken} aber immer als automatisiert bestimmbar und damit als Ergebnis einer automatisierten statischen Code-Analyse betrachtet. Das Konzept der \glslink{SCA}{statischen Code-Analyse} kann auch genutzt werden, um subjektive explizite Probleme im Code zu lokalisieren. Dazu gehören beispielsweise die Verwendung von obsoleten Klassen und Methoden, sowie fehlende Klassenkommentare und unkonventionelle Benennungen. In dieser Master-Thesis wird das Konzept der \glslink{SCA}{statischen Code-Analyse} ausschließlich für die Bestimmung der \glslink{Metrik}{Metriken} verwendet, die in Abschnitt \ref{sec:metrics} beschrieben werden.




\chapter{Anforderungen}
\label{chap:requirements}
In diesem Kapitel werden die Anforderungen an die Visual Studio-Erweiterung zur statischen Code-Anaylse beschrieben, die im Rahmen dieser Master-Thesis entwickelt werden soll. Dabei werden die Anforderungen in einem agilen Kontext wie Sprint 0\footnote[1]{Agile Anforderungsanalyse: "`10 Things to do in Sprint 0"' \url{http://www.pmscrum.com/blog/2011/06/10-things-do-sprint-0}} bestimmt und in Form von Zielen, Interessenvertreter, Use Cases und User Stories definiert. Dieses Kapitel gibt damit eine Antwort auf die Frage, was während dieser Master-Thesis gemacht werden soll.


\section{Interessenvertreter}
\label{sec:stakeholder}
Die \emph{Interessenvertreter} (engl. Stakeholder) im Kontext dieser Master-Thesis sind Gruppen von Personen, die einen Einfluss auf Anforderungen des Systems haben können. Die folgenden fünf Gruppen wurden dafür identifiziert.
\begin{stakeholder}[andrena objects ag]
\label{stake:andrena}
Als Arbeitgeber stellt andrena das Umfeld dar, indem das Projekt durchgeführt und das System implementiert wird. Sie legt Wert auf agile Softwareentwicklung und möchte Entwicklungsprozesse und Praktiken gewinnbringend einsetzen. Die andrena objects ag hat bereits ein Plugin zur statischen Code-Analyse für Java und Eclipse entwickelt und möchte ihren Entwicklern ein ähnliches Programm auch für die .NET-Umgebung zur Verfügung stellen können.
\end{stakeholder}
\begin{stakeholder}[Leser dieser Thesis]
\label{stake:reader}
Die Leser der vorliegenden Thesis haben ebenfalls ein Interesse an dem zu entwickelnden Produkt. Dieses Interesse ist dabei hauptsächlich theoretischer Natur. Sie haben einen Informatik-artigen Hintergrund und möchten einen Einblick in die Algorithmen und die Implementierungsdetails sämtlicher implementierten Aspekte des Systems erhalten.
\end{stakeholder}
\begin{stakeholder}[.NET-Entwickler mit wenig Erfahrung]
\label{stake:littleex}
Entwickler mit wenig Erfahrung arbeiten an Projekten mit relativ wenig Quellcode und wollen auf einfache Weise einen Überblick über Problemfälle des Systems behalten. Mithilfe des Systems wollen sie diese rechtzeitig beseitigen und sicherstellen, dass dadurch keine neuen Probleme entstehen.
\end{stakeholder}
\begin{stakeholder}[.NET-Entwickler mit viel Erfahrung]
\label{stake:muchex}
Entwickler mit viel Erfahrung arbeiten an Projekten mit viel und kompliziertem Quellcode. Sie möchten das System einsetzen um Tendenzen im System zu erkennen und Spezialfälle zu analysieren. Auch sie wollen einen besseren Überblick erhalten und das System aus möglichst vielen verschiedenen Perspektiven sehen.
\end{stakeholder}
\begin{stakeholder}[.NET, \gls{CleanCode}-Entwickler]
\label{stake:cleancoder}
Clean Coder legen sehr viel Wert auf Quellcode, der möglichst einfach zu verstehen ist und damit schnell an neue Anforderungen angepasst werden kann. Sie erwarten von dem System Feedback und Unterstützung bei der Entwicklung von sauberem Code. Außerdem möchten sie auf Stellen im Code hingewiesen werden, die nicht ihren Vorstellungen entsprechen.
\end{stakeholder}
Die Beschreibungen der Interessengruppen sind grob und allgemein gehalten, während versucht wurde, die direkten Bedürfnisse der jeweiligen Gruppe zu benennen. Natürlich ist die Erklärung damit nicht vollständig oder exklusiv. So kann beispielsweise auch ein erfahrener .NET-Entwickler ein Interesse an \gls{CleanCode} haben.


\section{Ziele}
\label{sec:goals}
Nachdem die beteiligten Interessengruppen definiert wurden, werden in diesem Abschnitt die Ziele des zu entwickelnden Systems beschrieben. Peter Hruschka und Chris Rupp erklären in ihrem Buch \cite{AgileSEUML} ein Ziel als "`ein erstrebenswerter Zustand"' in der Zukunft, den es zu erreichen gilt\footnote[1]{Seite 26}. Damit ist ein Ziel eine abstrakte Form einer Anforderung an das System, die sich auch in einem agilen Projekt nicht so schnell ändert wie spezielle Anforderungen. In der vorliegenden Arbeit werden nun die folgenden vier Ziele definiert.
\begin{goal}[Einsicht in die Codebasis]
\label{goal:insight}
Große Entwicklungsprojekte haben eine große Codebasis, die es den Entwicklern erschwert, Aussagen über den Quellcode des Systems zu treffen. Mithilfe statischer Code-Analyse kann eine Einsicht in diesen Quellcode gewährleistet und so zum Vorteil aller Interessenvertreter genutzt werden. Eigenschaften des Quellcodes können als \glslink{Metrik}{Metriken} berechnet und bewertet werden. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Eigenschaften des Codes erkennen und darauf reagieren kann.
\end{goal}
\begin{goal}[Erkennen von Problemfällen]
\label{goal:problems}
In einer vorhandenen Codebasis besteht die Gefahr, den Überblick über Problemfälle zu verlieren. Ein Problem kann beispielsweise eine Klasse sein, die zu viele Abhängigkeiten zu anderen Klassen hat, oder eine Methode, die zu viel Funktionalität besitzt. Das Erkennen und Anzeigen dieser Stellen ist ein Vorteil, von dem alle Interessenvertreter profitieren können und der es ermöglicht, Schwachstellen systematisch zu entfernen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Probleme im Code erkennen und darauf reagieren kann.
\end{goal}
\begin{goal}[Förderung von \gls{CleanCode}]
\label{goal:cleancode}
Das Entwickeln von Quellcode kann auf eine sehr rücksichtslose Art und Weise geschehen, sodass spätere Anpassungen nur schwer vorzunehmen sind. Durch motivierendes Feedback während der Programmierung, kann die Entwicklung von \gls{CleanCode} gefördert werden. Das führt zu einer Codebasis, die flexibler auf Anpassungen reagieren kann. Dieses Ziel ist erreicht, sobald ein Entwickler mehr \gls{CleanCode}-Prinzipien und -Praktiken beachtet und einhält, als er dies ohne Unterstützung des Systems getan hätte.
\end{goal}
\begin{goal}[Interpretation der Softwarequalität]
\label{goal:interpret}
Um eine bestehende Codebasis zu bewerten, ist eine detaillierte Kenntnis über alle Klassen, deren Interaktionen und vielem mehr, erforderlich. Außerdem muss eine Bewertung durch ein Codereview manuell jedes mal neu erfolgen, ist subjektiv und fehleranfällig. Eine teilweise automatisierte Interpretation anhand von Regeln und Gewichtungen, die auf Erfahrungen basieren, kann die menschliche Bewertung optimieren und einem Entwickler jederzeit mit verhältnismäßig geringem Aufwand eine Qualitätsinterpretation ermöglichen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, die Qualität des Quellcodes durch Interpretation einschätzen und mit anderen Systemen vergleichen kann.
\end{goal}


\section{Architektur}
\label{sec:architecture}
In diesem Abschnitt wird die grundlegende Architektur des zu entwickelnden Systems erläutert. Im Rahmen dieser Master-Thesis soll ein System entwickelt werden, dass die in Abschnitt \ref{sec:goals} genannten Ziele erreicht. Zusätzlich soll dieses System als Erweiterung in Visual Studio laufen und den Quelltext (kompiliert und/oder unkompiliert) in einer .NET-Sprache, wie beispielsweise C$^\sharp$, analysieren. Abbildung \ref{fig:architecture} zeigt die beiden Komponenten \emph{Visualisierung} und \emph{\gls{SCA}}, um die es sich im weiteren Verlauf handeln wird.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/architektur.jpg}
	\caption{Grobe Architektur des zu entwickelnden Systems}
	\label{fig:architecture}
\end{figure}
Die Komponente, die die \glslink{SCA}{statische Code-Analyse} durchführt, verwendet drei Aktionen, die einem kompletten Analyseprozess entsprechen. Die schwarzen Pfeile symbolisieren dabei Zugriffe auf Daten. Die Aktion \emph{Berechnung} betrachtet das Softwaresystem und kann dafür auf den Quellcode und das erzeugte Kompilat zugreifen. Das Ergebnis dieser Betrachtung wird in Form von \glslink{Metrik}{Metriken} in einer Datenbank gespeichert, die die Daten für die Aktion \emph{Gewichtung} bereitstellt. Diese gewichtet die Daten und erzeugt Statistiken, die ebenfalls in der Datenbank hinterlegt werden. Die Aktion \emph{Bewertung} versucht anhand der gewichteten Daten eine Aussage über die Qualität des Softwaresystems zu treffen. Nachdem diese drei Aktionen abgelaufen sind, ist der Analyseprozess beendet. Die Komponente \emph{Visualisierung}, die in Visual Studio ausgeführt wird, kann diesen Analyseprozess starten und auf dessen Daten zugreifen. Sie zeigt die berechneten \glslink{Metrik}{Metriken} in geeigneten Darstellungsformen an und gibt, basierend auf der Bewertung, ein entsprechendes Entwicklerfeedback. Dieses Feedback bezieht sich direkt auf den Quellcode, der von der \glslink{SCA}{statischen Code-Analyse} verarbeitet wurde. Nach einer Veränderung des Quelltext, kann der Prozess erneut gestartet werden, um auch diese Veränderung zu analysieren. So entsteht theoretisch ein kontinuierlicher Verbesserungskreislauf. Dieser Zyklus wird durch die breiten transparenten Pfeile angezeigt und entspricht dem Informationsfluss in dieser Umgebung.


\section{Use Cases}
Aus den in Abschnitt \ref{sec:goals} festgelegten Zielen dieses Projekts lassen sich zunächst vier Anwendungsfälle bestimmen, die in Abbildung \ref{fig:usecases} dargestellt sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/usecases.jpg}
	\caption{Anwendungsfälle des zu entwickelnden Systems}
	\label{fig:usecases}
\end{figure}
Die Akteure entsprechen ungefähr den in Abschnitt \ref{sec:stakeholder} definierten Interessenvertretern. Alle Akteure sind .NET-Entwickler und unterscheiden sich durch ihr Interesse. \emph{.NET-Entwickler mit Interesse an Metriken} entspricht ungefähr dem .NET-Entwickler mit wenig Erfahrung (Interessenvertreter \ref{stake:littleex}). Seine Interaktion mit dem System beschränkt sich auf die Bestimmung von \glslink{Metrik}{Codemetriken} sowie der Identifizierung von Code-Problemen als Verletzung definierter \gls{Metrik}-Grenzen. Der .NET-Entwickler mit viel Erfahrung (Interessenvertreter \ref{stake:muchex}) findet sich im Akteur \emph{.NET-Entwickler mit Interesse an Qualitätsinterpretation} wieder. Er benutzt das System um eine Interpretation der Qualität zu erhalten, die anhand der \glslink{Metrik}{Metriken} vorgenommen wird. Der Akteur \emph{.NET-Entwickler mit Interesse an \gls{CleanCode}} ist an den Clean Code-Entwickler (Interessenvertreter \ref{stake:cleancoder}) angelehnt. Er lässt sich durch das System bei der Erzeugung von \gls{CleanCode}, wie er in Unterabschnitt \ref{subsec:cleancode} beschrieben wurde, unterstützen. Diese Hilfestellung geschieht anhand der Code-Probleme, die durch \glslink{Metrik}{Codemetriken} erkannt werden. Es ist ebenfalls zu sehen, dass der Anwendungsfall \emph{Codemetriken bestimmen} alle anderen Anwendungsfälle direkt oder indirekt ergänzt. Damit ist er ein entscheidender Bestandteil des Systems, wenn nicht sogar der wichtigste. andrena objects ag (Interessenvertreter \ref{stake:andrena}) und Leser des Thesis (Interessenvertreter \ref{stake:reader}) haben keine direkte Interaktion mit dem System und werden bei der Betrachtung der Use Cases ignoriert. 


\section{Produkt-Backlog}
\label{sec:productbacklog}
Die Anwendungsfälle lassen sich in \emph{User Stories} ("`Anwendererzählungen"') unterteilen. Abbildung \ref{fig:productbacklog} zeigt diese Aufteilung in der horizontalen und die Verteilung auf geplanten Iterationen in der vertikalen Dimension. Dieses zwei-dimensionale Backlog stellt die konkreten Anforderungen aus Benutzersicht an das komplette System dar.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/backlog.jpg}
	\caption{Produkt-Backlog des zu entwickelnden Systems}
	\label{fig:productbacklog}
\end{figure}
Die User Stories sind allgemein gehalten, da auf ein großes Design vor der Implementierung aus Agilitätsgründen verzichtet wurde. Pro Iteration werden die User Stories dann in konkrete Entwicklungs-Aufgaben unterteilt. Die Begründung jeder Story wurde nicht explizit aufgeschrieben, da die Beziehung zu den Use Cases und damit den Zielen aus Abschnitt \ref{sec:goals} erhalten und offensichtlich geblieben ist. Eine Priorisierung ist ebenfalls implizit durch das Aufteilen auf die Iterationen entstanden, sodass eine explizite Business Value-Analyse nicht notwendig ist. Da die Entwicklungsgeschwindigkeit noch nicht bekannt ist, ist die Planung der Iterationen vorläufig. Eine Änderung kann also jederzeit erfolgen, wenn neue Use Cases und User Stories dazukommen, andere wegfallen oder nicht alle in einer Iteration geschafft werden. Zum Zeitpunkt dieser Planung lassen sich die bereits gefunden User Stories in schätzungswiese fünf Iterationen implementieren. 
\paragraph{}
Was die Abnahmekriterien jeder Anwendererzählung betrifft, so wurde auch hier kein Mehrwert in der expliziten Definition gesehen. Pro Story kann ohne viel Aufwand ein exemplarischer manueller Akzeptanztest durchgeführt werden, der zeigt, ob das Ziel erreicht wurde. Zusätzlich können automatisierte Akzeptanztests zu Beginn der jeweiligen Iterationen festgelegt werden.




\chapter{Vorgehensweise}
Nachdem die Anforderungen an das System, das in dieser Masther-Thesis entwickelt werden soll, in Kapitel \ref{chap:requirements} definiert wurden, wird in diesem Kapitel die Vorgehensweise beschrieben. Dieses Kapitel gibt damit eine Antwort auf die Frage, wann die Anforderungen realisiert werden sollen. Dabei wird zuerst eine grobe Zeitplanung vorgestellt, die zu Beginn der Thesis erstellt wurde. Anschließend wird dieser ursprüngliche Plan mit der tatsächlichen zeitlichen Durchführung verglichen, dessen Plan gegen Ende der Thesis erstellt wurde. Abbildung \ref{fig:planning1} zeigt die zeitliche Aufteilung der Aufgaben zu Beginn der Master-Thesis und nimmt eine Aufteilung in einen praktischen und einen theoretischen Teil vor. Beide Teile überlagern sich, sodass eine Dokumentation der Implementierung zeitnah erfolgen kann und keine große Schreibphase gegen Ende des sechsmonatigen Zeitrahmen notwendig ist.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planning1.png}
	\caption{Ursprünglicher Projektplan}
	\label{fig:planning1}
\end{figure}


\section{Praktischer Teil}
Der praktische Teil besteht aus einer Evaluierungsphase und der eigentlichen Implementierungsphase. Während der Evaluierung werden verschiedene Technologien betrachtet, mit denen eine \glslink{SCA}{statische Code-Analyse} durchgeführt werden kann. Das Ergebnis der Evaluierung wird die Grundlage der nächsten Phase darstellen. In der zweiten Phase werden die User Stories aus Abschnitt \ref{sec:productbacklog} in fünf zweiwöchigen (10 Tage) Iterationen implementiert.
\begin{description}
\item[Iteration 1] 16.05.12 bis 29.05.12
\item[Iteration 2] 01.06.12 bis 14.06.12
\item[Iteration 3] 19.06.12 bis 02.07.12
\item[Iteration 4] 05.07.12 bis 18.07.12
\item[Iteration 5] 01.08.12 bis 14.08.12
\end{description}
Nach jeder Iteration liegt eine funktionstüchtige Version der Visual Studio-Erweiterung zur statischen Code-Analyse vor. Außerdem folgen allen Iterationen Phasen der schriftlichen Zusammenfassung.


\section{Theoretischer Teil}
Der theoretische Teil entspricht hauptsächlich der Dokumentation aller Ergebnisse und deren Beschreibung in Form der schriftlichen Ausarbeitung dieser Master-Thesis. So werden in einer Planungsphase zunächst Grundlagen (Kapitel \ref{chap:basics}) beschrieben, sowie eine agile Anforderungsanalyse (Kapitel \ref{chap:requirements}) durchgeführt. Außerdem wird das Usus-Programm, dessen Funktionsumfang einen maßgeblichen Einfluss auf das entwickelte System hat, näher betrachtet und dessen \glslink{Metrik}{Metriken} beschrieben (Kapitel \ref{chap:usus}). Anschließend wird das Ergebnis der Evaluierungsphase beschrieben (Kapitel \ref{chap:techeval}), bevor die tatsächlichen Iterationen in Form von schriftlichen Zusammenfassungen abgeschlossen werden (Kapitel \ref{chap:ususnet}, \ref{chap:ususnetvsext}, \ref{chap:cleancodesupport} und \ref{chap:andrenasqi}). Nach der Zusammenfassung der vierten Iteration wird eine Fallstudio auf Basis eines andrena-Kurs zum Thema Refactoring durchgeführt. Bei diesem Kurs wird das in dem praktischen Teil entwickelte System eingesetzt und ermittelt, wie gut das Werkzeug einen Entwickler unterstützt (Kapitel \ref{chap:evaluation}). Unmittelbar vor der fünften und vorläufig letzten Iteration wird eine Analyse von \glslink{Verteilung}{statistischen Verteilungen} der \gls{Metrik}{Metriken} sowie deren Bedeutung erfolgen (Kapitel \ref{chap:cleancodesupport}).


\section{Tatsächlicher Ablauf}
Nach der ersten Iteration bestand das in dieser Master-Thesis entwickelte Programm nur aus einem Kommandozeilenwerkzeug, welches \glslink{ASM}{Assemblies} einlesen und deren Methoden analysieren konnte. In der anschließenden Zusammenfassung sind große Teile von Kapitel \ref{chap:ususnet} entstanden. Die zweite Iteration hat eben dieses Kommandozeilenwerkzeug um die Fähigkeit auch Klassen analysieren zu können erweitert. Kapitel \ref{chap:ususnet} konnte danach abgeschlossen werden. Erst nach der dritten Iteration war das Programm zum ersten Mal als Erweiterung in Visual Studio lauffähig und führte die \glslink{SCA}{Analysen} bei jedem Build-Vorgang durch. Die daraus resultierende Zusammenfassung war aufwendiger als erwartet und dauerte vier Tage. Dabei ist Kapitel \ref{chap:ususnetvsext} entstanden. Die darauf folgende vierte Iteration musste daher um eine halbe Woche verschoben werden. Der neue Zeitraum dieser Iteration ist 09.07.12 bis 20.07.12.
\paragraph{}
Nach dieser vierten Iteration hatte das Programm als Visual Studio-Erweiterung die Fähigkeit eine \gls{CleanCode}-\gls{Metrik} sowie den \gls{SQI} zu bestimmen. Ein besseres Verständnis der Use Cases \emph{\gls{CleanCode}-Hilfe bekommen} (Ziel \ref{goal:cleancode}) und \emph{Softwarequalität interpretieren} (Ziel \ref{goal:interpret}) hat dazu geführt, dass die für die fünfte Iteration geplanten User Stories aus Abschnitt \ref{sec:productbacklog} bereits in der vierten Iteration implementiert werden konnten. Die anschließende Zusammenfassung dieser Iteration dauerte dadurch länger. Für den \gls{CleanCode}-Teil, der in Kapitel \ref{chap:cleancodesupport} beschrieben wird, und den \glslink{SQI}{SQI}-Teil, der in Kapitel \ref{chap:andrenasqi} vorgestellt wird, wurden jeweils drei Tage benötigt. Da für diese Zusammenfassung aber nur zwei Tage eingeplant waren, wurde das Refactoring-Fallbeispiel geringer priorisiert und als Teil der fünften Iteration vorgenommen. Diese fünfte und letzte Iteration brauchte daraufhin nicht wieder verschoben zu werden.
\paragraph{}
Während der fünften Iteration wurden einige Fehler des Programms behoben, sowie die Performance gemessen und verbessert. Außerdem wurde die \glslink{SCA}{Analyse} des andrena-Fallbeispiels durchgeführt. Die Zusammenfassungen der Laufzeitmessungen und des Fallbeispiels konnten in jeweils zwei Tagen abgeschlossen und in Kapitel \ref{chap:evaluation} als Evaluierung der Visual Studio-Erweiterung beschrieben werden. Da die fünftägige Analyse der \gls{Metrik}-\glslink{Verteilung}{Verteilungen} als Teil der \gls{CleanCode}-\gls{Metrik} bereits in der vierten Iteration implementiert werden konnte, konnten diese Tage gespart und die zeitliche Verspätung wieder aufgeholt werden. Abbildung \ref{fig:planning2} stellt den tatsächlichen Projektablauf grafisch dar.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planning2.png}
	\caption{Tatsächlicher Projektablauf}
	\label{fig:planning2}
\end{figure}




\chapter{Usus}
\label{chap:usus}
Das Wort \emph{usus} kommt aus dem Lateinischen und bedeutet "`das, was üblich ist"'. In diesem Kapitel wird das Usus-Plugin \cite{UsusEclipsePlugin} für die Java-Entwicklungsumgebung Eclipse vorgestellt, sowie auf die \glslink{Metrik}{Metriken}, die es berechnet, eingegangen. Das Usus-Programm ist im Rahmen einer Initiative von andrena (Abschnitt \ref{sec:andrena}) entstanden. Usus entspricht im Groben dem Werkzeug für Eclipse und Java, das im Rahmen dieser Master-Thesis auch für Visual Studio und .NET entwickelt werden soll. Aus diesem Grund wird dessen Funktionsumfang an dieser Stelle betrachtet, um ihn besser in nachimplementieren zu können. Eine direkte Portierung ist anhand der Technologieunterschiede von Visual Studio und Eclipse, sowie .NET und Java höchstwahrscheinlich nicht möglich, sodass diese Option in der vorliegenden Master-Thesis nicht weiter verfolgt wird.


\section{Eclipse-Plugin}
\label{sec:eclipseusus}
Über den Menüeintrag \texttt{Help / Install New Software} lässt sich das Usus-Plugin für Eclipse installieren. Dort muss zunächst eine neue Software Site mit der URL \url{http://projectusus.googlecode.com/svn/updates/} hinzugefügt und anschließend "`Project Usus"' ausgewählt werden. Nach der Installation steht die "`Project Usus perspective"' zur Verfügung, die die folgenden Fenster enthält.

\subsection{Usus Cockpit}
\label{subsec:ususcockpit}
In diesem Fenster werden die Usus-\glslink{Metrik}{Metriken} angezeigt, die für alle Projekte, die Usus betrachtet, berechnet werden. Zusätzlich wird der Trend pro \gls{Metrik} dargestellt, also ob sich die Ausprägung der \gls{Metrik} verbessert oder verschlechtert hat. Die Verbesserung wird dabei zwischen zwei erstellten Snapshots gemessen, die entweder manuell oder durch einen neuen Speichervorgang ausgelöst werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=8cm]{images/usus_cockpit.png}
	\caption{Usus Cockpit zeigt Übersicht über alle Projekte}
	\label{fig:usus_cockpit}
\end{figure}
Die in Abbildung \ref{fig:usus_cockpit} dargestellten Statistiken der \glslink{Metrik}{Metriken} errechnen sich aus der Aggregation der Paket-, Klassen- oder Methoden-Eigenschaften.

\subsection{Usus Info}
\label{subsec:ususinfo}
Dieses Fenster lässt sich im Kontext einer Methode oder einer Klasse öffnen und zeigt \glslink{Metrik}{Metriken}, die anhand der Eigenschaften des Kontextes ermittelt werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=8cm]{images/usus_info.png}
	\caption{Usus Info zeigt Übersicht über eine Methode oder Klasse}
	\label{fig:usus_info}
\end{figure}
Das in Abbildung \ref{fig:usus_info} gezeigte Info-Fenster lässt sich mit \texttt{Ctrl-U} öffnen und mit \texttt{Esc} wieder schließen.

\subsection{Usus Hotspots}
\label{subsec:usushotspots}
Dieses Fenster zeigt sogenannte Hotspots, also Stellen im Quellcode, dessen \glslink{Metrik}{Metriken} definierte Grenze oder einen Schwellwert überschreiten. Hotspots lassen sich für jede \gls{Metrik} einsehen, die im Usus Cockpit angezeigt wird. Zusätzlich wird der Trend pro Hotspot angezeigt, also ob sich die \gls{Metrik} des Hotspots verbessert oder verschlechtert.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_hotspots.png}
	\caption{Usus Hotspots zeigt die Stellen im Code, die eine besonders negative Ausprägung der \glslink{Metrik}{Metriken} haben}
	\label{fig:usus_hotspots}
\end{figure}
Das in Abbildung \ref{fig:usus_hotspots} gezeigte Hotspot-Fenster zeigt Hotspots immer nur für eine \gls{Metrik} an. Der Wechsel zu einer anderen Hotspot-\gls{Metrik} erfolgt über einen Doppelklick auf die Metrikanzeige im Usus Cockpit. Über einen Doppelklick auf einen Hotspot lässt sich entweder zu der dazugehörigen Methode im Quelltext oder dem entsprechende Paket oder der Klasse in einem der beiden Usus Graph-Ansichten navigieren.

\subsection{Usus Histogram}
Dieses Fenster zeigt die absolute Häufigkeitsverteilung der Ausprägungen einer \gls{Metrik} über alle Projekte an, die Usus betrachtet. Die verwendete \gls{Metrik} wird dabei auf der der x-Achse angezeigt, während die Anzahl der Ausprägungen auf der y-Achse dargestellt wird. Die \gls{Verteilung} lässt sich für eine der \glslink{Metrik}{Metriken} einsehen, die im Usus Cockpit angezeigt werden.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_histogram.png}
	\caption{Usus Histogram zeigt die \glslink{Verteilung}{statistische Verteilung} der Werte der ausgewählten \gls{Metrik}}
	\label{fig:usus_histogram}
\end{figure}
Das in Abbildung \ref{fig:usus_histogram} gezeigte Histogramm-Fenster zeigt die \gls{Verteilung} der \gls{Metrik} an, die zuvor über einen Einfachklick im Usus Cockpit markiert wurde. Es werden immer nur die Daten für eine \gls{Metrik} angezeigt. Die Ansicht kann vergrößert, verkleinert, skaliert und als Grafik gespeichert werden.

\subsection{Usus Class Graph \& Usus Package Graph}
\label{subsec:ususgraphs}
Diese Fensterkombination zeigt die Abhängigkeiten der betrachteten Projekte entweder auf Klassenebene oder auf Paketebene an. Auf Paketebene lassen sich optional nur die Pakete anzeigen, die sich in einem Zyklus von Abhängigkeiten zu anderen Paketen befinden. Auf Klassenebene lassen sich optional nur die Klassen anzeigen, die über eine Abhängigkeit über Paketgrenzen hinweg verfügen. Dabei werden auch nur eben diese paketübergreifenden Abhängigkeiten angezeigt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_graph.png}
	\caption{Usus Graph Schaubilder zeigen die Abhängigkeiten der Klassen oder Pakete voneinander an}
	\label{fig:usus_graph}
\end{figure}
Das in Abbildung \ref{fig:usus_graph} dargestellte Fenster besteht eigentlich aus zwei Fenstern. Eine Fenster zeigt den Usus Class Graph, während das andere den Usus Package Graph darstellt. Zwischen den beiden Ansichten kann beliebig gewechselt werden. Die Knoten in den Graphen lassen sich mit der Maus frei positionieren. Zusätzlich lassen sich die Darstellungen der Graphen auch automatisch anordnen.


\section{Metriken}
\label{sec:metrics}
In den Fenstern Usus Cockpit und Usus Info zeit das Eclipse-Plugin die Werte verschiedener \glslink{Metrik}{Metriken} an. Das Usus Info-Fenster zeigt im Kontext einer Methode neben den \glslink{Metrik}{Methodenmetriken} auch die \glslink{Metrik}{Klassenmetriken} an. In diesem Abschnitt wird daher zuerst auf die \glslink{Metrik}{Metriken} eingegangen, die das Usus-Plugin für Methoden berechnet, bevor die \glslink{Metrik}{Klassenmetriken} näher betrachtet werden. Abschließend werden die \glslink{Metrik}{Metriken} beschrieben, die im Usus Cockpit angezeigt werden. Diese Beschreibungen sind von Bedeutung, da sämtliche \glslink{Metrik}{Metriken} im Rahmen der Usus-Erweiterung für Visual Studio nachimplementiert werden sollen.

\subsection{Pro Methode}
Wenn das Usus Info-Fenster im Kontext einer Methode geöffnet wird, wird die \glslink{CC}{zyklomatische Komplexität} sowie die \gls{ML} angezeigt.
\subsubsection{Zyklomatische Komplexität}
\label{subsubsec:cyclomaticcomplexity}
Die \gls{Metrik} \emph{\gls{CC}} (engl. Cyclomatic Complexity, CC) wurde von Thomas J. McCabe vorgestellt \cite{AComplexityMeasure}, um Methoden anhand von linear unabhängigen Ablaufpfaden in Bezug auf Komplexität zu bewerten. McCabe bezieht sich in seinem Artikel auf die Graphentheorie und errechnet die Komplexität eines Ablaufgraphen wie folgt.
\begin{equation}
v(G) = e - n + 2p
\label{eq:cyclomaticcomplexity1}
\end{equation}
\begin{eqnarray*}
G&=&\text{Ablaufgraph}\\
v(G)&=&\text{zyklomatische Komplexität von $G$}\\
e&=&\text{Anzahl Kanten im Ablaufgraph $G$}\\
n&=&\text{Anzahl Knoten im Ablaufgraph $G$}\\
p&=&\text{Anzahl Zusammenhangskomponenten in $G$}\\
\label{eq:cyclomaticcomplexity1agenda}
\end{eqnarray*}
Ernest Wallmüller beschreibt die \glslink{CC}{zyklomatische Komplexität} in seinem Buch \cite{SoftwareQMPraxis} auch als Anzahl aller entscheidungstreffenden Stellen in der Methode. Im Falle einer Verkettung von binären Entscheidungen zu logischen Ausdrücken, zählt jede Entscheidung als eine solche Stelle. Diese einfachere Rechnung ergibt sich als
\begin{equation}
	v(G) = 1 + \Big( \sum_{\displaystyle b \in Bs(G)} 1 \Big)
\label{eq:cyclomaticcomplexity2}
\end{equation}
wobei $Bs(G)$ die Menge aller binären Entscheidungen im Ablaufgraph $G$ darstellt. Voraussetzung für diese Rechnung ist, dass die Methode nur einen Eingang und nur einen Ausgang besitzt. Der Quellcode in Listing \ref{listing:simpleifs} soll die Grundlage für eine demonstrative Berechnung der zyklomatischen Komplexität darstellen.
\begin{lstlisting}[caption={Einfache if-Verschachtelung},label={listing:simpleifs}]
public void doSomething() {
   if (condition1) {
      if (condition2 || condition3)
         do1();
   }
}
\end{lstlisting}
Nach Formel \ref{eq:cyclomaticcomplexity2} ergeben sich drei Entscheidungsstellen, welche durch die drei binären Bedingungen dargestellt werden. Die \glslink{CC}{zyklomatische Komplexität} entspricht damit \begin{math}v(G) = 1 + 3 = 4\end{math}.
\begin{figure}[h]
	\centering
		\includegraphics[width=9cm]{images/cc.jpg}
	\caption{Ablaufgraph G des Quellcodes \ref{listing:simpleifs}}
	\label{fig:ccsamplegraph}
\end{figure}
Die Berechnung anhand Formel \ref{eq:cyclomaticcomplexity1} basiert auf der Struktur des Ablaufgraphen, der in Abbildung \ref{fig:ccsamplegraph} dargestellt ist. Hier entspricht die \glslink{CC}{zyklomatische Komplexität} \begin{math}v(G) = 10 - 8 + 2 * 1 = 4\end{math}. Die Ergebnisse beider Rechnungen sind identisch. Die Eigenschaften einer Methode, die für die Berechnung der \glslink{CC}{zyklomatische Komplexität} erforderlich sind, sind also entweder die Anzahl der binären Entscheidungen oder der vollständige Ablaufgraph.
\subsubsection{Methodenlänge}
\label{subsubsec:methodlength}
Die Länge einer Methode kann auf unterschiedliche Weise ermittelt werden. Eine Unterscheidung der Möglichkeiten wird von Mark Lorenz und Jeff Kidds in \cite{OOSMetrics} vorgenommen. In der vorliegenden Arbeit werden zwei Möglichkeiten wie folgt definiert.
\begin{definition}[Anzahl Code-Zeilen]
Die \emph{Anzahl der Code-Zeilen} (engl. Lines of code) entspricht der tatsächlichen Anzahl an Zeilenumbrüchen ohne leere Zeilen und Kommentarzeilen. Diese Längenangabe ist stark vom Entwicklerstil abhängig und kann sich daher unterschiedlich ausprägen, je nachdem wie beispielsweise eine Parameterliste umgebrochen wird.
\end{definition} 
\begin{definition}[Anzahl der Anweisungen]
Die \emph{Anzahl der Anweisungen} (engl. Number of statements) ist eine stabilere Längenangabe. Eine Anweisung ist jeder durch ein Semikolon abgeschlossene Ausdruck, sowie Bedingungs- und Wiederholungsanweisungen.
\end{definition} 
Die im Usus Info-Fenster angezeigte \glslink{ML}{Methodenlänge} entspricht der Anzahl der Anweisungen der Methode. Eine Berechnung kann daher über die Aufsummierung der Semikola und der \texttt{if}-, \texttt{switch}-, \texttt{for}-, \texttt{while}- und \texttt{try-catch}-Anweisungen erfolgen.

\subsection{Pro Klasse}
\label{subsec:perclass}
Wenn das Usus Info-Fenster im Kontext einer Klasse geöffnet wird, wird die \gls{CS} sowie die \glslink{CCD}{kumulierte Komponentenabhängigkeit} der Klasse dargestellt.
\subsubsection{Klassengröße}
\label{subsubsec:classsize}
Ähnlich der \glslink{ML}{Methodenlänge} lässt sich auch die Größe einer Klasse auf verschiedene Weise berechnen. Lorenz und Jeff unterscheiden mehrere Möglichkeiten \cite{OOSMetrics}. In der vorliegenden Master-Thesis werden im folgenden zwei Varianten der \gls{CS} definiert.
\begin{definition}[Anzahl der Methoden]
Indem die \emph{Anzahl der Methoden} betrachtet wird, können Klassen erkannt werden, die zu viele oder zu wenige Funktionen erfüllen. Weitere Unterscheidungsmöglichkeiten sind Methoden in Klassen- und Instanzmethoden aufzuteilen oder Methoden anhand der Sichtbarkeit zu klassifizieren. Ein Konstruktor würde sich wie eine statische Methode, also eine Klassenmethode, verhalten.
\end{definition} 
\begin{definition}[Anzahl der Felder]
Indem die \emph{Anzahl der Felder} betrachtet wird, können Klassen erkannt werden, die zu viele Informationen verwalten. Auch hier ist eine weitere Unterteilung in Klassen- und Instanzfelder möglich. Die Sichtbarkeit der Felder erlaubt eine weitere Einschränkung.
\end{definition}
Das Usus Info-Fenster zeigt als \gls{CS} die Anzahl der Instanzmethoden, der Klassenmethoden sowie der Konstruktoren an. Dabei wird die Sichtbarkeit der Methode oder des Konstruktors nicht berücksichtigt. Das Usus-Plugin fokussiert damit auf die Funktion der Klassen und nicht auf die Information und das Wissen einer Klasse, welches in den Feldern liegt. Die \gls{CS} kann also berechnet werden, wenn alle Methoden und Konstruktoren einer Klasse ermittelt werden können.
\subsubsection{Kumulierte Komponentenabhängigkeit}
\label{subsubsec:ccd}
Die \gls{Metrik} \emph{\gls{CCD}} (engl. Cumulative Component Dependency, CCD) ist laut Peter Grogono \cite{SoftwareQControl} eine \gls{Metrik}, die für Systeme und Untersysteme ermittelt wird. Dabei werden für jede Klasse (Komponente) in diesem System die Anzahl der Klassen ermittelt, von denen die betrachtete Klasse direkt und indirekt abhängt. Eine Klasse ist immer auch von sich selbst abhängig. Marc Philipp und Nicole Rauch bezeichnen diese Abhängigkeiten in ihrem Artikel \cite{EclipseMagUsus} als reflexsiv und transitiv. Anschließend werden die Abhängigkeiten aller betrachteten Klassen aufsummiert und ergeben den \glslink{CCD}{CCD}-Wert des Systems. In dem Usus Info-Fenster wird dieser Abhängigkeitswert einer betrachteten Klasse als "`CCD (of class)"' bezeichnet. Um die Anzahl der Klassen zu bestimmen, von denen eine betrachtete Klasse abhängig ist, ist mindestens der vollständige Abhängigkeitsgraph der Klasse erforderlich. Mit einem Durchmusterungsalgorithmus kann die Erreichbarkeitsmenge (Reach-Menge) der Klasse (Startknoten) in diesem Abhängigkeitsgraph mit linearer Laufzeit $O(V+E)$ ermittelt werden. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} die beiden Algorithmen \emph{Breadth First Search} (BFS) und \emph{Depth First Search} (DFS) für diesen Zweck. %Seite 594, 603
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/ccd.jpg}
	\caption{Abhängigkeitsgraph einer Klasse mit aufsummierten Abhängigkeiten}
	\label{fig:ccd}
\end{figure}
Abbildung \ref{fig:ccd} zeigt sieben Klassen, die in einer hierarchischen Abhängigkeitsstruktur stehen. Offensichtlich ist Klasse A von allen anderen Klassen direkt oder indirekt abhängig und hat damit den \glslink{CCD}{CCD}-Wert sieben. Dies entspricht der Kardinalität der Reach-Menge von A, \begin{math}\{A,B,C,D,E,F,G\}\end{math}, die ermittelt wird, indem BFS oder DFS mit Klasse A als Startknoten im Abhängigkeitsgraph gestartet wird. Dabei werden die durch den Algorithmus markierten Knoten als Ergebnis des Algorithmus behandelt. Bei dem Abhängigkeitsgraph muss es sich nicht um einen Baum handeln. Formel \ref{eq:cumulativecomponentdependencyofclass} zeigt die Berechnungsvorschrift unter Verwendung des DFS-Algorithmus.
\begin{equation}
	ccd(c) = | DFS(dG, c) |
\label{eq:cumulativecomponentdependencyofclass}
\end{equation}
\begin{eqnarray*}
dG&=&\text{Abhängigkeitsgraph des Systems}\\
c&=&\text{Klasse im System}\in dG\\
ccd(c)&=&\text{CCD-Wert der Klasse } c\\
\label{eq:cumulativecomponentdependencyofclassagenda}
\end{eqnarray*}
Die Berechnung des \glslink{CCD}{CCD}-Werts einer Klasse kann also durchgeführt werden, sobald ein Abhängigkeitsgraph erzeugt werden kann. Um einen solchen Graphen zu erzeugen, müssen die direkten Abhängigkeiten aller Klassen ermittelt werden können. Jede Klasse wird dann einem Knoten zugeordnet und jede Abhängigkeit einer gerichteten Kante. Eine grafische Darstellung (siehe Unterabschnitt \ref{subsec:ususgraphs}) ist dann ebenfalls möglich. Die direkten Abhängigkeiten einer Klasse können bestimmt werden, wenn die Typen aller Felder, Variablen, Methodenparameter, Oberklasse, Interfaces und sämtlicher Methodenaufrufe entfernter Klassen identifiziert werden können. Abhängigkeiten zu Klassen außerhalb des betrachteten Systems, wie beispielsweise \texttt{String} oder \texttt{Object}, können ignoriert werden.

\subsection{Projektübergreifend}
\label{subsec:allprojectsmetrics}
Neben den \glslink{Metrik}{Metriken}, die Usus für Methoden und Klassen berechnet, werden im Usus Cockpit Statistiken zu der Codebasis angezeigt. Dafür werden die ermittelten \glslink{Metrik}{Metriken} so bewertet, wie es Marc Philipp und Nicole Rauch in ihrem Artikel \cite{EclipseMagUsus} beschreiben. In diesem Unterabschnitt werden die verscheiden Statistiken vorgestellt und auf ihre Bewertung eingegangen. Weiterhin werden die Schwellwerte der Statistiken definiert, anhand derer eine Klasse, Methode oder Paket als Hotspot (siehe Unter-Unterabschnitt \ref{subsec:usushotspots}) eingestuft wird.
\subsubsection{Durchschnittliche Komponentenabhängigkeit}
\label{subsubsec:acd}
Die \gls{Metrik} \emph{\gls{ACD}} (engl. Average Component Dependency, ACD) ist laut Peter Grogono \cite{SoftwareQControl} eine \gls{Metrik}, die für Systeme und Untersysteme ermittelt wird. Dabei wird der Mittelwert der in Unterabschnitt \ref{subsubsec:ccd} beschriebenen \glslink{CCD}{kumulierten Komponentenabhängigkeiten} der Klassen des Systems wie in Formel \ref{eq:averagecomponentdependency1} berechnet, wobei $n$ die Anzahl der Klassen ist.
\begin{equation}
	acd = \frac{ccd}{n}
\label{eq:averagecomponentdependency1}
\end{equation}
Da Usus die \glslink{CCD}{CCD}-Werte nicht für Systeme oder Untersysteme ermittelt, sondern die \glslink{CCD}{CCD}-Werte der Klassen bestimmt ohne sie aufzusummieren (siehe Unterabschnitt \ref{subsubsec:ccd}), kann der \glslink{ACD}{ACD}-Wert anhand einer Menge von Klassen $Cs$ berechnet werden, wie in Formel \ref{eq:averagecomponentdependency2} dargestellt. Die Rechnung ist äquivalent zu Formel \ref{eq:averagecomponentdependency1}.
\begin{equation}
	acd(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} ccd(C)}{|Cs|}
\label{eq:averagecomponentdependency2}
\end{equation}
Peter Grogono beschreibt die Bedeutung des \glslink{ACD}{ACD}-Werts als durchschnittliche Anzahl an Komponenten, die durch eine Änderung einer Komponente betroffen sind und eventuell ebenfalls geändert werden müssen. Der \glslink{ACD}{ACD}-Wert wird im Usus Cockpit als Statistik in Prozent angezeigt. Dazu wird nochmal der Mittelwert über die betrachteten Klassen gebildet, was in Formel \ref{eq:averagecomponentdependency3} zu sehen ist und der Bewertungsfunktion von Philipp und Rauch entspricht.
\begin{equation}
	acd'(Cs) = \frac{acd(Cs)}{|Cs|}
\label{eq:averagecomponentdependency3}
\end{equation}
Eine Klasse wird von Usus dann als Hotspot betrachtet, wenn ihr \glslink{CCD}{CCD}-Wert über einer Schwelle liegt, die von der Projektgröße abhängig ist. Die Projektgröße wird dabei als Anzahl der Klassen festgelegt. Anhand der Tooltip-Erklärung im Usus Cockpit liegt diese Schwelle für kleine Projekte bei 15\% der Klassenanzahl, während bei großen Projekten 5\% der Klassenanzahl verwendet wird. Dafür haben Philipp und Rauch Formel \ref{eq:averagecomponentdependency4} mithilfe von Erfahrungswerten definiert, um die Berechnung des \glslink{CCD}{CCD}-Schwellwert-Faktors $L_{ccd}$ anhand der Menge aller Klassen $Cs$ im System durchführen zu können.
\begin{equation}
	L_{ccd}(Cs) = \frac{1,5}{2^{\displaystyle (\log_{5} |Cs|)}}
\label{eq:averagecomponentdependency4}
\end{equation}
Um den tatsächlichen Schwellwert für eine Menge von Klassen $Cs$ zu bestimmen, muss der Faktor $L_{ccd}(Cs)$ noch mit der Anzahl der Klassen $|Cs|$ multipliziert werden.
\subsubsection{Durchschnittliche Klassengröße}
Eine Klasse wird von Usus als Hotspot gesehen, sobald die in Unterabschnitt \ref{subsubsec:classsize} beschriebene \gls{CS} den Schwellwert 12 übersteigt. Das haben Philipp und Rauch festgelegt. Die im Usus Cockpit angezeigte \glslink{ACS}{durchschnittliche Klassengröße}  betrachtet nur die Klassen, die bereits als Hotspot markiert wurden. Das liegt an der Bewertungsfunktion $rating_{cs}$ von Philipp und Rauch, die in Formel \ref{eq:averageclasssize1} angegeben ist.
\begin{equation}
	rating_{cs}(cs) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{cs}{12}\bigg) - 1, & \text{wenn }cs > 12\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averageclasssize1}
\end{equation}
Die Bewertungsfunktion der \gls{CS} $cs$ ist direkt von dem Schwellwert 12 abhängig und bewertet alle Klassen, dessen Größe 12 oder weniger beträgt mit 0. Um die \glslink{ACS}{durchschnittliche Klassengröße}  $acs$ einer Menge von Klassen $Cs$ zu berechnen, bildet Usus den Mittelwert aller bewerteten Klassengrößen. Dazu wird die Formel \ref{eq:averageclasssize2} verwendet.
\begin{equation}
	acs(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} rating_{cs}(c)}{|Cs|}
\label{eq:averageclasssize2}
\end{equation}
Dabei gehen die mit 0 bewerteten \glslink{CS}{Klassengrößen} ebenfalls in die Durchschnittsberechnung mit ein.
\subsubsection{Durchschnittliche zyklomatische Komplexität}
Die Berechnung der \glslink{ACC}{durchschnittlichen zyklomatischen Komplexität} findet auf ähnliche Weise statt. Philipp und Rauch haben dafür den Schwellwert 4 gewählt. Damit werden Methoden ignoriert, die vier oder weniger unabhängige Ablaufpfade besitzen oder anders ausgedrückt, weniger als vier verschiedene Entscheidungen treffen. Die Bewertungsfunktion $rating_{cc}$ eines wie in Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} berechneten zyklomatischen Komplexitäts-Wert sieht damit folgendermaßen aus.
\begin{equation}
	rating_{cc}(cc) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{cc}{4}\bigg) - 1, & \text{wenn }cc > 4\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagecyclomaticcomplexity}
\end{equation}
Anschließend kann der Mittelwert der bewerteten Komplexitäten gebildet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Durchschnittliche Methodenlänge}
Auch die Berechnung der \glslink{AML}{durchschnittlichen Methodenlänge} findet ähnlich statt. Philipp und Rauch haben den Schwellwert für diese \gls{Metrik} auf 9 festgelegt \cite{EclipseMagUsus}. Methoden mit 9 oder weniger Anweisungen werden damit ignoriert. Die Bewertungsfunktion $rating_{ml}$ sieht dann folgendermaßen aus.
\begin{equation}
	rating_{ml}(ml) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{ml}{9}\bigg) - 1, & \text{wenn }ml > 9\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagemethodlength}
\end{equation}
Aus den bewerteten Längen kann wieder der Mittelwert berechnet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Anzahl nicht-statischer öffentlicher Felder}
\label{subsubsec:nonstaticpublicfields}
Wenn eine Klasse mindestens ein öffentliches Feld hat, das nicht statisch oder eine Konstante ist, dann betrachtet Usus diese Klasse als einen Hotspot. Dabei wird jede Klasse mit 1 bewertet, die mindestens eines dieser Felder besitzt. Der Schwellwert ist ebenfalls 1. Die Anzahl der betroffenen Klassen wird wie jede andere \gls{Metrik} im Usus Cockpit über die Anzahl aller Klassen gemittelt und somit als Prozent dargestellt.
\subsubsection{Pakete mit zyklischen Abhängigkeiten}
\label{subsubsec:packetswithcyclicdependencies}
Für Klassen wurde in Unterabschnitt \ref{subsubsec:ccd} ein Abhängigkeitsgraph unabhängig vom Paket ermittelt, in dem sich die betrachtete Klasse befindet. Um \glslink{NCD}{Pakete mit zyklischen Abhängigkeiten} zu identifizieren, müssen alle Klassenknoten eines Pakets zu einem Paketknoten in einem neuen Abhängigkeitsgraph auf Paketebene zusammengefasst werden. Die Kanten zwischen den Klassen werden zu Kanten zwischen den Paketen. Anschließend können alle trivialen Kreise im Abhängigkeitsgraph der Pakete entfernt und Zyklen gesucht werden. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} den Algorithmus \emph{Strongly Connected Components} (SCC, starke Zusammenhangskomponenten) mit linearer Laufzeit $O(V+E)$ für diesen Zweck. Mit diesem Algorithmus können alle starken Zusammenhangskomponenten (SCCs) eines Graphen ermittelt werden. Da per Definition von Cormen und co alle Knoten in einer SCC sich gegenseitig erreichen können, handelt es sich um Kreise. Folglich enthalten alle starken Zusammanhangskomponenten, die mehr als eine Paket beinhalten, Pakete, die auf einem Kreis im Abhängigkeitsgraph liegen. %Seite 615, 617
\begin{equation}
	cyclicPackages(pdG) = \sum_{\displaystyle scc \in SCCs(pdG)}
	\begin{cases}
		| scc |, & \text{wenn }|scc| > 1\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:packageswithcyclicdependencies}
\end{equation}
\begin{eqnarray*}
pdG&=&\text{Paket-Abhängigkeitsgraph}\\
SCCs(pdG)&=&\text{Menge aller starken Zusammenhangskomponenten in }pdG\\
scc&=&\text{Starke Zusammenhangskomponente als Menge von Paketen}\\
cyclicPackages(pdG)&=&\text{Anzahl aller Pakete in allen SCCs in }pdG\\
\label{eq:packageswithcyclicdependenciesagenda}
\end{eqnarray*}
Formel \ref{eq:packageswithcyclicdependencies} zeigt dabei die Aufsummierung aller Pakete in nicht-trivialen starken Zusammenhangskomponenten eines Abhängigkeitsgraph auf Paketebene. Abschließend kann das Ergebnis, also der $cyclicPackages$-Wert, durch die Anzahl der betrachteten Pakete dividiert werden, um einen durchschnittlichen \glslink{NCD}{Paketzyklus-Wert} zu bestimmen, der im Usus Cockpit angezeigt wird. Alle Pakete, die 2 oder mehr zyklische Abhängigkeiten besitzen werden als Hotspots behandelt.


\section{Zusammenfassung}
In diesem Kapitel wurde Usus für Java betrachtet. Dabei wurden zuerst die einzelnen Fenster und deren Funktionen beschrieben. Anschließend wurden die \glslink{Metrik}{Metriken}, die das Programm berechnet, gewichtet und bewertet, ausführlich dokumentiert. Jede \gls{Metrik}, sei es auf Methoden-, Klassen oder Paketebene, wurde dabei analysiert und deren Berechnung beschrieben. In Bezug auf die in Abschnitt \ref{sec:goals} definierten Ziele ermöglicht der Funktionsumfang von Usus für Java eine Einsicht in die Codebasis (Ziel \ref{goal:insight}) und macht problematische Stellen im Code offenbar (Ziel \ref{goal:problems}). Leider wird die Entwicklung von \gls{CleanCode} (Ziel \ref{goal:cleancode}) dabei nicht direkt unterstützt. Auch ermöglicht Usus keine einfache Interpretation der Codequalität (Ziel \ref{goal:interpret}). Es wird zwar eine Gewichtung der berechneten \glslink{Metrik}{Metriken} vorgenommen und im Cockpit-Fenster angezeigt, allerdings sind diese Werte nicht sehr transparent und ihre Bedeutung ist nicht aussagekräftig genug. Dennoch sind diese Werte wertvoll und sollten daher auch entsprechende Beachtung finden. Die in dieser Master-Thesis zu entwickelnde Visual Studio-Erweiterung wird diese Werte ebenfalls berechnen, da sie eine Einsicht in den Code ermöglichen und dazu dienen, Probleme im Quellcode zu lokalisieren. Die Beschreibungen in diesem Kapitel dienen dabei als Spezifikation. Sämtliche Funktionen von Usus für Java sollten auch in der Version für das .NET Framework enthalten sein. Es liegt daher nahe, dort auch ähnliche Fenster zu haben. Ein Entwickler, der sich mit einem Usus auskennt, sollte sich dadurch auch schnell an das andere gewöhnen können.




\chapter{Andere Tools}
\label{chap:othertools}
Nachdem in dem vorherigen Kapitel das Eclipse-Plugin Usus vorgestellt wurde, werden in diesem Kapitel einige andere Werkzeuge beschrieben, die ebenfalls eine \glslink{SCA}{statische Code-Analyse} durchführen. Während Usus die direkte Inspiration für das in dieser Master-Thesis zu entwickelnde Tool darstellt, werden in diesem Kapitel einige Visual Studio-Erweiterungen betrachtet. Diese Erweiterungen versuchen bereits, die in Kapitel \ref{chap:requirements} definierten Anforderungen zu erfüllen und sind dabei auf Projekte spezialisiert, die für das .NET Framework entwickelt werden.


\section{Visual Studio Metrics}
In diesem Abschnitt werden die Möglichkeiten beschrieben, die Visual Studio von Haus aus bietet, um Software zu analysieren. Ab Visual Studio 2010 Premium können zu jeder Solution (Menge von Projekten) verschiedene \glslink{Metrik}{Codemetriken} direkt berechnet werden. Die Anzeige der Ergebnisse ist in Abbildung \ref{fig:vsmetricsresult} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/vsmetricsresult.png}
	\caption{Metrik-Fenster in Visual Studio 2010 Premium}
	\label{fig:vsmetricsresult}
\end{figure}
Bei den berechneten \glslink{Metrik}{Metriken} handelt es sich um "`Lines of Code"' (eigentlich "`Number of Statements"'), "`Class Coupling"' (direkte Klassenabhängigkeiten), "`\glslink{CC}{Cyclomatic Complexity}"' und "`Maintainability Index"' (Microsofts Indikator für Wartbarkeit). Jede dieser \glslink{Metrik}{Metriken} wird auf Methodenebene erhoben und zusammenfassend in der hierarchischen Struktur nach oben (Klasse, Paket, \gls{ASM}) propagiert. Zusätzlich wird die \gls{Metrik} "`Depth of Inheritance"' (Anzahl der direkten und indirekten Oberklassen ohne Interfaces) auf Klassenebene bestimmt und ebenfalls nach oben aggregiert. Der Wartbarkeitsindex sowie dessen Berechnung wird von Zain Naboulsi in seinem Artikel \cite{VSMaintainabilityIndex} umfangreich erläutert. Neben der einfachen Darstellung erlaubt Visual Studio das Filtern der Methoden und Klassen anhand der \glslink{Metrik}{Metriken} und zeigt neben der Ausprägung des Wartbarkeitsindex eine Ampel an, die nach Microsofts Empfinden die Methode/Klasse als gut wartbar, weniger gut wartbar und nicht so gut wartbar klassifiziert.
\paragraph{}
In Visual Studio 2010 Ultimate können zudem mehrere grafische Funktionen genutzt werden. So lassen sich zum Beispiel Methoden automatisch als Sequenzdiagramme darstellen, was einen Hinweis auf deren Komplexität und Abhängigkeiten geben kann. Zusätzlich kann der Abhängigkeitsgraph einer Solution mithilfe des Architecture Explorer visualisiert und so zyklische Abhängigkeiten von Klassen und Pakten schnell gefunden werden. Abbildung \ref{fig:vsarchitecturenamespaces} zeigt das Ergebnis als Graph an. Das Ergebnis kann auch als Matrix dargestellt werden kann.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/vsarchitecturenamespaces.png}
	\caption{Architekturdiagramm in Visual Studio 2010 Ultimate auf Basis von Paketen, aufklappbar bis auf Methodenebene}
	\label{fig:vsarchitecturenamespaces}
\end{figure}
Leider sind diese Funktion zur \gls{Metrik}-Berechnung und zur Visualisierung in der am weitesten verbreiten Professional-Version von Visual Studio nicht verfügbar. Zwei kostenlose Programme, die die gleichen \glslink{Metrik}{Codemetriken} berechnen, werden in den folgenden Unterabschnitten vorgestellt.

\subsection{Visual Studio Code Metrics Power Tool}
\label{subsec:vscodemetricspowertool}
Das Kommandozeilenwerkzeug Visual Studio Code Metrics Power Tool\footnote[1]{Download: "`Visual Studio Code Metrics PowerTool 10.0"' \url{http://www.microsoft.com/download/en/details.aspx?id=9422}} wird kostenfrei von Microsoft zum Download angeboten. Es erlaubt die Berechnung der gleichen \glslink{Metrik}{Metriken} wie die in Visual Studio 2010 Premium integrierte Funktionalität und erzeugt eine XML-Datei. Diese Datei enthält die \glslink{Metrik}{Metriken} für Projekte, Namespaces, Typen und Methoden in hierarchischer Form.

\subsection{Code Metrics Viewer}
Die Erweiterung Code Metrics Viewer\footnote[2]{Download: "`Code Metrics Viewer extension"' \url{http://visualstudiogallery.msdn.microsoft.com/9f35524b-a784-4dbc-bd7b-6babd7a5a3b3}} für Visual Studio 2010 wird von Matthias Friedrich zum kostenlosen Download angeboten. Das Tool nutzt das Kommandozeilenwerkzeug Visual Studio Code Metrics Power Tool um \glslink{Metrik}{Metriken} direkt in der Entwicklungsumgebung grafisch anzeigen zu können. In einem Visual Studio-Fenster, das dem aus Abbildung \ref{fig:vsmetricsresult} nachempfunden ist, wird der Inhalt der durch das Power Tool erzeugten XML-Datei visualisiert. Es lassen sich ebenfalls verschiedene Filter einstellen. Der Hauptunterschied zu der integrierten Funktionalität besteht darin, dass die Ampel zu jeder \gls{Metrik} angezeigt wird.


\section{NDepend}
\label{sec:ndepend}
Für die grafische Darstellung des Abhängigkeitsgraphen kann das kommerzielle Werkzeug NDepend\footnote[1]{Mehr Informationen: "`NDepend tutorial with explanations and screenshots"' \url{http://www.ndepend.com/GettingStarted.aspx\#Tuto}} (299\EUR für eine Einzelplatzlizenz) genutzt werden. Dieses Tool ist neben der umfangreichen Darstellung von Zusammenhängen und Abhängigkeiten in der Lage, viele verschiedene \glslink{Metrik}{Metriken} auf Anwendungs-, Projekt-, Namespace-, Klassen- und Methodenebene zu berechnen. Die Abhängigkeiten können, wie im Architecture Explorer in Visual Studio Ultimate, in Form einer Matrix oder in Form eines Diagramms veranschaulicht werden. Dafür analysiert NDepend genau wie das Code Metrics Power Tool die pro Projekt von dem Compiler erzeugten \gls{ASM}-Dateien (exe oder dll). Das Programm ist neben .NET auch für Java und C++ erhältlich und kann als eigenständige Anwendung oder als Visual Studio-Addin verwendet werden.

\subsection{Code Query Language}
Abhängig von der \gls{Metrik}- und Abhängigkeitsberechnung kann NDepend Warnungen und Hinweise anzeigen, die den Programmierer rechtzeitig auf schwierige Stellen im Code hinweisen und es ihm erlauben, dort gezielt einzugreifen. Es lassen sich auch eigene Warnungen und Berichte mithilfe der deklarativen Sprache CQL (Code Query Language) erstellen und ausführen.

\subsection{Abstraktheit und Instabilität}
Eine sehr interessante \gls{Metrik} im NDepend \gls{Metrik}-Portfolio ist \emph{Abstraktheit und Instabilität}. Diese Kombination zweier \glslink{Metrik}{Metriken} geht auf einen Artikel von Robert C. Martin \cite{OODesignMetrics} zurück. In diesem Artikel beschreibt Martin verschiedene \glslink{Metrik}{Metriken} um Abhängigkeiten zwischen Kategorien zu messen. Eine Kategorie definiert er als Gruppe zusammenhängender Klassen, die gemeinsam benutzt werden. Diese Definition kann somit auf Pakete (Namespaces) oder auf \glslink{ASM}{Assemblies} angewendet werden. Als erste \gls{Metrik} stellt Martin \emph{Afferent Couplings} (hinführende Kupplungen $Ca(k)$) einer Kategorie $k$ als Anzahl der Klassen vor, die nicht in der Kategorie sind und eine Abhängigkeit von Klassen in der Kategorie haben. Daraus ergibt sich Formel \ref{eq:afferentcouplings}.
\begin{equation}
	Ca(k) = \sum_{\displaystyle c_o \in Cs \setminus Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_o, c_i) \in dG \mid c_i \in Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:afferentcouplings}
\end{equation}
\begin{eqnarray*}
Cs&=&\text{Menge aller Klassen im System}\\
Cs(k)&=&\text{Menge aller Klassen in der Kategorie }k\\
dG&=&\text{Abhängigkeitsgraph des Systems}\\
\label{eq:afferentcouplingsagenda}
\end{eqnarray*}
Martin bezieht sich auf die Abhängigkeiten zwischen Kategorien. In Formel \ref{eq:afferentcouplings} und den folgenden Formeln wird der bereits aus Unterabschnitt \ref{subsec:perclass} bekannte Abhängigkeitsgraph $dG$ auf Klassenebene verwendet um die Abhängigkeiten abzubilden. Die Grenze einer Kategorie $k$ wird in Bezug auf die Abhängigkeiten der Klassen durch die Funktion $Cs(k)$ bestimmt. Während Formel \ref{eq:afferentcouplings} alle Abhängigkeiten in Richtung der betrachteten Kategorie beschreibt, definiert Formel \ref{eq:efferentcouplings} alle Abhängigkeiten aus der Richtung der betrachteten Kategorie. Die \gls{Metrik} \emph{Efferent Couplings} (wegführende Kupplungen $Ce(k)$) bezeichnet die Anzahl der Klassen innerhalb einer Kategorie $k$, die Abhängigkeiten zu Klassen außerhalb der Kategorie besitzen.
\begin{equation}
	Ce(k) = \sum_{\displaystyle c_i \in Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_i, c_o) \in dG \mid c_o \in Cs \setminus Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:efferentcouplings}
\end{equation}
Die Formeln \ref{eq:afferentcouplings} und \ref{eq:efferentcouplings} besitzen die gleiche Struktur und unterscheiden sich nur durch die Richtung der gesuchten Kante im Abhängigkeitsgraph $dG$ und der Menge der Klassen, die gezählt werden soll.
\paragraph{}
Mit der Anzahl der hinführenden und wegführenden Abhängigkeiten kann jetzt die \gls{Metrik} \emph{Instability} (Instabilität $I(k)$) einer Kategorie $k$ wie in Formel \ref{eq:instability} bestimmt werden. Martin beschreibt diese \gls{Metrik} als Maß dafür, wie die betrachtete Kategorie beeinträchtigt ist, wenn sich das restliche System ändert.
\begin{equation}
	I(k) = \frac{Ce(k)}{Ca(k) + Ce(k)}
\label{eq:instability}
\end{equation}
Eine Instabilität von 1.0 bedeutet maximale Instabilität und wird erreicht, wenn nur wegführende Abhängigkeiten vorhanden sind, also die Klassen innerhalb der Kategorie von Klassen außerhalb abhängig sind. Im Falle einer Änderung im restlichen System ist diese Kategorie sehr wahrscheinlich ebenfalls betroffen. Eine Instabilität von 0.0 bedeutet maximale Stabilität, da keine wegführenden Abhängigkeiten vorhanden sind und Abhängigkeiten nur von Klassen außerhalb der Kategorie zu Klassen in der Kategorie bestehen. Eine Änderung des restlichen Systems hätte also keinen Einfluss auf die betrachtete Kategorie. Instabilität kann nur bestimmt werden, wenn mindestens ein Abhängigkeit (wegführend oder hinführend) vorhanden ist.
\paragraph{}
Robert C. Martin erläutert in seinem Artikel zudem den Zusammenhang von Instabilität und Abstraktheit. Dafür schreibt er, dass Abhängigkeiten von instabilen Kategorien zu vermeiden sind. Da Kategorien mit abstrakten Klassen und Schnittstellen hinführende Abhängigkeit einer externen Klasse motivieren, empfiehlt er keine abstrakten Typen innerhalb einer instabilen Kategorie zu positionieren. Um den Grad der Abstraktheit $A(k)$ einer Kategorie $k$ zu bestimmen, hat Martin die \gls{Metrik} \emph{Abstractness} als Verhältnis zwischen abstrakten Klassen und Schnittstellen zu konkreten Klassen beschrieben. Dieses Verhältnis kann mit Formel \ref{eq:abstractness} berechnet werden.
\begin{equation}
	A(k) = \frac{|aCs(k)|}{|Cs(kp)|}
\label{eq:abstractness}
\end{equation}
\begin{eqnarray*}
aCs(k)&=&\text{Menge der abstrakten Klassen und Schnittstellen in der Kategorie }k\\
\label{eq:abstractnessagenda}
\end{eqnarray*}
Genau wie bei der Instabilität liegt auch die Ausprägung der Abstraktheit zwischen 0.0 und 1.0. Eine Abstraktheit von 0.0 entspricht einer konkreten Kategorie ohne abstrakte Typen, während eine Abstraktheit von 1.0 für eine Kategorie mit ausschließlich abstrakten Typen steht.
\paragraph{}
Die Abstraktheit und die Instabilität können kombiniert werden. NDepend greift die Idee von Martin auf und trägt jede \gls{ASM} der betrachteten Projektumgebung in einem Diagramm ähnlich Abbildung \ref{fig:abstractnessinstability} entsprechend ein.
\begin{figure}[h]
	\centering
		\includegraphics[width=7cm]{images/abstractnessinstability.jpg}
	\caption{Schematische Darstellung des "`Abstraktheit und Instabilität"'-Diagramm in NDepend}
	\label{fig:abstractnessinstability}
\end{figure}
Robert C. Martin beschreibt eine Kategorie, die in der Hauptsequenz liegt, als ausgeglichen, da sie zum Teil erweiterbar und zum Teil stabil ist. Laut Martin sind die beiden Endpunkte der Hauptsequenz die optimalen Punkte. Nach seiner Erfahrung können nur ungefähr die Hälfte der Kategorien in einem System diese optimalen Positionen einnehmen. Die andere Hälfte sollte möglichst nah an der Hauptsequenz liegen, was durch eine weitere \gls{Metrik} in Form einer Abstandsberechnung festgehalten werden könnte.


\section{CCD-Addin}
\label{sec:ccdaddin}
In Kapitel \ref{chap:requirements} wurde im Rahmen der Anforderungsanalyse der Anwendungsfall \emph{\gls{CleanCode}-Hilfe bekommen} identifiziert. Das Visual Studio-Addin CcdAddIn\footnote[1]{Download: "`CcdAddIn is a visual Studio Add-In that displays the CCD values according to your current CCD Grade"' \url{https://github.com/AlexZeitler/CcdAddIn}} von Alexander Zeitler versucht eine solche Hilfestellung in passiver Form zu geben. In Unterabschnitt \ref{subsec:cleancode} wurde die Idee von \gls{CleanCode} bereits erläutert und auf das sieben-Grade-System von Ralf Westphal und Stefan Lieser \cite{CleanCodeDeveloper} eingegangen. Das Programm integriert sich in die IDE und zeigt zu jedem Grad die entsprechenden Prinzipien und Praktiken an, sodass der Entwickler immer an seinen aktuellen Grad und an die damit verbundenen Regeln erinnert wird. Jede Praktik und jedes Prinzip ist anklickbar, sodass das Addin weitere Informationen anzeigen kann. Leider zeigt das Addin die Informationen nur an und bietet sonst kein weitere Hilfestellung.

\subsection{Prinzipien}
\label{subsec:ccdprinciples}
In diesem Unterabschnitt werden die einzelnen Grade vorgestellt. Da der \emph{schwarze} Grad lediglich einer Interessenbekundung entspricht und der \emph{weiße} Grad das komplette Spektrum abdeckt, werden im Folgenden nur die verbleibenden fünf Grade erwähnt. Die folgenden Prinzipien wurden direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen.
\begin{description}
	\item[Rot] "`Don´t Repeat Yourself"' (DRY), "`Keep it simple, stupid"' (KISS), Vorsicht vor Optimierungen!, "`Favour Composition over Inheritance"' (FCoI)
	\item[Orange] "`Single Level of Abstraction"' (SLA), "`Single Responsibility Principle"' (SRP), "`Separation of Concerns"' (SoC), Source Code Konventionen
	\item[Gelb] "`Interface Segregation Principle"' (ISP), "`Dependency Inversion Principle"' (DIP), "`Liskov Substitution Principle"' (LSP), "`Principle of Least Astonishment"' (PLA), "`Information Hiding Principle"' (IHP)
	\item[Grün] "`Open Closed Principle"' (OCP), "`Tell, don´t ask"' (TDA), "`Law of Demeter"' (LD)
	\item[Blau] Entwurf und Implementation überlappen nicht, Implementation spiegelt Entwurf, "`You Ain´t Gonna Need It"' (YAGNI)
\end{description}

\subsection{Praktiken}
\label{subsec:ccdpractices}
Neben den Prinzipien existieren zu jedem Grad auf Praktiken, die ebenfalls direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen wurden.
\begin{description}
	\item[Rot] die Pfadfinderregel beachten, "`Root Cause Analysis"', ein Versionskontrollsystem einsetzen, einfache Refaktorisierungsmuster anwenden, Täglich reflektieren
	\item[Orange] Issue Tracking, Automatisierte Integrationstests, Reviews, Lesen, Lesen, Lesen
	\item[Gelb] Automatisierte Unit Tests, Mockups (Testattrappen), Code Coverage-Analyse, Teilnahme an Fachveranstaltungen, Komplexe Refaktorisierungen
	\item[Grün] Continuous Integration, \gls{SCA} (\glslink{Metrik}{Metriken}), "`Inversion of Control"' (IOC) Container, Erfahrung weitergeben, Messen von Fehlern
	\item[Blau] Continuous Delivery, Iterative Entwicklung, Komponentenorientierung, Test first
\end{description}


\section{Zusammenfassung}
In diesem Kapitel wurden einige Möglichkeiten beschrieben, wie \glslink{Metrik}{Metriken} für .NET-Quellcode berechnet werden können. Doch weder die integrierten Funktionen in Visual Studio, noch die darauf aufbauenden Erweiterungen können die \glslink{Metrik}{Metriken} berechnen, gewichten und bewerten, die Usus für Java bestimmen kann. NDepend kann dies auch nicht aber NDepend erlaubt es eigene Regeln zu definieren. Mit diesen eigenen Regeln könnten wahrscheinlich einige aber sicher nicht alle Cockpit-\glslink{Metrik}{Metriken} und Hotspot-Funktionen von Usus nachgebaut werden. Dafür bietet NDepend jede Menge andere interessante \glslink{Metrik}{Metriken} und Funktionen, die für die in dieser Master-Thesis zu entwickelnde Erweiterung nicht relevant sind. Zuletzt wurde auch eine Erweiterung betrachtet, die einfach nur die \gls{CleanCode}-Grade von Ralf Westphal und Stefan Lieser anzeigt. Auch wenn dies \gls{CleanCode} nur indirekt fördert, kann die zu entwickelnde Erweiterung diese Idee aufgreifen. In Bezug auf die in Abschnitt \ref{sec:goals} definierten Ziele, kann keines der betrachteten Werkzeuge eine Interpretation der Softwarequalität (Ziel \ref{goal:interpret}) oder aktive \gls{CleanCode}-Unterstützung (Ziel \ref{goal:cleancode}) bieten.




\chapter{Evaluierung der Technologien}
\label{chap:techeval}
Nachdem in Kapitel \ref{chap:requirements} die Anforderungen an die zu entwickelnde Visual Studio-Erweiterung beschrieben wurden, werden in diesem Kapitel verschiedene Technologien in Betracht gezogen, um ein Werkzeug zu entwickeln, das einen ähnlichen Funktionsumfang wie das in Kapitel \ref{chap:usus} beschrieben Usus-Plugin besitzt. In diesem Kapitel liegt der Schwerpunkt auf der \glslink{SCA}{statischen Code-Analyse}, mit dessen Hilfe die \glslink{Metrik}{Metriken} aus Unterabschnitt \ref{sec:metrics} berechnet werden sollen. Zu diesem Zweck werden Möglichkeiten untersucht um Quellcode zu analysieren und um die Rohdaten zu ermitteln, die für die Berechnung der vorgestellten \glslink{Metrik}{Metriken} benötigt werden. Diese \glslink{SCA}{Analyse} wird auch von Artur Wagner in seiner Ausarbeitung \cite{IntroStaticCodeAnalysis} mit der Analyse, die ein Compilers durchführt, verglichen. Allerdings ist es möglich, eine \glslink{SCA}{statische Code-Analyse} auch nach dem Kompilieren durchzuführen, indem das Kompilat betrachtet wird. Dies ist im Fall von Java und .NET möglich, da es sich bei dem erzeugten Format um eine Zwischensprache handelt, die erst unmittelbar vor dem Ausführen in Maschinensprache übersetzt wird. Die Technologien, die in diesem Kapitel behandelt werden, nutzen entweder den Quellcode oder das Compiler-Ergebnis um eine \glslink{SCA}{statische Code-Analyse} durchzuführen. Um die Technologien anhand ihrer Eignung zu evaluieren, wird die Bewertung nach verschiedenen Kriterien vorgenommen. Die Kriterien sind nach Wichtigkeit absteigend sortiert. 
\begin{enumerate} 
\item Können alle Informationen gesammelt werden, die benötigt werden um die von Usus berechneten \glslink{Metrik}{Metriken} zu berechnen?
\item Ist die Technologie allgemein verfügbar und kann als Bestandteil einer Anwendung veröffentlicht werden?
\item Ist die Technologie kostenfrei verwendbar?
\item Ist die Technologie einfach zu verwenden und kann leicht eingesetzt werden?
\item Unterstützt die Technologie alle Versionen der .NET-Laufzeitumgebungen unter Windows?
\item Ist die Technologie unabhängig von anderen Laufzeitumgebungen und anderen externen Komponenten?
\item Kann die Technologie ein unvollständiges System verarbeiten, das Klassen und Pakete verwendet, die nicht im betrachteten System definiert sind?
\item Ist die Technologie in der Lage ein System zu analysieren, dass nicht nur mit C$^\sharp$ entwickelt wurde sondern auch mit VB.NET?
\item Kann die Technologie mit dem kompilierten Quellcode, also der Assembly, arbeiten?
\item Kann die Technologie mit dem unkompilierten Quellcode arbeiten?
\end{enumerate}
Die Kriterien sind in Form von Fragen so formuliert, dass eine bejahende Antwort als erstrebenswert gilt. Anhand dieser Kriterien können verschiedene Technologien, die in den folgenden Abschnitten beschrieben werden, evaluiert werden. Das Ergebnis wird abschließend im letzten Abschnitt dieses Kapitels in Form einer Zusammenfassung vorgestellt. Die Auswahl der betrachteten Technologien wurde abhängig vom subjektiven Bekanntheitsgrad eingeschränkt und ist nicht vollständig.


\section{FxCop}
\label{sec:fxcop}
Jason Kresowaty beschreibt FxCop\footnote[1]{Download: "`FxCop 10.0"' \url{http://www.microsoft.com/en-us/download/details.aspx?id=6544}} in seiner Ausarbeitung \cite{FxCopCustomRules} als Werkzeug zur \glslink{SCA}{statischen Code-Analyse} für \glslink{ASM}{Assemblies}, die mit C$^\sharp$, VB.NET und allen anderen .NET-Sprachen entwickelt wurden. Dabei werden Regeln ausgeführt, die nach Problemen im Sinne von Verletzungen von Konventionen und Richtlinien suchen. Diese \glslink{SCA}{Analyse} ist möglich, da der Compiler aus dem C$^\sharp$- oder VB.NET-Quellcode Befehle in der \emph{Common Intermediate Language} (CIL) erzeugt. Im ECMA-335-Standard beschreibt Microsoft diese Zwischensprache als Bestandteil der Common Language Infrastructure ausführlich \cite{CLIECMA335}.

\subsection{Umgebung}
Die FxCop-Technologie besteht aus zwei Teilen. Der erste Teil ist die FxCop-Anwendung und der zweite Teil sind die Regeln, die genutzt werden um die \glslink{SCA}{statische Analyse} zu nutzen. Microsoft veröffentlicht mit dem Programm eine Menge von Regeln, um \glslink{ASM}{Assemblies} anhand den von Krzysztof Cwalina und Brad Abrams veröffentlichten Konventionen und Richtlinien \cite{FrameworkDesignGuidelines} zu untersuchen. Eine Regel, die eine Berechnung von \glslink{Metrik}{Metriken} zur späteren Verwendung durchführt, ist nicht vorhanden. Es lassen sich allerdings eigene Regeln definieren, die FxCop genauso ausführen kann, und mit der das Programm beliebig erweitert werden kann. Eine solche eigene Regel könnte alle notwendigen Informationen sammeln, um ein Programm mit einem Usus-ähnlichen Funktionsumfang zu entwickeln. Kresowaty beschreibt in seiner Ausarbeitung \cite{FxCopCustomRules} wie so eine Regel erstellt werden kann. Regeln lassen sich auch automatisiert ausführen, wenn eine \glslink{SCA}{Analyse} mit der grafischen Oberfläche, die in Abbildung \ref{fig:fxcoprunner} dargestellt ist, nicht sinnvoll ist. Abbildung \ref{fig:fxcopcmdrunner} zeigt die Kommandozeilenversion des FxCop Runners.
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/fxcoprunner.png}
	\caption{FxCop Runner}
	\label{fig:fxcoprunner}
\end{figure}
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/fxcopcmdrunner.png}
	\caption{FxCop Runner in der Kommandozeile}
	\label{fig:fxcopcmdrunner}
\end{figure}
\paragraph{}
Eine FxCop-Regel entspricht einer Klassenbibliothek, die eine Regelklasse und eine Konfigurationsdatei enthält. Während FxCop den Code analysiert, erzeugt es Instanzen der Regelklasse und nutzt diese um in der Codebasis Problemfälle zu finden. Problemfälle können dann von der Regelklasse in Problemlisten eingetragen werden, die FxCop entweder grafisch anzeigt oder in eine Report-Datei exportiert. Zusätzlich können Problemfälle als kritisch gekennzeichnet und mit verschiedenen Texten und Beschreibungen versehen werden um eine möglichst detaillierte Beschreibung der Schwierigkeit zu ermöglichen. FxCop ist also auf das Finden von Problemen und nicht auf objektive Datensammlung spezialisiert. Um eine \gls{ASM} möglichst schnell analysieren zu können, erzeugt FxCop mehrere Instanzen einer Regel und führt diese in mehreren Threads parallel aus. Jason Kresowaty betont in seiner Ausarbeitung \cite{FxCopCustomRules}, dass sich die Regeln nicht Thread-sicher verhalten. Damit mit FxCop weiterverwendbare Daten gesammelt werden können, müssen diese auf eine geeignete Weise exportiert werden. Entweder können diese Daten in Form von Zeichenketten als Probleme verpackt oder direkt an ein Ziel gespeichert werden. Diese beiden Lösungen sind umständlich und nicht intuitiv und werden von der Nebenläufigkeit von FxCop noch erschwert.

\subsection{API}
\label{subsec:fxcopapi}
Regeln für FxCop können mit C$^\sharp$ in Form einer Klassenbibliothek entwickelt werden, wie es Jason Kresowaty in seiner Ausarbeitung \cite{FxCopCustomRules} vorstellt. Die dadurch erzeugte \emph{Dynamic Link Library} (dll-Datei) kann dann von FxCop verwendet werden. Dazu muss die DLL über eine spezielle Metadatendatei als eingebettete Ressource verfügen, die die Regel dem Runner bekanntmacht. Die Regel selbst wird in einer Klasse implementiert, die von einer abstrakten Oberklasse für Regeln abgeleitet ist und somit Analysemethoden überladen kann. Mit diesen Methoden kann das Objektmodell der zu analysierenden \gls{ASM} untersucht werden. Alle Basisklassen und Klassen, die das Objektmodell repräsentieren befinden sich im Namespace \texttt{Microsoft.FxCop.Sdk}. Das \emph{Application Programming Interface} (API) um FxCop-Regeln zu programmieren enthält Teile, die dem in das .NET Framework integrierten \texttt{System.Reflection}-API ähnlich sind. Beide APIs enthalten Klassen um das Objektmodell von .NET-Sprachen zu repräsentieren.
\paragraph{}
Um Operationen von einer Datenstruktur zu trennen, beschreiben Erich Gamma, Richard Helm, Ralph E. Johnson und John Vlissidest das Besuchermuster (Visitor Pattern) in \cite{DesignPatterns}. Mit dem Besuchermuster ermöglicht die FxCop-API die gleiche Datenstruktur (Objektmodell) mit vielen Regeln (Besuchern) zu analysieren. In der Regelklasse, die von \texttt{BaseIntrospectionRule} abgeleitet ist, können oberflächliche Besuchermethoden überladen werden. Diese oberflächlichen Methoden bestimmen, an welcher Stelle im Objektmodell eine weitere Überprüfung vorgenommen werden soll. Zum Beispiel wird die \texttt{Check(Member)}-Methode in Listing \ref{listing:fxcopapisample} für jedes Property oder Methode in jeder Klasse aufgerufen. Die \texttt{Check(TypeNode)}-Methode wird zusätzlich für jede Klasse oder Interface ausgeführt.
\begin{lstlisting}[caption={Beipiele der FxCop-API},label={listing:fxcopapisample}]
ProblemCollection Check(Member member) {...}
ProblemCollection Check(TypeNode type) {...}
void VisitMemberBinding(MemberBinding memberBinding) {...}
void VisitBranch(Branch branch) {...}
void VisitAssignmentStatement(AssignmentStatement assignment) {...}
\end{lstlisting}
Nachdem sich die Regel mit einer dieser oberflächlichen \texttt{Check}-Methoden in den Kontrollfluss der \glslink{SCA}{Analyse} integriert, kann eine tiefer gehende Analyse erfolgen. Dazu wird beispielsweise ein \texttt{BinaryReadOnlyVisitor}-Besucher erstellt, der die aktuelle Stelle im Objektmodell detaillierter besuchen kann. In der Klasse, die von \texttt{BinaryReadOnlyVisitor} erbt, können \texttt{Visit}-Methoden überladen werden. Listing \ref{listing:fxcopapisample} zeigt einige dieser Methoden. Beispielsweise kann in der \texttt{VisitMemberBinding}-Methode jeder Methodenaufruf und in der \texttt{VisitAssignmentStatement}-Methode jede Zuweisung analysiert werden. Auf diese Weise und in Verbindung mit sämtlichen Parameter- und Rückgabetypen kann aus dem Objektmodell der für die zu berechnenden \glslink{Metrik}{Metriken} erforderliche Abhängigkeitsgraph erstellt werden. Die Anzahl der Anweisungen pro Methode kann entweder über die vom Compiler erzeugte Zwischensprache (engl. Common Intermediate Language, CIL) oder über die \texttt{Statement}-Objekte von FxCop erfolgen. Während die CIL-Anweisungen die C$^\sharp$-Anweisungen sehr viel granularer abbilden, entsprechen die FxCop-Anweisungen zusammengefassten CIL-Anweisungen. Eine Entsprechung der C$^\sharp$-Anweisungen konnte ohne detaillierte Betrachtung der konkreten \texttt{Statement}-Typen nicht ermittelt werden. Die Anzahl der Zeilen kann dafür auf eine sehr einfach Weise bestimmt werden, da jedes \texttt{Statement} über einen \texttt{SourceContext} und dort über Start- und Endzeilennummern verfügt. Anhand der Liste aller Anweisungen kann die erste Zeile als kleinste Startzeile und die letzte als größte Endzeile gesucht und mittels der Differenz die \glslink{ML}{Methodenlänge} berechnet werden. Die \glslink{CC}{zyklomatische Komplexität} kann bestimmt werden, da jede Verzweigung im Code von der \texttt{VisitBranch}-Methode besucht wird.


\section{Common Compiler Infrastracture}
\label{sec:cci}
Die \emph{\gls{CCI}} (CCI) ist eine Sammlung von Bibliotheken, die Compiler-ähnliche Funktionen bereitstellen und von Microsoft Research entwickelt wurde \cite{CCI}. Auf Codeplex lässt sich die Komponente \gls{CCIMetadata}\footnote[1]{Download und mehr Informationen: "`CCI: Metadata API"' \url{http://ccimetadata.codeplex.com/}} finden. Guy Smith beschreibt sie als Obermenge von \texttt{System.Reflection}, \texttt{System.Reflection.Emit} und \texttt{System.CodeDom}, also den Mechanismen des .NET Framework, die zur Laufzeit Reflektion und Code-Erzeugung möglich machen \cite{CCIMetadata}. Smith beschreibt \gls{CCIMetadata} als Werkzeug, das mit den vom Compiler erzeugten CIL-Anweisungen arbeitet. Um einfacher mit Methoden zu arbeiten, stellt Smith mit \gls{CCIAst}\footnote[1]{Download und mehr Informationen: "`CCI: Code Model and AST API"' \url{http://cciast.codeplex.com/}} eine weitere Komponente vor \cite{CCICode}. \gls{CCIAst} erleichtert das Arbeiten mit Methoden, da es von den CIL-Anweisungen abstrahiert und Quellcode-ähnliche Bäume nutzt. Beide Komponenten sind unter der Microsoft Public License veröffentlicht. Die \glslink{CCI}{CCI} wird in einer ähnlichen Variante unter anderem von dem Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} und FxCop aus Abschnitt \ref{sec:fxcop} genutzt. Die \gls{ASM} Microsoft.Cci.dll, die mit diesen Tools ausgeliefert wird, besitzt viele Funktionen, die nur intern oder von erlaubten \glslink{ASM}{Assemblies} aufrufbar sind. Funktionen, die beispielsweise konkrete \glslink{Metrik}{Methodenmetriken} berechnen, sind nur von Programmen aufrufbar, die in der CCI-\gls{ASM} aufgelistet sind, wie in Abbildung \ref{fig:cciinternalsvisible} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/cciinternalsvisible.png}
	\caption{\texttt{InternalsVisibleTo}-Attribute der \gls{ASM} Micorsoft.Cci.dll}
	\label{fig:cciinternalsvisible}
\end{figure}

\subsection{CCI Metadata}
\label{subsec:ccimetadata}
Im Gegensatz zu der FxCop-API kann eine .NET-\gls{ASM} mit \glslink{CCI}{CCI} direkt untersucht werden, ohne das die \glslink{SCA}{Analyse} in Form einer einschränkenden Regel parallelisiert erfolgt. \glslink{CCI}{CCI} überlässt dem Verwender der Bibliothek ob und wie die Untersuchung stattfinden soll. Mit einem \texttt{PeReader.DefaultHost} können \glslink{ASM}{Assemblies} eingelesen werden, die von \glslink{CCI}{CCI} als \glslink{ASM}{PE-Dateien} bezeichnet werden. \glslink{ASM}{PE-Dateien} werden in der vorliegenden Master-Thesis wie folgt definiert.
\begin{definition}[Portable Executable]
Eine \emph{Portable Executable}-Datei (PE-Datei), also eine (wörtlich übersetzt) "`transportierbare"' und ausführbare Datei, ist das Ergebnis einer Kompilierung eines Visual Studio .NET-Projekts. Die Datei ist entweder eine Bibliothek (dll-Datei) oder eine direkt ausführbare Datei (exe-Datei).
\end{definition}
Zusätzlich kann die vom Compiler erzeugte \glslink{PDB}{pdb-Datei} mit einem \texttt{PdbReader} importiert werden. Eine \glslink{PDB}{pdb-Datei} wird hier wie folgt definiert.
\begin{definition}[Program Database]
Die \emph{Program Database}-Datei (pdb-Datei) enthält die Datei- und Zeilenzuordnung der kompilierten Funktionen in einer PE-Datei. Laut Microsoft \cite{PDBFile} enthält sie generell Debug- und Projektinformationen.
\end{definition}
Mit der \texttt{IAssembly.GetAllTypes()}-Methode können alle Typen einer \gls{ASM} ermittelt werden. Alle Methoden und Properties eines Typen, können mit der Eigenschaft \texttt{INamedTypeDefinition.Methods} bestimmt werden. Der Inhalt von Methoden und Properties kann in Form von CIL-Anweisungen genauer betrachtet werden. Diese Anweisungen lassen sich mit der Eigenschaft \texttt{Operations} ermitteln, die auf dem \texttt{IMethodBody}-Interface definiert ist. So lassen sich beispielsweise alle lokalen Variablen und Methodenaufrufe lokalisieren, um Abhängigkeiten der Methode zu anderen Typen zu finden. Die CIL-Anweisung eines Methodenaufrufs enthält immer auch den Typ, der das Aufrufziel darstellt. Zusammen mit Attributen, Parametern und Rückgabewerten kann die Abhängigkeitsmenge eines Typen ermittelt werden. Die \glslink{CC}{zyklomatische Komplexität} einer Methode kann ebenfalls über die CIL-Anweisungen bestimmt werden, was durch das Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} sowie Steve Gilham \cite{CCperCIL} demonstriert wird. Um die \glslink{ML}{Methodenlänge} einer Funktion aus den CIL-Anweisungen zu ermitteln, kann auch hier die Funktionalität durch das Code Metrics Power Tool inspiriert werden. Wenn zu der .NET-\gls{ASM} zusätzlich eine \glslink{PDB}{pdb-Datei} existiert, kann außerdem die Start- und Endzeile jeder Anweisung auf die Methode bezogen werden, ähnlich der Lösung für die FxCop-Regel aus Unterabschnitt \ref{subsec:fxcopapi}.

\subsection{CCI Code and AST Components}
\label{subsec:ccicodeast}
Soweit wurden nur Funktionen von \gls{CCIMetadata} betrachtet. \gls{CCIAst} erlaubt es das Modell des Quellcodes einer Methode in Form eines \glslink{Ast}{abstrakten Syntaxbaums} zu analysieren. Philip Newcomb beschreibt einen \glslink{Ast}{AST} in seiner Präsentation über den \glslink{Ast}{AST} Metamodel Standard \cite{ASTMetamodel}. In der vorliegenden Master-Thesis wird ein \glslink{Ast}{AST} wie folgt definiert.
\begin{definition}[Abstrakter Syntaxbaum]
Ein \emph{\glslink{Ast}{abstrakter Syntaxbaum}} (engl. Abstract Syntax Tree, AST) ist eine formale Repräsentation der syntaktischen Struktur einer Software auch innerhalb von Methoden. Besonders in Methoden enthält der \glslink{Ast}{AST} einen Knoten für jede Anweisung. Wenn diese Anweisung aus mehreren anderen Anweisungen besteht, besitzt der Knoten für diese Anweisungen entsprechende Unterknoten.
\end{definition} 
Um einen solchen Baum zu betrachten, können Besucher verwendet werden. Beispielsweise erlaubt eine Objekt vom Typ \texttt{CodeTraverser} jede strukturelle Stelle der \gls{ASM} mit überladbaren Methoden, von denen einige in Listing \ref{listing:ccicodeastsample} aufgeführt sind, zu besuchen.
\begin{lstlisting}[caption={\texttt{CodeTraverser}-Methoden von \gls{CCIAst}},label={listing:ccicodeastsample}]
TraverseChildren(IConditionalStatement conditionalStatement) {...}//if
TraverseChildren(IConditional conditional) {...}//bool expression
TraverseChildren(IForStatement forStatement) {...}
TraverseChildren(ISwitchStatement switchStatement) {...}
\end{lstlisting}
Für jede Stelle im Code leitet \texttt{CodeTraverser} den Aufruf an die registrierten \texttt{ICodeVisitor}-Objekte weiter und ermöglicht so die Analyse des \glslink{Ast}{AST}. Das Interface \texttt{ICodeVisitor} besitzt für jede \texttt{Traverse}-Methode eine entsprechende \texttt{Visit}-Methode. Da \texttt{CodeTraverser} das Code-Modell von links nach rechts und "`Depth First"' besucht, können zwei Besucher registriert werden. Einer wird aufgerufen bevor ein Syntax-Element im Baum besucht wird und der andere wird aufgerufen nachdem der Besuch abgeschlossen ist.
\paragraph{}
\gls{CCIAst} ermöglicht das syntaktische Besuchen von Sprachelementen, indem von CIL abstrahiert wird. Es existieren Besuchermethoden für alle Sprachelemente, die aus C$^\sharp$ 4.0 bekannt sind, wie beispielsweise Lambda-Ausdrücke, Generics, Attribute und vielen mehr. Die herunterladbare Visual Studio-Solution der \gls{CCIAst} enthält das Beispiel "`PeToTextViaCodeModel"', das sämtliche Strukturelemente einer \glslink{ASM}{dll-} oder \glslink{ASM}{exe-Datei} besucht und wieder C$^\sharp$-Quelltext erzeugt. Das Ergebnis entspricht Code, der dem Original sehr ähnlich ist und an professionelle Decompiler erinnert. Die \glslink{CCI}{CCI} erlaubt es außerdem eine geladene \gls{ASM} zu verändern und anschließend wieder zu exportieren.


\section{NRefactory}
\label{sec:nrefactory}
Auch in der Mono-Welt existieren Werkzeuge für Compiler-ähnliche Funktionen. Das Team hinter Mono beschreibt Mono als Implementierung des .NET Frameworks für Windows, Linux, Mac OS und verschiedene mobile Plattformen \cite{Mono}. In diesem Umfeld ist NRefactory\footnote[1]{Download: "`Repository for NRefactory 5"' \url{https://github.com/icsharpcode/NRefactory/}} Teil der freien .NET-Entwicklungsumgebung SharpDevelop\footnote[2]{Download und mehr Informationen: "`SharpDevelop"' \url{http://www.icsharpcode.net/OpenSource/SD/}} und arbeitet im Gegensatz zur \glslink{CCI}{CCI} und FxCop nicht nur auf \gls{ASM}-Ebene, sondern hauptsächlich mit Quellcode.

\subsection{AST aus Quellcode}
Mit NRefactory ist es möglich einen \glslink{Ast}{AST} aus C$^\sharp$-Quelltext zu erzeugen. Unterstützung für VB.NET ist nach Angaben in der Funktionsbeschreibung der Bibliothek \cite{NRefacRepo} noch nicht implementiert. Anschließend können AST-Besucher als direkte Implementierung der \texttt{IAstVisitor}-Schnittstelle oder als Ableitung von \texttt{DepthFirstAstVisitor} erstellt werden und mit dem \glslink{Ast}{abstrakten Syntaxbaum} arbeiten. Listing \ref{listing:nrefacastsample} zeigt einige wenige Methoden, die im \texttt{IAstVisitor}-Interface definiert sind.
\begin{lstlisting}[caption={\texttt{IAstVisitor}-Methoden von NRefactory},label={listing:nrefacastsample}]
VisitIfElseStatement(IfElseStatement ifElseStatement) {...}
VisitBinaryOperatorExpression(BinaryOperatorExpression expression) {...}
VisitPrimitiveExpression(PrimitiveExpression expression) {...}
VisitNewLine(NewLineNode newLineNode) {...}
VisitInvocationExpression(InvocationExpression expression) {...}
\end{lstlisting}
Mit einem solchen Besucher können strukturelle Code-Elemente wie if-Anweisungen sehr gut besucht werden, was die Berechnung der zyklomatischen Komplexität ermöglicht, ohne kompiliern zu müssen. Wie in Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben, brauchen dafür nur alle Entscheidungsstellen besucht und aufsummiert werden. Die \glslink{ML}{Methodenlänge} kann ebenfalls einfach bestimmt werden. Es ist möglich entweder alle Statements oder alle Zeilenumbrüche zu besuchen und aufzusummieren. Der \glslink{Ast}{AST} kann auch verändert und anschließend neuer Code erzeugt werden. Allerdings kann der Abhängigkeitsgraph nicht durch die alleinige Erzeugung des \glslink{Ast}{AST} erstellt werden.

\subsection{Mono.Cecil}
NRefactory ordnet Methodenaufrufe in Form von \texttt{InvocationExpression}-Objekten erst dann der definierenden Stelle zu, wenn alle Typen und Methoden im \glslink{Ast}{AST} mit einem \texttt{CSharpAstResolver}-Objekt komplett aufgelöst werden. Dazu verwendet NRefactory die Mono.Cecil-Bibliothek, die Jean-Baptiste Evain als API zum Erzeugen, Analysieren und Verändern von .NET-\glslink{ASM}{Assemblies} beschreibt \cite{MonoCecil}. Die \glslink{ASM}{Assemblies}, in denen sich die Typen befinden, auf die der Code zugreift, werden von Mono.Cecil geladen. Listing \ref{listing:nrefacastresolvercreation} zeigt wie ein \texttt{CSharpAstResolver}-Objekt zur Auflösung des abstrakten Syntaxbaums erzeugt werden kann.
\begin{lstlisting}[caption={Erzeugung eines \texttt{CSharpAstResolver}-Objekts},label={listing:nrefacastresolvercreation}]
CSharpAstResolver CreateResolver(
    CompilationUnit parsed, params Type[] types)
{
    IProjectContent project = new CSharpProjectContent();
    CSharpParsedFile file = parsed.ToTypeSystem();
    project = project.UpdateProjectContent(null, file);
    project = project.AddAssemblyReferences(LoadAssemblies(types));
    return new CSharpAstResolver(
        project.CreateCompilation(), parsed, file);
}
\end{lstlisting}
Der Code orientiert sich an dem Code-Beispiel von Daniel Grunwald in dem NRefactory-Repository \cite{NRefacRepo}. Das übergebene \texttt{CompilationUnit}-Objekt ist der Wurzelknoten des AST, der aus dem Quellcode-Fragment erstellt wurde. Dieser \glslink{Ast}{AST} wird für die Typzuordnung vorbereitet und gemeinsam mit allen anderen \glslink{ASM}{Assemblies}, die für die Auflösung von externen Typen verwendet werden sollen, zusammengefasst. Das zusammenfassende Objekt ist von Typ \texttt{CSharpProjectContent}. Um diese \glslink{ASM}{Assemblies} zu finden, wird jede durch einen in ihr enthaltenen, nicht weiter relevanten Typ identifiziert. Für die Erzeugung des \texttt{CSharpAstResolver}-Objekts, wird der unvorbereitete AST, der vorbereitete \glslink{Ast}{AST} und das Kompilat des \texttt{CSharpProjectContent}-Objekts übergeben. Die eigentliche Auflösung wird dann über einen Aufruf der \texttt{ApplyNavigator}-Methode auf einem \texttt{CSharpAstResolver}-Objekt synchron durchgeführt. Diese Funktion erwartet ein Objekt vom Typ \texttt{IResolveVisitorNavigator} und teilt diesem alle aufgelösten Details zu allen Knoten im \glslink{Ast}{AST} mit. Ähnlich wie die \glslink{CCI}{CCI} erlaubt auch Mono.Cecil das manuelle Einlesen von \glslink{ASM}{Assemblies} und \glslink{PDB}{pdb-Dateien} um diese anhand der CIL-Anweisungen zu analysieren. \glslink{ASM}{Assemblies} und \glslink{PDB}{pdb-Dateien} können außerdem auch verändert und gespeichert werden.


\section{Codename "`Roslyn"'}
\label{sec:roslyn}
Karen Ng, Matt Warren, Peter Golde und Anders Hejlsberg beschreiben in ihrem Dokument \cite{RoslynOverview} ein Projekt um den C$^\sharp$- und den VB.NET-Compiler als Dienst zur Verfügung zu stellen. Sie beschreiben das Problem, dass Compiler viel isoliertes und ungeteiltes Wissen über die zu kompilierende Sprache besitzten. Dieses Wissen ist auch für andere Anwendungen, wie beispielsweise Entwicklungsumgebungen, Werkzeuge die Refactorings unterstützen und Code-Analyse-Tools von Bedeutung. Momentan müssen diese Programme das Wissen der Compiler neu erfinden und Teile des Compilers neu implementieren. Im Rahmen des Projekts \emph{Roslyn}\footnote[1]{Download und mehr Informationen: "`Microsoft Roslyn June 2012 CTP"' \url{http://msdn.com/roslyn}} sollen die Compiler ihr Wissen teilen können. Dazu werden sie als Dienste zur Verfügung gestellt und bieten APIs an. Diese APIs können dann von sämtlichen Code-orientierten Werkzeugen genutzt werden. Kirill Osenkov stellt in seinem Blog-Post \cite{RoslynCTPIntro} die CTP (Community Technology Preview) von Roslyn vor und erwähnt ein weiteres Ziel. Die bisherigen Compiler sollen in einer Sprache, die auf der .NET-Laufzeitumgebung (Common Language Runtime, CLR) ausgeführt wird, neu geschrieben werden. Auf diese Weise soll das Team hinter Visual Studio schneller und bessere Features entwickeln können.

\subsection{Schichten}
In ihrem Dokument \cite{RoslynOverview} beschreiben Hejlsberg und co die traditionelle Compiler-Pipeline der .NET-Umgebung. Die Roslyn-Compiler werden diese Pipeline ebenfalls haben. Ein Parser erzeugt einen Syntaxbaum anhand der Grammatik der Sprache. Darauf folgt die Deklarierungsphase. In dieser Phase werden die Deklarierungen im Code zusammen mit importierten Metadaten in Form von benannten Einheiten, sogenannten Symbols, erstellt. Danach folgt die Binder-Phase, in der Typen im Syntaxbaum den Symbols zugeordnet werden. In der letzten Phase wird alle vom Compiler gesammelte Information in Form von CIL-Anweisungen in eine \gls{ASM}-Datei exportiert. Project Roslyn bietet für jede dieser Phasen eine entsprechende API im Rahmen einer Compiler API Schicht, die auf der Compiler-Pipeline aufbaut. Auf diese Compiler-API-Schicht setzt Roslyn noch eine Language Service-Schicht, die mit dem Objektmodell der Compiler-Phasen arbeitet und beispielsweise Refactorings unterstützt.
\paragraph{}
Hejlsberg und co unterscheiden zwischen verschiedenen Architekturschichten, die getrennt von den oben beschrieben Schichten über der Compiler-Pipeline beschrieben werden. Die Compiler-APIs erlauben den Zugriff auf das syntaktische und das semantische Objektmodell der Compiler-Pipeline und stellen sie dadurch zur Verfügung. Die nächste Schicht ist die Scripting-API. Sie bietet eine Umgebung für das Ausführen von Code-Schnippseln in Form von Ausdrücken und Anweisungen. Mit dieser Umgebung kann eine interaktive Programmierschleife (Read Eval Print Loop, REPL) realisiert werden. Die Workspace-API stellt die nächste Schicht dar und ermöglicht eine \glslink{SCA}{Analyse} auf der Basis von kompletten Visual Studio-Solutions. Die letzte Schicht ist die Services-API. Sie ist die einzige Schicht, die eine Abhängigkeit von Visual Studio hat. Sämtliche IDE-Funktionen, wie beispielsweise Visual Studio IntelliSense, Refactorings und Formatierungsfunktionen, befinden sich in dieser Schicht.

\subsection{Syntax Tree}
\label{subsec:roslynsyntaxtree}
In diesem Unterabschnitt werden die Möglichkeiten beschrieben, wie der Syntaxbaum der Compiler-API verwendet werden kann. Interessant ist zu sehen, dass Roslyn im Gegensatz zu NRefactory die Datenstruktur nicht als \glslink{Ast}{abstrakten Syntaxbaum} bezeichnet, sondern lediglich als Syntaxbaum. Philip Newcomb beschreibt in seiner Präsentation über den AST Metamodel Standard \cite{ASTMetamodel} den Unterschied als Nähe zum tatsächlichen Quellcode. Der Syntax Tree von Roslyn orientiert sich sehr am Quellcode. Hejlsberg und co legen in ihrem Dokument \cite{RoslynOverview} besonderen Wert auf die Vollständigkeit des Baums. Jedes Leerzeichen und sogar syntaktische Fehler sind Bestandteil des Syntaxbaums.
\paragraph{}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt die Erzeugung eines Syntaxbaums aus einem Quellcodeausschnitt, der in der Variable \texttt{sourceText} enthalten ist. Ähnlich wie NRefactory bietet auch Roslyn die Möglichkeit, den Baum mit LINQ-Abfragen zu analysieren, da die Eigenschaft \texttt{DescendentNodes} ein \texttt{IEnumerable} zurückliefert. LINQ\footnote[1]{Mehr Informationen: "`LINQ (Language-Integrated Query)"' \url{http://msdn.microsoft.com/de-de/library/bb397926.aspx}} ist ein Sprachkonstrukt, das es erlaubt, mit Keywords wie \texttt{from}, \texttt{where} und \texttt{select} SQL-ähnliche Abfragen direkt in C$^\sharp$ oder VB.NET zu schreiben.
\begin{lstlisting}[caption={Erzeugung eines Syntax Tree mit der Rosyln Compiler-API},label={listing:roslynsyntaxtreecreation}]
SyntaxTree tree = SyntaxTree.ParseCompilationUnit(sourceText);
methods = tree.Root.DescendentNodes().OfType<MethodDeclarationSyntax>();
...
ifs = method.DescendentNodes().OfType<IfStatementSyntax>();
invocations = method.DescendentNodes().OfType<InvocationExpressionSyntax>();
\end{lstlisting}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt auch, wie alle Methodendeklarationen in \texttt{sourceText} gefunden werden. In jeder dieser Methoden kann anschließend nach \texttt{if}-Anweisungen und ähnlichen Entscheidungsträgern gesucht werden, um die \glslink{CC}{zyklomatische Komplexität}, wie sie in Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben wurde, auszurechnen. Um die Typen zu finden, von denen eine Methode abhängig ist, können neben sämtlichen Variablen alle Methodenaufrufe gefunden werden. Daraus kann anschließend der Abhängigkeitsgraph bestimmt werden. Ähnlich zu NRefactory kann auch für den Roslyn-Baum ein Besucher als Ableitung von \texttt{SyntaxWalker} erstellt werden. Über entsprechende Überladungen kann dann auf alle Knoten im Syntaxbaum reagiert werden. Leerzeichen, Zeilenumbrüche und andere Elemente, die keine nicht syntaktische Relevanz haben, sind im Baum in Form von \texttt{Trivia}-Objekten vorhanden und lassen sich ebenfalls finden. Eine Manipulation des Code-Baums ist auch möglich, indem ein neuer Baum erzeugt wird. Bestehende Bäume sind laut Hejlsberg und co unveränderlich.

\subsection{Semantik}
\label{subsec:roslynsemanticmodel}
In diesem Unterabschnitt wird beschrieben, wie die Compiler-API die Semantik von Code verwaltet. Nach der Erzeugung der syntaktischen Repräsentation von Code, dem Syntax Tree, werden beispielsweise die Methodenaufrufe nicht automatisch der Stelle zugeordnet, die sie deklarieren. Ähnlich wie bei NRefactory wird dazu eine Auflösung benötigt, die den Baum mit den Symbols verbindet. Listing \ref{listing:rosylnsemanticmodelcreation} zeigt wie ein Syntaxbaum kompiliert werden kann. Durch die Kompilierung werden alle Verweise, die sich wie im Beispiel auf die \texttt{mscorlib} (Bibliothek der Basistypen wie \texttt{object}, \texttt{string}, \texttt{DateTime}, usw) beziehen, aufgelöst.
\begin{lstlisting}[caption={Erzeugung eines semantischen Modells aus Syntax-Bäumen},label={listing:rosylnsemanticmodelcreation}]
Compilation compilation = Compilation.Create(name)
				.AddReferences(mscorlib)
				.AddSyntaxTrees(tree);
SemanticModel semanticModel = compilation.GetSemanticModel(tree);
\end{lstlisting}
Das Kompilieren findet im Speicher statt und das Ergebnis wird nicht in Form einer \gls{ASM} in eine Datei geschrieben. Aus dem Kompilat kann das semantische Modell erzeugt werden. Dieses Modell kann anschließend genutzt werden, um zu sämtlichen syntaktischen Elementen im Syntax Tree semantische Eigenschaften zu erhalten.
\begin{lstlisting}[caption={Ermitteln der semantischen Information eines Methodenaufrufs},label={listing:roslynsemanticmodelusage}]
SemanticInfo invocationSymbols = semanticModel.GetSemanticInfo(invocation);
string typeName = invocationSymbols.Symbol.ContainingType.Name;
\end{lstlisting}
Dafür kann die \texttt{GetSemanticInfo}-Methode mit dem entsprechenden Element aufgerufen werden, wie in Lisiting \ref{listing:roslynsemanticmodelusage} dargestellt. Das semantische Modell enthält alle Symbols des Kompilats und nicht nur die, die für die Auflösung der Typen benötigt werden die im Syntaxbaum deklariert wurden. Wenn also über alle Typen im semantischen Modell iteriert wird, werden nicht nur die Typen aus dem Baum, sondern auch alle Typen aller referenzierten \glslink{ASM}{Assemblies} betrachtet.

\subsection{Workspaces}
In diesem Unterabschnitt werden die Möglichkeiten der Compiler-API in Bezug auf die \glslink{SCA}{Analyse} von ganzen Visual Studio-Solutions beschrieben. Eine \emph{Solution} ist eine sln-Datei, die es Visual Studio ermöglicht mehrere Projekte mit mehreren Quellcodedateien zu verwalten und zu kompilieren. In einer Solution sind in der Regel alle Abhängigkeiten der beinhalteten Projekte entweder durch andere beinhaltete Projekte oder durch referenzierte \glslink{ASM}{Assemblies} auflösbar. Die Roslyn Services-API erlaubt es im Kontext einer laufenden Visual Studio-Instanz einen sogenannten Workspace zu verwenden, der die Visual Studio-Umgebung repräsentiert und den Syntaxbaum ändert, sobald sich der Quellcode ändert. Ein Workspace kann auch ohne Abhängigkeit von Visual Studio erzeugt werden, indem die Solution-Datei direkt geladen wird, wie in Listing \ref{listing:roslynsolutionworkspacecreation} zu sehen ist.
\begin{lstlisting}[caption={Erzeugung eines Workspace aus einer Visual Studio-Solution-Datei},label={listing:roslynsolutionworkspacecreation}]
IWorkspace workSpace = Workspace.LoadSolution(solutionFile);
ISolution solution = ws.CurrentSolution;
...
SyntaxTree tree = document.GetSyntaxTree();
SemanticModel semantic = document.GetSemanticModel();
\end{lstlisting}
In einem \texttt{ISolution}-Objekt kann über alle enthaltenen Projekte iteriert werden. In jedem Projekt können alle Dokumente als \texttt{IDocument}-Objekte betrachtet werden. Zu jedem Dokument kann der zugehörige Syntaxbaum und das semantische Modell bestimmt werden. Da die Workspace-Repräsentation das Erzeugen und Kompilieren der Dateien übernimmt, kann die \glslink{SCA}{statische Code-Analyse} direkt auf Solution-Ebene durchgeführt werden. Der dazu nötige Syntaxbaum und das semantische Modell wurden bereits in den Unterabschnitten \ref{subsec:roslynsyntaxtree} und \ref{subsec:roslynsemanticmodel} beschrieben.


\section{Zusammenfassung}
In den oberen Abschnitten wurden die vier Technologien FxCop, \glslink{CCI}{CCI}, NRefactory und Projekt Roslyn kurz vorgestellt. Zu jeder Technologie wurden Eigenheiten und Besonderheiten beschrieben, die sich mehr oder weniger auf die Eignung der Technologie in Bezug auf ein Usus-ähnliches Programm für .NET auswirken. Abbildung \ref{fig:techevalsummary} visualisiert die sich daraus ergebenen bewerteten Verbindungen zwischen den Technologien und den Eingangs festgelegten Fragen. Es ist zu sehen, dass die für die Berechnung der \glslink{Metrik}{Metriken} erforderlichen Informationen von allen untersuchten Lösungen ermittelt werden können. Bei zwei Lösungen allerdings mit Vorbedingung.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/techevalsummary.png}
	\caption{Tabellarisches Ergebnis der Evaluierung der verschiedenen Technologien}
	\label{fig:techevalsummary}
\end{figure}
\paragraph{}
Zuerst wurde in Abschnitt \ref{sec:fxcop} FxCop betrachtet. Diese Technologie wird im Rahmen der Evaluierung als nicht tauglich bewertet. Der Grund dieser Entscheidung ist auf die Umgebung zurückzuführen. Die eigentliche \glslink{SCA}{statische Code-Analyse} könnte von einer eigenen speziellen Regel durchgeführt werden, die im Kontext der FxCop Runner-Anwendung ausgeführt wird. Dadurch wird die Kommunikation zwischen Regel und aufrufendem Programm erschwert was zu einer größeren Distanz zwischen Informationssammlung und Informationsaufbereitung führt.
\paragraph{}
Anschließend wurde in Abschnitt \ref{sec:cci} die \gls{CCI} betrachtet. Im Rahmen der Evaluierung wird diese Technologie als sehr geeignet erachtet. Als einzigen Nachteil wurde festgestellt, dass \glslink{CCI}{CCI} mit \glslink{ASM}{Assemblies} und CIL-Anweisungen arbeitet und daher keinen direkten Bezug zu dem originalen Quellcode hat. Da das zu analysierende Programm in Form einer \gls{ASM} vorliegen muss, wurden alle Abhängigkeiten bereits zur Kompilierzeit aufgelöst und Ziele von Methodenaufrufen bestimmt. \glslink{CCI}{CCI} kann diese auslesen und brauch nicht selbst zu kompilieren.
\paragraph{}
Danach wurde in Abschnitt \ref{sec:nrefactory} NRefactory untersucht. Diese Technologie wird in der Evaluierung als geeignet angesehen. Die Besonderheit von NRefactory ist, dass diese Bibliothek Unterstützung für die \glslink{SCA}{Analyse} von Quelltext bietet (zumindest für C$^\sharp$, VB.NET kommt wahrscheinlich bald dazu). Diese Form der \glslink{SCA}{Analyse} hat einige Einschränkungen. Beispielsweise kann das tatsächliche Aufrufziel eines Methodenaufrufs durch die alleinige Betrachtung von Quelltext nicht ermittelt werden. Dafür muss NRefactory kompilieren, was dann nur in einer vollständigen Umgebung möglich ist. Um mit \glslink{ASM}{Assemblies} zu arbeiten wird Mono.Cecil genutzt, das hier in Verbindung mit NRefactory gesehen wird. Während der Evaluierung wurden die Möglichkeiten der \gls{ASM}-Analyse mithilfe von \glslink{CCI}{CCI} als umfangreicher festgestellt.
\paragraph{}
Abschließend wurde in Abschnitt \ref{sec:roslyn} das Projekt mit dem Codename Roslyn vorgestellt. In dieser Evaluierung wurde diese Technologie als nicht geeignet bewertet. Diese Entscheidung wurde aufgrund der Tatsache getroffen, dass Roslyn noch nicht offiziell verfügbar ist, sondern derzeitig nur als CTP bezogen werden kann (was sich nach dieser Master-Thesis wahrscheinlich bald ändert). Weiterhin ist die Installation der Roslyn-Umgebung erforderlich. Langfristig ist diese Technologie die bessere Lösung, da sie direkt von Microsoft kommt und im Gegensatz zu NRefactory wesentlich umfangreichere Möglichkeiten, wie beispielsweise die Workspace-API, bietet. Roslyn arbeitet mit Quellcode und muss zur Auflösung von Methodenaufrufen ebenfalls kompilieren was wieder nur in einer vollständigen Umgebung funktioniert. Dank der Workspace-API wird diese aber automatisch verwaltet.
\paragraph{}
Zusammenfassend ist zu sagen, dass die \gls{CCI} derzeitig die beste Möglichkeit darstellt, eine \glslink{SCA}{statische Code-Analyse} durchzuführen. Dabei werden die \glslink{ASM}{Assemblies} analysiert, die die verschiedenen .NET-Compiler erzeugen. Sollte die \glslink{SCA}{Analyse} von reinem Quellcode in einem Sonderfall erforderlich sein, kann eine Kombination mit NRefactory genutzt werden. Sobald Projekt Roslyn allerdings einen offiziellen Zustand erreicht, sollte eine mögliche Technologieersetzung in Betracht gezogen werden. Bis dahin unterstützt die Tatsache, dass FxCop und andere Programme ebenfalls die \glslink{CCI}{CCI} verwenden, die Entscheidung zugunsten der \gls{CCI}.




\chapter{Usus.NET}
\label{chap:ususnet}
Nachdem das Usus-Plugin für Java einfach \emph{Usus} heißt, wird die Visual Studio-Erweiterung, die in der vorliegenden Master-Thesis entwickelt wird, im weiteren Verlauf als \emph{Usus.NET} bezeichnet. Die Architektur von Usus.NET, das in Abschnitt \ref{sec:architecture} noch grob als System bezeichnet wurde, besteht aus drei Teilen, die in Abbildung \ref{fig:architecture2} abgebildet sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=8cm]{images/architektur2.jpg}
	\caption{Architektur von Usus.NET}
	\label{fig:architecture2}
\end{figure}
\texttt{Usus.net} als Visual Studio-Erweiterung verwendet Oberflächenelemente, die in einer Bibliothek zusammengefasst und unabhängig von Visual Studio sind. Die Oberflächen sind Bestandteil der Bibliothek \texttt{Usus.net.View}. Diese verwendet die \texttt{Usus.net.Core}-Bibliothek, die den allgemeinen Funktionsumfang von Usus enthält und die \glslink{SCA}{statische Code-Analyse} von \glslink{ASM}{Assemblies}, die Bewertung der \glslink{Metrik}{Metriken} und die Hotspot-Analyse durchführen kann. Diese Bibliothek kann direkt in andere Anwendungen integriert werden, wie beispielsweise in \texttt{Usus.net.Console}, um Usus.NET auch über die Kommandozeile bedienen zu können. In diesem Kapitel wird ausschließlich auf die zentralen Funktionen von Usus.NET eingegangen, die in \texttt{Usus.net.Core} implementiert sind. In diesem Zusammenhang wird die konkrete Berechnung der \glslink{Metrik}{Metriken} mit der \gls{CCI} beschrieben, sowie auf das zugrunde liegende Objektmodell eingegangen. Das Objektmodell dient dazu die Ergebnisse der \glslink{SCA}{statischen Code-Analyse} weiter zu verarbeiten und als Bericht zur Verfügung zu stellen. Abschließend wird das Verifikations-Framework vorgestellt, mit dem \texttt{Usus.net.Core} selbst getestet wurde.


\section{Metrikberechnung}
\label{sec:metriccalc}
In diesem Abschnitt wird beschrieben, wie die \glslink{Metrik}{Metriken} aus Abschnitt \ref{sec:metrics} von Usus.NET berechnet werden. In Abschnitt \ref{sec:cci} wurde erklärt wie \glslink{ASM}{Assemblies} mit \glslink{CCI}{CCI} analysiert werden können. Deswegen beginnt auch die Berechnung der \glslink{Metrik}{Metriken} mit einem Pfad zu einer PE-Datei, wie sie in Unterabschnitt \ref{subsec:ccimetadata} definiert wurde. Abbildung \ref{fig:metriccalc} zeigt die Klassen, die an der Berechnung beteiligt sind. Diese Klassen befinden sich alle im Namespace \texttt{andrena.Usus.net.Core.Metrics}.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/metriccalc.jpg}
	\caption{Klassen, die an der Metrikberechnung von Usus.NET beteiligt sind}
	\label{fig:metriccalc}
\end{figure}
Ein \texttt{AssemblyVisitor}-Objekt ist in der Lage, eine \glslink{ASM}{PE-Datei} einzulesen und definierte Typen und Methoden zu lokalisieren. Dies ist mit \gls{CCIMetadata} möglich. Die Klasse \texttt{MetricsCollector} erbt die \glslink{SCA}{Analyse}-Funktionalität von \texttt{AssemblyVisitor} und berechnet für die gefundenen Typen und Methoden die \glslink{Metrik}{Metriken}, die ohne den Kontext berechenbar sind. Für Methoden sind dies \emph{\glslink{CC}{zyklomatische Komplexität}}, \emph{Anzahl der Anweisungen}, \emph{Anzahl der tatsächlichen Codezeilen}, \emph{Anzahl der logischen Codezeilen} und \emph{Abhängigkeiten von Typen}. Als \glslink{Metrik}{Klassenmetriken} sind \emph{Anzahl der nicht-statischen öffentlichen Felder}, \emph{Anzahl der Methoden} und \emph{direkte Abhängigkeiten von Typen} kontextfrei. Alle weiteren \glslink{Metrik}{Metriken} sind nur dann berechenbar, wenn die kontextfreien \glslink{Metrik}{Metriken} vollständig bestimmt wurden. So lassen sich beispielsweise die \emph{interessanten direkten Typ-Abhängigkeiten} einer Klasse erst ermitteln, wenn alle deklarierten Typen im betrachteten System bekannt sind. Das gleiche gilt für die \emph{\glslink{NCD}{zyklischen Abhängigkeiten von Namespaces}}, die nur in einem vollständigen Graph der Namespaces gefunden werden können. Diese kontext-sensitiven \glslink{Metrik}{Metriken} werden von Usus.NET im Rahmen einer nachträglichen Bearbeitung der \glslink{Metrik}{Metriken} berechnet. Dazu wird zum einen die Klasse \texttt{PostProcessTypeDependencies} verwendet, die aus allen interessanten Abhängigkeiten den Abhängigkeitsgraph erzeugt um anschließend die \glslink{CCD}{kumulierte Komponentenabhängigkeit} zu bestimmen. Zum anderen wird die Klasse \texttt{PostProcessNamespaceDependencies} genutzt um aus dem Abhängigkeitsgraph der Typen einen Abhängigkeitsgraph der Namespaces zu erstellen. Dieser kann dann genutzt werden, um die \glslink{NCD}{zyklischen Abhängigkeiten der Namespaces} zu suchen.
\paragraph{}
Für jede zu bestimmende \gls{Metrik} existiert eine Klasse, die die Berechnung durchführen kann. Alle Ergebnisse werden in einem \texttt{MetricsReport}-Objekt gesammelt und in Form eines Berichts im \texttt{MetricsCollector}-Objekt hinterlegt. Der Aufrufer kann diesen Bericht jederzeit einsehen. Abschnitt \ref{sec:ususobjectmodel} beschreibt diesen Bericht als Bestandteil des Objektmodells ausführlicher, während Listing \ref{listing:ususnetcoreusage} einen vereinfachten Codeausschnitt aus der Bibliothek \texttt{Usus.net.Console} zeigt, der die \glslink{SCA}{statische Code-Analyse} durchführt und sämtliche \glslink{Metrik}{Metriken} aller Methoden einfach auf der Console ausgibt.
\begin{lstlisting}[caption={Aufruf der Code-Analyse von \texttt{Usus.net.Core} in \texttt{Usus.net.Console}},label={listing:ususnetcoreusage}]
var metrics = Analyze.PortableExecutable(assemblyToAnalyze);
//alternativ: Analyze.Me();
foreach (var method in metrics.Methods) {
	Console.WriteLine("Signature: " + method.Signature);
	Console.WriteLine("CC: " + method.CyclomaticComplexity);
	...
}
\end{lstlisting}
Nachdem die Infrastruktur der Metrikberechnung hiermit beschrieben wurde, werden in den folgenden Unterabschnitten die konkreten Berechnungen der einzelnen \glslink{Metrik}{Metriken} vorgestellt.

\subsection{Zyklomatische Komplexität}
Die \glslink{CC}{zyklomatische Komplexität} einer Methode gibt an, wie viele unterschiedliche Ablaufpfade durch diese Methode existieren. In Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} wurde diese \gls{Metrik} ausführlicher erklärt. In Usus.NET kann die Berechnung auf zwei verschiedene Arten durchgeführt werden. Zum einen kann ausschließlich \gls{CCIMetadata} verwendet und alle CIL-Anweisungen die eine Entscheidung treffen, aufsummiert werden. Eine einfache Abwandlung des Algorithmus, der unter anderem von Steve Gilham vorgestellt \cite{CCperCIL} und laut ihm angeblich auch in frühen Versionen von NDepend (Abschnitt \ref{sec:ndepend}) verwendet wurde, ist in der Klasse \texttt{CyclomaticComplexityOfIl} implementiert. Die andere Variante, die in Usus.NET standardmäßig verwendet wird, nutzt \gls{CCIAst}. Die Klasse \texttt{CyclomaticComplexityOfAst} erzeugt ein spezielles Besucher-Objekt vom Typ \texttt{CyclomaticComplexityCalculator}, das den aus dem Methodenrumpf erzeugten abstrakten Syntaxbaum besucht. Die Erzeugung des \glslink{Ast}{AST} aus der Methodendefinition übernimmt CCI. Listing \ref{listing:cyclomaticcomplexityofast} zeigt den Code, der die \glslink{CC}{zyklomatische Komplexität} in \texttt{Usus.net.Core} bestimmt.
\begin{lstlisting}[caption={Statement-Analyse zur Bestimmung der zyklomatischen Komplexität},label={listing:cyclomaticcomplexityofast}]
var methodBody = method.Decompile(pdb, host);
var cyclomaticComplexityCalculator = new CyclomaticComplexityCalculator();
cyclomaticComplexityCalculator.Traverse(methodBody.Statements());
var result = cyclomaticComplexityCalculator.Result;
\end{lstlisting}
Das \texttt{CyclomaticComplexityCalculator}-Objekt erbt die Funktionalität, sämtliche Anweisungen (engl. Statements) in einem Methodenrumpf zu besuchen, von \texttt{CodeTraverser}, einer Klasse in der CCI. Jede Bedingung, jede \texttt{if}-, \texttt{while}-, \texttt{for}-, \texttt{case}- und \texttt{catch}-Anweisung erhöht einen anfangs mit 1 initiierten Zähler. Obwohl \texttt{CodeTraverser} auch eine Behandlungsroutine für \texttt{foreach}-Anweisungen anbietet, ist die \glslink{CCI}{CCI} momentan nicht in der Lage diese als solche erfolgreich zu erkennen. Dies hat zur Folge, das \texttt{foreach}-Anweisungen, die vom Compiler in \texttt{while}-\texttt{if}-\texttt{finally}-Anweisungen übersetzt werden, auch also solche erkannt werden. Durch das \texttt{while} und das \texttt{if} entstehen also zwei Stellen, die eine Entscheidung treffen, während im Quellcode mit \texttt{foreach} nur eine erkennbar ist. Die in Usus.NET berechnete \glslink{CC}{zyklomatische Komplexität} einer Methode entspricht also der Komplexität, die der Compiler generiert und nicht der, die durch den Quellcode suggeriert wird. Für die Berechnung wird immer nur die aktuell Methode betrachtet. Bedingungen in anderen Methoden, die von der aktuellen Methode aufgerufen werden, werden nicht berücksichtigt. \gls{CCIAst} erlaubt die Statement-Analyse unabhängig davon, ob eine \glslink{PDB}{pdb-Datei} vorhanden ist oder nicht. Die \glslink{CC}{zyklomatische Komplexität} kann also in beiden Fällen korrekt berechnet werden.

\subsection{Methodenlänge}
\label{subsec:methodlength}
Die Länge einer Methode sagt etwas darüber aus, wie viele Dinge diese Methode tut. Eine kurze Methode ist einfacher zu verstehen und zu verändern als eine lange. In Unterabschnitt \ref{subsubsec:methodlength} wurde diese \gls{Metrik} und ihre Varianten genauer beschrieben. Usus.NET bestimmt drei verschiedene \glslink{ML}{Methodenlängen}.
\paragraph{}
Als sehr nachvollziehbare Längenangabe wird wohl die Anzahl der Codezeilen gesehen, die Logik enthalten. Dieser Wert wird von der Klasse \texttt{NumberOfLogicalLines} bestimmt, indem nur \gls{CCIMetadata} verwendet wird. Alle CIL-Anweisungen, außer leeren Anweisungen (\texttt{Nop}), Block-Verlassen-Anweisungen (\texttt{Leave.S}) und Methodenende-Anweisungen (\texttt{Ret}) werden dabei betrachtet. Listing \ref{listing:numberoflogicallines} zeigt den Code, der die Codezeilen der betroffenen CIL-Anweisungen (Operationen) einer Methode findet, doppelte Werte entfernt und deren Anzahl bestimmt.
\begin{lstlisting}[caption={Operation-Analyse zur Bestimmung der Anzahl der logischen Codezeilen},label={listing:numberoflogicallines}]
var locations = method.LocatedOperations(pdb);
var result = locations.GetAllStartLinesOfInterestingOpCodes()
		.Distinct().Count();
\end{lstlisting}
Die Zuordnung der Codezeilen des Quelltexts vor der Kompilierung zu den CIL-Anweisungen danach, kann nur durchgeführt werden, wenn zu der zu analysierenden \glslink{ASM}{PE-Datei} eine \glslink{PDB}{pdb-Datei} existiert. Wie in Unterabschnitt \ref{subsec:ccimetadata} definiert, beinhaltet die \glslink{PDB}{pdb-Datei} die erforderlichen Zeilenangaben. Die \glslink{CCI}{CCI} unterstützt die Analyse dieser Dateien ebenfalls mithilfe der Klasse \texttt{PdbReader}. Wenn keine \glslink{PDB}{pdb-Datei} zur Verfügung steht, oder es sich bei der Methode um eine Iterator-Methode mit \texttt{yield return} handelt, kann die \glslink{CCI}{CCI} die Zeileninformationen nicht bestimmen. In diesem Fall ist der Ergebniswert der \texttt{NumberOfLogicalLines}-\gls{Metrik} -1.
\paragraph{}
Standardmässig verwendet Usus.NET die Anzahl der logischen Codezeilen als \glslink{ML}{Methodenlänge}. Sollte deren Bestimmung aufgrund einer fehlenden \glslink{PDB}{pdb-Datei} oder spezieller Compiler-Funktionen, wie beispielsweise Iterator-Methoden, nicht möglich sein, wird die Anzahl der logischen Anweisungen (Statements) verwendet. Die \texttt{NumberOfStatements}-Klasse verwendet \gls{CCIAst} um den Methodenrumpf zu dekompilieren und einen \glslink{Ast}{AST} zu erzeugen. Dieser kann anschließend analysiert und sämtliche Anweisungen besucht werden. Dieses Vorgehen ist vergleichbar mit der Bestimmung der zyklomatischen Komplexität. Listing \ref{listing:numberofstatements} zeigt wie dafür ein \texttt{StatementCollector}-Objekt verwendet wird.
\begin{lstlisting}[caption={Statement-Analyse zur Bestimmung der Anzahl der Anweisungen},label={listing:numberofstatements}]
var methodBody = method.Decompile(pdb, host);
var statementCollector = new StatementCollector(pdb);
statementCollector.Traverse(methodBody.Statements());
var result = return statementCollector.Result.Count();
\end{lstlisting}
Wenn die \glslink{PDB}{pdb-Datei} nicht vorhanden ist, enthält die \texttt{pdb}-Variable keine Referenz auf ein \texttt{PdbReader}-Objekt, sondern lediglich \texttt{null}. Das Dekompilieren der Methode funktioniert trotzdem. Neben der Anzahl der Anweisungen kann Usus.NET auch die Anzahl der CIL-Anweisungen, den sogenannten Operationen, bestimmen. Dafür wird kein \glslink{Ast}{AST} erzeugt, sodass nur die \gls{CCIMetadata}-Infrastruktur benötigt wird. Allerdings besteht eine Methode aus einer Vielzahl von Operationen, die keinen direkten Zusammenhang mit der Länge des Quellcodes vor dem Kompilieren erkennen lassen. Die Anzahl der CIL-Anweisungen kann daher nicht als nachvollziehbare \glslink{ML}{Methodenlänge} gesehen werden und wird daher nicht weiter berücksichtigt.
\paragraph{}
Als dritte nachvollziehbare \glslink{ML}{Methodenlänge} kann Usus.NET die Anzahl der tatsächlichen Zeilen einer Methode ausrechnen. Genau wie bei der Anzahl der logischen Codezeilen ist hierfür \gls{CCIMetadata} sowie eine \glslink{PDB}{pdb-Datei} erforderlich. In der Klasse \texttt{NumberOfRealLines} werden die Zeilen aller CIL-Anweisungen eines Methodenrumpfs ermittelt. Durch die Differenz der ersten und letzten Zeile kann die Anzahl der Zeilenumbrüche bestimmt werden. Listing \ref{listing:numberofreallines} zeigt diese Berechnung.
\begin{lstlisting}[caption={Operation-Analyse zur Bestimmung der Anzahl der tatsächlichen Zeilen},label={listing:numberofreallines}]
var locations = method.LocatedOperations(pdb);
var firstLine = locations.GetAllValidLines(l => l.EndLine).Min();
var lastLine = locations.GetAllValidLines(l => l.EndLine).Max();
var result = Math.Max(0, lastLine - firstLine - 1);
\end{lstlisting}
Wenn die \glslink{PDB}{pdb-Datei} nicht existiert, ist der Wert der \texttt{NumberOfRealLines}-\gls{Metrik} wieder -1. Da die Anzahl der tatsächlichen Zeilen einer Methode wenig Auskunft über die logische Größe der Methode gibt, bevorzugt Usus.NET die Anzahl der logischen Zeilen als \glslink{ML}{Methodenlänge}. Und nur wenn dieser Wert nicht ermittelt werden kann, fällt Usus.NET auf die Anzahl der logischen Anweisungen zurück.

\subsection{Kumulierte Komponentenabhängigkeit}
\label{subsec:ccdcode}
Die Anzahl aller Klassen, von denen eine Klasse im objektorientierten Sinne (siehe Unterabschnitt \ref{subsec:oo}) direkt und indirekt abhängig ist, ist auch als \glslink{CCD}{kumulierte Komponentenabhängigkeit} (CCD) bekannt. Diese \gls{Metrik} wurde bereits ausführlich in Unterabschnitt \ref{subsubsec:ccd} vorgestellt. Damit die direkten Abhängigkeiten einer Klasse bestimmt werden können, müssen zunächst die direkten Klassenabhängigkeiten jeder Methode ermittelt werden. Jede Verwendung eines Typen innerhalb der Methodensignatur sowie dem Methodenrumpf muss erkannt werden. Usus.NET verwendet dazu die Klasse \texttt{TypeDependencies}.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Klassenabhängigkeiten einer Methode},label={listing:typedependencies1}]
var dependenciesOfMethod = Enumerable.Empty<string>()
		.Union(TypeDependenciesOfSignature.Of(method))
		.Union(TypeDependenciesOfVariables.Of(method))
		.Union(TypeDependenciesOfCallOperations.Of(method))
		.Union(TypeDependenciesOfNewOperations.Of(method))
		.Union(TypeDependenciesOfCatches.Of(method))
		.Union(TypeDependenciesOfTypeMentions.Of(method));
\end{lstlisting}
Mithilfe der \gls{CCIMetadata}-Infrastruktur werden die CIL-Anweisungen der Methode nach Referenzen auf Typen untersucht. Die dabei verwendeten Strategien sind in Listing \ref{listing:typedependencies1} zu sehen. Die Ergebnisse dieser Strategien werden in einer Liste konsolidiert, wobei doppelte Vorkommen ignoriert werden. Die Variable \texttt{method} enthält eine Referenz auf ein Objekt vom Typ \texttt{IMethodDefinition}, welches in \gls{CCIMetadata} definiert ist. Nachdem zu jeder Methode alle Abhängigkeiten bestimmt wurden, können die Abhängigkeiten einer Klasse einfach ermittelt werden, wie in Listing \ref{listing:typedependencies2} dargestellt.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Klassenabhängigkeiten einer Klasse},label={listing:typedependencies2}]
var dependenciesOfType = Enumerable.Empty<string>()
		.Union(type.FullName().Return())
		.Union(GetMethodTypes(methods))
		.Union(GetFieldTypes(type.Fields))
		.Union(GetAncestorTypes(type))
		.Union(GetGenericConstraints(type));
\end{lstlisting}
Dazu werden die Abhängigkeitslisten der Methoden zusammengefasst und mit den Typen der Felder, den Typen der Oberklassen und den Typen eventueller generischer Einschränkungen kombiniert. Eine Klasse ist auch von sich selbst abhängig. Diese Konsolidierung der Listen erfolgt in der Klasse \texttt{DirectDependencies}. Doppelte Vorkommen eines Typen werden wieder ignoriert. Die Variable \texttt{type} enthält eine Referenz auf ein Objekt vom Typ \texttt{INamedTypeDefinition}, welches in \gls{CCIMetadata} definiert ist. \texttt{methods} enthält eine Sequenz von \texttt{MethodMetricsReport}-Objekten, die den Methoden der Klasse in \texttt{type} zugeordnet sind.
\paragraph{}
Um Typen wie \texttt{object}, \texttt{string} und \texttt{int}, die in der Base Class Library (BCL) des .NET Frameworks definiert sind, zu ignorieren, brauchen nur die interessanten Typen betrachtet werden. Dies sind Klassen, die in den analysierten \glslink{ASM}{Assemblies} selbst deklariert und definiert wurden. Dieser Filter ist in der Klasse \texttt{InterestingDirectDependencies} definiert. Da zu diesem Zeitpunkt alle deklarierten Typen des Systems bereits bekannt sein müssen, kann der Filter erst im Rahmen der nachträglichen Bearbeitung durch die \texttt{PostProcessTypeDependencies}-Klasse angewendet werden. Jeder in den \glslink{ASM}{Assemblies} deklarierte Typ ist anschließend nur noch von anderen in den \glslink{ASM}{Assemblies} deklarierten Typen abhängig. Aus diesem Netz der Abhängigkeiten erzeugt Usus.NET mithilfe der QuickGraph\footnote[1]{QuickGraph: "`Generic Graph Data Structures and Algorithms for .NET"' \url{http://quickgraph.codeplex.com/}}-Bibliothek einen Abhängigkeitsgraph auf Typebene. Um jetzt alle direkten und indirekten Abhängigkeiten einer Klasse \texttt{type} zu bestimmen, kann der Algorithmus Depth First Search verwendet werden. In Unterabschnitt \ref{subsubsec:ccd} wurde der Algorithmus bereits ausgewählt, um die Erreichbarkeitsmenge des \texttt{type}-Knoten zu finden. Wie in Listing \ref{listing:cumulatedcomponentdependency} dargestellt, ist die \glslink{CCD}{kumulierte Komponentenabhängigkeit} einer Klasse \texttt{type} die Anzahl der nicht vom Compiler erzeugten Typen, in der Erreichbarkeitsmenge von \texttt{type}.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der \glslink{CCD}{kumulierten Komponentenabhängigkeit}},label={listing:cumulatedcomponentdependency}]
var result = typeGraph.Reach(type).Vertices
		      .Count(t => !t.CompilerGenerated);
\end{lstlisting}
Die Implementierung der \texttt{Reach}-Funktion verwendet die \texttt{DepthFirstSearchAlgorithm<T, Edge<T>>}-Klasse von QuickGraph und setzt den Startknoten auf \texttt{type}. Zusätzlich wird die Suche abgebrochen, nachdem die Erreichbarkeitsmenge des Startknotens gefunden wird.

\subsection{Klassengröße}
\label{subsec:classsize}
Die \gls{CS} gehört zu den \glslink{Metrik}{Metriken} die kontextfrei bestimmt werden können. In Unterabschnitt \ref{subsubsec:classsize} wurde die \gls{CS} in Usus als Anzahl der Methoden festgelegt. Die API der \gls{CCIMetadata} erlaubt eine bedingte Aufsummierung aller Methoden in einer Klassendefiniton, wie in Listing \ref{listing:numberofmethods} gezeigt.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Anzahl der Methoden},label={listing:numberofmethods}]
var result = type.Methods.Count(m => !m.IsDefaultCtor());
\end{lstlisting}
Da jeder nicht-statische Typ immer einen Default-Konstruktor enthält, wird dieser in der \gls{CS} nicht berücksichtigt. Alle anderen Konstruktoren werden gezählt. Neben Konstruktoren und Destruktoren erzeugen der C$^\sharp$- und VB.NET-Compiler aus Properties, Indexern, Operatoren und Events ebenfalls Methoden, die von \gls{CCIMetadata} auch als solche erkannt werden. Gerade in den \texttt{get}- und \texttt{set}-Blöcken eines Properties wird oft Logik implementiert, sodass auch hier mehr als nur Datenzugriff passiert und Methoden-ähnliche Konstrukte entstehen. Eine Unterscheidung, ob ein Property-Block Logik enthält oder nicht (wie im Falle von Auto Implemented Properties), kann Usus.NET nicht vornehmen. Usus.NET sieht deswegen sowohl im \texttt{get}- als auch im \texttt{set}-Block jeweils eine Methode. Wenn Properties generell ignoriert werden würden, könnte die \gls{CS} sehr leicht manipuliert werden, indem Methoden als Properties implementiert werden. Da Indexer sich wie Properties verhalten wird auch hier wieder eine Methode pro Zugriffsrichtung gezählt. Operatoren werden als statische Methoden definiert und beeinflussen daher ebenfalls die Klassengröße. Das letzte Sprachkonstrukt das ebenfalls in Methoden resultiert, ist das Event. Ein als \texttt{event} definiertes Feld beinhaltet ähnlich wie Properties zwei Blöcke. Über den \texttt{add}-Block kann ein \texttt{EventHandler} registriert und den \texttt{remove}-Block kann dieser wieder entfernt werden. Auch hier wird wieder pro Block eine Methode erkannt, da in diesen Event-Blöcken ebenfalls Logik implementiert werden kann.

\subsection{Nicht-statische öffentliche Felder}
Die Anzahl der \glslink{NSPF}{öffentlichen Felder, die nicht statisch sind}, kann ebenfalls im Rahmen der kontextfreien Bestimmung der \glslink{Metrik}{Klassenmetriken} ermittelt werden. Diese \gls{Metrik} wurde bereits in Unterabschnitt \ref{subsubsec:nonstaticpublicfields} vorgestellt. Listing \ref{listing:nonstaticpublicfields} zeigt diese bedingte Aufsummierung der Felder einer Klasse.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der \glslink{NSPF}{nicht-statischen öffentlichen Felder}},label={listing:nonstaticpublicfields}]
var result = type.Fields.Count(f => !f.IsStatic 
	     && f.Visibility == TypeMemberVisibility.Public);
\end{lstlisting}
Auch hier ermöglicht die API der \gls{CCIMetadata} eine Iteration über alle Felder einer Typ-Definition.

\subsection{Namespaces mit zyklischen Abhängigkeiten}
\label{subsec:namespaceswithcyclicdependencies}
Die Anzahl der \glslink{NCD}{zyklischen Abhängigkeiten} ist die einzige \gls{Metrik}, die Usus.NET für Namespaces bestimmen kann. In Unterabschnitt \ref{subsubsec:packetswithcyclicdependencies} wurde hergeleitet, dass dafür der Algorithmus Strongly Connected Components verwendet werden kann. Für die Berechnung wird also der vollständige Abhängigkeitsgraph auf Namespace-Ebene benötigt. Um die Berechnung der \glslink{CCD}{kumulierten Komponentenabhängigkeit} in Unterabschnitt \ref{subsec:ccdcode} durchführen zu können, wurde der vollständige Abhängigkeitsgraph auf Typebene bereits erstellt. Aus diesem Graph kann der Namespace-Graph reduziert werden. Damit ist offensichtlich, dass auch diese \gls{Metrik} im Rahmen der nachträglichen Bearbeitung kontextabhängig bestimmt wird. Die Klasse \texttt{PostProcessNamespaceDependencies} führt die nötigen Berechnungen durch, indem zuerst der Abhängigkeitsgraph auf Namespace-Ebene erstellt wird. Danach werden die Kreise ermittelt und den entsprechenden Namespaces zugewiesen.
\subsubsection{Namespace-Graph}
Die Erstellung des Graphen aller Namespaces geschieht wie in Listing \ref{listing:namespacegraphcreation} dargestellt.
\begin{lstlisting}[caption={Erzeugung des Abhängigkeitsgraphen auf Namespace-Ebene},label={listing:namespacegraphcreation}]
namespaceGraph = metrics.GraphOfTypes.Cast(t => t.AsNamespaceWithTypes());
foreach (var namespaceGroup in namespaceGraph.Vertices
	.GroupBy(n => n.Itself.Name)) {
	namespaceGraph.Reduce(
		namespaceGroup.AsNamespaceWithTypes(), 
		namespaceGroup);
}
\end{lstlisting}
Der Abhängigkeitsgraph auf Klassenebene ist ein Graph vom Typ \texttt{MutableGraph}, der Knoten vom Typ \texttt{TypeMetricsReport} enthält. Dieser Graph wird zunächst in einen neuen \texttt{MutableGraph}-Graphen mit Knoten vom Typ \texttt{NamespaceMetricsWithTypeMetrics} überführt. Dies ist notwendig, da Knoten im nächsten Schritt zusammengefasst werden und alle Knoten in einem Graph den gleichen Knotentyp haben müssen. Jeder Knoten vom Typ \texttt{TypeMetricsReport} wird zu einen \texttt{NamespaceMetricsWithTypeMetrics}-Knoten umgestaltet. Das Ergebnis dieser \texttt{Cast}-Operation ist also ein identischer Graph mit einem unterschiedlichen Knotentyp. Anschließend können alle Knoten, die den gleichen Namespace (\texttt{n.Itself.Name}) besitzen zusammengefasst werden. Alle diese gruppierten Knoten (Typen) des gleichen Namespace können dann mit der \texttt{Reduce}-Operation des Graphen zu einem einzigen Knoten zusammengefasst werden, der alle Typen des Namespace repräsentiert. Der erste Parameter von \texttt{Reduce} ist der neue Knoten, der die Knoten in der Menge, die als zweiter Parameter übergeben wird, ersetzen soll. Selbstverständlich müssen alle Kanten zwischen Knoten außerhalb und Knoten innerhalb der zu reduzierenden Menge zu Kanten zwischen dem neuen Knoten und den Knoten außerhalb der reduzierten Menge umgestaltet werden.
\paragraph{}
In der QuickGraph-Bibliothek konnte kein Algorithmus gefunden werden, der diesen Reduktionsvorgang komplett übernimmt. QuickGraph bietet lediglich die \texttt{MergeVertex}-Operation an, die es erlaubt, einen einzigen Knoten aufzulösen und die Knoten seiner eingehenden Kanten mit den Knoten seiner ausgehenden Kanten zu verbinden. Auf dieser Basis kann der Algorithmus in Listing \ref{listing:vertexreduction} aufsetzen, der in der vorliegenden Master-Thesis als \emph{Vertex Reduction} bezeichnet wird. Der erste Parameter dieses Algorithmus ist der neue Knoten \texttt{reducedVertex}, der eine Menge an anderen Knoten zusammenfassen soll. Der zweite Parameter des Algorithmus sind die Knoten, die zusammengefasst werden sollen, welche als Menge von Knoten in \texttt{vertices} vorliegen. Der neue Knoten wird in den Graph eingefügt und mit allen Knoten, die er ersetzen soll, \emph{stark} verbunden. Anschließend können alle Knoten, die ersetzt werden sollen, mithilfe der \texttt{MergeVertex}-Operation aufgelöst werden.
\begin{lstlisting}[caption={Vertex Reduction - Reduktion von Knotenmengen in einem Digraph},label={listing:vertexreduction}]
graph.AddVertex(reducedVertex);
foreach (var vertex in vertices) {
	graph.AddEdge(new Edge<T>(reducedVertex, vertex));
	graph.AddEdge(new Edge<T>(vertex, reducedVertex));
	graph.MergeVertex(vertex, (s, t) => new Edge<T>(s, t));
}
\end{lstlisting}
Durch die beidseitigen Verbindungen der aufzulösenden Knoten mit dem neuen Knoten werden alle Kanten der alten Knoten auf den neuen Knoten umgebogen. Abbildung \ref{fig:vertexreduction} zeigt die schematische Funktionsweise des Algorithmus Vertex Reduction an einem Beispiel.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/vertexreduction.jpg}
	\caption{Schematische Funktionsweise des Algorithmus Vertex Reduction}
	\label{fig:vertexreduction}
\end{figure}
Die beiden mittleren Knoten sollen zu einem zusammengefasst werden, ohne dass die Kanten verloren gehen. Diese Graphenreduktion, wie sie für die Erstellung des Abhängigkeitsgraph auf Namespace-Ebene erforderlich ist, kann mit der wiederholten Anwendung des Algorithmus Vertex Reduction erreicht werden. Bei jeder Anwendung wird dem Graph ein neuer \texttt{NamespaceMetricsWithTypeMetrics}-Knoten hinzugefügt, der alle \texttt{NamespaceMetricsWithTypeMetrics}-Knoten des gleichen Namespace ersetzt. Sobald der Algorithmus für alle Gruppen von Typen, die sich im gleichen Namespace befinden angewendet wurde, ist der Abhängigkeitsgraph auf Namespace-Ebene vollständig.
\subsubsection{Namespace-Kreise}
Die QuickGraph-Bibliothek bietet eine Implementierung des Algorithmus zur Erkennung der starken Zusammenhangskomponenten. Die Methode \texttt{StronglyConnectedComponents} kann dazu auf dem QuickGraph-Graphen vom Typ \texttt{BidirectionalGraph<V, Edge<V>>} aufrufen werden. Das Ergebnis ist eine Zuordnung von Knoten \texttt{V} zu der eindeutigen Identifikationsnummer der Strongly Connected Component in Form eines \texttt{IDictionary<V, int>}-Objekts. Um die Kreise den enthalten Knoten zuordnen zu können, ist eine Zuordnung von Knoten zu einer Menge von Knoten (dem Kreis) erforderlich. Tabelle \ref{tab:sccfunctionalcomp} zeigt die Transformation der ursprünglichen Zuordnung, um die gewünschte Abbildung von Knoten auf Knotenmenge zu erhalten. IE\textless{}$V$\textgreater{} steht für eine Sequenz von Objekten vom Typ $V$ und ist eine Abkürzung des Typen \texttt{IEnumerable<V>}. Die Transformation hat einen einmaligen Aufwand von $O(n)$, da die initiale Abbildung einmal vollständig invertiert werden muss (2).
\begin{table}
\centering
\begin{array}[t]{ l r c l l}
(1) & V & \rightarrow & int & \text{Ergebnis der SCC-Methode}\\
(2) & int & \rightarrow & IE<V> & \text{Umkehrung der Abbildung (1)}\\
(3) & V \rightarrow int & \rightarrow & int \rightarrow IE<V> & \text{Funktionale Komposition von (1) und (2)}\\
(4) & V & \rightarrow & IE<V> & \text{Reduktion der funktionalen Komposition (3)}\\
\end{array}
\caption{Abbildung von Knoten zu starker Zusammenhangskomponente zu anderen Knoten}
\label{tab:sccfunctionalcomp}
\end{table}
Diese neue Abbildung wird in einem \texttt{StronglyConntectedComponents<V>}-Objekt gekapselt. Um die Anzahl der \glslink{NCD}{zyklischen Abhängigkeiten} eines konkreten Namespace zu ermitteln, muss die \texttt{StronglyConntectedComponents}-Methode auf dem Graph auf Namespace-Abhängigkeiten aufgerufen werden. Auf das Ergebnis kann die in Tabelle \ref{tab:sccfunctionalcomp} gezeigte Transformation angewendet werden. Durch diese Transformation wird ein Objekt vom Typ \texttt{StronglyConntectedComponents<NamespaceMetricsWithTypeMetrics>} erzeugt. Dieses Objekt kann jederzeit nach allen oder speziellen Kreisen gefragt werden. Die \glslink{NCD}{zyklischen Abhängigkeiten eines Namespace} werden in der nachträglichen Bearbeitung der \glslink{Metrik}{Metriken} von der Klasse \texttt{CyclicDependencies} bestimmt. Listing \ref{listing:namespacedependencies} zeigt wie das Objekt, dass die starken Zusammenhangskomponenten repräsentiert (also das Ergebnis der Komposition aus Tabelle \ref{tab:sccfunctionalcomp}), nach dem Kreis gefragt werden kann, auf dem sich der Knoten des Namespace \texttt{namespaceWithTypes} befindet.
\begin{lstlisting}[caption={Namespace-Analyse zur Bestimmung der \glslink{NCD}{zyklischen Abhängigkeiten}},label={listing:namespacedependencies}]
var result = from n in cycles.OfVertex(namespaceWithTypes).Vertices
	     select n.Itself;
\end{lstlisting}
Nachdem alle Namespaces Informationen über die Kreise, auf denen sie sich eventuell befinden, erhalten haben, ist die nachträgliche Bearbeitung der \glslink{SCA}{statischen Code-Analyse} beendet. Das vollständige \texttt{MetricsReport}-Objekt steht dem Aufrufer der Analysemethoden der \texttt{Analyze}-Klasse zur Verfügung.
\subsubsection{Vertikale Kreise}
Namespaces sind hierarchisch. Jeder Typ befindet sich direkt in einem Namespace, wobei dieser wieder Bestandteil eines übergeordneten Namespace sein kann. Der Typ ist also mehreren Namespaces zugeordnet, dem direkten und den indirekten. Usus.NET verwendet den Namespace, der den Typ direkt enthält, als Namespace der Klasse oder des Interfaces. Wenn die Zyklen ermittelt werden, werden also auch Referenzen innerhalb den Hierarchieebenen beachtet. Eine Abhängigkeit eines Typen in Namespace \texttt{A} von einem Typen in Namespace \texttt{A.B} erzeugt für Usus.NET also einen Namespace-Kreis, wenn ein Typ in Namespace \texttt{A.B} einen Typen aus \texttt{A} referenziert. Dieser Kreis ist vertikal, da er zwischen den Ebenen der Namespace-Hierarchie existiert. Prinzipiell sind in .NET alle öffentlichen Typen der übergeordneten Namespaces von den untergeordneten Namespaces ohne \texttt{using}-Anweisungen sichtbar. Wenn Usus.NET vertikale Zyklen ignorieren würde, könnten fragwürdige Klassenabhängigkeiten unerkannt bleiben.


\section{Objektmodell}
\label{sec:ususobjectmodel}
Im vorherigen Abschnitt wurde die Berechnung der \glslink{Metrik}{Metriken} ausführlich beschrieben. Dieser Abschnitt stellt das Objektmodell des Metrikberichts vor. Alle Klassen dieses Modells befinden sich im Namespace \texttt{andrena.Usus.net.Core.Reports}. Abbildung \ref{fig:metriccalc} zeigt, dass das zentrale Datenobjekt der \texttt{MetricsReport}-Typ ist. Wie in Abschnitt \ref{sec:metriccalc} beschrieben, wird dieses Objekt zunächst mit den Daten befüllt, die das \texttt{MetricsCollector}-Objekt sammelt. Anschließend werden im Rahmen der nachträglichen Bearbeitung weitere Berechnungen vorgenommen um auch die kontextabhängigen \glslink{Metrik}{Metriken} zu bestimmen. Die komplette \glslink{SCA}{statische Code-Analyse} wird durch die statischen Methoden der \texttt{Analyze}-Klasse gestartet. Diese Methoden liefern das \texttt{MetricsReport}-Objekt als Ergebnis an den Aufrufer zurück. In diesem Abschnitt wird genau dieses Objekt genauer betrachtet. Abbildung \ref{fig:metricsreport} zeigt alle Klassen, aus denen dieser Bericht besteht.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/metricsreport.jpg}
	\caption{Objektmodell und Klassen des vollständigen Metrikberichts}
	\label{fig:metricsreport}
\end{figure}

\subsection{Methodenberichte}
Der Metrikbericht besteht aus mehreren Methodenberichten. Diese \texttt{MethodMetricsReport}-Objekte enthalten alle relevanten Daten und \glslink{Metrik}{Metriken} jeder im System gefundenen Methode. Die eindeutige Zuordnung von Methode zu Methodenbericht ist über die Eigenschaft \texttt{Signature} möglich. Die Signatur einer Methode macht sie im System eindeutig, da neben Methodenname auch Typ- und Namespace-Name, sowie vollständige Namen des Rückgabetypen und aller Parametertypen enthalten sind. Neben der Menge aller Methodenberichte kann der Bericht zu einer bestimmten Methode in \texttt{MetricsReport} auch gesucht werden. Dazu existieren mehrere Extension Methods\footnote[1]{Mehr Informationen: "`Extension Methods"' \url{http://msdn.microsoft.com/en-us/library/bb383977.aspx}}, die wie in Listing \ref{listing:methodpropertysearch} dargestellt, benutzt werden können. Die Variable \texttt{metrics} enthält die Referenz zu dem \texttt{MetricsReport}-Objekt. Methodenberichte sind vom Typ \texttt{MethodMetricsReport} und lassen sich zum einen über die \texttt{Signature}-Eigenschaft der Methode finden, wie Zeile 2 zeigt. Wenn die gesuchte Methode im Scope ist, also aufgerufen werden könnte, kann sie wie in Zeile 4 auch über einen \texttt{Expression}-Ausdruck angegeben werden. Microsoft beschreibt dieses Konzept in Verbindung mit den in C$^\sharp$ integrierten Lambda-Ausdrücken in einem eigenen Artikel in der MSDN Library \cite{MSDNExpressions}. Dadurch bleibt die Methodenreferenz, im Gegensatz zur Verwendung von Strings, Ziel von automatisierten Refactorings. Eine dritte Möglichkeit erlaubt das Suchen von Methodenberichten mit \texttt{MethodInfo}-Objekten aus der \texttt{System.Reflection}-API des .NET Framework.
\begin{lstlisting}[caption={Methoden- und Property-Suche in einem \texttt{MetricsReport}-Objekt},label={listing:methodpropertysearch}]
//Methoden
methodMetrics = metrics.ForMethod(
  "System.Void andrena.Usus.net.Console.Analyzer.AnalyzeFile(System.String)");
methodMetrics = metrics.ForMethod(() => AnalyzeFile(null));
//Properties
propertyMetrics = metrics.ForProperty(() => Name);
methodMetrics = metrics.ForMethod(
  "System.String andrena.Usus.net.Console.Analyzer.Name.get()");
\end{lstlisting}
Das gleiche gilt auch für Properties. Da der C$^\sharp$-Compiler den \texttt{get}- und \texttt{set}-Block eines Properties als Methoden kompiliert, werden diese ebenfalls auf \texttt{MethodMetricsReport}-Objekte abgebildet. Was der Compiler sonst noch als Methoden erzeugt, wurde bereits in Unterabschnitt \ref{subsec:classsize} beschrieben. Wie in Zeile 6 in Listing \ref{listing:methodpropertysearch} gezeigt, lassen sich Properties auch über einen \texttt{Expression}-Ausdruck suchen. Das resultierende Objekt vom Typ \texttt{PropertyMetricsReport} ist einfach eine Zusammenfassung zweier Objekte vom Typ \texttt{MethodMetricsReport}, nämlich eins für den \texttt{get}- und eins für den \texttt{set}-Teil des Properties. Diese \texttt{MethodMetricsReport}-Objekte der Properties lassen sich aber auch direkt über die Signatur finden, wie Zeile 7 zeigt.

\subsection{Klassenberichte}
Da die Methoden, zu denen \texttt{MetricsReport} die Methodenberichte enthält, in einer Klasse deklariert sind, existiert auch ein Bericht für eben diese Klasse. Die Abbildung von Klasse zu Methode ist im Usus.NET-Objektmodell als Abbildung von \texttt{TypeMetricsReport}-Objekt zu \texttt{MethodeMetricsReport}-Objekten realisiert.
\begin{lstlisting}[caption={Klassen- und Methodensuche in einem \texttt{MetricsReport}-Objekt},label={listing:classmethodsearch}]
typeMetrics = metrics.ForType<Analyzer>();
typeMetrics = metrics.ForType(typeof(Analyzer));
typeMetrics = metrics.ForType("andrena.Usus.net.Console.Analyzer");
foreach (var methodMetrics in metrics.MethodsOfType(typeMetrics)) {...}
\end{lstlisting}
Der Codeausschnitt in Listing \ref{listing:classmethodsearch} zeigt in Zeile 4 wie mithilfe der \texttt{MethodsOfType}-Methode alle Methodenberichte, die zu einem Klassenbericht gehören, ermittelt werden können. Die Variable \texttt{metrics} enthält wieder die Referenz zu dem \texttt{MetricsReport}-Objekt. Zeile 1 und 2 zeigen wie der Klassenbericht für einen Typen gesucht werden kann. Das \texttt{MetricsReport}-Objekt muss in diesem Fall für die \gls{ASM} erzeugt worden sein, in der sich auch der gesuchte Typ befindet. Der Klassenname kann damit weiterhin von automatisierten Refactorings erreicht werden. In Zeile 3 wird der Bericht anhand der \texttt{Fullname}-Eigenschaft des Klassenberichts gesucht. Diese Eigenschaft enthält den Namespace, den Klassennamen sowie eventuelle generische Parameter und ist damit eindeutig.
\paragraph{}
Die \glslink{Metrik}{Metriken} auf Klassenebene, die im \texttt{TypeMetricsReport} enthalten sind, beinhalten auch die Menge aller direkten Abhängigkeiten. In Unterabschnitt \ref{subsec:ccdcode} wurde beschrieben, dass daraus ein Abhängigkeitsgraph auf Klassenebene erstellt wird. Dieser Klassengraph steht anschließend in einem schreibgeschützten Format im \texttt{MetricsReport}-Objekt zur Verfügung. Nach außen ist der Graph als \texttt{IGraph<V>}-Objekt sichtbar, das Knoten vom Typ \texttt{TypeMetricsReport} enthält. Neben der Liste von Knoten besteht der Graph auch aus einer Liste von Kanten zwischen diesen Knoten. Eine Kante ist vom Typ \texttt{Tuple<TypeMetricsReport, TypeMetricsReport>}. Das erste Element in diesem Tuple stellt die Quelle, das zweite das Ziel der Verbindung dar. Beide Listen sind schreibgeschützt, sodass der Graph nicht ohne weiteres von außen verändert werden kann. Intern verwendet Usus.NET den Typ \texttt{MutableGraph<V>}, der das \texttt{IGraph<V>}-Interface implementiert. Dieser Typ ist nicht mehr schreibgeschützt und erlaubt einige weitere Operationen. Beispielsweise lassen sich Kreise ermitteln, Erreichbarkeitsmengen bestimmen und Knoten reduzieren. Der Graph ist Bestandteil des Metrikberichts um eine Abbildung der Beziehungen zwischen den Klassen zu haben.

\subsection{Namespace-Berichte}
Neben den Methoden- und Klassenberichte enthält das \texttt{MetricsReport}-Objekt auch Berichte über Namespaces. Diese Berichte sind vom Typ \texttt{NamespaceMetricsReport} und enthalten im Vergleich zu den Methoden- und Klassenberichten nur wenig Informationen. Doch auch Namespaces haben einen eindeutigen Namen. Diese \texttt{Name}-Eigenschaft des Berichts wird für die Suche verwendet, wie Listing \ref{listing:namespaceclasssearch} in Zeile 1 zeigt.
\begin{lstlisting}[caption={Namespace- und Klassensuche in einem \texttt{MetricsReport}-Objekt},label={listing:namespaceclasssearch}]
namespaceMetrics = metrics.ForNamespace("andrena.Usus.net.Console");
foreach (var typeMetrics in metrics.TypesOfNamespace(namespaceMetrics)) {...}
\end{lstlisting}
Da Namespaces mehrere Klassen enthalten, lässt sich diese Zuordnung auch unter den Berichten auflösen. Die Schleife in Zeile 2 iteriert über alle Klassenberichte eines Namespace-Berichts, indem die \texttt{TypesOfNamespace}-Methode verwendet wird.
\paragraph{}
Neben dem Abhängigkeitsgraph auf Klassenebene steht auch der Abhängigkeitsgraph auf Namespace-Ebene zur Verfügung. In Unterabschnitt \ref{subsec:namespaceswithcyclicdependencies} wurde beschrieben, wie dieser Graph aus dem Klassengraph erzeugt wird. Der Namespace-Graph besteht aus Kanten zwischen Knoten vom Typ \texttt{NamespaceMetricsReport}. Im Gegensatz zum Graph auf Typebene verwendet Usus.NET intern keinen \texttt{MutableGraph<NamespaceMetricsReport>}-Graph, sondern einen Graph, dessen Knoten \texttt{NamespaceMetricsWithTypeMetrics}-Objekte sind. Dies ist der Fall, da der Namespace-Graph aus dem Graph mit Klassenberichten als Knoten erzeugt wird. Um trotzdem einen schreibgeschützten Graphen vom Typ \texttt{IGraph<NamespaceMetricsReport>} zur Verfügung stellen zu können, ohne das ein neuer Graph erzeugt werden muss, verwendet Usus.NET eine Projektion des Knotentypen. Für diese Projektion wird ein \texttt{GraphSurrogate<V, R>}-Objekt verwendet, welches das Interface \texttt{IGraph<V>} implementiert und ein Objekt vom Typ \texttt{IGraph<R>} kapselt. Die Knoten- und Kantenliste in diesem Typ werden über die Projektion von $R \rightarrow V$ an den Zieltyp angepasst. Über diesen Adapter ist es möglich, einen Graph mit Knoten vom Typ \texttt{NamespaceMetricsWithTypeMetrics} als Graph mit Knoten vom einem anderen Typ zu behandeln. In diesem Fall mit Knoten vom Typ \texttt{NamespaceMetricsReport}. Dies ist allerdings nur möglich, wenn eine Abbildung von $R$ nach $V$ existiert. Da ein \texttt{NamespaceMetricsWithTypeMetrics}-Objekt den eigentlichen Namespace-Bericht sowie alle Klassenberichte in diesem Namespace enthält, ist die Abbildung einfach zu realisieren.


\section{Metrikgewichtung}
\label{sec:metricweighting}
Nachdem in den vorherigen beiden Abschnitten beschrieben wurde, wie die Berechnung der \glslink{Metrik}{Metriken} funktioniert und in welcher Struktur das Ergebnis präsentiert wird, beschäftigt sich dieser Abschnitt mit der Weiterverarbeitung dieser Ergebnisse. Usus verwendet die \glslink{Metrik}{Metriken} beispielsweise für die in Unterabschnitt \ref{subsec:ususcockpit} vorgestellte Cockpit-Ansicht und in der in Unterabschnitt \ref{subsec:usushotspots} betrachteten Hotspots-Ansicht. Für diese beiden Ansichten werden die ermittelten \glslink{Metrik}{Metriken} gewichtet, mit Schwellwerten verglichen und Mittelwerte gebildet. Wie dies geschieht wurde bereits in Unterabschnitt \ref{subsec:allprojectsmetrics} ausführlich beschrieben. Die im folgenden vorgestellten Klassen befinden sich alle im Namespace \texttt{andrena.Usus.net.Core.Hotspots}.

\subsection{Hotspots}
\label{subsec:hotspots}
Hotspots sind Methoden, Klassen und Namespaces dessen \glslink{Metrik}{Metriken} über einer Schwelle liegen. Usus.NET kann diese Hotspots in Form eines \texttt{MetricsHotspots}-Objekts aus einem \texttt{MetricsReport}-Objekt bestimmen. Listing \ref{listing:hotspots} zeigt dies in Zeile 1. Die Variable \texttt{metrics} enthält wieder eine Referenz zu einem \texttt{MetricsReport}-Objekt. Anschließend können alle Berichte der Methoden, Klassen und Namespaces ermittelt werden, dessen \glslink{Metrik}{Metriken} über den Schwellen liegen, die in Unterabschnitt \ref{subsec:allprojectsmetrics} erwähnt wurden.
\begin{lstlisting}[caption={Methoden-, Klassen- und Namespace-Hotspots in \texttt{MetricsReport}},label={listing:hotspots}]
MetricsHotspots hotspots = metrics.Hotspots();
methodHotspots = hotspots.OfMethodLength();
classHotspots = hotspots.OfClassSize();
classHotspots = hotspots.OfCumulativeComponentDependency();
classHotspots = hotspots.OfNumberOfNonStaticPublicFields();
namespaceHotspots = hotspots.OfNamespacesInCycle();
\end{lstlisting}
Wenn, wie beispielsweise in Zeile 2, alle \texttt{MethodMetricsReport}-Objekte bestimmt werden, dessen \texttt{MethodLength}-Eigenschaft über der definierten Schwelle liegt, iteriert Usus.NET über alle Methoden im \texttt{MetricsReport}-Objekt. Dabei werden nur Berichte zurückgegeben, dessen \glslink{ML}{Methodenlängen} über dem Ergebnis der Schwellwertfunktion für \glslink{ML}{Methodenlängen} liegen. Die Schwellwerte der \glslink{Metrik}{Metriken} müssen nicht konstant sein. Der Schwellwert kann sich auch abhängig von der Projektgröße ändern, wie es beispielweise bei der \glslink{CCD}{kumulierten Komponentenabhängigkeit} der Fall ist (siehe Unterabschnitt \ref{subsubsec:acd}). Daher verwendet Usus.NET das Konzept einer Schwellwertfunktion. Alle Schwellwertfunktionen können bei Bedarf auch zur Laufzeit geändert werden. Dafür lässt sich das \texttt{RatingFunctionLimits}-Objekt über die statische Eigenschaft \texttt{RatingFunctions.Limits} erreichen. In diesem Objekt sind alle Schwellwertfunktionen definiert. Listing \ref{listing:limitfunctions} zeigt die Deklaration und Definition der Schwellwertfunktionen für die \glslink{CCD}{kumulierte Komponentenabhängigkeit} und die \glslink{ML}{Methodenlänge} unter Verwendung von Lambda-Ausdrücken. Die Formel der Schwellwertfunktion \texttt{CumulativeComponentDependency} entspricht der bereits beschriebenen Formel \ref{eq:averagecomponentdependency4}.
\begin{lstlisting}[caption={Schwellwertfunktionen sind abhängig von \texttt{MetricsReport}-Daten},label={listing:limitfunctions}]
//Deklarationen
Func<CommonReportKnowledge, int> MethodLength { get; set; }
Func<CommonReportKnowledge, int> CumulativeComponentDependency { get; set; }
...
//Definitionen
MethodLength = ck => 9;
CumulativeComponentDependency = ck => ck.NumberOfClasses * 
	(1.5 / Math.Pow(2, (Math.Log(ck.NumberOfClasses) / Math.Log(5))));
...
\end{lstlisting}
Alle Schwellwertfunktionen sind Abbildungen von einem \texttt{CommonReportKnowledge}-Objekt auf eine Ganzzahl. \texttt{CommonReportKnowledge} ist Teil des Objektmodells des vollständigen Metrikberichts und wurde bereits in Abbildung \ref{fig:metricsreport} gezeigt. Dieses Objekt enthält einige allgemeine Daten der \glslink{SCA}{statischen Code-Analyse}, wie beispielsweise die Anzahl der analysierten Klassen und Namespaces.

\subsection{Statistiken}
\label{subsec:statistics}
Die Unterscheidung zwischen \gls{Metrik} und Statistik der \gls{Metrik} wurde bereits in Unterabschnitt \ref{subsec:staticcodeanalysis} definiert. Die Theorie, also wie diese Statistiken in Usus entstehen und berechnet werden können, wurde in Unterabschnitt \ref{subsec:allprojectsmetrics} vorgestellt. In Usus.NET lassen sich die gleichen Werte über ein \texttt{RatedMetrics}-Objekt bestimmen, welches wie in Listing \ref{listing:statistics} in Zeile 1 gezeigt, über die \texttt{Rate}-Methode erzeugt werden kann. Die Variable \texttt{metrics} enthält wieder eine Referenz eines \texttt{MetricsReport}-Objekts.
\begin{lstlisting}[caption={Statistiken aller Berichte in einem \texttt{MetricsReport}-Objekt},label={listing:statistics}]
RatedMetrics statistics = metrics.Rate();
double acd = statistics.AverageComponentDependency;
double acs = statistics.AverageRatedClassSize;
double acc = statistics.AverageRatedCyclomaticComplexity;
double aml = statistics.AverageRatedMethodLength;
double anf = statistics.AverageRatedNumberOfNonStaticPublicFields;
double ncn = statistics.NamespacesWithCyclicDependencies;
\end{lstlisting}
Diese Statistiken entstehen durch eine Gewichtung der Methoden-, Klassen und Namespace-Berichte, die anschließend gezählt oder gemittelt werden. Die Berichte können auch unabhängig von einander gewichtet werden. Die \texttt{Rate}-Methode existiert für die einzelnen Berichte ebenfalls und erzeugt Objekte vom Typ \texttt{RatedMethodMetrics} für Methoden, \texttt{RatedTypeMetrics} für Klassen und \texttt{RatedNamespaceMetrics} für Namespaces. Tatsächlich ruft Usus.NET diese Methode für jeden Bericht auf und speichert die dadurch erzeugten Objekte in einem \texttt{RatedMetrics}-Objekt. Dort können dann die Mittelwerte der einzelnen gewichteten \glslink{Metrik}{Metriken} als projektübergreifende Statistiken bestimmt werden. Sämtliche Gewichtungsfunktionen implementieren die Formeln aus Unterabschnitt \ref{subsec:allprojectsmetrics} und sind in der Klasse \texttt{RatingFunctions} definiert.
\begin{lstlisting}[caption={Berechnung der Statistiken in einem \texttt{RatedMetrics}-Objekt},label={listing:statisticscalc}]
AverageRatedMethodLength = RatedMethods.AverageAny(m => m.RatedMethodLength);
AverageComponentDependency = 
	RatedTypes.AverageAny(m => m.CumulativeComponentDependency) 
	/ metrics.CommonKnowledge.NumberOfClasses;
NamespacesWithCyclicDependencies = 
	RatedNamespaces.CountAny(m => m.IsInCycle) 
	/ metrics.CommonKnowledge.NumberOfNamespaces;
\end{lstlisting}
Listing \ref{listing:statisticscalc} zeigt die Berechnung der \glslink{AML}{durchschnittlichen Methodenlänge} in Zeile 1, der \glslink{ACD}{durchschnittlichen Komponentenabhängigkeit} in den Zeilen 2 bis 4 und der Anzahl der \gls{NCD} in den Zeilen 5 bis 7. Obwohl die Berechnungen einfach lesbar sind, ist der Aufwand zur Bestimmung jeder Statistik $O(n)$. Für jede Statistik müssen alle Methoden oder Klassen-Berichte, die die \gls{Metrik} enthalten, berücksichtigt werden.

\subsection{Ignorierbares}
In Unterabschnitt \ref{subsec:statistics} wurde beschrieben, dass alle Methodenberichte berücksichtigt werden müssen, wenn eine Statistik einer \gls{Metrik} für Methoden bestimmt werden soll. Allerdings existieren in einer \gls{ASM} Methoden, die keine relevanten \glslink{Metrik}{Metriken} enthalten. Alle Methoden und Klassen, die vom Compiler erzeugt wurden, werden mit einem Attribut vom Typ \texttt{[CompilerGenerated]} gekennzeichnet. So gekennzeichnete Stellen ignoriert Usus.NET bei der Berechnung der Statistiken und der Hotspots. Da diese Methoden und Klassen im Quellcode nicht offensichtlich sind, würde ein Hotspot an einer solchen Stelle den Entwickler auf etwas nicht nachvollziehbares hinweisen.
\paragraph{}
Beispielsweise erzeugt der Compiler aus einem \texttt{yield return}-Statement eine Klasse, die den Zustand der Methode verwaltet. Die erzeugte Logik ist kein Hotspot und sollte die Statistik auch nicht beeinflussen, da ein daraus resultierender Komplexitätsanstieg nicht nachvollziehbar ist. Ein weiteres Beispiel sind anonyme Methoden. Die durch einen Lambda-Ausdruck erzeugte Klasse wird teilweise ignoriert. Lambda-Ausdrücke sind Funktionen, die in Form von \texttt{()=>}\{\} geschrieben und wie Objekte behandelt werden können. Microsoft beschreibt diese Funktionsobjekte in der MSDN Library \cite{MSDNExpressions}. In einem Lambda-Ausdruck können die Variablen, die sich zum Zeitpunkt der Definition im Scope befinden, verwendet werden. Wenn der Lamdba-Ausdruck dann als Objekt weitergegeben wird, behält dieser weiterhin den Scope der Definition. Dies ist möglich, da der .NET-Compiler eine Klasse generiert, die eine generierte Methode enthält. Diese generierte Methode enthält die Logik des Lambda-Ausdrucks. Externe Variablen, die von diesem Ausdruck verwendet werden, werden vom Compiler ebenfalls in der generierten Klasse deklariert und nicht wie erwartet in der Klasse, die den Lambda-Ausdruck definiert. Diese erzeugt lediglich ein Objekt der generierten Klasse um die Variablen definieren zu können. Dank der in Unterabschnitt \ref{subsec:ccicodeast} beschriebenen Bibliothek \gls{CCIAst} ist Usus.NET in der Lage, die Logik des Lambda-Ausdrucks in der Methode zu finden, die den Ausdruck definiert und nicht nur in der Methode, die ihn nach dem Kompilieren enthält. Dadurch werden die \glslink{CC}{zyklomatische Komplexität} und die \glslink{ML}{Methodenlänge} der definierenden Methode, unter Berücksichtigung der Logik des Lambda-Ausdrucks, korrekt berechnet. Die \glslink{Metrik}{Metriken} der erzeugten Klasse werden ignoriert, da diese wieder die Statistiken nicht nachvollziehbar beeinflussen würden.
\paragraph{}
Außerdem betrachtet Usus.NET nur Methoden, die einen nicht leeren Methodenrumpf besitzen. Abstrakte Methoden und Methodendeklarationen in Interfaces haben offensichtlich eine \glslink{ML}{Methodenlänge} und \glslink{CC}{zyklomatische Komplexität} von 0. Sie werden ebenfalls nicht in die Berechnung der Statistiken miteinbezogen, da sie das Ergebnis verfälschen. Eine Methodendeklaration ist weder gut noch schlecht, würde aber als sehr gute Methode die Statistik ungewollt verbessern. Um die ignorierbaren Methoden und Klassen zu finden, bieten die Methoden- und Klassenberichte im Usus.NET-Objektmodell aus Abschnitt \ref{sec:ususobjectmodel} die beiden Eigenschaften \texttt{CompilerGenerated} und \texttt{OnlyDeclaration} an. Das in Abschnitt \ref{sec:eclipseusus} vorgestellte Usus-Plugin für Eclipse nimmt diese Unterscheidung nicht vor und behandelt abstrakte Methoden und Interface-Deklarationen wie normale Methoden, was zu einer trügerischen Verbesserung der Statistiken führt, wenn viele Interfaces und abstrakte Methoden vorhanden sind.


\section{Metrikverteilung}
\label{sec:distributions}
Im Namespace \texttt{andrena.Usus.net.Core.Math} existiert die Klasse \texttt{Distributions}. In dieser Klassen sind mehrere Extensions Methods definiert, die \glslink{Verteilung}{Verteilungen} von Methoden- und \glslink{Metrik}{Klassenmetriken} bestimmen können. Listing \ref{listing:methodtypedistributions} zeigt, wie diese Methoden verwendet werden können.
\begin{lstlisting}[caption={\glslink{Verteilung}{Verteilungen} der Methoden- und Klassenberichte erstellen},label={listing:methodtypedistributions}]
IHistogram css = Metrics.TypeDistribution(t => t.ClassSize);
IHistogram ccs = Metrics.MethodDistribution(m => m.CyclomaticComplexity);
\end{lstlisting}
Die Variable \texttt{Metrics} enthält eine Referenz auf ein \texttt{MetricsReport}-Objekt. Die \gls{Verteilung} besteht aus einem \texttt{Histogram}-Objekt und weiteren Verteilungsinformationen. Diese \texttt{Histogram}-Klasse bekommt über den Konstruktor eine Sequenz von \texttt{int}-Werten übergeben, aus denen sie das Histogramm erstellt. Das Histogramm ist eine einfache Abbildung von den diskreten Werten der Sequenz zu der absoluten Häufigkeit des Auftretens des entsprechenden Werts. Diese Zuordnung kann auch in einem Koordinatensystem angezeigt werden kann. Auf der x-Achse werden die diskreten Werte der Sequenz dargestellt, während die absoluten Häufigkeiten des Auftretens auf der y-Achse angezeigt werden. Dadurch wird ersichtlich, wie oft ein bestimmter Wert in der Sequenz enthalten ist. Listing \ref{listing:distributioncreation} zeigt, wie ein Histogramm in Usus.NET erstellt wird.
\begin{lstlisting}[caption={Erzeugung eines Histogramms mit Math.NET},label={listing:distributioncreation}]
var maxValue = data.Max();
for (int i = 0; i <= maxValue; i++)
	histogram.AddBucket(new Bucket(-0.5 + i, 0.5 + i));
histogram.AddData(data.Select(d => d * 1.0));
\end{lstlisting}
Die Variable \texttt{data} enthält die erwähnte Sequenz von Ganzzahlen (\texttt{IEnumerable<int>}), die über den Konstruktor übergeben wird. Um diese Sequenz auf die diskreten Werte abzubilden, verwendet die \texttt{Histogram}-Klasse Funktionalität der öffentlichen Bibliothek Math.NET\footnote[1]{Download und mehr Informationen: "`Math.NET Numerics"' \url{http://mathnetnumerics.codeplex.com/}}. Usus.NET unterstützt dabei nur Histogramme mit positiven Werten. Ein fertiges Histogramm kann in Form eines \texttt{IHistogram}-Objekts weitergegeben und analysiert werden. Dort können die Werte der x-Achse mithilfe der Eigenschaft \texttt{BinCount} von 0 bis \texttt{BinCount}-1 bestimmt werden. Um den y-Wert, also die absolute Häufigkeit zu einem x-Wert zu bestimmen, kann die \texttt{IHistogram}-Methode \texttt{ElementsInBin(x)} mit dem x-Wert als Parameter aufgerufen werden.
\paragraph{}
Usus.NET nutzt Mechanismen um das Histogramm zu analysieren und speichert die Ergebnisse in Form von \texttt{IFittingReport}-Objekten ebenfalls in dem \texttt{Distribution}-Objekt. Das Interface \texttt{IFittingReport} definiert die beiden Properties \texttt{Parameter} und \texttt{Error}, welche von einer konkreten Verteilungsfunktion zur Verfügung gestellt werden können. In der aktuellen Version von Usus.NET wird nur die geometrische \gls{Verteilung} unterstützt. Die Klasse \texttt{Distribution} hat dafür das \texttt{GeometricalFit}-Property. Dieses Property liefert ein \texttt{GeometricalDistributionFitting}-Objekt, welches als \texttt{Parameter} das \gls{LGD} aus Formel \ref{eq:gdistribution} zurückgibt. Um diese Parameter der \glslink{Verteilung}{Verteilungen} zu bestimmen, berechnet Usus.NET statistische Kennzahlen (beispielsweise den Mittelwert) der Sequenz des Histogramms mithilfe der Math.NET-Bibliothek. Wie diese Analyse des Histogramms und die Annäherung der Verteilungsfunktionen genau funktioniert, ist in Abschnitt \ref{sec:histogramapproximation} beschrieben. Sobald der Parameter einer \gls{Verteilung} bestimmt wurde, kann auch der Fehler dieser \gls{Verteilung} berechnet und über das \texttt{Error}-Property veröffentlicht werden. Anhand des Fehlers können unterschiedliche Approximationen des Histogramms verglichen werden. Da Usus.NET momentan nur eine \gls{Verteilung} unterstützt, ist der Vergleich der Fehler noch nicht relevant. Wie der Fehler ermittelt werden könnte, wird in Abschnitt \ref{sec:histogramerror} behandelt.


\section{Testen}
Nachdem in den vorherigen Abschnitten die \glslink{SCA}{statische Code-Analyse}, das Objektmodell sowie die Statistiken von Usus.NET erläutert wurden, beschäftigt sich dieser Abschnitt mit einer Möglichkeit \glslink{Metrik}{Metriken} mit Quellcode zu verbinden. \texttt{Usus.net.Core} stellt dafür eine Infrastruktur zur Verfügung, die in dieser Master-Thesis als \emph{Verification Framework} bezeichnet wird. Das Verification Framework befindet sich im Unter-Namespace \texttt{Verification} und besteht aus einer Menge an Attributen, mit denen Methoden und Klassen dekoriert werden können.
\begin{lstlisting}[caption={Erwartungswerte für \glslink{Metrik}{Metriken} per Attribut definieren},label={listing:expectedmetrics}]
[ExpectDirectDependency("System.Exception")]
class ClassWithOneMethod
{
	[ExpectCyclomaticComplexity(1)]
	public void MethodWithNothing(Exception e) {}
}
\end{lstlisting}
Diese Attribute beschreiben Erwartungen in Form von \glslink{Metrik}{Metriken} an die betroffene Methode oder Klasse, wie in Listing \ref{listing:expectedmetrics} gezeigt. Diese Erwartungen können mithilfe der Methoden der Klasse \texttt{Verify} überprüft werden, was in Listing \ref{listing:expectedverification} zu sehen ist. Dazu ist ein \texttt{MetricReport}-Objekt erforderlich, welches auf einfache Weise mit \texttt{Analyse.Me()} ermittelt werden kann.
\begin{lstlisting}[caption={Verifikation der erwarteten \glslink{Metrik}{Metriken} für Methoden und Klassen},label={listing:expectedverification}]
Verify.MethodsWith<ExpectCyclomaticComplexityAttribute>(metrics);
Verify.TypesWith<ExpectDirectDependencyAttribute>(metrics);
\end{lstlisting}
Bei der Verifikation werden dann alle Methoden und Klassen in der aktuellen \gls{ASM} ermittelt, die mit einem solchen Attribut dekoriert sind. Für diese werden anhand der Signatur oder dem Klassennamen die entsprechenden Berichte in \texttt{metrics} gesucht. Anschließend werden die Erwartungswerte, die über die Konstruktoren der Attribute angegeben werden, mit den tatsächlichen \glslink{Metrik}{Metriken} verglichen. Im Falle einer Abweichung wird eine \texttt{VerificationException} geworfen. Auf diese Weise können \glslink{Metrik}{Metriken} erzwungen werden. Dadurch kann erreicht werden, dass eine Methode oder Klasse Bedingungen an die eigene Implementierung stellt, die auf Basis von \glslink{Metrik}{Metriken} formuliert werden können. Eine unabsichtliche Verletzung dieser Bedingungen wird dann sofort offensichtlich. Außerdem sind die erwarteten \glslink{Metrik}{Metriken} bereits im Quellcode sichtbar.
\paragraph{}
Usus.NET nutzt das Verification Framework um die eigene Metrikberechnung und das Objektmodell zu testen. So bestehen die Integrationstests von \texttt{Usus.net.Core} aus beispielhaften Klassen, dessen tatsächliche \glslink{Metrik}{Metriken} künstlich erzeugt und mit den erwarteten Werten der Attribute verglichen werden. Sind die Werte nicht kongruent, schlagen die Testfälle fehl und ein eventueller Fehler in der Metrikberechnung wurde gefunden. Entsprechen die tatsächlichen \glslink{Metrik}{Metriken} den Werten in den Attributen, laufen die Tests erfolgreich durch und bestätigen so die Berechnungen der \glslink{Metrik}{Metriken}. Ein weiterer Anwendungsfall ist ein Konzept, das in dieser Master-Thesis als \emph{Metrics Meta Testing} bezeichnet wird. Damit sind Testfälle gemeint, die die \glslink{Metrik}{Metriken} von Testfällen testen. Zum Beispiel schreibt Roy Osherove in seinem Buch \cite{ArtOfUnitTesting}, dass Testmethoden keine Logik enthalten sollen. Keine Logik bedeutet keine entscheidungstreffenden Anweisungen, wie beispielsweise \texttt{if} oder \texttt{while} zu verwenden. Eine solche Anforderung an Tests kann einfach mit einem \texttt{[ExpectCyclomaticComplexity(1)]}-Attribut an allen Tests sichergestellt werden. Eine spezielle Testmethode erzeugt dann das \texttt{MetricsReport}-Objekt des Testprojekts mit \texttt{Analyze.Me()} und ruft die entsprechende Methode auf der \texttt{Verify}-Klasse auf. Dieser spezielle Testfall testet also, ob alle Testmethoden mit dem Attribut auch wirklich nur einen Ablaufpfad enthalten. Ein anderes Beispiel wäre die Sicherstellung, dass kein Testfall von einem bestimmten Objekt der Implementierung abhängig ist. Dafür kann die Testklasse um das Attribut \texttt{[ExpectNoDirectDependency("...")]} mit dem vollständigen Klassennamen erweitert werden. Eine spezielle Testmethode würde wieder die entsprechende Methode der \texttt{Verify}-Klasse aufrufen und fehlschlagen, sobald eine Methode in der Klasse von dem Typ aus dem Attribut abhängig ist. Das Verification Framework dient also dazu die \glslink{Metrik}{Metriken}, die eigentlich implizit im Code existieren, offen zu legen und einen Fehler zu erzeugen wenn die Implementierung nicht mit den erwarteten \glslink{Metrik}{Metriken} übereinstimmt. Der Entwickler bekommt so die Gelegenheit über ein eventuell fehlerhaftes Verhalten der Implementierung zu reflektieren und ein ansonsten verstecktes Problem schnell zu beheben.
\paragraph{}
Die Funktionen von Usus.NET, die für die Durchführung der \glslink{SCA}{statischen Code-Analyse} zuständig sind, können automatisiert getestet werden. Die dafür erforderlichen Tests sind alle zusammen mit der Implementierung entstanden und können auf Knopfdruck ausgeführt werden. Neben den oben erwähnten Integrationstests existieren auch viele Unit Tests, die beispielsweise die korrekte Gewichtung der \glslink{Metrik}{Metriken} oder die Funktionsweise der Manipulation der Graphen sicherstellen. Eine Liste aller automatisierten Testfälle befindet sich im Anhang \ref{sec:testplans}.




\chapter{Usus.NET als Visual Studio-Erweiterung}
\label{chap:ususnetvsext}
Abbildung \ref{fig:architecture2} zeigt die Verwendung der in Kapitel \ref{chap:ususnet} beschrieben Funktionen der Komponente \texttt{Usus.net.Core}. \texttt{Usus.net.Core} steht als Bibliothek in Form einer \gls{ASM} zur Verfügung und wird von der Bibliothek \texttt{Usus.net.View} genutzt. Diese Bibliothek enthält alle grafischen Oberflächen von Usus.NET und wird von der \texttt{Usus.net}-Komponente in Form einer Visual Studio-Erweiterung verwendet. Die Erweiterung stellt dann nur noch die Infrastruktur der Fenster für die Usus.NET-Oberflächen zur Verfügung. Usus.NET ist kein Addin im Sinne von Unterabschnitt \ref{subsec:visualstudio}, sondern eine Erweiterung. In diesem Kapitel werden zunächst die Steuerelemente von \texttt{Usus.net.View} vorgestellt. Anschließend wird auf die Integration in Visual Studio eingegangen.


\section{Oberflächen}
\label{sec:ususnetviews}
Die Oberfläche von Usus.NET besteht genau wie das Usus für Eclipse (Kapitel \ref{chap:usus}), aus mehreren grafischen Benutzeroberflächen. Alle diese Oberflächen bieten besondere Sichten auf eine gemeinsame Datenquelle. Der Metrikbericht aus Abschnitt \ref{sec:ususobjectmodel} ist als Ergebnis der statischen Code-Analyse aus Abschnitt \ref{sec:metriccalc} das zentrale Objekt. Sobald dieses Objekt vom Typ \texttt{MetricsReport} zur Verfügung steht, müssen sich alle Sichten aktualisieren und die Daten des neuen Berichts verwenden. In diesem Abschnitt wird zunächst die Infrastruktur beschrieben, die es den Usus.NET-Oberflächen erlaubt, eine gemeinsame Datenquelle zu verwenden. Anschließend werden die Implementierungen der Ansichten beschrieben, die bereits für das Usus für Eclipse vorgestellt wurden.

\subsection{Hubs}
\label{subsec:ususnethubs}
Usus.NET besteht aus mehreren Fenstern mit einer gemeinsamen Datenquelle. Jedes Fenster enthält ein Steuerelement vom Typ \texttt{UserControl}\footnote[1]{Mehr Informationen: "`Windows Presentation Foundation"' \url{http://msdn.microsoft.com/de-de/library/ms754130.aspx}}. Um alle diese Steuerelemente mit einem zentralen Objekt zu verknüpfen, bietet die Bibliothek \texttt{Usus.net.View} die Klasse \texttt{ViewHub} an, welche nur in Form einer einzigen Instanz existieren kann. Die Ansichten \texttt{Cockpit}, \texttt{Hotspots}, \texttt{Distribution} und \texttt{CleanCode} werden von der \texttt{ViewFactory} in Kombination mit den entsprechenden ViewModels erzeugt. Das \texttt{ViewHub}-Objekt wird dabei bei den ViewModels bekannt gemacht. Diese können sich dann für die Events \texttt{AnalysisStarted} und \texttt{MetricsReady} registrieren. Ein Aufruf der \texttt{TryStartAnalysis}-Methode, mit einer Liste an \gls{ASM}-Pfaden, startet die \glslink{SCA}{statische Code-Analyse} und teilt allen registrierten Objekten das neue Objekt vom Typ \texttt{MetricsReport} mit. In Abbildung \ref{fig:viewhub} sind die Beziehungen zwischen den Views und den ViewModels in Bezug auf die Hub-Infratstuktur verdeutlicht. Die Oberflächen besitzen eigene ViewModels und implementieren damit das MVVM-Muster, welches Josh Smith in seinem Artikel \cite{WPFMVVM} ausführlich beschreibt.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/viewhub.jpg}
	\caption{Oberflächen und ViewModels in Verbindung mit dem \texttt{ViewHub}-Objekt}
	\label{fig:viewhub}
\end{figure}
Nachdem die Steuerelemente erzeugt wurden, erreichen die Events \texttt{AnalysisStarted} und \texttt{MetricsReady} des einen \texttt{ViewHub}-Objekts, die ViewModels aller Oberflächen in Usus.NET. In der \texttt{TryStartAnalysis}-Methode wird sichergestellt, dass eine \glslink{SCA}{Analyse} nur dann gestartet werden kann, wenn sie nicht schon läuft. Wie die \glslink{SCA}{Analyse} dann gestartet wird, ist in Listing \ref{listing:startanalysis} zu sehen.
\begin{lstlisting}[caption={Start der statischen Code-Analyse in der \texttt{TryStartAnalysis}-Methode},label={listing:startanalysis}]
AnalysisStarted();
ThreadPool.QueueUserWorkItem((c) =>
{
	MetricsReport metrics = Analyze.PortableExecutable(files.ToArray());
	MetricsReady(metrics);
});
\end{lstlisting}
Zu Beginn wird das Event \texttt{AnalysisStarted} gefeuert. Alles weitere findet asynchron in einem eigenen Thread statt, der über den \texttt{ThreadPool} erzeugt wird. Dadurch muss der Aufrufer der \texttt{TryStartAnalysis}-Methode nicht warten, da die \glslink{SCA}{Analyse} im Hintergrund ausgeführt wird. Die Klasse \texttt{Analyse} ist bereits aus Abschnitt \ref{sec:metriccalc} bekannt. Sobald der Bericht vom Typ \texttt{MetricsReport} erzeugt wurde, wird dieser über das Event \texttt{MetricsReady} an alle ViewModels übergeben. Diese müssen sich beim Anzeigen der Daten des Berichts nur noch darum kümmern, dass sie die Daten mit dem Thread der Oberfläche synchronisieren. Die grafischen Steuerelemente und die Factory befinden sich im Namespace \texttt{andrena.Usus.net.View}. Im Namespace \texttt{andrena.Usus.net.View.Hub} befindet sich die Hub-Infrastruktur. Sämtliche ViewModels der Oberflächen sind im Namespace \texttt{andrena.Usus.net.View.ViewModels} zu finden.

\subsection{Cockpit}
\label{subsec:ususnetcockpit}
Das Fenster mit den am weitesten aggregierte \glslink{Metrik}{Metriken} ist "`Usus.NET Cockpit"'. Nach dem Vorbild aus Unterabschnitt \ref{subsec:ususcockpit} enthält die Oberfläche eine einfache Tabelle und zeigt alle Statistiken an, die bereits in Unterabschnitt \ref{subsec:statistics} vorgestellt wurden. Abbildung \ref{fig:ususnet_cockpit} zeigt das Cockpit-Steuerelement als Fenster in Visual Studio.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_cockpit.png}
	\caption{Usus.NET Cockpit-Fenster}
	\label{fig:ususnet_cockpit}
\end{figure}
Dieses Fenster verhält sich wie alle anderen Fenster und kann in Visual Studio beliebig angedockt werden. Das ViewModel reagiert auf einen verfügbaren Metrikbericht, indem es die Einträge der Tabelle durch neue Einträge für die Statistiken ersetzt. Wenn die neuen Werte kleiner sind, werden sie als Verbesserung grün angezeigt, während größere Werte als Verschlechterung rot dargestellt werden. Per Doppelklick auf die Tabelle lassen sich die Methoden anzeigen, die sich seit dem letzten Kompilieren geändert haben. Usus.NET erlaubt es dann auch zu eben diesen Methoden zu springen. Dafür wird der gleiche Mechanismus wie für die Hotspots aus Unterabschnitt \ref{subsec:ususnethotspots} verwendet. Als Tabelle wird ein \texttt{DataGrid}-Objekt verwendet. Neben der Anzahl der Hotspots wird in der Spalte "`Distribution"' zu jeder \gls{Metrik} das \gls{LGD} angezeigt, das ausführlicher in Abschnitt \ref{sec:histogramanalysis} beschrieben wird. Hier ist ein größerer Wert ein besserer Wert. Außerdem ist mit einem Blick in die Statusleiste ersichtlich, wie viele relevante Codezeilen die analysierte Codebasis enthält. Unterabschnitt \ref{subsec:rloc} beschreibt wie sich dieser Wert zusammensetzt.

\subsection{Info}
\label{subsec:ususnetinfo}
Das nächste Usus.NET-Fenster entspricht dem Usus Info-Fenster aus Unterabschnitt \ref{subsec:ususinfo}. Dieses Fenster zeigt die \glslink{Metrik}{Metriken} einer Methode in Verbindung mit der Klasse an. Im Gegensatz zu der Eclipse Variante, lässt sich dieses Fenster nicht mit dem Shortcut \texttt{Ctrl-U} öffnen. Usus.NET platziert einen kleinen Button rechts neben jeder Methodendeklaration, wie in Abbildung \ref{fig:ususnet_info} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_info.png}
	\caption{Usus.NET Info-Fenster}
	\label{fig:ususnet_info}
\end{figure}
Ein einfacher Mausklick öffnet das Usus.NET Info-Fenster und zeigt die \glslink{Metrik}{Metriken} der entsprechenden Methode an. Die \glslink{Metrik}{Metriken} der Klasse sind ebenfalls sichtbar. Wie der Button im Code-Editor angezeigt wird, ist in Unterabschnitt \ref{subsec:editoradornment} beschrieben. Der Button erscheint nur neben Methoden und nicht neben Properties oder Klassen. Daher lässt sich das Info-Fenster auch nur für Methoden öffnen. Dies ist ausreichend, da die \glslink{Metrik}{Klassenmetriken} ja ebenfalls angezeigt werden. Das Info-Fenster in der Eclipse Variante lässt sich zusätzlich auch für Klassen direkt öffnen. Wenn der Entwickler auf den Button klickt, werden die Zeilennummer sowie der Name der Datei an das ViewModel des Info-Fensters übertragen. Beide Informationen kommen dort in Form eines \texttt{LineLocation}-Objekts an. Obwohl die Editor-Buttons und das Fenster in separaten Erweiterungsprojekten implementiert sind, ist diese Übertragung über das in Unterabschnitt \ref{subsec:vsmenus} beschriebene Event-System möglich. Um den Methoden- und Klassenbericht zu einer Datei und Zeile zu ermitteln, wird die Klasse \texttt{CurrentMethodInfoCalculator} verwendet. Jeder Methodenbericht erhält durch die Metrikberechnung aus Abschnitt \ref{sec:metriccalc} die Zeileninformationen der \glslink{PDB}{pdb-Datei} in Form eines \texttt{SourceCodeLocation}-Objekts. Usus.NET kann dann anhand der Zeilennummer und dem Dateipfad des geklickten Button, den entsprechenden Methodenbericht finden und dessen \glslink{Metrik}{Metriken} anzeigen.

\subsection{Hotspots}
\label{subsec:ususnethotspots}
Abbildung \ref{fig:ususnet_hotspots} zeigt alle Hotspots in der Codebasis.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_hotspots.png}
	\caption{Usus.NET Hotspots-Fenster}
	\label{fig:ususnet_hotspots}
\end{figure}
Wie die Oberfläche in Unterabschnitt \ref{subsec:usushotspots}, lassen sich zu jeder \gls{Metrik} genau die Methoden, Klassen und Namespaces anzeigen, dessen \glslink{Metrik}{Metriken} über den definierten Schwellen aus Abschnitt \ref{sec:metrics} liegen. Dazu wird die API verwendet, die bereits in Unterabschnitt \ref{subsec:hotspots} vorgestellt wurde. Diese Problemfälle sind nach \gls{Metrik} gruppiert und lassen sich über die Registerkarte der entsprechenden \gls{Metrik} anzeigen. Mit einen Doppelklick auf einen Methoden- oder Klassen-Hotspot springt Visual Studio an die Problemstelle im Quellcode. Dies ist möglich, da alle Methodenberichte ja ein \texttt{SourceCodeLocation}-Objekt beinhalten. Das ViewModel von "`Usus.NET Hotspots"' verwendet das Interface \texttt{IJumpToSource}, um an beliebige Zeilen von beliebigen Dateien zu springen. Auf der Seite von Visual Studio implementiert das Fenster, das das grafische Hotspots-Element enthält, dieses Interface. Wie eine Zeile in einer Visual Studio-Erweiterung angesprungen werden kann, beschreibt Unterabschnitt \ref{subsec:vsrowjumps}. Listing \ref{listing:jumptomethod} zeigt den Sprung von der Seite des Hostspots-ViewModel.
\begin{lstlisting}[caption={Zu der Methode eines \texttt{MethodMetricsReport}-Objekt springen},label={listing:jumptomethod}]
if (Report.SourceLocation.IsAvailable)
	jumper.JumpToFileLocation(
		Report.SourceLocation.Filename,
		Report.SourceLocation.Line, true);
\end{lstlisting}
Die Variable \texttt{Report} enthält eine Referenz auf das \texttt{MethodMetricsReport}-Objekt eines Hotspots. Der letzte Parameter des Methodenaufrufs gibt an, dass die entsprechende Zeile selektiert werden soll und damit schneller sichtbar wird. Die \glslink{PDB}{pdb-Datei} einer \gls{ASM} enthält keine Zeileninformationen für Klassen. Um per Doppelklick zu einem Klassen-Hotspot zu springen, ermittelt das ViewModel die erste Methode dieser Klasse und springt zu dieser. Wenn ein Typ keine anspringbaren Methoden enthält, kann Usus.NET zu diesem Typen nicht springen. Ein Doppelklick auf einen Namespace-Zyklus-Hotspot öffnet den Dialog aus Abbildung \ref{fig:ususnet_hotspotscycle}.
\begin{figure}[h]
	\centering
		\includegraphics[width=14cm]{images/ususnet_hotspotscycle.png}
	\caption{Usus.NET Namespace-Zyklus-Dialog}
	\label{fig:ususnet_hotspotscycle}
\end{figure}
In der linken Spalte werden alle Namespaces in eben diesem Zyklus anzeigt. Per Doppelklick auf einen dieser Namespaces werden in der rechten Spalte die Typen angezeigt, die einen Typen in einem der anderen Namespaces referenzieren. Zusätzlich wird der dort referenzierte Typ angegeben und von welcher Methode diese Referenz ausgeht. Auch hier kann mit einem Doppelklick auf einen der Typen in der rechten Spalte direkt zu der Quellcodedatei, die den Typen enthält, gesprungen werden. Dadurch können die Klassen, die den Zyklus erzeugen schnell gefunden werden.

\subsection{Histogramm}
\label{subsec:ususnethistogram}
Abbildung \ref{fig:ususnet_histogram} zeigt die Häufigkeitsverteilungen aller Berichte des Objektmodells aus Abschnitt \ref{sec:ususobjectmodel} in Bezug auf die \glslink{Metrik}{Metriken} an.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_histogram.png}
	\caption{Usus.NET Histogramm-Fenster}
	\label{fig:ususnet_histogram}
\end{figure}
Ähnlich wie das Hotspots-Fenster, ist auch das Verteilungs-Fenster mit Registerkarten unterteilt. Um die Histogramme zu bestimmen, werden die Funktionen verwendet, die bereits in Abschnitt \ref{sec:distributions} vorgestellt wurden. Diese \glslink{Verteilung}{Verteilungen} können anschließend angezeigt werden. Dazu verwendet Usus.NET das Spaltendiagramm des WPF Toolkits\footnote[1]{Download und mehr Informationen: "`WPF Toolkit - February 2010 Release"' \url{http://wpf.codeplex.com/releases/view/40535}}. Usus.NET versucht die Histogramme zu interpretieren, was in Abschnitt \ref{sec:histogramanalysis} beschrieben wird. Das Ergebnis dieser Interpretation wird am rechten oberen Rand angezeigt.

\subsection{Class Graph \& Package Graph}
In Unterabschnitt \ref{subsec:ususgraphs} wurde vorgestellt, wie Usus für Eclipse die Abhängigkeitsgraphen auf Klassen- und Paketebene visualisiert. Usus.NET erstellt diese Graphen ebenfalls und veröffentlicht sie als Teil des Objektmodells, wie in Abschnitt \ref{sec:ususobjectmodel} beschrieben. Eine grafische Visualisierung dieser Graphen in Form eines Fensters in Visual Studio, wird von Usus.NET noch nicht unterstützt. Dieses Fenster kann im zeitlichen Rahmen dieser Master-Thesis nicht implementiert werden, da dafür eine zeitintensive Evaluierung der Darstellungsmöglichkeiten erforderlich wäre.

\subsection{Clean Code-Grade}
\label{subsec:ususnetcleancodegrades}
Ein Usus.NET-Fenster, das es nicht in der Eclipse-Version gibt, ist "`Usus.NET CleanClode"'. Damit ist Alexander Zeitler's Idee die \gls{CleanCode}-Grade von Ralf Westphal und Stefan Lieser \cite{CleanCodeDeveloper} immer direkt in der IDE zu sehen, in Usus.NET integriert. Zeitlers Idee wurde bereits in Abschnitt \ref{sec:ccdaddin} vorgestellt. Abbildung \ref{fig:ususnet_cleancode} zeigt die Liste, mit den verschiedenen Graden.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_cleancode.png}
	\caption{Usus.NET Clean Code-Grade-Fenster}
	\label{fig:ususnet_cleancode}
\end{figure}
Zu jedem Grad werden die Prinzipien (Unterabschnitt \ref{subsec:ccdprinciples}) und Parktiken (Unterabschnitt \ref{subsec:ccdpractices}) als Hyperlinks aufgelistet. Über diese Hyperlinks lassen sich die Internetseiten von Westphal und Lieser öffnen, die ausführliche Beschreibungen der Grade enthalten. 

\subsection{SQI}
\label{subsec:ususnetsqi}
Ein weiteres Usus.NET-Fenster, welches es in der Eclipse Version ebenfalls nicht gibt, ist "`Usus.NET \glslink{SQI}{SQI}"'. Abbildung \ref{fig:ususnet_sqi} zeigt die Parameter des \gls{SQI} (SQI) in der Tabelle, sowie den berechneten \glslink{SQI}{SQI} einer Beispielanwendung. Wie diese Berechnung funktioniert und was die Parameter bedeuten, wird in Kapitel \ref{chap:andrenasqi} ausführlich beschrieben.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_sqi.png}
	\caption{Usus.NET \glslink{SQI}{SQI}-Fenster}
	\label{fig:ususnet_sqi}
\end{figure}
Nach jedem Kompiliervorgang trägt Usus.NET alle Werte automatisiert ein, bis auf die Testabdeckung. Da Usus.NET die prozentuale Testabdeckung noch nicht automatisiert bestimmt, kann dieser Wert vom Entwickler manuell eingetragen werden. Der \glslink{SQI}{SQI}-Wert wird daraufhin sofort aktualisiert und in groß in der Registerkarte "`Current"' angezeigt. Die Registerkarte "`Change Over Time"' zeigt an, wie sich der \glslink{SQI}{SQI} über die letzten Build-Vorgänge verändert hat. Die Entwicklung des \glslink{SQI}{SQI} wird für jede Solution separat verwaltet. Wenn Visual Studio eine neue Solution analysiert, werden deren \glslink{SQI}{SQI}-Werte angezeigt. Wie diese Veränderungen gespeichert werden, wird in Abschnitt \ref{sec:sqichange} ausführlicher beschrieben.


\section{Visual Studio Integration}
Nachdem alle Oberflächen von Usus.NET beschrieben wurden, beschäftigt sich dieser Abschnitt mit der tatsächlichen Integration der Views in Visual Studio. Jede Oberfläche erhält ein eigenes Visual Studio-Fenster, welches beliebig in der IDE verschoben, angedockt und angepasst werden kann. Diese Fenster sind alle in separaten Projekten vom Typ \emph{VSPackage} implementiert. Die sechs Fensterprojekte sind \texttt{Usus.net.Cockpit} (1), \texttt{Usus.net.Current} (2), \texttt{Usus.net.Hotspots} (3) und \texttt{Usus.net.Distributions} (4). Dazu kommen \texttt{Usus.net.CleanCode} (5) und \texttt{Usus.net.Sqi} (6). Zusätzlich zeichnet das Info-Fenster (\texttt{Usus.net.Current}) Buttons direkt neben dem Quellcode im Visual Studio-Editor. Diese Buttons sind in dem \emph{Editor Adornment}-Projekt \texttt{Usus.net.EditorAdornment} (7) definiert. Das Projekt \texttt{Usus.net.Menus} (8) ist ein weiteres VSPackage, welches das Usus.NET-Menü in die Menüleiste von Visual Studio integriert. Alle diese acht Erweiterungsprojekte werden vom dem VSPackage-Projekt \texttt{Usus.net} (0) zusammengefasst. Dieses Projekt enthält keinen Quellcode und erzeugt auch keine eigene Assembly. Das \texttt{Usus.net}-Projekt erzeugt die VSIX-Datei der kompletten Usus.NET-Erweiterung. Eine VSIX-Datei ist eine ZIP-Datei, welche alle benötigten \glslink{ASM}{Assemblies} und das Erweiterungsmanifest enthält. Durch die Aufteilung von Usus.NET in separate Projekte, braucht Visual Studio nicht die komplette Erweiterung zu laden sondern lediglich die Fenster, die tatsächlich benutzt werden. Ein weiterer Vorteil der getrennten Projekte ist, dass ein potenzieller Fehler in einem VSPackage sich nicht auf die anderen auswirkt. Nur das fehlerhafte VSPackage wird dann von Visual Studio beendet, während die anderen Fenster, die sich ja in anderen VSPackages befinden, weiter lauffähig bleiben.
\paragraph{}
Im Folgenden werden die allgemeinen Implementierungsdetails der Usus.NET-Fenster vorgestellt. Dabei wird beschrieben, wie diese Fenster auf das Build-Ereignis in Visual Studio reagieren können. Weiterhin wird die Integration aller Erweiterungsprojekte in einen einzigen Menüpunkt behandelt, der außerdem eine Kommunikation zwischen den Fenstern ermöglicht. Abschließend wird gezeigt wie Erweiterungen an beliebige Codezeilen springen und wie in diesen Codezeilen grafische Elemente dargestellt werden können.

\subsection{Events}
\label{subsec:vsievents}
Um auf Ereignisse in Visual Studio zu reagieren, wird eine Referenz auf das \texttt{DTE2}-Objekt benötigt. Laut Microsoft ist dieses Objekt, als Bestandteil des \texttt{EnvDTE}-Namespace, Teil der COM\footnote[1]{Mehr Informationen: "`What is COM?"' \url{http://www.microsoft.com/com/default.mspx}}-Bibliothek, die für die Automatisierung von Visual Studio verwendet werden kann \cite{MSDNDTE2}. Listing \ref{listing:getdte2} zeigt, wie eine Referenz zu diesem Objekt erstellt werden kann. Dafür muss dieser Code innerhalb einer Klasse, die von \texttt{ToolWindowPane} erbt, ausgeführt werden, sodass sich \texttt{base} auf ein Objekt vom Typ \texttt{WindowPane} bezieht.
\begin{lstlisting}[caption={Zentrales Automatisierungsobjekt von Visual Studio referenzieren},label={listing:getdte2}]
EnvDTE80.DTE2 dt2 = base.GetService(typeof(SDTE)) as EnvDTE80.DTE2;
\end{lstlisting}
Sobald eine Referenz zu dem \texttt{DTE2}-Objekt verfügbar ist, kann die aktuelle Solution in der Visual Studio-Instanz mit \texttt{dt2.Solution} ermittelt werden. Über dieses \texttt{Solution}-Objekt können dann alle Projekte in dieser Solution bestimmt werden. Mit \texttt{dt2.Events} kann außerdem ein Objekt erhalten werden, über welches Eventhandler für sämtliche Ereignisse definiert werden können. Für Usus.NET ist das \texttt{OnBuildDone}-Ereignis des \texttt{dt2.Events.BuildEvents}-Objekts am wichtigsten. Nur wenn der Kompiliervorgang erfolgreich beendet wird, soll die \glslink{SCA}{statische Code-Analyse} gestartet werden. Ob der Build erfolgreich war, kann mit der \texttt{LastBuildInfo}-Eigenschaft ermittelt werden, die über das \texttt{dt2.Solution.SolutionBuild}-Objekt aufgerufen wird.

\subsection{Fenster}
Ein Visual Studio-Fenster ist eine Klasse, die von \texttt{ToolWindowPane} erbt. Alle Fenster von Usus.NET sollen auf das Build-Ereignis reagieren und alle Projekte der aktuellen Solution und deren erzeugte \glslink{ASM}{Assemblies} bestimmen können. Um diese Logik für alle Usus.NET-Fenster wiederverwenden zu können, stellt Usus.NET einige Oberklassen zur Verfügung, die die benötigten Funktionen bereitstellen. Diese Klassen befinden sich im Namespace \texttt{andrena.Usus.net.ExtensionHelper}.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/windows.jpg}
	\caption{Oberklassen der Usus.NET-Fenster}
	\label{fig:windows}
\end{figure}
Abbildung \ref{fig:windows} zeigt \texttt{DtAwareToolWindow} als oberste Klasse der Hierarchie. Diese Klasse erbt von \texttt{ToolWindowPane} und stellt das in Unterabschnitt \ref{subsec:vsievents} beschriebene \texttt{DT2}-Objekt zur Verfügung. Zusätzlich erbt die Klasse \texttt{SolutionAwareToolWindowPane} von \texttt{DtAwareToolWindow} und nutzt das dort verfügbare Automatisierungsobjekt, um eine Referenz auf die aktuelle Solution, sowie alle Projekte dieser Solution zu ermitteln. Da die Projekte alle als COM-Objekte vorliegen, werden diese in einfache Objekte vom Typ \texttt{Project} konvertiert. Weiterhin erbt die Klasse \texttt{SolutionEventsAwareToolWindowPane} von \texttt{SolutionAwareToolWindowPane} und verwendet die COM-Objekte der Oberklassen um Ereignisse in Visual Studio verfügbar zu machen. Diese Ereignisse wurden bereits in Unterabschnitt \ref{subsec:vsievents} erwähnt. Alle Klassen die von dieser Klasse ableiten, können damit informiert werden, wenn der Entwickler einen Speicher- oder Kompiliervorgang ausführt. Zusätzlich können alle betroffenen Projekte dieses Kompiliervorgangs bestimmt werden. Um über die tatsächlich erzeugten \gls{ASM}-Dateien im Falle eines Builds benachrichtigt werden zu können, erbt die Klasse \texttt{BuildAwareToolWindowPane} abschließend von \texttt{SolutionEventsAwareToolWindowPane}. Diese Klasse stellt ein Ereignis zur Verfügung, welches nur nach einem erfolgreichen Kompilieren ausgeführt wird und welchem eine Liste an Dateipfaden übergeben wird. Diese Liste enthält zu jedem Projekt die aktuellste Assembly. Wenn ein Projekt keine \gls{ASM}-Datei erzeugt, wird es ignoriert. Die aktuellste \gls{ASM} wird von der Methode \texttt{LatestOutputAssembly} der Klasse \texttt{Project} gefunden. Auf diese Weise wird sichergestellt, dass immer der aktuellste Build berücksichtigt wird, unabhängig davon, ob die Dateien im build- oder debug-Verzeichnis erstellt werden.
\paragraph{}
Die in Abschnitt \ref{sec:ususnetviews} vorgestellten Oberflächen von Usus.NET sind also Fensterklassen vom Typ \texttt{BuildAwareToolWindowPane}. Diese Fenster erzeugen in ihren Konstruktoren die entsprechenden ViewModels, registrieren sich für das \texttt{BuildSuccessfull}-Ereignis und leiten dessen Liste mit Dateipfaden an die \texttt{TryStartAnalysis}-Methode der Hub-Infrastruktur aus Unterabschnitt \ref{subsec:ususnethubs} weiter.
\begin{lstlisting}[caption={Initialisierung eines Usus.NET-Fenster},label={listing:ususnetwindowsetup}]
BuildSuccessfull += files => ViewHub.Instance.TryStartAnalysis(files);
base.Content = ViewFactory.CreateCockpit(ViewHub.Instance);
\end{lstlisting}
Alle Fenster werden also über die Build-Vorgänge informiert und benachrichtigen die \texttt{ViewHub}-Instanz. Listing \ref{listing:ususnetwindowsetup} zeigt diese Initialisierung exemplarisch im Konstruktor des Cockpit-Fenster. Usus.NET ist als Erweiterung im Sinne von Unterabschnitt \ref{subsec:visualstudio} implementiert. Dadurch können alle Usus.NET-Fenster als separate Projekte mit der Projektvorlage VSPackage realisiert werden. Das \texttt{ViewHub}-Objekt ist für alle diese Fenster aber das gleiche. In einem speziellen Container-Projekt werden alle VSPackage-Projekte von Usus.NET dann zu einer VSIX-Datei zusammengefasst.

\subsection{Menüpunkt}
\label{subsec:vsmenus}
Standardmäßig werden alle selbsterstellten \emph{Visual Studio Tool Windows} unter \texttt{View / Other Windows} aufgeführt. Für Usus.NET sollen die in Abschnitt \ref{sec:ususnetviews} beschriebenen Fenster aber einen besonderen Stellenwert genießen. Microsoft beschreibt in der MSDN Library wie ein solcher Menüpunkt in Form eines VSPackage-Projekts implementiert werden kann \cite{MSDNMenuBar}. Abbildung \ref{fig:ususnet_menu} zeigt diesen Menüeintrag direkt in Visual Studio.
\begin{figure}[h]
	\centering
		\includegraphics[width=7cm]{images/ususnet_menu.png}
	\caption{Usus.NET-Menüpunkt in der Menüleiste von Visual Studio}
	\label{fig:ususnet_menu}
\end{figure}
Um die einzelnen Fenster zu öffnen, muss das VSPackage des Fensters erst gestartet werden. Dies ist der Fall, da Visual Studio die Erweiterungen erst dann startet, wenn sie das erste Mal durch den Entwickler verwendet werden. Microsoft beschreibt in der MSDN Library wie ein VSPackage manuell gestartet werden kann \cite{MSDNForcePackageLoad}. Sobald das VSPackage eines Fensters gestartet wurde, kann dieses Fenster angezeigt werden. Um das Anzeigen von Usus.NET-Fenstern zu vereinfachen, steht die Klasse \texttt{UsusNetWindow} im Namespace \texttt{andrena.Usus.net.ExtensionHelper} zur Verfügung. Diese Klasse enthält für jedes Usus.NET-Fenster die eindeutige Identifikationsnummer des dazugehörigen VSPackage in Form einer GUID\footnote[1]{Mehr Informationen: "`Guid Structure"' \url{http://msdn.microsoft.com/en-us/library/system.guid.aspx}}. Listing \ref{listing:ususnetdisplaywindows} zeigt wie das VSPackage anhand dieser Identifikationsnummer geladen werden kann.
\begin{lstlisting}[caption={Anzeigen eines Usus.NET-Fenster},label={listing:ususnetdisplaywindows}]
Guid packageToBeLoaded = new Guid(guid);
shell.LoadPackage(ref packageToBeLoaded, out package);
GlobalEventManager.Instance.FireEvent(guid, parameter);
\end{lstlisting}
Nachdem das VSPackage des Fensters in Zeile 2 geladen wurde, kann das Fenster in Visual Studio geöffnet werden. Dazu verwendet Usus.NET ein einziges Objekt vom Typ \texttt{GlobalEventManager}. Sobald das VSPackage eines Fensters geladen wird, registriert es eine Ereignisbehandlung bei der einzigen Instanz der \texttt{GlobalEventManager}-Klasse. Es ist eine Konvention in Usus.NET, dass das Paket dafür seine GUID als Trigger verwendet. Die Ereignisbehandlung kann dann mit der GUID des VSPackage ausgeführt werden, was in Listing \ref{listing:ususnetdisplaywindows} in Zeile 3 zu sehen ist. Listing \ref{listing:ususnetdisplaywindowsevent} zeigt exemplarisch, wie das VSPackage des Usus.NET Cockpit-Fenster die Ereignisbehandlung zum Anzeigen des Fensters registriert. Alle VSPackage-Projekte, die zur der einen VSIX-Datei zusammengefasst werden, teilen sich also die gleiche Instanz des \texttt{GlobalEventManager}-Objekts. Fenster und Menüs können über Packagegrenzen hinweg kommunizieren, indem Ereignisse definiert und ausgeführt werden. Dies ist die einzige Möglichkeit der Fenster-Menü-Kommunikation im Kontext von Usus.NET.
\begin{lstlisting}[caption={Registrierung eines Ereignisses beim \texttt{GlobalEventManager}-Objekt},label={listing:ususnetdisplaywindowsevent}]
GlobalEventManager.Instance.RegisterEvent(
	UsusNetWindow.Cockpit,
	p => ShowToolWindow(null, null));
\end{lstlisting}

\subsection{Zeilensprünge}
\label{subsec:vsrowjumps}
In Unterabschnitt \ref{subsec:ususnethotspots} wurde das Hotspots-Fenster vorgestellt. Nach einem Doppelklick auf einen Hotspot soll Visual Studio zu der entsprechenden Methode oder Klasse springen. Listing \ref{listing:openfilejumprow} zeigt, wie Visual Studio mithilfe des in Unterabschnitt \ref{subsec:vsievents} vorgestellten \texttt{DTE2}-Objekts eine Datei öffnen und zu einer Zeile in dieser Datei springen kann. Das \texttt{DTE2}-Objekt wird durch das \texttt{MasterObjekt}-Property der Klasse \texttt{DtAwareToolWindow} ermittelt.
\begin{lstlisting}[caption={Datei öffnen und an Zeile springen},label={listing:openfilejumprow}]
MasterObjekt.ItemOperations.OpenFile(fileName, 
	EnvDTE.Constants.vsViewKindTextView);
var file = MasterObjekt.ActiveDocument.Selection as EnvDTE.TextSelection;
file.GotoLine(fileLine, selectLine);
\end{lstlisting}
Dieser Code befindet sich in der \texttt{DtAwareToolWindow}-Klasse und lässt sich über die Methode \texttt{OpenFileAtLine} aufrufen. Die Variable \texttt{fileName} enthält den vollständigen Pfad der zu öffnenden Datei und die Variable \texttt{fileLine} die Zeilennummer der zu markierenden Zeile. Ob der Code in der Zeile tatsächlich markiert werden soll, kann über den Parameter \texttt{selectLine} festgelegt werden. Sollte Visual Studio das Dokument bereits geöffnet haben, bringt es dies bei Bedarf in den Vordergrund und springt nur zu der betroffenen Zeile.

\subsection{Editor Adornment}
\label{subsec:editoradornment}
In Unterabschnitt \ref{subsec:ususnetinfo} wurde beschrieben, dass das Info-Fenster von Usus.NET über Buttons aufgerufen wird, die sich direkt neben den Methodensignaturen befinden. Das Erweiterungsmodell von Visual Studio unterstützt das Zeichnen von beliebigen WPF-Elementen im Code-Editor. Über die Projektvorlage \emph{Editor Adornment} (Editor-Verzierung) kann eine Erweiterung erstellt werden, welche auf die aktuell sichtbaren Codezeilen reagieren kann. In dem von der Projektvorlage generierten Code existiert die Methode \texttt{CreateVisuals}, die einen Parameter vom Typ \texttt{ITextViewLine} übergeben bekommt. In dieser Methode kann die Logik implementiert werden, die ein grafisches Element in der übergebenen Zeile anzeigt. Im Fall von Usus.NET ist dies ein kleiner Button, der in der Klasse \texttt{CodeTag} implementiert ist. Dieser Button wird nur neben einer Methodensignatur dargestellt. Usus.NET stellt dies durch einen regulären Ausdruck sicher. Dieser Ausdruck besteht aus vier Komponenten. Die erste Komponente ist in Listing \ref{listing:methodregex1} zu sehen und stellt eine Form dar, die die anderen drei Komponenten mehrfach wiederverwendet.
\begin{lstlisting}[caption={Regulärer Ausdruck einer gültigen Methodensignatur in C$^\sharp$},label={listing:methodregex1}]
^{0}{1} {1}\\((((out |ref |this |params )?{1} {2})?(,[ ]?(out |ref |params )?
{1} {2})*)\\)\$
\end{lstlisting}
\{0\} ist der Platzhalter für die zweite Komponente, während \{1\} für die dritte und \{2\} für die vierte Komponente steht.
\begin{lstlisting}[caption={Regulärer Ausdruck einer gültigen Zugriffseinschränkung in C$^\sharp$},label={listing:methodregex2}]
(private |protected |public |internal )?(static |virtual new |virtual |new 
|override |override sealed )?
\end{lstlisting}
Listing \ref{listing:methodregex2} zeigt die zweite Komponente des regulären Ausdrucks, welche die Sichtbarkeit einer Methode beschreibt. Die dritte Komponente beschreibt die Syntax eines Typen und die vierte beschreibt einen Variablennamen. Beide Ausdrücke sind in Listing \ref{listing:methodregex3} abgebildet.
\begin{lstlisting}[caption={Regulärer Ausdruck eines gültigen Klassen- und Parameternamen in C$^\sharp$},label={listing:methodregex3}]
Klassenname:	([_a-zA-Z]+[\\._a-zA-Z0-9\\[\\]]*(<.*>)?)
Parametername:	([_a-zA-Z]+[_a-zA-Z0-9]*([ ]?=[ ]?[^,<> ]*)?)
\end{lstlisting}
Zusammengesetzt entsteht ein Ausdruck, der nahezu alle gültigen Methodensignaturen zuverlässig erkennen kann und gleichzeitig weitgehend immun gegenüber Fehlern bleibt. Eine 100\%ige Korrektheit wurde nicht angestrebt und würde im zeitlichen Rahmen dieser Master-Thesis auch nicht erreicht werden können. Listen, generische Typen, Standardwerte und automatische \texttt{params}-Arrays werden aber alle korrekt erkannt. Die Erkennung der Methoden wurde mit Unit Tests spezifiziert und getestet.
\paragraph{}
Wenn eine Methode als solche erkannt wurde, wird die Zeilennummer und der Pfad der Codedatei ermittelt und innerhalb des Buttons gespeichert. Beide Informationen sind erforderlich, um eine Methodensignatur in der Quellcodedatei mit einem Methodenbericht des Usus.NET-Objektmodells zu verbinden. Usus.NET kann diese Zuordnung noch nicht anhand der Signatur vornehmen. Die Signatur, die durch die \glslink{SCA}{statische Code-Analyse} der \gls{ASM} mittels \gls{CCIMetadata} bestimmt wird, besteht aus vollqualifizierten Namen und unterscheidet sich im schlimmsten Falle zu sehr von der Signatur die im Quelltext steht. Obwohl ein Ähnlichkeitsvergleich prinzipiell möglich ist, würde dies doch den zeitlichen Rahmen dieser Master-Thesis sprengen. Idealerweise könnte dazu der reguläre Ausdruck aus Listing \ref{listing:methodregex1}, \ref{listing:methodregex2} und \ref{listing:methodregex3} mit einer leichten Anpassung verwendet werden. Wenn eine pdb-Dateil vorhanden ist, funktioniert der zeilenbasierte Ansatz allerdings auch sehr gut. Da die Buttons ja sowieso nur in Visual Studio zu sehen sind und Visual Studio auch die Kompilierung des Codes vornimmt, wird eine solche pdb-Datei auch immer erzeugt. Listing \ref{listing:getlinenr} zeigt, wie in einer Editor Adornment-Erweiterung die aktuelle Zeilennummer ermittelt werden kann.
\begin{lstlisting}[caption={Die tatsächlichen Zeilennummer eines \texttt{ITextViewLine}-Objekts},label={listing:getlinenr}]
int lineNumber = _view.TextSnapshot
		.GetLineNumberFromPosition(line.Start.Position) + 1;
\end{lstlisting}
Die Variable \texttt{line} enthält das Objekt vom Typ \texttt{ITextViewLine}. Die Variable \texttt{\_view} enthält eine Referenz auf ein \texttt{IWpfTextView}-Objekt. Listing \ref{listing:getfile} zeigt wie zusätzlich noch der Pfad der aktuellen Datei ermittelt werden kann. Es ist zu beachten, dass dafür die Zeile nicht erforderlich ist. Visual Studio kann den Dateinamen allein anhand des \texttt{IWpfTextView}-Objekts bestimmen. Nachdem jede Methodensignatur eine Kombination aus Zeilennummer und Dateinamen zugewiesen bekommen hat, ist der Button bereit auf das Klickereignis zu reagieren.
\begin{lstlisting}[caption={Bestimmung des Datei-Pfads eines \texttt{IWpfTextView}-Objekts},label={listing:getfile}]
ITextDocument document;
string filePath = string.Empty;
if (_view != null && _view.TextDataModel.DocumentBuffer.Properties
		.TryGetProperty(typeof(ITextDocument), out document))
	string filePath = document.FilePath;
\end{lstlisting}
Sobald der Entwickler auf den Button klickt, wird die Zeileninformation verpackt und über die Event-Infrastruktur aus Unterabschnitt \ref{subsec:vsmenus} an das VSPackage geschickt, welches das Info-Fenster enthält und daraufhin anzeigt.
\begin{lstlisting}[caption={Öffnen des Info-Fensters mit einem \texttt{LineLocation}-Objekt},label={listing:sendlineandfiletoinfo}]
GlobalEventManager.Instance.FireEvent(UsusNetWindow.Current, 
	new LineLocation { Line = lineNumber, File = filePath });
\end{lstlisting}
Listing \ref{listing:sendlineandfiletoinfo} zeigt wie ein Methodensignatur-Button seine Daten an das Info-Fenster aus Unterabschnitt \ref{subsec:ususnetinfo} sendet. \texttt{UsusNetWindow.Current} enthält die GUID des Info-Fensters, sodass standardmäßig die Ereignisbehandlung zum Öffnen des Fensters ausgeführt wird. Diese Behandlung wird auch von dem Menüpunkt verwendet. Im Gegensatz zu dem Menüpunkt, öffnet der Button das Fenster mit einem Parameter. Die Behandlung auf der Seite des Fensters muss also unabhängig davon funktionieren, ob eine Zeileninformation übergeben wird oder nicht.




\chapter{Clean Code-Unterstützung}
\label{chap:cleancodesupport}
Eine Anforderung an Usus.NET ist die Unterstützung bei der Entwicklung von \gls{CleanCode} (Ziel \ref{goal:cleancode}). Dafür wurde bereits das \gls{CleanCode}-Grade-Fenster in Unterabschnitt \ref{subsec:ususnetcleancodegrades} vorgestellt. Dieses Fenster erinnert den Entwickler kontinuierlich an die Prinzipien und Parktiken, die er am besten befolgen sollte. Um ein Maß für das Level an \gls{CleanCode} zu haben, reichen die bisher vorgestellten \glslink{Metrik}{Metriken} nicht aus. Robert C. Martin beschreibt in seinem Blog-Post \cite{CleanCodeMetrics} die beiden \gls{CleanCode}-\glslink{Metrik}{Metriken} \emph{CRAP} und \emph{The Braithwaite Correlation}, welche nicht Bestandteil dieser Ausarbeitung sind. In dieser Master-Thesis wird eine dritte \gls{Metrik} betrachtet, die aus der Häufigkeitsverteilung der \glslink{Metrik}{Metriken} berechnet werden kann. Der Parameter der approximierten Verteilungsfunktion soll die \gls{CleanCode}-\gls{Metrik} von Usus.NET sein.


\section{Kleine Metriken}
\label{sec:histogramanalysis}
In Abschnitt \ref{sec:distributions} wurde beschrieben, dass Usus.NET Histogramme für alle \glslink{Metrik}{Metriken} erstellen kann. Dieser Abschnitt beschäftigt sich mit der Analyse ebendieser Metrik-Histogramme und wie die \glslink{Metrik}{Metriken} tatsächlich verteilt sind. Nach einer ersten Überlegung folgen beispielsweise \glslink{ML}{Methodenlängen} einer \glslink{Verteilung}{Exponentialverteilung}. "`Kurz"'\footnote[1]{Seite 34} ist das Erste, was Robert C. Martin über Methoden in Bezug auf \gls{CleanCode} schreibt \cite{CleanCode}. In einem Softwaresystem, das mit einem Bewusstsein für \gls{CleanCode} entwickelt wurde, werden also sehr viele sehr kurze Methoden existieren und wenig lange Methoden. Die \glslink{ML}{Methodenlänge} nimmt dabei aber nicht linear ab, sondern eher exponentiell. Diese Entwicklung sollte auch im Histogramm der \glslink{ML}{Methodenlängen} zu sehen sein. Die Funktion der \glslink{Verteilung}{Exponentialverteilung} ist laut Eric W. Weisstein wie in Formel \ref{eq:edistribution} definiert \cite{ExponentialDist}.
\begin{equation}
f_\lambda(x) = 
	\begin{cases}
		\lambda e^{-\lambda x}&x>=0\\
		0&x<0\\
	\end{cases}
\label{eq:edistribution}
\end{equation}
Da alle \glslink{Metrik}{Metriken} ganze Zahlen sind (es gibt keine \glslink{ML}{Methodenlänge} mit 1,5 logischen Zeilen), enthalten auch die Metrik-Histogramme nur diskrete Werte auf der x-Achse. Für die analytische Annäherung einer Verteilungsfunktion empfiehlt sich daher auch die Verwendung einer diskreten Verteilung. Laut Eric W. Weisstein ist das diskrete Gegenstück der kontinuierlichen \glslink{Verteilung}{Exponentialverteilung} die geometrische \gls{Verteilung} \cite{GeometricsDist}. Die Funktion der geometrische \gls{Verteilung} ist in Formel \ref{eq:gdistribution} zu sehen.
\begin{equation}
f_\lambda(x) = 
	\begin{cases}
		\lambda (1 - \lambda)^{x-1}&0 < x \wedge x <= 1  \\
		0&\text{sonst}\\
	\end{cases}
\label{eq:gdistribution}
\end{equation}
Beide Funktionen sind von dem Parameter $\lambda$ abhängig. Die eigentliche Histogramm-Analyse besteht darin, diesen Parameter so zu bestimmen, dass die Funktionen das Histogramm möglichst genau beschreibt.


\section{Approximation}
\label{sec:histogramapproximation}
Eine Methode um das $\lambda$ zu berechnen ist die Maximum Likelyhood-Methode, die Weisstein ebenfalls in einer MathWorld-Veröffentlichung beschreibt \cite{MaximumLikelihood}. Mit dieser Methode kann eine Schätzer-Funktion errechnet werden, die den Parameter $\lambda$ in Abhängigkeit der Werte des Histogramms bestimmt. Sigbert Klinke, Patrick Lehmann, Bernd Rönz, Sibylle Schmerbach und Olga Zlatkin-Troitschanskaia haben den Schätzer für die \glslink{Verteilung}{Exponentialverteilung} bereits bestimmt \cite{MLExponentialDist}. Der Schätzer der geometrischen \gls{Verteilung} wurde von Künzer, Meister und Nebe berechnet \cite{MLGeometricsDist}. Beide Schätzer-Funktionen sind identisch und abhängig von der Histogramm-Sequenz. Formel \ref{eq:edistributionml} zeigt diese Rechenvorschrift zur Bestimmung des $\lambda$-Parameters beider \glslink{Verteilung}{Verteilungen}.
\begin{equation}
\lambda = \frac{n}{\sum_{i=1}^n x_i} = \frac{1}{\bar{x}}
\label{eq:edistributionml}
\end{equation}
Der Parameter $\lambda$ entspricht also dem reziproken Mittelwert. Je mehr kurze Methoden der Quellcode enthält, dest niedriger ist der Mittelwert. Für ein großes $\lambda$ ist der Mittelwert klein und umgekehrt. Auf das Histogramm bezogen bedeutet ein großes $\lambda$, dass die Exponentialfunktion der \gls{Verteilung} schnell fällt (sehr viele kurze und sehr wenige lange Methoden). Abbildung \ref{fig:edist} zeigt die wünschenswerte \gls{Verteilung} in rot und die weniger optimale in blau. Das Schaubild geht von einer Stichprobe mit 100 Werten aus, beispielsweise \glslink{ML}{Methodenlängen}.
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/edist.png}
	\caption{\glslink{Verteilung}{Exponentialverteilung} für \textcolor[rgb]{0.6,0,0}{großes} und \textcolor[rgb]{0,0,0.6}{kleines} $\lambda$}
	\label{fig:edist}
\end{figure}
Die Funktion der geometrischen \gls{Verteilung} verhält sich genauso, da sie den gleichen Maximum Likelihood-Schätzer wie die \glslink{Verteilung}{Exponentialverteilung} hat. Abbildung \ref{fig:gdist} zeigt wieder die wünschenswerte \gls{Verteilung} in rot und die weniger optimale in blau. Auch hier besteht die Stichprobe aus 100 Werten.
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/gdist.png}
	\caption{Geometrische \gls{Verteilung} für \textcolor[rgb]{0.6,0,0}{großes} und \textcolor[rgb]{0,0,0.6}{kleines} $\lambda$}
	\label{fig:gdist}
\end{figure}
Obwohl die \glslink{Verteilung}{Exponentialverteilung} und die geometrische \gls{Verteilung} nicht identisch sind, kann der Parameter, von dem beide abhängig sind, auf die gleiche Art berechnet werden. Das Ergebnis verhält sich in beiden \glslink{Verteilung}{Verteilungen} vergleichbar. In der vorliegenden Master-Thesis wird das \gls{LGD} einer \gls{Metrik} als neue \gls{CleanCode}-\gls{Metrik} definiert.
\begin{definition}[Lambda der geometrischen \gls{Verteilung}]
Das \emph{\gls{LGD}} ist eine \gls{Metrik}, die per Approximation der Funktion \ref{eq:gdistribution} an ein \gls{Metrik}-Histogramm ermittelt wird. Je größer das $\lambda$, desto eher entsprechen die Werte der betrachteten \gls{Metrik} dem \gls{CleanCode}-Paradigma. Der Wert liegt im Intervall \(\left]0, 1\right[\).
\end{definition}
Ein großes $\lambda$ deutet darauf hin, dass die betrachtete \gls{Metrik} dem \gls{CleanCode}-Paradigma von Robert C. Martin folgt. Martin befürwortet sehr einfache und sehr kurze Methoden, sowie Klassen mit sehr wenig Abhängigkeiten \cite{CleanCode}.
\paragraph{}
Usus.NET berechnet den $\lambda$-Parameter in der Klasse \texttt{GeometricalDistributionFitting} nach Formel \ref{eq:edistributionml}. Die Komponenten, die für diese Berechnung zuständig sind, wurden bereits in Abschnitt \ref{sec:distributions} vorgestellt. Das Ergebnis kann anschließend in der Oberfläche aus Unterabschnitt \ref{subsec:ususnethistogram} angezeigt werden. Beispielsweise zeigt Abbildung \ref{fig:ususnet_histogram} die \gls{Verteilung} der \glslink{CS}{Klassengrößen} einer Beispielanwendung. In Kapitel \ref{chap:evaluation} werden konkretere Beispiele betrachtet und mit Usus.NET analysiert.


\section{Abweichung}
\label{sec:histogramerror}
Da das Histogramm von einer stetigen Funktion repräsentiert wird, ist es sehr wahrscheinlich, dass die Funktion mit dem bestimmten Parameter nicht exakt durch die Punkte des Histogramms läuft. Diese Abweichung kann laut Eric W. Weisstein mit den Chi-Squared-Test ermittelt werden \cite{ChiSquared}. Formel \ref{eq:chisquaredtest} zeigt dieses Maß der Abweichung.
\begin{equation}
\chi^2 = \sum_{i=1}^n \frac{(x_i - f(x_i))^2}{f(x_i)}
\label{eq:chisquaredtest}
\end{equation}
Da das \gls{LGD} bekannt ist, kann die Funktion $f(x_i)$ durch die Funktion $f_\lambda(x_i)$ aus Formel \ref{eq:gdistribution} ersetzt werden. Das berechnete Ergebnis kann über den \texttt{Error}-Parameter des \texttt{GeometricalDistributionFitting}-Objekts zurückgegeben werden. Die Implementierung dieser Fehlerfunktion ist in der aktuellen Version von Usus.NET noch nicht enthalten. Sobald Usus.NET die Bestimmung von verschiedenen \glslink{Verteilung}{Verteilungen} unterstützt, kann mithilfe des Fehlers die Verteilungsfunktion bestimmt werden, die das Histogramm am Besten (mit dem geringsten Fehler) beschreibt. Aufgrund der dadurch bestimmten wahrscheinlichsten \gls{Verteilung} könnte eine akkuratere Aussage über die \glslink{Metrik}{Metriken} im betroffenen Softwaresystem getroffen werden. Diese weiteren \glslink{Verteilung}{Verteilungen} könnten eventuell die Poisson-\gls{Verteilung} und die Pareto-\gls{Verteilung} sein. In Usus.NET ist aktuell nur die geometrische \gls{Verteilung} implementiert.


\section{Refactoring-Vorschläge}
Da die \glslink{Metrik}{Metriken} durch die Verteilungsanalyse besser verstanden werden, könnten gezielt Refactorings vorgeschlagen werden, die eine \gls{Verteilung} in eine andere \gls{Verteilung} überführen. Zustände der inneren Softwarequalität können dadurch auf zwei Informationen reduziert werden. Zum Einen die wahrscheinlichste \gls{Verteilung} und zum Anderen die Parameter dieser Verteilung. Anschließend könnten die gewünschten \glslink{Verteilung}{Verteilungen} und deren Parameter als Endzustand definiert werden. Um diese \gls{Verteilung} und deren Parameter zu erreichen, könnten von allen anderen \glslink{Verteilung}{Verteilungen} Übergänge in Form von Refactorings definiert werden. Dadurch entsteht ein gerichteter Graph. Sobald Usus.NET die betrachtete Codebasis einem Zustand zuordnet, könnten die Übergänge (Refactorings) ermittelt werden, die zu einem Endzustand (gewünschte \gls{Verteilung} und deren Parameter) führen.
\paragraph{}
Natürlich ist die \gls{Verteilung} als Repräsentation der inneren Codequalität eine sehr allgemeine \gls{Metrik}. Die damit ermittelten Refactorings müssten also auch sehr allgemein sein. Solche allgemeinen Refactorings könnten beispielsweise "`Methode/Klasse $X$ auf Methoden/Klassen $X_1$ und $X_2$ aufteilen"' oder "`Namespace-Zyklus $X-Y-Z$ auflösen"' sein. Eine weiterführende theoretische Betrachtung oder eine rudimentäre Implementierung dieses Verteilung-Refactoring-Graph, kann im zeitlichen Rahmen dieser Master-Thesis nicht vorgenommen werden.




\chapter{andrena-Softwarequalitätsindex}
\label{chap:andrenasqi}
Dieses Kapitel beschäftigt sich mit dem Anwendungsfall \emph{Software Qualität interpretieren} (Ziel \ref{goal:interpret}). Wie bereits in Kapitel \ref{chap:cleancodesupport} beschrieben, interpretieren Entwickler kleinere \glslink{Metrik}{Metriken} in der Regel als bessere \glslink{Metrik}{Metriken} und das obwohl bessere \glslink{Metrik}{Metriken} nicht automatisch besseren Code beschreiben. In Bezug auf die \glslink{ML}{Methodenlänge} ist Robert C. Martin in seinem Buch sehr deutlich und verteidigt kurze Methoden \cite{CleanCode}. Ein Softwaresystem, welches evolutionär gewachsen ist, enthält leider nicht nur kurze Methoden sondern auch zunehmend längere. Eine alleinige Interpretation über die Verteilung, wie in Abschnitt \ref{sec:histogramanalysis} beschrieben, ist dann schnell nicht mehr ausreichend. Die Gewichtung der \glslink{Metrik}{Metriken}, die in Usus für Eclipse und Usus.NET vorgenommen und in Abschnitt \ref{sec:metrics} beschrieben wird, versucht eine weitere Interpretation zu ermöglichen. Deswegen zeigen die Cockpit-Fenster der beiden Usus-Versionen auch nicht die ungewichteten \glslink{Metrik}{Metriken} an. Allerdings sind die Bedeutungen dieser Statistiken nicht sofort verständlich und erfordern anschließend viel manuelle Interpretation. Die Metrikgewichtung von Usus geht auf das andrena-interne Werkzeug Isis zurück. Isis erlaubt es ungewichtete \glslink{Metrik}{Metriken}, die von einem anderen Tool erstellt wurden, zu importieren und zu bewerten. Das Ergebnis ist der von andrena sogenannte \emph{\gls{SQI}} (SQI), welcher in dem Manuskript von Eberhard Kuhn ausführlich beschrieben wird \cite{IsisSQI} und sämtliche \glslink{Metrik}{Metriken} zu einem einzigen Wert aggregiert. Mit diesem Wert kann die innere Softwarequalität beschrieben werden, sodass weniger manuelle Interpretation erforderlich ist.


\section{Parameter}
\label{sec:sqiparams}
Der von Isis berechnete \gls{SQI} ist von mehreren \glslink{Metrik}{Metriken} abhängig. Im Folgenden werden diese \glslink{Metrik}{Metriken} in der vorliegenden Master-Thesis so definiert, wie sie Kuhn in seinem Manuskript ebenfalls verwendet.
\begin{definition}[Testabdeckung] Die \gls{Metrik} \emph{Testabdeckung} ist der prozentuale Anteil allen Quellcodes, der durch automatisierte Tests abgedeckt wird.
\end{definition}
\begin{definition}[Pakete in Zyklen] Die \gls{Metrik} \emph{\glslink{NCD}{Pakete in Zyklen}} ist die Anzahl aller Namespaces, die Teil eines Namespace-Zyklus sind.
\end{definition}
\begin{definition}[Komplizierte Methoden] Die \gls{Metrik} \emph{Komplizierte Methoden} ist die Anzahl aller Methoden, deren \glslink{CC}{zyklomatische Komplexität} den Schwellwert 5 übersteigen.
\end{definition}
\begin{definition}[Average Component Dependency] Die \gls{Metrik} \emph{\glslink{ACD}{ACD}} ist der durchschnittliche \glslink{CCD}{CCD}-Wert aller Klassen und gibt an, von wie viel Prozent aller Klassen jeder Klasse direkt oder indirekt abhängig ist. Die Berechnung wurde in Unterabschnitt \ref{subsubsec:acd} beschrieben.
\end{definition}
\begin{definition}[Große Klassen] Die \gls{Metrik} \emph{Große Klassen} ist die Anzahl aller Klassen, die mehr als 20 Methoden haben.
\end{definition}
\begin{definition}[Große Methoden] Die \gls{Metrik} \emph{Große Methoden} ist die Anzahl aller Methoden, die mehr als 15 Codezeilen enthalten.
\end{definition}
\begin{definition}[Compiler-Warnungen] Die \gls{Metrik} \emph{Compiler-Warnungen} ist die Anzahl der Warnungen, die der Compiler beim Kompilieren anzeigt.
\end{definition}
Nachdem diese \glslink{Metrik}{Metriken} durch ein Tool bestimmt wurden, berechnet Isis für jede \gls{Metrik} $m$, bis auf die Testabdeckung, das Softwarequalitätsniveau. Die Berechnungsvorschrift ist in Formel \ref{eq:sqniveau} dargestellt. Das Softwarequalitätsniveau der Testabdeckung ist die Testabdeckung selber.
\begin{equation}
SQNiveau(m) = \frac{100}{1,5^{\Big(\displaystyle \frac{RelativeGroeße(m)}{Zweidrittelkonstante(m)}\Big)}}
\label{eq:sqniveau}
\end{equation}
Isis rechnet nicht mit den Rohwerten der \glslink{Metrik}{Metriken}, sondern verwendet dessen relative Größe. Diese relative Größe wird zusätzlich noch mit einem Faktor gewichtet, den Kuhn "`Zweidrittelkonstante"' nennt. Tabelle \ref{tab:sqniveaufactors} zeigt diese Faktoren.
\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.5}
\rowcolors{1}{}{shadethmcolor}
\begin{tabular}{ l | c | c }
	Metrik $m$ & Relative Größe & Zweidrittelkonstante \\
	\hline
	Pakete in Zyklen & $\frac{\displaystyle m}{Anzahl Packages}$ & $\frac{1}{15}$ \\
	Komplizierte Methoden & $\frac{\displaystyle m}{Anzahl Methoden}$ & $\frac{1}{50}$ \\
	Average Component Dependency & $m$ & $100 \times Anzahl Klassen^{-1/3}$ \\
	Große Klassen & $\frac{\displaystyle m}{Anzahl Klassen}$ & $\frac{1}{25}$ \\
	Große Methoden & $\frac{\displaystyle m}{Anzahl Methoden}$ & $\frac{1}{25}$ \\
	Compiler-Warnungen & $\frac{\displaystyle m}{Anzahl Klassen}$ & $\frac{1}{50}$ \\
\end{tabular}
\caption{Relative Größen und Zweidrittelkonstanten aller Isis-\glslink{Metrik}{Metriken}}
\label{tab:sqniveaufactors}
\end{table}
Wie die Zweidrittelkonstanten zustande kommen, beschreiben Andreas Leidig und Nicole Rauch in ihrem technischen Artikel \cite{Isis}. Um das Softwarequalitätsniveau gegenüber monolithischen Konstruktionen robuster zu machen, kann der von Kuhn beschriebenen "`Monolithkorrekturfaktor"' angewendet werden \cite{IsisSQI}. Als Beispiel beschreibt Kuhn, dass eine zweifelhafte Verbesserung der \glslink{Metrik}{Metriken} erreicht werden könnte, indem alle Klassen in einem einzigen Paket oder alle Methoden in einer einzigen Klasse platziert werden. Diese Fälle sollen durch den Monolithkorrekturfaktor berücksichtigt werden. Die Testabdeckung und die Compiler-Warnungen sind von dieser Korrektur nicht betroffen. Formel \ref{eq:sqifmk} zeigt wie dieser Faktor für jede \gls{Metrik} $m$ bestimmt werden kann.
\begin{equation}
f_{mk}(m) = \frac{1}{1,5^{\Big(\displaystyle \frac{MittlereGroeße(m)}{Zweidrittelkonstante_{fmk}(m)}\Big)^3}}
\label{eq:sqifmk}
\end{equation}
Isis verwendet an dieser Stelle wieder eine Zweidrittelkonstante aus Tabelle \ref{tab:sqniveaufmkfactors}, um die Gewichtung des Korrekturfaktors zu regulieren. Die Größe des Systems ist ebenfalls von Bedeutung und wird in Form der Anzahl aller relevanten Codezeilen (RLOC) verwendet. Wie Usus.NET diese Codezeilen ermitteln kann, ist in Unterabschnitt \ref{subsec:rloc} beschrieben.
\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.5}
\rowcolors{1}{}{shadethmcolor}
\begin{tabular}{ l | c | c }
	Metrik $m$ & Mittlere Größe & Zweidrittelkonstante$_{fmk}$ \\
	\hline
	Pakete in Zyklen & $\frac{\displaystyle RLOC}{Anzahl Packages}$ & 3000 \\
	Komplizierte Methoden & $\frac{\displaystyle RLOC}{Anzahl Methoden}$ & 15 \\
	Average Component Dependency & $\frac{\displaystyle RLOC}{Anzahl Klassen}$ & 200 \\
	Große Klassen & $\frac{\displaystyle RLOC}{Anzahl Klassen}$ & 200 \\
	Große Methoden & $\frac{\displaystyle RLOC}{Anzahl Methoden}$ & 15 \\
\end{tabular}
\caption{Zweidrittelkonstanten$_{fmk}$ der Isis-Monolithkorrekturfaktoren}
\label{tab:sqniveaufmkfactors}
\end{table}
Dieser Faktor $f_{mk}$ wird, wie in Formel \ref{eq:sqniveaufmk} gezeigt, mit dem Softwarequalitätsniveau multipliziert, um ein korrigiertes Softwarequalitätsniveau zu erhalten.
\begin{equation}
SQNiveau_{fmk}(m) = SQNiveau(m) \times f_{mk}(m)
\label{eq:sqniveaufmk}
\end{equation}
Nachdem die endgültigen Softwarequalitätsniveaus aller \glslink{Metrik}{Metriken} bekannt sind, können diese aufsummiert werden. Diese Summe ist in Formel \ref{eq:sqisum} dargestellt.
\begin{equation}
SQI = \sum_{m \in M} SQNiveau_{fmk}(m) \times Gewicht(m) \times 0,1
\label{eq:sqisum}
\end{equation}
Isis nimmt dabei eine abschließende Gewichtung anhand Tabelle \ref{tab:sqiweights} vor.
\begin{table}[htb]
\centering
\rowcolors{1}{}{shadethmcolor}
\begin{tabular}{ l | c }
	Metrik $m$ & Gewicht \\
	\hline
	Testabdeckung & 2,28 \\
	Pakete in Zyklen & 1,93 \\
	Komplizierte Methoden & 1,75 \\
	Average Component Dependency & 1,58 \\
	Große Klassen & 1,05 \\
	Große Methoden & 1,05 \\
	Compiler-Warnungen & 0,36 \\
\end{tabular}
\caption{\glslink{SQI}{SQI}-Gewichte}
\label{tab:sqiweights}
\end{table}
\paragraph{}
In diesem Abschnitt wurden die Parameter und deren Gewichtungen beschrieben, mit denen Isis den \gls{SQI} berechnet. Die nachfolgenden Abschnitte beschäftigen sich damit, wie die Berechnung des \glslink{SQI}{SQI} in Usus.NET durchgeführt wird.


\section{Berechnung in Usus.NET}
Nachdem in Abschnitt \ref{sec:sqiparams} die Parameter und die Berechnungsvorschriften des \gls{SQI} beschrieben wurden, beschäftigt sich dieser Abschnitt mit der tatsächlichen Berechnung in Usus.NET. Der Namespace \texttt{andrena.Usus.net.Core.SQI} enthält die Klasse \texttt{Calculate}, welche die Methode \texttt{SoftwareQualityIndex} enthält. Dieser Methode wird ein Objekt übergeben, das das \texttt{IParameterProvider}-Interface implementiert. Jenes Interface definiert \texttt{get}-Properties für alle Parameter, die für die Berechnung des \glslink{SQI}{SQI} erforderlich sind. Listing \ref{listing:sqibigmethods} zeigt die beispielhafte Berechnung der \emph{Großen Methoden}. Die Variable \texttt{parameters} enthält eine \texttt{IParameterProvider}-Referenz, über die die beiden Methoden \texttt{SqNiveau} und \texttt{SqNiveauCorrection} als Extension Methods aufgerufen werden können.
\begin{lstlisting}[caption={Berechnung des \glslink{SQI}{SQI}-Werts für Großen Methoden},label={listing:sqibigmethods}]
return parameters.SqNiveau(m => m.BigMethods, 
		Sqi.RelativeSizeBigMethods, Sqi.CalibrationBigMethods) 
     * parameters.SqNiveauCorrection(m => m.BigMethods, 
		Sqi.MiddleSizeBigMethods, Sqi.CorrectionBigMethods);
\end{lstlisting}
Die \texttt{Sqi}-Klasse enthält für jede \glslink{SQI}{SQI}-\gls{Metrik} je ein Objekt vom Typ \texttt{CorrectionCalibration}, \texttt{Calibration}, \texttt{RelativeSize} und \texttt{MiddleSize}. Diese Typen repräsentieren die Metrik-abhängigen Berechnungen und Gewichtungen aus Abschnitt \ref{sec:sqiparams}. Mit diesen Berechnungen lassen sich das Softwarequalitätsniveau sowie der Monolithkorrekturfaktor jeder \glslink{SQI}{SQI}-\gls{Metrik} bestimmen und multiplizieren. Diese Produkte können anschließend aufsummiert werden um den \gls{SQI} zu erhalten.
\paragraph{}
Die Berechnung des \glslink{SQI}{SQI} kann für jedes Objekt stattfinden, dessen Klasse das Interface \texttt{IParameterProvider} implementiert. In Unterabschnitt \ref{subsec:ususnetsqi} wurde das \glslink{SQI}{SQI}-Fenster vorgestellt, welches das Ergebnis in Visual Studio präsentiert. Im ViewModel dieses Steuerelements, nämlich der Klasse \texttt{ViewModels.SQI}, wird für jeden Parameter ein \texttt{SqiParameter}-Objekt verwaltet. Diese Objekte werden direkt an die Oberfläche gebunden und in Form eines editierbaren \texttt{DataGrid}-Controls angezeigt. Eine Änderung eines Werts wird durch das Data Binding des ViewModels direkt in dem entsprechenden \texttt{SqiParameter}-Objekt vorgenommen. Die Parameterobjekte werden über ein Objekt vom Typ \texttt{SqiParameters} erzeugt. Dieses Objekt beobachtet alle erzeugten Parameter und berechnet im Falle einer Änderung (entweder durch neue \glslink{Metrik}{Metriken} oder manuelle Eingabe) den neuen \glslink{SQI}{SQI}. Die \texttt{SqiParameters}-Klasse implementiert dafür das \texttt{IParameterProvider}-Interface. Über das Ereignis \texttt{SqiChanged} wird der neue \gls{SQI} dann dem ViewModel und damit der View mitgeteilt.
\paragraph{}
Ein von Usus.NET erstellter Metrikbericht in Form eines \texttt{MetricsReport}-Objekt, enthält fast alle Daten, die für die Berechnung des \glslink{SQI}{SQI} erforderlich sind. Im Folgenden wird die Berechnung der Parameter beschrieben, die im Rahmen der Usus.NET-Metrikberechnung aus Abschnitt \ref{sec:metriccalc} und der Metrikgewichtung aus Abschnitt \ref{sec:metricweighting} noch nicht beschrieben wurden.

\subsection{Relevante Code-Zeilen}
\label{subsec:rloc}
Der Isis-\glslink{SQI}{SQI} verwendet eine einheitliche Größe für Projekte, nämlich die \emph{Anzahl aller relevanten Codezeilen} (engl. Relevant Lines Of Code, RLOC). Dabei werden alle Codezeilen in allen Quellcodedateien, ohne Kommentare und ohne Klammern, berücksichtigt. Der Wert wird in dem \texttt{CommonReportKnowledge}-Objekt des Metrikberichts gespeichert (siehe Abschnitt \ref{sec:ususobjectmodel}). \gls{CCIMetadata} erlaubt es die Zeileninformationen der CIL-Anweisungen innerhalb einer Methoden mithilfe der \texttt{PeReader}-Klasse zu bestimmen. In Unterabschnitt \ref{subsec:methodlength} wurde beschrieben, dass Usus.NET auf diese Weise auch die \glslink{ML}{Methodenlänge} einer Methode berechnet. Die Zeileninformationen von Methoden- und Klassendefinitionen können über das \texttt{PeReader}-Objekt nicht ermittelt werden. \gls{CCIMetadata} kann die Anzahl der relevanten Codezeilen also nicht direkt aus einer \gls{ASM} bestimmen. Aus diesem Grund versucht Usus.NET den RLOC-Wert auszurechnen. Die \glslink{ML}{Methodenlänge} bildet dafür die Grundlage. Für jede Methode im \texttt{MetricsReport}-Objekt addiert Usus.NET die \glslink{ML}{Methodenlänge} sowie eine weitere Zeile (Methodendefiniton) zu dem \texttt{RelevantLinesOfCode}-Property in dem \texttt{CommonReportKnowledge}-Objekt. Für jede Klasse wird dieses Property um zwei weitere Zeilen erhöht, welche für die Klassendefinition sowie die Namespace-Zugehörigkeit stehen. Mehrzeilige Methodensignaturen und Klassendefinitionen werden also trotzdem mit nur jeweils einer Zeile gerechnet. Auch für jedes Feld wird die Eigenschaft \texttt{RelevantLinesOfCode} um einen Zähler erhöht. Die \texttt{using}-Angaben am Anfang jeder Quellcodedatei werden ignoriert.

\subsection{Compiler-Warnungen}
Wenn beim Kompilieren Warnungen entstehen, werden diese ebenfalls in die Berechnung des Isis-\glslink{SQI}{SQI} einbezogen. \texttt{Usus.net.Core} kann die Anzahl dieser Warnungen allerdings nicht bestimmen, da diese nicht in der kompilierten \gls{ASM} hinterlegt sind. Eine Visual Studio-Erweiterung in Form eines VSPackage kann auf die Warnungen und Fehler eines Build-Vorgangs zugreifen. Wie in Listing \ref{listing:compilerwarnings} gezeigt, ist dies über das \texttt{DTE2}-Objekt möglich, welches über das Property \texttt{MasterObjekt} der \texttt{DtAwareToolWindow}-Klasse veröffentlicht wird.
\begin{lstlisting}[caption={Anzahl der Compiler-Warnungen bestimmen},label={listing:compilerwarnings}]
ErrorList list = MasterObjekt.ToolWindows.ErrorList;
for (long index = 1; index <= list.ErrorItems.Count; index++)
{
	ErrorItem error = list.ErrorItems.Item(index);
	if (error.ErrorLevel == vsBuildErrorLevel.vsBuildErrorLevelMedium
	 || error.ErrorLevel == vsBuildErrorLevel.vsBuildErrorLevelLow)
		AddWarning();
}
\end{lstlisting}
Da das Usus.NET \glslink{SQI}{SQI}-Fenster ebenfalls eine Unterklasse von \texttt{BuildAwareToolWindowPane} ist, können die Warnungen von dem Fenster bestimmt werden. Warnungen und Fehler werden von Visual Studio in dem Fenster der Fehlerliste angezeigt. Über alle diese Warnungen und Fehler kann iteriert werden, wobei die Unterscheidung zwischen Fehler und Warnung mithilfe der \texttt{ErrorLevel}-Eigenschaft vorgenommen werden kann. Das Fehlerlevel \texttt{vsBuildErrorLevelHigh} steht für einen Fehler, während \texttt{vsBuildErrorLevelMedium} oder \texttt{vsBuildErrorLevelLow} eine Warnung repräsentieren. Alle Warnungen können somit aufsummiert und an das \texttt{SqiParameters}-Objekt des ViewModel weitergeben werden. Dazu implementiert das \glslink{SQI}{SQI}-Fenster das Interface \texttt{IKnowSqiDetails}. Bei der Erzeugung des ViewModels registriert sich das Fenster bei dem ViewModel, sodass im Falle einer \glslink{SQI}{SQI}-Berechnung auch die Werte, die nur vom VSPackage bestimmt werden können, ermittelt werden können. Durch das \texttt{IKnowSqiDetails}-Interface kann das Property \texttt{CompilerWarnings} des Fensters vom ViewModel aufgerufen werden, ohne das das ViewModel abhängig von dem VSPackage ist.

\subsection{Testabdeckung}
Usus.NET bezieht bei der Berechnung des Isis-\glslink{SQI}{SQI} auch die prozentuale Testabdeckung mit ein. Dieser Wert wird von einem Test-Runner ermittelt, der sich in Visual Studio integriert. Das Ergebnis kann nicht aus einer \gls{ASM} allein bestimmt werden. Genau wie die Anzahl der Compiler-Warnungen muss die Testabdeckung von dem VSPackage des \glslink{SQI}{SQI}-Fenster bestimmt werden. Anschließend kann der Wert wieder über das \texttt{IKnowSqiDetails}-Interface an das \texttt{SqiParameters}-Objekt des ViewModel übergeben werden. Da Visual Studio in der Professional-Version die Analyse der Testabdeckung nicht unterstützt, muss ein anderes Werkzeug genutzt werden. Usus.NET müsste also in der Lage sein, unabhängig vom verwendeten Werkzeug die Testabdeckung eines Projekts zu extrahieren. Dies ist nur möglich wenn Usus.NET die Formate, in denen die einzelnen Code Coverage Tools ihr Ergebnis speichern, analysieren kann. Im Rahmen dieser Master-Thesis wurden diese Analysen nicht implementiert. Die Testabdeckung kann daher im \glslink{SQI}{SQI}-Fenster der aktuellen Version von Usus.NET von Hand eingegeben werden, nachdem sie mit Visual Studio oder einem anderen Werkzeug, wie beispielsweise NCover\footnote[1]{Download und mehr Informationen: "`NCover: Code Coverage for .NET Developers"' \url{http://www.ncover.com/}}, ermittelt wurde.


\section{Veränderung}
\label{sec:sqichange}
Um die Veränderung der Softwarequalität zu beobachten, müssen die \glslink{Metrik}{Metriken} bei jedem Kompiliervorgang gemerkt werden. Anschließend können die neusten \glslink{Metrik}{Metriken} mit den vorherigen \glslink{Metrik}{Metriken} verglichen werden. Auf diese Weise könnten Veränderung betrachtet und eine eventuelle Verbesserung der Qualität festgestellt werden. Bei den betrachteten \glslink{Metrik}{Metriken} handelt es sich um die Werte, die im Usus.NET Cockpit-Fenster angezeigt werden, sowie dem \glslink{SQI}{SQI}-Wert. Die \gls{CleanCode}-\gls{Metrik} von Usus.NET wird ebenfalls berücksichtigt, da die Verteilungsparameter auch in der Cockpit-Ansicht angezeigt werden. Das Cockpit-Fenster, welches bereits in Unterabschnitt \ref{subsec:ususnetcockpit} vorgestellt wurde, visualisiert Veränderungen durch Farben. Ist der neue Wert weniger gut als der alte, wird er rot dargestellt. Ein besserer Wert wird grün angezeigt. Die Veränderung der Werte im Cockpit bezieht sich also immer nur auf den letzten und den vorletzten Build. Beim \glslink{SQI}{SQI} dagegen, werden Veränderungen über mehrere Builds hinweg betrachtet. Diese zeitliche Entwicklung des \glslink{SQI}{SQI} wird, wie Abbildung \ref{fig:ususnet_sqihistory} zeigt, im \glslink{SQI}{SQI}-Fenster dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_sqihistory.png}
	\caption{Zeitliche Entwicklung des \glslink{SQI}{SQI} im Usus.NET \glslink{SQI}{SQI}-Fenster}
	\label{fig:ususnet_sqihistory}
\end{figure}
Das \glslink{SQI}{SQI}-Fenster wurde bereits in Unterabschnitt \ref{subsec:ususnetsqi} beschrieben. Das ViewModel verwendet dafür ein Objekt vom Typ \texttt{SqiHistory}, mit dessen \texttt{Now}-Methode neue \glslink{SQI}{SQI}-Werte, die einer Solution zugeordnet sind, gespeichert werden können. Nach jedem Kompiliervorgang speichert Usus.NET den neuen \glslink{SQI}{SQI}-Wert in Zusammenhang mit der aktuellen Zeit und dem aktuellen Datum in dem Unterverzeichnis \_sqi des Solution-Verzeichnisses. Die erzeugten Dateien haben die Dateiendung .sqi und verwenden den Wert der \texttt{DateTime.Now.Ticks}-Eigenschaft als Dateinamen. Dadurch kann es keine Dateien mit doppeltem Namen geben und eine natürliche Sortierung ist implizit. Als Dateiinhalt wird der \glslink{SQI}{SQI}-Wert als \texttt{double} serialisiert. Um diese Gleitkommazahl in einem länderunabhängigen Format zu speichern, werden die Methoden des .NET Framework verwendet, die auch in Listing \ref{listing:doublecultureinvariant} angegeben sind. In dem \_sqi-Verzeichnis der aktuellen Solution entsteht also pro Build eine sqi-Datei. Sobald eine andere Solution geladen und kompiliert wird, werden auch die letzten hundert \glslink{SQI}{SQI}-Werte dieser Solution geladen und in dem Schaubild angezeigt. Auf diese Weise kann die zeitliche Entwicklung des \gls{SQI} beobachtet werden.
\begin{lstlisting}[caption={Länderunabhängie Serialisierung von \texttt{double}-Werten},label={listing:doublecultureinvariant}]
string sqiSerialized = Convert.ToString(sqi, CultureInfo.InvariantCulture);
...
double sqi = Convert.ToDouble(sqiSerialized, CultureInfo.InvariantCulture); 
\end{lstlisting}
Eventuell kann die Kombination aus \glslink{SQI}{SQI}-Wert, Zeit und Datum auch ergänzt werden. Eine Serialisierung der \glslink{SQI}{SQI}-Messpunkte kann dann auch mehr Werte als nur den \glslink{SQI}{SQI} selber in den sqi-Dateien speichern.




\chapter{Usus.NET-Evaluation}
\label{chap:evaluation}
Nachdem Usus.NET in den vergangenen Kapiteln umfangreich beschrieben wurde, soll die Erweiterung in diesem Kapitel einmal tatsächlich eingesetzt werden. In diesem Zusammenhang werden unter anderem einige frei verfügbare Open-Source-Projekte analysiert, um die Performance von Usus.NET zu messen. Zusätzlich wird Usus.NET auch selber analysiert. Dabei werden die Größe dieser Programme mit der Laufzeit der \glslink{SCA}{statischen Code-Analysen} in Verbindung gebracht. Abschließend wird eine Refactoring-Übung aus einem andrena-Kurs mit Usus.NET durchgeführt.


\section{Laufzeitmessungen}
Die \glslink{Metrik}{Metriken}, die Usus.NET berechnet und gewichtet, werden in dieser Konstellation nur von dem Usus für Java berechnet. Ein fairer Vergleich mit anderen Werkzeugen wie Visual Studio Code Metrics Power Tool, Code Metrics Viewer und NDepend kann leider nicht durchgeführt werden, da diese Tools andere \glslink{Metrik}{Metriken} berechnen. Es hat den Anschein, dass NDepend die \glslink{SCA}{Analysen} schneller durchführen kann als Usus.NET. Dies könnte daran liegen, dass NDepend eventuell nur \gls{CCIMetadata} und nicht auch \gls{CCIAst}, oder sogar eine optimierte Eigenentwicklung verwendet. Abbildung \ref{fig:projecttimes} zeigt die Laufzeiten von Usus.NET bei der \glslink{SCA}{Analyse} verschiedener Projekte. Die beiden CCI-Bibliotheken, sowie QuickGraph werden von der Usus.NET-Implementierung direkt verwendet. GraphSharp ist eine Bibliothek, die die mit QuickGraph erzeugten Graphen visualisieren kann. Zusätzlich liegt es nahe, Usus.NET selbst ebenfalls zu analysieren. Als weiteres Projekt wird ein von andrena entwickeltes System mit dem Namen "`Mescor"' analysiert.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/projecttimes.png}
	\caption{Laufzeiten der \glslink{SCA}{statischen Code-Analyse} verschiedener Industrie- und Open-Source-Projekte}
	\label{fig:projecttimes}
\end{figure}
Die Schaubilder zeigen deutlich, dass die \glslink{SCA}{Analyse} größerer Projekte länger dauert. Als Projektgröße hat dabei die Anzahl der \glslink{ASM}{Assemblies} einen größeren Einfluss auf die Laufzeit, als die Anzahl an relevanten Codezeilen (RLOC). Dieser Einfluss ist gut an der Laufzeit von QuickGraph zu erkennen. Obwohl diese eine Bibliothek im Vergleich zu GraphSharp mehr Zeilen Quellcode enthält, ist die \glslink{SCA}{Analyse} schneller. Da GraphSharp aus zwei \glslink{ASM}{Assemblies} mit insgesamt weniger Zeilen besteht, dauert die \glslink{SCA}{Analyse} hier länger. Um die \glslink{SCA}{Analyse} von großen Projekten zu beschleunigen, kann Usus.NET eine Menge von \glslink{ASM}{Assemblies} auch parallelisiert analysieren. Abbildung \ref{fig:projecttimes} zeigt daher auch für jedes Projekt einmal die Laufzeit der sequentiellen und einmal die der parallelen \glslink{SCA}{Analyse}. Je größer das Projekt, umso eher kann durch die Verwendung mehrerer Prozessorkerne eine Laufzeitreduktion gemessen werden. Im Beispiel konnte die Laufzeit des CciAst-Projekts (\gls{CCIAst}) auf einem System mit vier Kernen sogar fast halbiert werden. Leider konnte dieser Geschwindigkeitsgewinn nicht bei der \glslink{SCA}{Analyse} des Mescor-Projekts erreicht werden. Das liegt vermutlich daran, dass die \glslink{ASM}{Assemblies} alle sehr klein sind. Viele große \glslink{ASM}{Assemblies} würden sich mit dieser Argumentation besonders effizient parallel analysieren lassen. Die tatsächlichen \glslink{Metrik}{Metriken} dieser Systems sind für die Performance-Messungen nicht von Bedeutung und befinden sich im Anhang \ref{sec:analysisresults}.
\paragraph{}
In Abschnitt \ref{sec:metriccalc} wurde für die sequentielle \glslink{SCA}{Analyse} die Klasse \texttt{Analyze} vorgestellt. Die Klasse \texttt{AnalyzeParallel} erlaubt es, die \glslink{SCA}{Analyse} auf die einzelnen Prozessorkerne des Systems aufzuteilen. In der MSDN Library beschreibt Microsoft \emph{Parallel LINQ} (PLINQ) als elegantes Mittel um Parallelität bei der Verarbeitung von Listen zu verwenden \cite{PLINQ}. Da sich die zu analysierenden \glslink{ASM}{Assemblies} in einer Liste befinden, kann PLINQ sehr einfach in Usus.NET verwendet werden. Listing \ref{listing:parallelanalyze} zeigt, dass nur durch den Methodenaufruf \texttt{AsParallel()} die Liste der \glslink{ASM}{Assemblies} parallel verarbeitet wird.
\begin{lstlisting}[caption={Sequentielle und parallele \glslink{SCA}{Analyse} von mehreren \glslink{ASM}{Assemblies}},label={listing:parallelanalyze}]
//sequentiell: Analyze.PortableExecutables(files)
from file in files select AnalyzeFile(file)

//parallel: AnalyzeParallel.PortableExecutables(files)
from file in files.AsParallel() select AnalyzeFile(file)
\end{lstlisting}
Leider hat die parallele \glslink{SCA}{Analyse} gegenüber der höheren Geschwindigkeit auch einen Nachteil. Manchmal werden die \glslink{PDB}{pdb-Dateien} von der \glslink{CCI}{CCI} nicht korrekt geladen, wenn die \glslink{SCA}{Analyse} auf mehrere Threads verteilt läuft. Dieses Problem äußert sich dadurch, dass beispielsweise Zeilenangaben für \glslink{ML}{Methodenlängen} nicht erfolgreich ermittelt werden können. Im Usus.NET Cockpit-Fenster entstehen dadurch sogenannte Phantomänderungen der \glslink{Metrik}{Methodenmetriken}, wenn die gleiche Solution zweimal hintereinander analysiert wird, ohne dass der Quellcode geändert wurde. Aus diesem Grund kann unter dem Menüeintrag \texttt{Tools / Options / Usus.NET} eingestellt werden, ob Usus.NET die \glslink{SCA}{Analyse} sequentiell oder parallel durchführen soll. Generell scheint die \glslink{CCI}{CCI} Schwierigkeiten mit dem Ressource Management der \glslink{PDB}{pdb-Dateien} zu haben. Wenn Usus.NET die \glslink{PDB}{pdb-Dateien} nutzt und anschließend sofort wieder über die \glslink{CCI}{CCI} freigibt, kann Visual Studio diese Dateien erst nach einer kurzen zeitlichen Verzögerung wieder ersetzen.


\section{Fallbeispiel andrena-Kurs}
Mit dem Kurs "`Agile Software Engineering"'\footnote[1]{Mehr Informationen: "`ASE - Agile Software Engineering"' \url{http://www.andrena.de/leistungen/ase-agile-software-engineering}} bietet andrena ein Training für Entwickler an, in dem moderne Softwareentwicklung vorgestellt und unter kontrollierten Rahmenbedingungen ausprobiert und geübt werden kann. Dabei wird unter anderem auch eine Übung zum Thema Refactoring durchgeführt. Die Teilnehmer bekommen dabei die Möglichkeit, eine bestehende Codebasis inklusive Tests selbstständig umzugestalten. Das Ausgangsprojekt wurde mit Usus.NET einmal analysiert. Abbildung \ref{fig:andrenarefacbefore} zeigt das Ergebnis dieser \glslink{SCA}{Analyse}.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/andrenarefacbefore.png}
	\caption{Vorher-\glslink{Metrik}{Metriken} des andrena Refactoring-Beispiels}
	\label{fig:andrenarefacbefore}
\end{figure}
Da das Projekt mit 96 relevanten Codezeilen sehr klein ist, gibt es nicht viele verbesserungswürdige Stellen. Das Hauptproblem ist die \texttt{GetMailMessage}-Methode der Klasse \texttt{MailComposer}. Mit 19 logischen Zeilen und einer \glslink{CC}{zyklomatischen Komplexität} von 7, ist diese Methode ein absoluter Hotspot und wird dementsprechend auch als solcher angezeigt. Ziel der Übung ist es also, diese Methode umzugestalten. Dank der 100\%igen Testabdeckung ist dies ohne Schwierigkeiten möglich. Zu dieser Übung existiert auch eine "`Musterlösung"' der Trainer, die ebenfalls mit Usus.NET analysiert wurde. Das Ergebnis ist in Abbildung \ref{fig:andrenarefacafter} zu sehen. Zwischen diesen beiden Messungen hat also das Refactoring stattgefunden.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/andrenarefacafter.png}
	\caption{Nachher-\glslink{Metrik}{Metriken} des andrena Refactoring-Beispiels}
	\label{fig:andrenarefacafter}
\end{figure}
\paragraph{}
Der \gls{SQI} konnte sehr verbessert werden. Dies konnte erreicht werden, indem die \texttt{GetMailMessage}-Methode auf 5 Zeilen und eine \glslink{CC}{zyklomatische Komplexität} von 1 reduziert wurde. Dafür wurden drei neue Typen erstellt, was dazu geführt hat, dass die \texttt{MailComposer}-Klasse mehr Abhängigkeiten bekommen hat. Tatsächlich hat diese Klasse jetzt so viele direkte und indirekte Abhängigkeiten, dass Usus.NET dies als Problem sieht und die Klasse in den Hotspots auflistet. Eine Interpretation dieses Hotspots ist, dass diese Klasse überdurchschnittlich viele Abhängigkeiten in dem betrachteten System hat. Da diese Klasse auch von der Testklasse \texttt{MailComposerTest} verwendet wird, die die gleichen indirekten Abhängigkeiten hat, wird auch diese Testklasse als Hotspot gesehen. Die \glslink{ACD}{durchschnittliche Komponentenabhängigkeit} ist dagegen gefallen, was darauf zurückzuführen ist, dass die neuen Abhängigkeiten der \texttt{MailComposer}-Klasse selbst nicht sehr viele Abhängigkeiten haben und den Durchschnitt senken. In Bezug auf das \gls{CleanCode}-Level der Codebasis hat sich das Hinzufügen der neuen Typen negativ auf die \gls{Verteilung} der \glslink{Metrik}{Klassenmetriken} ausgewirkt. Die \glslink{Verteilung}{Verteilungen} der \glslink{Metrik}{Klassenmetriken} entsprechen also geometrischen \glslink{Verteilung}{Verteilungen}, die weniger schnell fallen, als vor dem Refactoring. Diese Verschlechterung würde den Entwickler motivieren im nächsten Schritt die Abhängigkeiten der Klassen zu verändern, sodass auch die \glslink{Verteilung}{Verteilungen} der \glslink{Metrik}{Klassenmetriken} auf \gls{CleanCode} hindeuten. Was die \glslink{Metrik}{Methodenmetriken} angeht, so fallen die geometrischen \glslink{Verteilung}{Verteilungen} schneller. Es gibt also mehr kleine \glslink{Metrik}{Methodenmetriken} als große, was nach Kapitel \ref{chap:cleancodesupport} ein sehr guter Indikator für \gls{CleanCode} ist.


\section{Ergebnis}
Die oben beschriebene Refactoring-Übung wurde nicht selbst durchgeführt. Dank Usus.NET konnte allein durch die Betrachtung der Analyseergebnisse vor und nach dem Refactoring, genügend Informationen ermittelt werden, um die Codebasis und das Refactoring zu interpretieren (Ziel \ref{goal:interpret} erreicht). Der Quellcode müsste theoretisch nicht einmal mehr eingesehen werden um zu erkennen, dass die Methoden verbessert wurden, ohne die Typen sehr zu verschlechtern (Ziel \ref{goal:insight} erreicht). Auch vor dem Refactoring hat Usus.NET die Problemfälle der Codebasis automatisch erkannt und so ein effizientes und zielgerichtetes Refactoring ermöglicht (Ziel \ref{goal:problems} erreicht). Nach dem Refactoring existieren zwar immer noch einige Klassen-Hotspots, die beachtet werden müssen, aber der höhere \glslink{SQI}{SQI} weißt auf eine sehr positiv zu wertende Verbesserung hin. Diese Verbesserung ist auch im Kontext von \gls{CleanCode} an dem \gls{LGD} der \glslink{Metrik}{Methodenmetriken} zu erkennen (Ziel \ref{goal:cleancode} erreicht). Ohne Usus.NET hätte die Problemstelle erst gesucht werden müssen. Eine anschließende Verbesserung wäre dann auch nur schwer messbar gewesen. Beispielsweise hätten viel gravierendere Probleme entstehen und unerkannt bleiben können. 
\paragraph{}
Usus.NET hat die \glslink{SCA}{statische Code-Analyse} automatisch nach dem Kompiliervorgang im Hintergrund durchgeführt, ohne das der Entwickler irgendetwas einstellen musste. Während der \glslink{SCA}{Analyse} kann der Entwickler weiterhin mit dem Quelltext arbeiten oder die Anwendung debuggen. Da die \glslink{SCA}{statische Code-Analyse} in einem eigenen Thread im Hintergrund läuft, wird Visual Studio nicht blockiert oder merklich verlangsamt. Lediglich das Zeichnen der Usus.NET Info-Buttons aus Unterabschnitt \ref{subsec:ususnetinfo} führt dazu, dass der Editor bei einer größeren Codebasis etwas langsamer wird. Wenn die Analyseergebnisse einmal erwartet werden, dauert die \glslink{SCA}{Analyse} dank der parallelen Verarbeitung auch in sehr großen Projekten in der Regel nicht länger als 5 Minuten. Die umfangreiche Darstellung der Ergebnisse unterstützt die Interpretation der Code-Qualität und nimmt diese durch das \gls{LGD} und dem \gls{SQI} teilweise sogar ab. Im dem Usus für Java sind genau diese Interpretationsfunktionen nicht enthalten, sodass Usus.NET an dieser Stelle eine umfangreichere Hilfestellung und Einsicht in den Code geben kann.
\paragraph{}
Abschließend ist interessant zu sehen, wie sich Usus.NET in der aktuellen Version selbst analysiert. Usus.NET hat sehr gute \gls{CleanCode}-\glslink{Metrik}{Metriken} auf Methodenebene und zufriedenstellende \glslink{Metrik}{Metriken} auf Klassenebene. Ein \gls{SQI} von 82,2\% bewertet die Visual Studio-Erweiterung insgesamt positiv. Das ausführliche Ergebnis befindet sich in der Anlage \ref{sec:analysisresults}.




\chapter{Zusammenfassung}
In dieser Master-Thesis wurde die Visual Studio-Erweiterung Usus.NET implementiert und dokumentiert. Bei der agilen Anforderungsanalyse wurden zunächst die Interessenvertreter und die Ziele der Erweiterung gefunden und in Kapitel \ref{chap:requirements} beschrieben. Usus.NET soll dem Entwickler Einsicht in die Codebasis geben (Ziel \ref{goal:insight}), problematische Stellen im Code erkennen (Ziel \ref{goal:problems}), die Entwicklung von \gls{CleanCode} fördern  (Ziel \ref{goal:cleancode}) und eine Interpretation der Softwarequalität ermöglichen und erleichtern (Ziel \ref{goal:interpret}). Alle genannten Ziele können anhand von \glslink{Metrik}{Softwaremetriken} erreicht werden.
\paragraph{}
Dazu müssen die \glslink{Metrik}{Metriken} zuerst berechnet, gewichtet und bewertet werden, was auch von dem Eclipse-Plugin Usus für Java getan wird. Usus für Java wurde von andrena entwickelt und ermöglicht ebenfalls eine Einsicht in die Codebasis (Ziel \ref{goal:insight}) und erkennt auch Problemfälle (Ziel \ref{goal:problems}). Das Java-Usus ermöglicht dabei keine Interpretation der Softwarequalität anhand von \gls{CleanCode}-\glslink{Metrik}{Metriken} oder dem \gls{SQI}. Um die Funktionen des Usus für Java auch in Usus.NET zu realisieren, wurde das Java-Usus analysiert. Dabei wurden die \glslink{Metrik}{Metriken}, die dieses Werkzeug berechnet, dokumentiert und für die Implementierung von Usus.NET spezifiziert. Um Ideen für die Realisierung der anderen beiden Ziele, \gls{CleanCode} fördern (Ziel \ref{goal:cleancode}) und Softwarequalität interpretieren (Ziel \ref{goal:interpret}), zu bekommen, wurden auch einige andere bekannte Tools betrachtet. Dabei wurde festgestellt, dass diese Werkzeuge besagte Ziele ebenfalls nicht erreichen können.
\paragraph{}
Um eine geeignete Technologie zu finden, mit dessen Hilfe Usus.NET die \glslink{SCA}{statische Code-Analyse} durchführen kann, wurden mehrere Frameworks untersucht und anhand von zuvor definierten Kriterien evaluiert. Dabei wurde festgestellt, dass das \gls{CCI}-Framework von Microsoft sich am ehesten für die Verwendung in Usus.NET eignet. Um die definierten Anforderungen zu erfüllen, wurde Usus.NET in fünf 10-tägigen Iterationen realisiert. Zwischen den Iterationen wurde dieses Dokument aktualisiert.
\paragraph{}
In den ersten beiden Iterationen wurde die hauptsächliche Funktionalität des Eclipse-Usus, also die \gls{Metrik}-Berechnung, -Gewichtung und -Bewertung, für Usus.NET neu entwickelt und getestet. Um die Entwicklung durch Testfällen absichern zu können, wurde ein eigenes Framework für Integrationstests implementiert, welches ebenfalls Bestandteil von Usus.NET ist. Dieses Framework nutzt einen speziell dafür konzipierten Ansatz um \glslink{Metrik}{Methoden-} und \glslink{Metrik}{Klassenmetriken} anhand von Erwartungswerten zu verifizieren. In der dritten Iteration wurde die Visual Studio-Erweiterung implementiert, sodass die Fenster, die aus dem Usus für Eclipse bekannt sind, auch in Visual Studio vorhanden sind. Nach jedem Kompiliervorgang berechnet Usus.NET die aktuellen \glslink{Metrik}{Metriken} der erzeugten \glslink{ASM}{Assemblies}. Das Fenster des Klassen- und Paketgraph wurde aus zeitlichen Gründen nicht realisiert.
\paragraph{}
In der vierten Iteration wurden die \gls{Metrik}-Histogramme analysiert. Dabei wurde festgestellt, dass \glslink{Metrik}{Metriken} in einem Softwaresystem tatsächlich der \glslink{Verteilung}{Exponentialverteilung}, beziehungsweise der geometrischen \gls{Verteilung}, folgen. Wenn in einem Projekt die \gls{CleanCode}-Prinzipien von Robert C. Martin, Ralf Westphal und Stefan Lieser berücksichtigt werden, ist der Parameter der Verteilungsfunktion höher. Je höher diese Parameter ist, desto schneller fällt die Verteilungsfunktion. Das bedeutet, dass es mehr kleine \glslink{ML}{Methodenlängen}, \glslink{CS}{Klassengrößen}, \glslink{CC}{zyklomatische Komplexitäten}, \glslink{CCD}{Klassenabhängigkeiten} und ähnliches gibt, als große. Diese Tendenz entspricht eindeutig den Gedanken, die Robert C. Martin auch in seinem Buch "`Clean Code"' beschreibt \cite{CleanCode}. Mit dem \gls{LGD} kann Usus.NET also eine \gls{CleanCode}-\gls{Metrik} berechnen. Diese \gls{Metrik} wird ebenfalls im Usus.NET Cockpit-Fenster angezeigt, sodass der Entwickler sofort sieht, wie \emph{clean} die Metriken seines Codes gerade sind. Wird dieser Wert besser, wird er grün hervorgehoben, wobei eine Verschlechterung rot dargestellt wird. Dadurch wird der Entwickler motiviert, die \gls{CleanCode}-Prinzipien mehr zu beachten. Usus.NET fördert so aktiv die Erzeugung von \gls{CleanCode} (Ziel \ref{goal:cleancode}).
\paragraph{}
In der vierten Iteration wurde zusätzlich die Berechnung des \gls{SQI} implementiert. Um diesem Wert eine besondere Bedeutung beizumessen, wird er nicht im Usus.NET Cockpit, sondern in einem eigenen Fenster angezeigt. Der \glslink{SQI}{SQI} gewichtet die \glslink{Metrik}{Metriken} ein wenig anders als Usus dies tut und kombiniert diese mit weiteren Details zu einem einzigen Wert. Die aktuelle Testabdeckung des betrachteten Softwaresystems ist ein solches Detail. Da die Testabdeckung von den verschiedenen Werkzeugen auf unterschiedliche Weise bestimmt wird, gibt es keine einheitliche Schnittstelle um diesen Wert auszulesen. In der aktuellen Version von Usus.NET wird dieser Wert daher noch nicht automatisiert ermittelt und kann manuell eingetragen werden. Sobald die Testabdeckung eingegeben wird, wird der \glslink{SQI}{SQI} neu berechnet. Die Veränderung dieses Werts lässt sich über die Zeit beobachten und grafisch im Usus.NET \glslink{SQI}{SQI}-Fenster darstellen. In Verbindung mit der \gls{CleanCode}-\gls{Metrik} und den anderen \glslink{Metrik}{Metriken} des Usus.NET Cockpit, erleichtert Usus.NET die manuelle Interpretation der Softwarequalität enorm (Ziel \ref{goal:interpret}). Damit wurden alle in Abschnitt \ref{sec:goals} genannten Ziele erreicht.
\paragraph{}
Dies wurde im Rahmen der fünften Interation anhand der \glslink{SCA}{Analyse} eines Refactoring-Beispiels aus einem andrena-Kurs verifiziert. Denoch ersetzt Usus.NET keine manuellen Codereviews, sondern erleichtert diese. Zusätzlich wurde die Performance analysiert und optimiert. Bei der \glslink{SCA}{Analyse} von einigen Industrie- und Open-Source-Projekten wurde festgestellt, dass die \glslink{SCA}{statische Code-Analyse} langsamer wird, sobald ein Projekt aus vielen \glslink{ASM}{Assemblies} besteht. Wenn diese \glslink{ASM}{Assemblies} allerdings eine größere Anzahl an Code-Zeilen besitzen, kann die \glslink{SCA}{Analyse} durch die Verwendung von mehreren Prozessorkernen wieder beschleunigt werden.
\paragraph{}
Die aktuelle Version von Usus.NET ist unter der LGPL\footnote[1]{Mehr Informationen: "`GNU Lesser General Public License"' \url{http://www.gnu.org/copyleft/lesser.html}} veröffentlicht. Der komplette Quellcode der Visual Studio-Erweiterung befindet sich auf github\footnote[2]{Download: "`Repository of Usus.NET"' \url{https://github.com/usus/Usus.NET}} und kann eingesehen und heruntergeladen werden. Zusätzlich kann die Integration beliebiger Weiterentwicklungen beantragt werden. Die aktuelle Installationsdatei von Usus.NET befindet sich im Anhang \ref{sec:ususnetext}.




\chapter{Fazit und Ausblick}
Innerhalb von fünf Iterationen wurde die Visual Studio-Erweiterung Usus.NET entwickelt. Das von andrena erwartete Ziel einer lauffähigen Software wurde erreicht. Da einige User Stories, die für die fünfte Iteration geplant waren, bereits in der vierten Iteration erledigt wurden, konnten in der letzten Iteration einige Probleme behoben, sowie die Beispiel- und Performance-Messungen durchgeführt und beschrieben werden. Da diese Master-Thesis als Dokumentation der Entwicklung sehr wichtig ist, wurden zugunsten der Dokumentation wenige potenzielle Features von Usus.NET nicht implementiert. So wurde beispielsweise auf eine Visualisierung der Graphen komplett verzichtet, da eine notwendige Evaluierung verschiedener Darstellungstechnologieen aus zeitlichen Gründen nicht durchgeführt werden konnte. Besonders sinnvoll hätte sich dieses Feature bei der Analyse von Hotspots in Form von Namespace-Zyklen einsetzen lassen. In der aktuellen Version werden die problematischen Klassen, also die Klassen, die Klassen in den anderen Namespaces im selben Zyklus referenzieren, in Listen angezeigt. Eine grafische Darstellung des Zyklus in Form eines Graphen würde die Suche nach der schuldigen Abhängigkeit erleichtern.
\paragraph{}
In einer Evaluierung wurde die \gls{CCI} als technisches Mittel gefunden, um eine \glslink{SCA}{statische Code-Analyse} durchführen zu können. Usus.NET ermöglicht in der aktuellen Version auch einige Einstellungen vorzunehmen. So kann eingestellt werden, ob eine \glslink{SCA}{Analyse} parallel oder sequentiell durchgeführt werden soll. Weitere Einstellungsmöglichkeiten, die die \glslink{SCA}{statische Code-Analyse} beispielsweise komplett ausschalten, wären noch wünschenswert. Usus.NET analysiert in der aktuellen Version bei jedem Kompiliervorgang automatisch alle Projekte der aktuellen Solution. Eine manuelle \glslink{SCA}{Analyse} auf Knopfdruck könnte sich in manchen Szenarien als brauchbarer erweisen.
\paragraph{}
Aus Zeit-Gründen konnte eine automatisierte Bestimmung der aktuellen Testabdeckung nicht realisiert werden. Um den \gls{SQI} in der aktuellen Usus.NET-Version vollständig zu bestimmen, kann dieser Wert manuell ermittelt und in das entsprechende Fenster eingetragen werden. Auch hier müsste wieder eine Evaluierung mehrerer Werkzeuge und Bibliotheken, die die Testabdeckung berechnen, durchgeführt werden.
\paragraph{}
Die oben beschrieben nicht realisierten Features können problemlos im Anschluss an diese Master-Thesis implementiert werden. In den sechs Monaten konnte eine Grundlage gelegt werden, die eine Weiterentwicklung der Erweiterung als Open-Source-Projekt ermöglicht. Das bedeutet, dass sich auch andrena-externe Entwickler an der Fortführung des Projekts beteiligen dürfen und sollen. Nachdem die oben erwähnten Funktionen entwickelt wurden, kann Usus.NET um viele andere Funktionen ergänzt werden.
\paragraph{}
Beispielsweise wäre es spannend zu sehen, wie Namespace-Zyklus-Hotspots noch besser dargestellt werden können. Da Usus.NET in der aktuellen Version nur alle Namespaces in einem Zyklus auflistet, wäre eine Suche nach dem kleinster Zyklus sehr interessant. Ein solcher kleinster Zyklus, der das eigentliche Problem darstellt, könnte eine effizientere Auflösung ermöglichen. Außerdem wäre die Integration weiterer \gls{CleanCode}-\glslink{Metrik}{Metriken} denkbar. Momentan berechnet Usus.NET zu jedem \gls{Metrik}-Histogramm das \gls{LGD} und verwendet diesen Wert als neuartige und alleinige \gls{CleanCode}-\gls{Metrik}. Sobald Usus.NET die automatisierte Bestimmung der Testabdeckung unterstützt, kann die in Kapitel \ref{chap:cleancodesupport} erwähnte CRAP-\gls{Metrik} ebenfalls berechnet werden. Eventuell kann diese \gls{Metrik} auch mit den Verteilungsinformationen kombiniert werden. Oder es können mehr \glslink{Verteilung}{Verteilungen} betrachtet werden, sodass die \gls{Metrik}-Histogramme besser interpretiert und Hinweise zu sinnvollen Refactorings gegeben werden können. Die Refactorings müssten im Vorfeld den Veränderungen der \glslink{Verteilung}{Verteilungen} zugeordnet werden. Anschließend könnte eine Veränderung der \gls{Verteilung} erreicht werden, indem ein Refactoring angewendet wird. So könnte Usus.NET den Entwickler Refactoring über Refactoring zu einer \gls{Verteilung} führen, die mehr für \gls{CleanCode} steht, beispielsweise die geometrische \gls{Verteilung} mit einem großen $\lambda$. Eventuell könnten diese Refactorings auch automatisiert durchgeführt werden. Da Usus.NET die Refactorings kennen würde, die notwendig sind um ein System in Richtung \gls{CleanCode} umzugestalten, könnte eine bestehende Codebasis eventuell auf Knopfdruck verbessert werden.
\paragraph{}
Aktuell sind noch keine Werkzeuge bekannt, die bestehenden Code \emph{clean} machen. Wenn eine solcher Trend weiter verfolgt wird, wäre Usus.NET die richtige Grundlage, um diese Funktionen zu implementieren, auszuprobieren und zu testen.




\newpage
\pagestyle{plain}
\pagenumbering{roman}
\setcounter{page}{15}



\printglossaries



\bibliography{masterthesis}
\bibliographystyle{alpha}




\appendix
\addchap{Anhang}
\refstepcounter{chapter}


\section{Manuskript über den Prozess- und Softwarequalitätsindex}
\label{sec:appendixsqi}
Das unveröffentlichte Manuskript "`Beschreibung der Berechnungsmethoden für Prozessqualitätsindex und \gls{SQI}"' von Dr. Eberhard Kuhn befindet sich auf der beiliegenden CD in der Datei \textcolor[rgb]{0,0.5,0}{\texttt{Isis Beschreibung der Berechnungsmethoden.pdf}}.


\section{Artikel über Isis}
\label{sec:appendixisis}
Der unveröffentlichte technische Artikel "`Indicator-based Process and Software Quality Control in Agile Development Projects"' von Andreas Leidig und Nicole Rauch befindet sich auf der beiliegenden CD in der Datei \textcolor[rgb]{0,0.5,0}{\texttt{Isis.pdf}}.


\section{Testpläne}
\label{sec:testplans}
Die Testpläne von Usus.NET befinden sich auf der beiliegenden CD in der Datei \textcolor[rgb]{0,0.5,0}{\texttt{Testpläne.xlsx}}.


\section{Messergebnisse der Laufzeitmessungen}
\label{sec:analysisresults}
Die Ergebnisse der Beispielmessungen aus der Usus.NET-Evaluation befinden sich auf der beiliegenden CD im Verzeichnis \textcolor[rgb]{0,0.5,0}{\texttt{Messungen}}.


\section{Visual Studio-Erweiterung Usus.NET}
\label{sec:ususnetext}
Die aktuelle Version der Visual Studio-Erweiterung Usus.NET befindet sich auf der beiliegenden CD in der Datei \textcolor[rgb]{0,0.5,0}{\texttt{Usus.NET.vsix}}. Eine Installation kann per Doppelklick durchgeführt werden.





\backmatter
\end{document}