\documentclass[
a4paper, 							% Papierformat
%10pt,								% Schriftgröße (12pt, 11pt (Standard))
%twoside,							% Doppelseiten
titlepage,						% Titelei auf eigener Seite
%normalheadings,			% Überschriften etwas kleiner (smallheadings)
%idxtotoc,						% Index im Inhaltsverzeichnis
%liststotoc,					% Abb.- und Tab.verzeichnis im Inhalt
%bibtotoc,						% Literaturverzeichnis im Inhalt
%leqno,   						% Nummerierung von Gleichungen links
%fleqn,								% Ausgabe von Gleichungen linksbündig
%draft								% überlangen Zeilen in Ausgabe gekennzeichnet
]
{scrreprt}
\usepackage[ngerman]{babel}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tipa}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm,includeheadfoot]{geometry}
\usepackage{marvosym}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=blue,
    urlcolor=blue
}
\usepackage{mathtools}
\usepackage{listings} \lstset{numbers=left, numberstyle=\tiny, numbersep=5pt, basicstyle=\fontsize{9}{13}\selectfont, xleftmargin=1cm, xrightmargin=1cm, frame=topline} \lstset{language=Java}
\usepackage{shadethm}
\newshadetheorem{definition}{Definition}
\newshadetheorem{stakeholder}{Interessenvertreter}
\newshadetheorem{goal}{Ziel}
\definecolor{shadethmcolor}{rgb}{.95,.95,.95}   % Farbe des Hintergrundes  
\definecolor{shaderulecolor}{rgb}{0.7,0.7,0.7}   % Farbe des Rahmens
\setlength{\shadeboxrule}{1.0pt}   % Breite des Rahmens

\begin{document}



\thispagestyle{empty}
\begin{titlepage}
\begin{figure}[t]
	\centering
  \includegraphics[width=80mm]{images/HsKaLogoKlein.png}
	\vspace{2.5cm}
\end{figure}
\begin{center}
\title{Master-Thesis}
\textbf{\huge{Master-Thesis}} \\[0.5cm]
\textbf{Visual Studio Erweiterung zur statischen Code-Analyse} \\[4cm]
\textbf{andrena objetcs ag} \\[0.25cm]
\author{Manuel Naujoks} Manuel Naujoks\\[2.5cm]
Betreut durch \\[0.25cm] 
Prof. Dr. Thomas Fuchß \\[2.5cm]
Bischweier, den \today
\end{center}
\end{titlepage}



\pagenumbering{roman}
\setcounter{page}{1}
\begin{center}\textbf{\large Erklärung}\\[1cm]\end{center}
Hiermit versichere ich, dass ich die vorliegende Arbeit selbstständig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe, dass alle Stellen der Arbeit, die wörtlich oder sinngemäß aus anderen Quellen übernommen wurden, als solche kenntlich gemacht sind und dass die Arbeit in gleicher oder ähnlicher Form noch keiner Prüfungsbehörde vorgelegt wurde.
\\[4\baselineskip]
Bischweier, den \today \\
Manuel Naujoks
\newpage



\chapter*{Zusammenfassung}
Im Rahmen dieser Master-Thesis soll eine Visual Studio Erweiterung entwickelt werden, die direktes Entwickler-Feedback anhand von Software-Metriken geben kann. Dabei dient das Plugin Usus für Eclipse als Vorlage, welches bereits existiert. Die zu erstellende Erweiterung soll eine statische Code-Analyse von .NET-Projekten in Visual Stuido 2010 durchführen und für andrena relevante Code-Metriken berechnen können.
\newline
Die zu entwickelnde Erweiterung soll genutzt werden können, um Software-Entwickler aktiv zu unterstützen "`Clean code"' zu schreiben. Eine ähnliche Lösung zu Microsofts Achievements Extension mit Achievements in Bezug auf clean code best practices wäre denkbar. Dazu soll eine Evaluierung anhand von Beispielaufgaben aus einem andrena-Kurs zum Thema Refaktorisierung bearbeitet und die Veränderung in den Metriken entsprechend erfasst und dokumentiert werden.
\newline
Weiterhin soll in einer Metrik-Analyse nach Heuristiken oder Regeln mit statischer Signifikanz gesucht werden, die eventuell guten von schlechtem Code unterscheiden können. Lassen sich hier Muster beziehungsweise Strukturen aufzeigen? Ein Indiz hierfür ist, dass die Metriken oft einer Exponentialverteilung folgen. Dabei soll untersucht werden, ob und wenn möglich wie sich dies auf den Software Qualitäts Index (SQI) von andrena abbilden lässt.
\newpage



\chapter*{Abstract}
Objective of this master thesis is the development of a Visual Studio Extension that is capable of providing direct development feedback based on software metrics. The Eclipse plugin Usus, which already exists, is going to be used as orientation. The extension that is developed shall be able to perform static code analysis of .NET projects in Visual Studio 2010 in order to calculate the code metrics that are relevant for andrena.
\newline
As far as feedback is concerned, the extension shall be able to actively support developers to write "`clean code"'. A similar solution to Microsofts Achievements Extension could likely be found with achievements based on common clean code best practices. Therefore an evaluation with sample exercises of an andrena course on the topic of refactoring is done and the variation in the metrics is detected and documented.
\newline
Another metric analysis is performed in order to find heuristics or rules with static significance, which might be able to distinguish good code from bad code. Are there detectable patterns? One thing might be that metrics often follow an exponential distribution. An analysis shall show whether it is possible and if yes, how this can be mapped to the Software Quality Index (SQI) of andrena.
\newpage




\tableofcontents




\chapter{Einführung}
\pagenumbering{arabic}
\setcounter{page}{1}
bla bla bla Softwarequalität
bla bla bla Metriken
bla bla bla Entwicklerfeedback
bla bla bla Übersicht über Codebasis
bla bla bla direkt in Visual Studio
bla bla bla

\section{andrena objects ag}
\label{sec:andrena}
Diese Master-Thesis wird bei dem Software-Unternehmen andrena objects ag durchgeführt. bla bla bla.

\section{Aufbau der Thesis}
bla bla bla.




\chapter{Grundlagen}
\label{chap:basics}
In diesem Kapitel sollen die Grundlagen vermittelt werden, die für ein Verständnis einer mit Quellcode arbeitenden Erweiterung für Visual Studio erforderlich sind. Dazu wird in Abschnitt \ref{sec:generalbasics} zunächst auf allgemeine Grundlagen wie Quellcode, sowie Entwicklungsumgebungen eingegangen. Anschließend werden in Abschnitt \ref{sec:technicalbasics} die technischen Grundlagen vorgestellt.


\section{Allgemeine Grundlagen}
\label{sec:generalbasics}
In diesem Abschnitt wird zunächst auf die Clean Code Idee von Robert C. Martin sowie einige seiner Prinzipien eingegangen. Anschließend werden die beiden Entwicklungsumgebungen Eclipse und Visual Studio vorgestellt. Beide Programme sind in dieser Master-Thesis von Bedeutung, da die zu entwickelnde Erweiterung bereits für Eclipse existiert und für Visual Studio ebenfalls erstellt werden soll.

\subsection{Clean Code}
\label{subsec:cleancode}
Ein Softwaresystem wird in Form von Quellcode erstellt. Dieser Code wird anschließend kompiliert um eine ausführbares Programm zu erhalten. Robert C. Martin beschreibt Code in seinem Buch "`Clean Code"' als Sprache, in der wir die Anforderungen an die Software maschinenlesbar zum Ausdruck bringen \cite{CleanCode}. Weiter beschreibt er in seinem Buch auch Prinzipien und Best Practices, die das Erstellen von verständlicherem und wartbareren Quellcode unterstützen. Die selben Prinzipien wurden auch von Ralf Westphal und Stefan Lieser aufgegriffen und im Rahmen eines Wertesystems mit sieben Graden vorgestellt \cite{CleanCodeDeveloper}. Martin's "`Clean Code"' Buch bleibt auch für Westphal und Lieser die grundlegende Lektüre.
\paragraph{}
Die Prinzipien und Best Practices der Clean Code Bewegung umfassen viele Aspekte, die bereits durch Kent Beck in seinem Buch über die Methodik \textit{Extreme Programming} (XP) \cite{XP} eingeführt wurden. Drei wichtige Bestandteile von XP, die ebenfalls in den Graden des Clean Code Wertesystems von Westphal und Lieser auftreten, werden hier wie folgt definiert.
\begin{definition}[Automatisiertes Testen]
Automatisiertes Testen ist eine der wichtigsten Praktiken in der Clean Code Bewegung. Nach Robert C. Martin ist es die Aufgabe eines Entwicklers keinen Schaden in einem Softwaresystem anzurichten. Damit meint er Schaden an der Funktionalität und Schaden an der Struktur der Anwendung. Beides kann mit automatisierten Testfällen sichergestellt werden.
\end{definition}
\begin{definition}[Ständiges Refactoring]
Ständiges Refactoring ist der effektivste Schutz gegen Schaden an der Struktur eines Softwaresystems bedingt durch evolutionäres Wachstum und vielen Anpassungen. Durch Tests kann dabei sichergestellt werden, dass Umstrukturierungen den Funktionsumfang nicht beeinträchtigen. Martin Fowler beschreibt ein solches Refactoring in seinem Buch \cite{Refactoring}.
\end{definition}
\begin{definition}[Schnelle Code Reviews]
Schnelle Code Reviews sind eine weitere Voraussetzung um Clean Code entwickeln zu können. Der entscheidende Punkt ist das Feedback. Je schneller der Entwickler Feedback bekommt um so früher können Probleme im Quellcode erkannt und mit relativ wenig Aufwand korrigiert werden.
\end{definition}

\subsection{Eclipse}
\label{subsec:eclipse}
Eclipse\footnote[1]{"`Eclipse - The Eclipse Foundation open source community website"' \url{http://www.eclipse.org/}} ist eine integrierte Entwicklungsumgebung (IDE) der Eclipse Foundation. Die Anwendung ist eine kostenfreies open source Programm und wird hauptsächlich für die Entwicklung von Software mit der Programmiersprache Java\footnote[2]{"`Oracle and Java"' \url{http://www.oracle.com/us/technologies/java/index.html}} verwendet. Eclipse unterstützt externe Erweiterungen in Form von Plugins.

\subsection{Visual Studio}
\label{subsec:visualstudio}
Visual Studio\footnote[3]{"`Die Microsoft Visual Studio 2010 Produktfamilie"' \url{http://www.microsoft.com/germany/visualstudio/products/default.aspx}} ist eine integrierte Entwicklungsumgebung von Microsoft. Im Gegensatz zu Eclipse ist Visual Studio ab der Professional Version ein kommerzielles Produkt. Die Entwicklung für das .NET-Framework\footnote[4]{"`Microsoft .NET Framework"' \url{http://www.microsoft.com/net}} von Microsoft kann mit Visual Studio durchgeführt werden, wobei mehrere Programmiersprachen unterstützt werden. Zu den bekanntesten und am weitesten verbreiteten Sprachen für das .NET-Framework zählen C\# und Viusal Basic.NET.
\paragraph{}
Visual Studio erlaubt die Installation von externen Erweiterungen als Addin oder Erweiterung ab der Professional Version. Die kostenfreie Express Edition besitzt einen sehr eingeschränkten Funktionsumfang. Der Unterschied zwischen einem Visual Studio Addin und einer Visual Studio Erweiterung ist der, dass Addins bereits in früheren Versionen unterstützt wurden und ein Entwickler die Schnittstellen in Visual Studio direkt anprogrammieren kann. Die Erweiterungen werden ab Visual Studio 2010 unterstützt und benötigen zur Entwicklung das \textit{Visual Studio 2010 SDK}\footnote[5]{Download: "`Visual Studio 2010 SP1 SDK"'\url{http://www.microsoft.com/download/en/details.aspx?id=21835}}, erlauben aber eine modernere Klassenbibliothek. Aaron Marten beschreibt in seinem Artikel \cite{VSCustomExtensions} die Möglichkeiten, wie mit der neuen Erweiterungstechnologie (VSIX) Addin-ähnliche Erweiterungen erstellt werden können.


\section{Technische Grundlagen}
\label{sec:technicalbasics}
In diesem Abschnitt werden die technischen Grundlagen erläutert. Dazu wird zunächst der Begriff der Objektorientierung eingeführt, da sämtliche Software-Systeme, die in dieser Master-Thesis betrachtet werden, obejktorientiert sind. Anschließend werden Graphen und Bäume beschrieben, da verschiedene Software-Metriken anhand dieser Datenstruktur berechnet werden können. Abschließend wird das Konzept der statischen Code-Analyse vorgestellt, da die zu entwickelnde Erweiterung eben diese durchführen können soll.

\subsection{Objektorientierung}
\label{subsec:oo}
Die Objektorientierung als Methode ermöglicht laut Benrd Oestereich die hohe Komplexität von Softwaresystemen zu beherrschen \cite{OOSE}. Das ist möglich, da diese Methode die Dinge der realen Welt als Objekte sieht und dadurch die Problemdomäne verständlich und anschaulich macht. Ein objektorientiertes Softwaresystem besteht aus fünf wesentlichen Komponenten, die hier wie folgt definiert werden.

\begin{definition}[Klasse]
Klasse kommt aus dem lateinischen von \emph{classis} und bedeutet "`Aufgebot"'. Damit ist laut Oestereich eine Teilmenge von Objekten der gleichen Struktur gemeint. Eine Klasse ist folglich auch der Typ aller seiner Objekte. Klassen können auch abstrakt sein. Eine abstrakte Klasse, oder auch genannt Schnittstelle, kann nicht als Objekt erzeugt werden. Eine nicht abstrakte Klasse, also eine konkrete Klasse, muss von dieser Klasse eine Vererbung der Struktur und des Verhaltens durchführen. Von dieser erbenden und konkreten Klasse kann dann ein Objekt erzeugt werden, das sowohl vom Typ der konkreten Klasse als auch vom Typ der abstrakten Klasse ist.
\end{definition}
\begin{definition}[Objekt]
Objekt kommt ebenfalls aus dem lateinischen von \emph{obicere} und bedeutet "`entgegenhalten"'. Bernd Oestereich beschreibt es als "`Gegenstand der Erkenntnis und Wahrnehmung, des Denkens und Handelns"' und bezieht sich dabei auf das Brockhaus Lexikon. Ein Objekt ist eine Instanz einer Klasse.
\end{definition}
\begin{definition}[Attribut]
Attribut kommt auch aus dem lateinischen von \emph{attributum} und bedeutet "`das Beigefügte"', was einer Eigenschaft oder einem Kennzeichen einer Sache entspricht. Die Daten, die ein Objekt ausmachen, werden anhand von Attributen gespeichert, auf die von den Operationen des Objekts aus zugegriffen werden kann. Attribute werden auch als Felder bezeichnet und lassen sich in Klassen-Felder und Instanz-Felder unterscheiden. Klassen-Felder können von allen Objekten der Klasse gemeinsam genutzt werden, während Instanz-Felder unterschiedliche Werte für konkrete Objekte haben können.
\end{definition}
\begin{definition}[Operation]
Operation kommt aus dem lateinischen von \emph{operatio} und bedeutet "`Handlung"'. Eine konkrete Aktion, die anhand einer definierten Vorschrift durchgeführt wird bezeichnet Oestereich in diesem Sinne als Operation. Das Verhalten von Objekten wird anhand ihrer Operationen festgelegt. Andere Bezeichnungen für Operation ist Funktion oder Methode. Methoden lassen sich in Klassen-Methoden und Instanz-Methoden aufteilen. Klassen-Methoden können nicht auf die Instanz-Felder sondern nur auf die Klassen-Felder zugreifen. Instanz-Methoden können auf Instanz-Felder und auf Klassenfelder zugreifen.
\end{definition}
\begin{definition}[Paket]
Paket wird von Oestereich als eine Ansammlung von Modellelementen bezeichnet. Dabei sind Modellelemente Klassen oder andere Pakete und dienen der besseren Strukturierung des Systems. Pakete werden auch als Namensräume bezeichnet, da sie eine benannte Zusammenfassung von Klassen und anderen Namensräumen sind.
\end{definition}
Zusätzlich beschreibt Oerstereich zwei weitere Mittel von objektorientierten Softwaresystemen, die der Abstraktion dienen und die es erlauben irrelevant Dinge wegzulassen. Beide Konzepte werden hier ebenfalls definiert.
\begin{definition}[Assoziation]
Assoziation kommt aus dem lateinischen von \emph{associare} und bedeutet "`verbinden"'. Nach Oestereich entspricht dies einer \emph{Hat-eine-Beziehung} und gibt an, dass eine Klasse mit einer anderen Klasse zusammenarbeitet. Objekte der Klasse können auf Objekte der verbundenen Klasse zugreifen. Damit ist die Klasse, von der die Assoziation ausgeht, von der anderen Klasse abhängig. Anders ausgedrückt hat diese Klasse eine Abhängigkeit von der anderen.
\end{definition}
\begin{definition}[Vererbung]
Vererbung entspricht einer \emph{Ist-ein-Beziehung} und gibt an, dass eine Klasse das Verhalten und die Struktur einer anderen Klasse erbt oder spezialisiert. Ein Objekt der erbenden Klasse ist damit auch ein Objekt der gerbten Klasse und hat somit auch eine Abhängigkeit von ihr.
\end{definition}
Mit diesen sieben Konzepten kann eine Softwaresystem objektorientiert beschrieben werden.

\subsection{Graphentheorie}
\label{subsec:graphs}
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben einen Graph in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} als Tupel \begin{math}G = (V, E)\end{math}. Der erste Wert, $V$, ist eine endliche Menge an Knoten und der zweite, $E$, ist eine endliche Menge an Kanten zwischen diesen Knoten. Eine Kante ist ein Paar aus \begin{math}V \times V\end{math} und beinhaltet die beiden Knoten, die sie verbindet. Cormen und co unterscheiden in gerichtete und ungerichtete Graphen. Bei letzterem verbindet eine Kante die Knoten in beiden Richtungen, wobei eine gerichtete Kante die Verbindungsrichtung anhand der Knoten-Reihenfolge im Kanten-Tupel vorgibt. Ein gerichteter Graph wird auch als Digraph bezeichnet. Weiter definieren Cormen und seine Koautoren einen Baum als zusammenhängenden azyklischen Graph, indem jeder Knoten von einem Wurzelknoten aus erreichbar ist. %Seite 1168, 1173

\subsection{Statische Code-Analyse}
\label{subsec:staticcodeanalysis}
Artur Wagner beschreibt in seiner Seminar-Ausarbeitung \cite{IntroStaticCodeAnalysis} die statische Codeanalyse als Prozess, der von einem Programm ähnlich einem Compiler gestartet wird. Dieses Programm führt den Code nicht aus und erzeugt auch keinen ausführbaren Code, sondern ein nimmt eine Analyse vor. Wagner erwähnt noch, das eine statische Code-Analyse keinen Korrektheitsnachweis liefert sondern lediglich eine Art Systemzusammenfassung erzeugt. Eine solche Analyse des Codes findet dabei automatisiert statt. Christof Ebert, Reiner Dumke, Manfred Bundschuh und Andreas Schmietendorf stellen ebenfalls den Vergleich mit einem Compiler an. In ihrem Buch \cite{BPSoftwareMeasurement} erwähnen sie zusätzlich noch ein Qualitätsmodell, das mit dem Analyseergebnis in Verbindung gebracht wird und so eine einfache Interpretierbarkeit des analysierten Systems ermöglicht. Zusätzlich beschreiben sie den Vorgang als Sammeln von Metriken und deren Bewertung anhand von Kriterien.
\paragraph{}
Nadine Vehring beschreibt eine \emph{Metrik} in ihrer Seminar-Ausarbeitung \cite{TestabilityMetrics} als Maß dafür, wie sehr eine \emph{Entität} ein \emph{Attribut} erfüllt. Als \emph{Entität} bezeichnet Vehring einen Teil des analysierten Systems, also beispielsweise eine Methode, Klasse oder eine Menge von Klassen. Weiterhin beschreibt sie ein \emph{Attribut} als Eigenschaft, die im betrachteten System, also bei den \emph{Entitäten} gemessen werden soll. In der vorliegenden Master-Thesis wird der Metrik-Begriff wie folgt definiert.
\begin{definition}[Metrik]
Die Metrik ist der Begriff für eine bestimmte und tatsächlich gemessene Eigenschaft die Methoden, Klassen, Paketen oder Mengen von Klassen im zu analysierenden System besitzen. Er entspricht damit dem direkten Ergebnis einer statischen Code-Analyse. Dieser Begriff wird manchmal Synonym für die Eigenschaft verwendet, die gemessen werden soll.
\end{definition}
\begin{definition}[Statistik der Metrik]
Die Statistik der Metrik ist die Bezeichnung für die zusammengefassten Werte aller Komponenten im System, für die eine bestimmte Metrik ausgerechnet werden kann. Zusätzlich können Metriken vor und nach der Aggregation gewichtet und bewertet werden. Ob ein Wert in einer Statistik berücksichtigt wird kann ebenfalls festgelegt werden. Marc Philipp und Nicole Rauch unterscheiden Metrik und Statistik in ihrem Artikel \cite{EclipseMagUsus} ebenfalls.
\end{definition}
Die Metriken eines Systems können auch manuell bestimmt werden. In dieser Master-Thesis werden Metriken aber immer als automatisiert bestimmbar und damit als Ergebnis einer automatisierten statischen Code-Analyse betrachtet. Das Konzept der statische Code-Analyse kann auch genutzt werden, um subjektive explizite Probleme im Code zu lokalisieren, wie beispielsweise die Verwendung von obsoleten Klassen und Methoden, sowie fehlende Klassenkommentare. In dieser Master-Thesis wird die statische Code-Analyse ausschließlich für die Bestimmung der Metriken genutzt.




\chapter{Anforderungen}
\label{chap:requirements}
In diesem Kapitel werden die Anforderungen an die Visual Studio Erweiterung zur statischen Code-Anaylse beschrieben, die im Rahmen dieser Master-Thesis entwickelt werden soll. Dabei werden die Anforderungen in einem agilen Kontext bestimmt und in Form von Sprint 0 wie in Scrum definiert\footnote[1]{Agile Anforderungsanalyse in Scrum: "`10 Things to do in Sprint 0"' \url{http://www.pmscrum.com/blog/2011/06/10-things-do-sprint-0}}. Dieses Kapitel gibt damit eine Antwort auf die Frage, was während dieser Master-Thesis gemacht werden soll.


\section{Interessenvertreter}
\label{sec:stakeholder}
Die Interessenvertreter (engl. \textit{Stakeholder}) im Kontext dieser Master-Thesis sind Gruppen von Personen, die einen Einfluss auf Anforderungen des Systems haben können. Die folgenden vier Gruppen wurden dafür identifiziert.
\begin{stakeholder}[andrena objects ag] Als Arbeitgeber stellt andrena das Umfeld dar, indem das Projekt durchgeführt und das System implementiert wird. Sie legt Wert auf agile Softwareentwicklung und möchte Entwicklungsprozesse und Praktiken gewinnbringend einsetzen. Die andrena objects ag hat bereits ein Plugin zur statischen Code-Analyse für Java und Eclipse entwickelt und möchte ihren Entwicklern ein ähnliches Programm auch für die .NET-Umgebung zur Verfügung stellen können.
\end{stakeholder}
\begin{stakeholder}[Leser dieser Thesis] Die Leser der vorliegenden Thesis haben ebenfalls ein Interesse an dem zu entwickelnden Produkt, das hauptsächlich theoretischer Natur ist. Sie haben einen Informatik-artigen Hintergrund und möchten einen Einblick in die Algorithmen und die Implementierungsdetails sämtlicher implementierten Aspekte des Systems erhalten.
\end{stakeholder}
\begin{stakeholder}[.NET-Entwickler mit wenig Erfahrung] Entwickler mit wenig Erfahrung arbeiten an kleineren Codebasen und wollen auf einfache Weise einen Überblick über Problemfälle des Systems behalten. Mithilfe des Systems wollen sie diese rechtzeitig beseitigen und sicherstellen, dass dadurch keine neuen Probleme entstehen.
\end{stakeholder}
\begin{stakeholder}[.NET-Entwickler mit viel Erfahrung] Entwickler mit viel Erfahrung arbeiten an großen und komplizierten Codebasen und möchten das System einsetzen um Tendenzen im System zu erkennen und Spezialfälle zu analysieren. Auch sie wollen einen besseren Überblick erhalten und das System aus möglichst vielen verschiedenen Perspektiven sehen.
\end{stakeholder}
\begin{stakeholder}[.NET, Clean Code-Entwickler] Clean Coder legen sehr viel Wert auf Quellcode, der möglichst einfach zu verstehen ist und damit schnell an neue Anforderungen angepasst werden kann. Sie erwarten von dem System Feedback und Unterstützung bei der Entwicklung von sauberem Code. Außerdem möchten sie auf Stellen im Code hingewiesen werden, die nicht ihren Vorstellungen entsprechen.
\end{stakeholder}
Die Beschreibungen der Interessengruppen sind grob und allgemein gehalten, während versucht wurde, die direkten Bedürfnisse der jeweiligen Gruppe zu benennen. Natürlich ist die Erklärung damit nicht vollständig oder exklusiv. So kann beispielsweise auch ein erfahrener .NET-Entwickler ein Interesse an Clean Code haben.


\section{Ziele}
\label{sec:goals}
Nachdem die beteiligten Interessengruppen definiert wurden, werden in diesem Abschnitt die Ziele des zu entwickelnden Systems beschrieben. Peter Hruschka und Chris Rupp erklären in ihrem Buch \cite{AgileSEUML} ein Ziel als "`ein erstrebenswerter Zustand"' in der Zukunft, den es zu erreichen gilt\footnote[1]{Seite 26}. Damit ist ein Ziel eine abstrakte Form einer Anforderung an das System, die sich auch in einem agilen Projekt nicht so schnell ändert wie spezielle Anforderungen. Es werden hier nun die folgenden vier Ziele definiert.
\begin{goal}[Einsicht in die Codebasis]
Große Entwicklungsprojekte haben eine große Codebasis, die es den Entwicklern erschwert Aussagen über den Quellcode des Systems zu machen. Mithilfe statischer Code-Analyse kann eine Einsicht in diesen Quellcode gewährleistet und so zum Vorteil aller Interessenvertreter genutzt werden. Eigenschaften des Quellcodes werden als können als Metriken berechnet und bewertet werden. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Eigenschaften des Codes erkennen und darauf reagieren kann.
\end{goal}
\begin{goal}[Erkennen von Problemfällen]
In einer vorhandenen Codebasis besteht die Gefahr, den Überblick über Problemfälle zu verlieren. Ein Problem kann beispielsweise eine Klasse sein, die zu viele Abhängigkeiten zu anderen Klassen hat, oder eine Methode, die zu viel Funktionalität besitzt. Das Erkennen und Anzeigen dieser Stellen ist ein Vorteil, von dem alle Interessenvertreter profitieren können, und der es ermöglicht, Schwachstellen systematisch zu entfernen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Probleme im Code erkennen und darauf reagieren kann.
\end{goal}
\begin{goal}[Förderung von Clean Code]
Das Entwickeln von Code kann auf eine sehr rücksichtslose Art und Weise geschehen, sodass spätere Anpassungen nur schwer vorzunehmen sind. Durch Feedback und Unterstützung während der Programmierung kann die Entwicklung von Clean Code gefördert werden, was zu einer Codebasis führt, die flexibler auf Anpassungen reagieren kann. Dieses Ziel ist erreicht, sobald ein Entwickler mehr Clean Code Praktiken beachtet und einhält, als er dies ohne Unterstützung des Systems getan hätte.
\end{goal}
\begin{goal}[Interpretation der Software-Qualität]
Eine bestehende Codebasis zu bewerten erfordert detaillierte Kenntnis über alle Klassen, deren Interaktionen und vielem mehr. Außerdem muss eine menschliche Bewertung manuell jedes mal neu erfolgen, ist subjektiv und fehleranfällig. Eine teilweise automatisierte Interpretation anhand von Regeln und Gewichtungen, die auf Erfahrungen basieren, kann die menschliche Bewertung optimieren und einem Entwickler jederzeit mit verhältnismäßig geringem Aufwand eine Qualitätsinterpretation ermöglichen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, die Qualität des Quellcodes durch Interpretation einschätzen und mit anderen Systemen vergleichen kann.
\end{goal}


\section{Architektur}
\label{sec:architecture}
In diesem Abschnitt wird die grundlegende Architektur des zu entwickelnden Systems erläutert. Im Rahmen dieser Master-Thesis soll ein System entwickelt werden, dass die in Abschnitt \ref{sec:goals} genannten Ziele erreicht. Zusätzlich soll dieses System als Erweiterung in Visual Studio laufen und den Quelltext (kompiliert und/oder unkompiliert) in einer .NET-Sprache, wie beispielsweise C\#, analysieren. Abbildung \ref{fig:architecture} zeigt die beiden Komponenten \emph{Visualisierung} und \emph{statische Code-Analyse}, um die es sich im weiteren Verlauf handeln wird.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/architektur.jpg}
	\caption{Grobe Architektur des zu entwickelnden Systems}
	\label{fig:architecture}
\end{figure}
Die Komponente, die die statische Code-Analyse durchführt, verwendet drei Aktionen, die einem kompletten Analyse-Prozess entsprechen. Die schwarzen Pfeile symbolisieren dabei Zugriffe auf Daten. Die Aktion \emph{Berechnung} betrachtet das Softwaresystem und kann dafür auf den Quellcode und das erzeugte Kompilat zugreifen. Das Ergebnis dieser Betrachtung wird in Form von Metriken in einer Datenbank gespeichert und stellt Daten für die Aktion \emph{Gewichtung} bereit. Diese gewichtet die Daten und erzeugt Statistiken, die ebenfalls in der Datenbank hinterlegt werden. Die Aktion \emph{Bewertung} versucht anhand der gewichteten Daten eine Aussage über die Qualität des Softwaresystems zu treffen. Nachdem diese drei Aktionen abgelaufen sind, ist der Analyse-Prozess beendet. Die Komponente \emph{Visualisierung}, die in Visual Studio ausgeführt wird, kann diesen Analyse-Prozess starten und auf dessen Daten zugreifen. Sie zeigt die berechneten Metriken in geeigneten Kontexten an und gibt basierend auf der Bewertung ein entsprechendes Entwickler-Feedback. Dieses Feedback entsteht dabei genau dort, wo der Quellcode entstanden ist, der von dem Analyse-Prozess verarbeitet wurde. Nach einer entsprechenden Veränderung des Quelltext kann der Prozess erneut gestartet werden, um auch diese Veränderung zu analysieren. So entsteht theoretisch ein kontinuierlicher Verbesserungskreislauf. Dieser Zyklus wird durch die breiten transparenten Pfeile angezeigt und entspricht dem Informationsfluss in dieser Umgebung.


\section{Use Cases}
Aus den in Abschnitt \ref{sec:goals} definierten Zielen dieses Projekts lassen sich zunächst vier Anwendungsfälle bestimmen, die in Abbildung \ref{fig:usecases} dargestellt sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/usecases.jpg}
	\caption{Anwendungsfälle des zu entwickelnden Systems}
	\label{fig:usecases}
\end{figure}
Die Akteure entsprechen ungefähr den in Abschnitt \ref{sec:stakeholder} definierten Interessenvertretern. Alle Akteure sind .NET-Entwickler und unterscheiden sich durch ihr Interesse. .NET-Entwickler mit \emph{Interesse an Metriken} entspricht ungefähr dem Interessenvertreter mit wenig .NET Erfahrung. Seine Interaktion mit dem System beschränkt sich auf die Bestimmung von Code-Metriken sowie der Identifizierung von Code-Problemen als Verletzung definierter Metrik-Grenzen. Der Interessenvertreter mit viel Erfahrung findet sich im Entwickler-Akteur mit \emph{Interesse an Qualitätsinterpretation} wieder. Er benutzt das System um eine Interpretation der Qualität zu erhalten, die anhand der Code-Metriken vorgenommen wird. Der Akteur .NET-Entwickler mit \emph{Interesse an Clean Code} ist an den Interessenvertreter Clean Coder angelehnt. Er lässt sich durch das System bei der Erzeugung von Clean Code, wie er in Unterabschnitt \ref{subsec:cleancode} beschrieben wurde, unterstützen. Diese Hilfestellung geschieht anhand der Code-Probleme, die durch Code-Metriken erkannt werden. Es ist ebenfalls zu sehen, dass der Anwendungsfall \emph{Code-Metriken bestimmen} alle anderen Anwendungsfälle direkt oder indirekt ergänzt. Damit ist er ein entscheidender Bestandteil des Systems, wenn nicht sogar der wichtigste. Die Interessenvertreter \emph{andrena objects ag} und \emph{Leser des Thesis} haben keine direkte Interaktion mit dem System und werden bei der Betrachtung der Use Cases ignoriert. 


\section{Produkt-Backlog}
\label{sec:productbacklog}
Die Anwendungsfälle lassen sich in User Stories (\emph{Anwendererzählungen}) unterteilen. Abbildung \ref{fig:productbacklog} zeit diese Aufteilung in der horizontalen und die Verteilung auf geplante Sprints in der vertikalen Dimension. Dieses zwei-dimensionale Backlog stellt die konkreten Anforderungen aus Benutzersicht an das komplette System dar.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/backlog.jpg}
	\caption{Produkt-Backlog des zu entwickelnden Systems}
	\label{fig:productbacklog}
\end{figure}
Die User Stories sind allgemein gehalten, da auf ein großes Design vor der Implementierung aus Agilitätsgründen verzichtet wurde. Pro Sprint werden die User Stories dann in konkrete Entwicklungs-Aufgaben unterteilt. Die Begründung jeder Story wurde nicht explizit aufgeschrieben, da die Beziehung zu den Use Cases und damit den Zielen aus Abschnitt \ref{sec:goals} erhalten und somit offensichtlich geblieben ist. Eine Priorisierung ist ebenfalls implizit durch das Aufteilen auf die Sprints entstanden, sodass eine explizite Business Value Analyse nicht notwendig ist. Da die Entwicklungsgeschwindigkeit noch nicht bekannt ist, ist die Sprint-Planung vorläufig. Eine Änderung kann also jederzeit erfolgen, wenn neue Use Cases und User Stories dazukommen, andere wegfallen oder nicht alle in einem Sprint geschafft werden. Zum Zeitpunkt dieser Planung lassen sich die bereits gefunden User Stories in schätzungswiese fünf Sprints implementieren. 
\paragraph{}
Was die Abnahmekriterien jeder Anwendererzählung betrifft, so wurde auch hier kein Mehrwert in der expliziten Definition gesehen. Pro Story kann ohne viel Aufwand ein exemplarischer manueller Akzeptanztest durchgeführt werden, der zeigt, ob das Ziel erreicht wurde. Zusätzlich können automatisierte Akzeptanztests zu Beginn des jeweiligen Sprints festgelegt werden.




\chapter{Vorgehensweise}
Nach dem die Anforderungen an das System, das in dieser Masther-Thesis entwickelt werden soll, in Kapitel \ref{chap:requirements} definiert wurden, wird in diesem Kapitel die grobe Vorgehensweise beschrieben. Dabei wird eine grobe Zeitplanung vorgestellt. Dieses Kapitel gibt damit eine Antwort auf die Frage, wie die Anforderungen realisiert werden sollen. Abbildung \ref{fig:plan_table} zeigt die zeitliche Aufteilung der Master-Thesis, während Abbildung \ref{fig:plan_gantt} das dazugehörige Gant-Chart darstellt. Die Thesis besteht aus einem praktischen und einen theoretischen Teil. Beide Teile überlagern sich, sodass eine Dokumentation der Implementierung zeitnah erfolgen kann und keine große Schreibphase gegen Ende des sechsmonatigen Zeitrahmen notwendig ist.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planningTable.png}
	\caption{Projektplan Tabelle}
	\label{fig:plan_table}
\end{figure}
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planningGantt.png}
	\caption{Projektplan Gantt-Chart}
	\label{fig:plan_gantt}
\end{figure}


\section{Praktischer Teil}
Der praktische Teil besteht aus einer Evaluationsphase und der eigentlichen Implementierungsphase. Während der Evaluierung werden verschiedene Technologien betrachtet, mit denen eine statische Code-Analyse durchgeführt werden kann. Das Ergebnis der Evaluierung wird die Grundlage der nächsten Phase darstellen. In der zweiten Phase werden die User Stories aus Abschnitt \ref{sec:productbacklog} im Rahmen der Visual Studio-Erweiterung zur statischen Code-Analyse in fünf zweiwöchigen (10 Tage) Sprints implementiert.


\section{Theoretischer Teil}
Der theoretische Teil entspricht hauptsächlich der Dokumentation aller Ergebnisse und deren Beschreibung in Form der schriftlichen Ausarbeitung dieser Master-Thesis. So werden in einer Planungsphase zunächst Grundlagen (Kapitel \ref{chap:basics}) beschrieben, sowie eine agile Anforderungsanalyse (Kapitel \ref{chap:requirements}) durchgeführt. Außerdem wird das Usus-Programm, dessen Funktionsumfang einen maßgeblichen Einfluss auf das zu entwickelnde System haben soll, näher betrachtet und dessen Metriken beschrieben (Kapitel \ref{chap:usus}). Anschließend soll das Ergebnis der Evaluierungsphase beschrieben werden (Kapitel \ref{chap:techeval}), bevor die tatsächlichen Sprints in Form von zwei-tägigen schriftlichen Zusammenfassungen abgeschlossen werden. Nach der Zusammenfassung des  vierten Sprints soll eine Fallstudio auf Basis eines andrena Kurs zum Thema Refactoring durchgeführt werden. Bei diesem Kurs soll das in dem praktischen Teil zu entwickelnde System eingesetzt und ermittelt werden, wie gut das Werkzeug einen Entwickler unterstützen kann. Unmittelbar vor dem fünften und vorläufig letzten Sprint soll eine Analyse von statischen Verteilungen der Metrik-Werte sowie deren Bedeutung erfolgen. Aufgrund dieser Verteilungen soll geprüft und beschrieben werden, ob und wenn ja, wie eine Aussage über den andrena Software Quality Index (SQI) anhand der Metriken möglich ist.




\chapter{Usus}
\label{chap:usus}
Das Wort \emph{usus} kommt aus dem lateinischen und bedeutet "`das, was üblich ist"'. In diesem Kapitel wird das Usus-Plugin \cite{UsusEclipsePlugin} für die Java Entwicklungsumgebung Eclipse vorgestellt, sowie auf die Metriken, die es berechnet, eingegangen. Das Usus Programm ist im Rahmen einer Initiative von andrena (Abschnitt \ref{sec:andrena}) entstanden. Usus entspricht im Groben dem Werkzeug für Eclipse und Java, das im Rahmen dieser Master-Thesis auch für Visual Studio und .NET entwickelt werden soll. Aus diesem Grund wird dessen Funktionsumfang an dieser Stelle betrachtet um ihn besser in nachimplementieren zu können. Eine direkte Portierung ist anhand der Technologieunterschiede von Visual Studio und Eclipse, sowie .NET und Java wahrscheinlich nicht möglich, sodass diese Option hier nicht in weiter verfolgt wird.


\section{Eclipse Plugin}
Das Usus-Plugin für Eclipse lässt sich über den Menü-Eintrag \texttt{Help / Install New Software} installieren, indem eine neue Software Site mit der Url \url{http://projectusus.googlecode.com/svn/updates/} hinzugefügt und anschließend \emph{Project Usus} ausgewählt wird. Nach der Installation steht die \emph{Project Usus perspective} zur Verfügung, die die folgenden Fenster enthält.

\subsection{Usus Cockpit}
\label{subsec:ususcockpit}
In diesem Fenster werden die Usus Metriken angezeigt, die für alle Projekte, die Usus betrachtet, gelten. Zusätzlich wird der Trend pro Metrik dargestellt, also ob sich die Ausprägung der Metrik verbessert oder verschlechtert hat. Die Verbesserung wird dabei zwischen zwei erstellten Snapshots gemessen, die entweder manuell oder durch einen neuen Speichervorgang ausgelöst werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_cockpit.png}
	\caption{Usus Cockpit zeigt Übersicht über alle Projekte}
	\label{fig:usus_cockpit}
\end{figure}
Die in Abbildung \ref{fig:usus_cockpit} dargestellten Statistiken der Metriken errechnen sich aus der Aggregation der Paket-, Klassen- oder Methoden-Eigenschaften.

\subsection{Usus Info}
Dieses Fenster lässt sich im Kontext einer Methode oder einer Klasse öffnen und zeigt Metriken, die anhand der Eigenschaften des Kontextes ermittelt werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_info.png}
	\caption{Usus Info zeigt Übersicht über eine Methode oder Klasse}
	\label{fig:usus_info}
\end{figure}
Das in Abbildung \ref{fig:usus_info} gezeigte Info-Fenster lässt sich mit \texttt{Ctrl-U} öffnen und mit \texttt{Esc} wieder schließen.

\subsection{Usus Hotspots}
\label{subsec:usushotspots}
Dieses Fenster zeigt sogenannte Hotspots, also Stellen im Quellcode, dessen Metriken definierte Grenze oder einen Schwellwert überschreiten. Hotspots lassen sich für jede Metrik definieren, die im Usus Cockpit angezeigt wird. Zusätzlich wird der Trend pro Hotspot gezeigt, also ob sich der Hotspot verbessert oder verschlechtert.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_hotspots.png}
	\caption{Usus Hotspots zeigt die Stellen im Code, die eine besondere Metrikausprägung haben}
	\label{fig:usus_hotspots}
\end{figure}
Das in Abbildung \ref{fig:usus_hotspots} gezeigte Hotspot-Fenster zeigt Hotspots immer nur für eine Metrik an. Der Wechsel zu einer anderen Hotspot-Metrik erfolgt über einen Doppelklick auf die Metrikanzeige im Usus Cockpit. Über einen Doppelklick auf einen Hotspot lässt sich entweder zu der dazugehörigen Methode im Quelltext oder dem entsprechende Paket oder der Klasse in einem der beiden Usus Graph Ansichten navigieren.

\subsection{Usus Histogram}
Dieses Fenster zeigt die absolute Häufigkeitsverteilung der Ausprägungen einer Metrik über alle Projekte an, die Usus betrachtet. Die verwendete Metrik wird dabei auf der der x-Achse angezeigt, während die Anzahl der Ausprägungen auf der y-Achse dargestellt wird. Die Verteilung lässt sich für eine der Metriken definieren, die im Usus Cockpit angezeigt werden.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_histogram.png}
	\caption{Usus Histogram zeigt die statistische Verteilung der Ausprägungen der definierten Metrik}
	\label{fig:usus_histogram}
\end{figure}
Das in Abbildung \ref{fig:usus_histogram} gezeigte Histogramm-Fenster zeigt die Verteilung der Metrik an, die zuvor über einen Einfachklick im Usus Cockpit markiert wurde. Es zeigt immer nur die Daten für eine Metrik an. Die Ansicht kann vergrößert, verkleinert, skaliert und als Grafik gespeichert werden.

\subsection{Usus Class Graph \& Usus Package Graph}
\label{subsec:ususgraphs}
Dieses Fenster zeigt die Abhängigkeiten der betrachteten Projekte entweder auf Klassenebene oder auf Paketebene an. Auf Paketebene lassen sich optional nur die Pakete anzeigen, die sich in einem Zyklus von Abhängigkeiten zu anderen Paketen befinden. Auf Klassenebene lassen sich optional nur die Klassen anzeigen, die über eine Abhängigkeit über Paketgrenzen hinweg verfügen. Dabei werden auch nur eben diese Paketübergreifenden Abhängigkeiten angezeigt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_graph.png}
	\caption{Usus Graph Schaubilder zeigen die Abhängigkeiten der Klassen oder Pakete voneinander an}
	\label{fig:usus_graph}
\end{figure}
Das in Abbildung \ref{fig:usus_graph} dargestellte Fenster besteht aus zwei Karteikarten. Eine Karteikarte zeigt den Usus Class Graph, während die andere den Usus Package Graph darstellt. Zwischen den beiden Ansichten kann beliebig gewechselt werden. Die Knoten in den Graphen lassen sich mit der Maus frei positionieren. Zusätzlich lassen sich die Graphen-Darstellungen auch automatisch anordnen.


\section{Metriken}
\label{sec:metrics}
In den Fenstern Usus Cockpit und Usus Info zeit das Eclipse Plugin die Werte verschiedener Metriken an. Das Usus Info Fenster zeigt im Kontext einer Methode neben den Metriken, die es zusätzlich für die Klasse anzeigt auch Methoden-Metriken. In diesem Abschnitt wird daher zuerst auf die Metriken eingegangen, die das Usus-Plugin für Methoden berechnet, bevor die Klassen-Metriken näher betrachtet werden. Abschließend werden die Usus Cockpit Metriken beschrieben. Diese Beschreibungen sind von Bedeutung, da sämtliche Metriken im Rahmen der Usus-Erweiterung für Visual Studio nach-implementiert werden sollen.

\subsection{Pro Methode}
Wenn das Usus Info Fenster im Kontext einer Methode geöffnet wird, wird die zyklomatische Komplexität sowie die Länge der Methode dargestellt.
\subsubsection{Zyklomatische Komplexität}
\label{subsubsec:cyclomaticcomplexity}
Die Metrik \emph{Cyclomatic Complexity} wurde von Thomas J. McCabe vorgestellt \cite{AComplexityMeasure} um Methoden anhand von linear unabhängigen Ablaufpfaden in Bezug auf Komplexität zu bewerten. McCabe bezieht sich in seinem Artikel auf die Graphentheorie und errechnet die Komplexität eines Ablaufgraphen wie folgt.
\begin{equation}
v(G) = e - n + 2p
\label{eq:cyclomaticcomplexity1}
\end{equation}
\begin{eqnarray*}
G&=&\text{Ablaufgraph}\\
v(G)&=&\text{zyklomatische Komplexität von $G$}\\
e&=&\text{Anzahl Kanten im Ablaufgraphen $G$}\\
n&=&\text{Anzahl Knoten im Ablaufgraphen $G$}\\
p&=&\text{Anzahl Zusammenhangskomponenten in $G$}\\
\label{eq:cyclomaticcomplexity1agenda}
\end{eqnarray*}
Ernest Wallmüller beschreibt die zyklomatische Komplexität in seinem Buch \cite{SoftwareQMPraxis} auch als Anzahl aller entscheidungstreffenden Stellen in der Methode. Im Falle einer Verkettung von binären Entscheidungen zu logischen Ausdrücken zählt jede Entscheidung als eine solche Stelle. Diese einfachere Rechnung ergibt sich als
\begin{equation}
	v(G) = 1 + \Big( \sum_{\displaystyle b \in Bs(G)} 1 \Big)
\label{eq:cyclomaticcomplexity2}
\end{equation}
wobei $Bs(G)$ die Menge aller binären Entscheidungen im Ablaufgraphen $G$ darstellt. Voraussetzung für diese Rechnung ist, das die Methode nur einen Eingang und nur einen Ausgang besitzt. Der Quellcode in Listing \ref{listing:simpleifs} soll die Grundlage für eine demonstrative Berechnung der zyklomatischen Komplexität darstellen.
\begin{lstlisting}[caption={Einfache if-Verschachtelung},label={listing:simpleifs}]
public void doSomething() {
   if (condition1) {
      if (condition2 || condition3)
         do1();
   }
}
\end{lstlisting}
Nach Formel \ref{eq:cyclomaticcomplexity2} ergeben sich drei Entscheidungsstellen, welche durch die drei binären Bedingungen dargestellt werden. Die zyklomatische Komplexität entspricht damit \begin{math}v(G) = 1 + 3 = 4\end{math}.
\begin{figure}[h]
	\centering
		\includegraphics[width=9cm]{images/cc.jpg}
	\caption{Ablaufgraph G des Quellcodes \ref{listing:simpleifs}}
	\label{fig:ccsamplegraph}
\end{figure}
Die Berechnung anhand Formel \ref{eq:cyclomaticcomplexity1} basiert auf der Struktur des Ablaufgraphen, der in Abbildung \ref{fig:ccsamplegraph} dargestellt ist. Hier entspricht die zyklomatische Komplexität \begin{math}v(G) = 10 - 8 + 2 * 1 = 4\end{math}. Die Ergebnisse beider Rechnungen sind identisch. Die Eigenschaften einer Methode, die für die Berechnung der \emph{Cyclomatic Complexity}-Metrik erforderlich sind, sind also entweder die Anzahl der binären Entscheidungen oder der vollständige Ablaufgraph.
\subsubsection{Methodenlänge}
\label{subsubsec:methodlength}
Die Länge einer Methode kann auf unterschiedliche Weise ermittelt werden. Eine Unterscheidung der Möglichkeiten wird von Mark Lorenz und Jeff Kidds in \cite{OOSMetrics} vorgenommen. Hier werden zwei Möglichkeiten wie folgt definiert.
\begin{definition}[Anzahl Code-Zeilen]
Die Anzahl der Code-Zeilen (engl. Lines of code) entspricht der tatsächlichen Anzahl an Zeilenumbrüchen ohne leere Zeilen und Kommentarzeilen. Diese Längenangabe ist stark vom Entwicklerstil abhängig und kann sich daher unterschiedlich ausprägen, je nachdem wie beispielsweise eine Parameterliste umgebrochen wird.
\end{definition} 
\begin{definition}[Anzahl der Anweisungen]
Die Anzahl der Anweisungen (engl. Number of statements) entspricht nach Lorenz und Kidds einer stabileren Längenangabe. Eine Anweisung ist jeder durch ein Semikolon abgeschlossene Ausdruck sowie Bedingungs- und Wiederholungsanweisungen.
\end{definition} 
Die im Usus Info Fenster angezeigte Methodenlänge entspricht der Anzahl der Anweisungen der Methode. Eine Berechnung kann daher über die Aufsummierung der Semikola und der if-, switch-, for-, while- und try-catch-Anweisungen erfolgen.

\subsection{Pro Klasse}
\label{subsec:perclass}
Wenn das Usus Info Fenster im Kontext einer Klasse geöffnet wird, wird die Klassengröße sowie die kumulierte Komponentenabhängigkeit der Klasse dargestellt.

\subsubsection{Klassengröße}
\label{subsubsec:classsize}
Ähnlich der Methodenlänge lässt sich auch die Größe einer Klasse auf verschiedene Weise berechnen. Lorenz und Jeff unterscheiden mehrere Möglichkeiten \cite{OOSMetrics}. Zwei Varianten werden hier im folgenden definiert.
\begin{definition}[Anzahl der Methoden]
In dem die Anzahl der Methoden betrachtet wird, können Klassen erkannt werden, die zu viel oder zu wenig Funktionen erfüllen. Weitere Unterscheidungsmöglichkeiten sind Methoden in Klassen- und Instanz-Methoden aufzuteilen oder Methoden anhand der Sichtbarkeit zu klassifizieren. Ein Konstruktor würde sich wie eine statische Methode, also eine Klassen-Methode, verhalten.
\end{definition} 
\begin{definition}[Anzahl der Felder]
Die Anzahl der Felder zu betrachten erlaubt es Klassen zu erkennen, die zu viel Informationen verwalten. Auch hier ist eine weitere Unterteilung in Klassen- und Instanz-Felder möglich. Die Sichtbarkeit der Felder erlaubt eine weitere Einschränkung.
\end{definition}
Das Usus Info Fenster zeigt als Klassengröße die Anzahl der Instanz-Methoden, der Klassen-Methoden sowie der Konstruktoren an. Dabei wird die Sichtbarkeit der Methode oder des Konstruktors nicht berücksichtigt. Das Usus-Plugin fokussiert damit auf die Funktion der Klassen und nicht auf die Information und das Wissen einer Klasse, welches in den Feldern liegt. Die Klassengröße kann also berechnet werden, wenn alle Methoden und Konstruktoren einer Klasse ermittelt werden können.
\subsubsection{Kumulierte Komponentenabhängigkeit}
\label{subsubsec:ccd}
Die Metrik \emph{Kumulierte Komponentenabhängigkeit} (engl. Cumulative Component Dependency) CCD ist laut Peter Grogono \cite{SoftwareQControl} eine Metrik, die für Systeme und Untersysteme ermittelt wird. Dabei werden für jede Klasse (Komponente) in diesem System die Anzahl der Klassen ermittelt, von denen die betrachtete Klasse direkt und indirekt abhängt. Eine Klasse ist immer auch von sich selber abhängig. Marc Philipp und Nicole Rauch bezeichnen diese Abhängigkeiten in ihrem Artikel \cite{EclipseMagUsus} als reflexsiv und transitiv. Anschließend werden die Abhängigkeiten aller betrachteten Klassen aufsummiert und ergeben den CCD-Wert des Systems. In dem Usus Info Fenster wird der Abhängigkeitswert einer betrachteten Klasse als \emph{CCD (of class)} bezeichnet. Um die Anzahl der Klassen zu bestimmen, von denen eine betrachtete Klasse abhängig ist, ist mindestens der vollständige Abhängigkeitsgraph der Klasse erforderlich. Mit einem Durchmusterungsalgorithmus kann die Erreichbarkeitsmenge (Reach-Menge) der Klasse (Startknoten) in diesem Abhängigkeitsgraph ermittelt werden. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} die beiden Algorithmen \emph{Breadth First Search} BFS und \emph{Depth First Search} DFS für diesen Zweck. %Seite 594, 603
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/ccd.jpg}
	\caption{Abhängigkeitsgraph einer Klasse mit aufsummierten Abhängigkeiten}
	\label{fig:ccd}
\end{figure}
Abbildung \ref{fig:ccd} zeigt sieben Klassen, die in einer hierarchischen Abhängigkeitsstruktur stehen. Offensichtlich ist Klasse A von allen anderen Klassen abhängig und hat damit den CCD-Wert sieben. Dies entspricht der Kardinalität der Reach-Menge von A, \begin{math}\{A,B,C,D,E,F,G\}\end{math}, die ermittelt wird, indem BFS oder DFS mit Klasse A als Startknoten im Abhängigkeitsgraph gestartet wird. Dabei werden die durch den Algorithmus markierten Knoten als Ergebnis des Algorithmus behandelt. Bei dem Abhängigkeitsgraph muss es sich nicht um einen Baum handeln.
\begin{equation}
	ccd(c) = | DFS(dG, c) |
\label{eq:cumulativecomponentdependencyofclass}
\end{equation}
\begin{eqnarray*}
dG&=&\text{Abhängigkeitsgraph des Systems}\\
c&=&\text{Klasse im System}\in dG\\
ccd(c)&=&\text{CCD-Wert der Klasse } c\\
\label{eq:cumulativecomponentdependencyofclassagenda}
\end{eqnarray*}
Formel \ref{eq:cumulativecomponentdependencyofclass} zeigt die Berechnungsvorschrift unter Verwendung des DFS-Algorithmus. Die Berechnung des CCD-Werts einer Klasse kann also durchgeführt werden, sobald ein Abhängigkeitsgraph erzeugt werden kann. Um einen solchen Graphen zu erzeugen müssen die direkten Abhängigkeiten einer Klasse ermittelt werden können. Jede Klasse wird dann einem Knoten zugeordnet und jede Abhängigkeit einer gerichteten Kante. Eine grafische Darstellung (siehe Unterabschnitt \ref{subsec:ususgraphs}) ist dann ebenfalls möglich. Die direkten Abhängigkeiten einer Klasse können bestimmt werden, wenn die Typen aller Felder, Methodenparameter, Oberklasse und Interfaces sowie sämtlicher Methodenaufrufe entfernter Klassen identifiziert werden können. Abhängigkeiten zu Klassen, wie beispielsweise \texttt{String} oder \texttt{Object}, die im Basis-Framework definiert sind, können ignoriert werden.

\subsection{Projektübergreifend}
\label{subsec:allprojectsmetrics}
Neben den Metriken, die Usus für Methoden und Klassen berechnet, werden im Usus Cockpit Statistiken zu der Codebasis angezeigt. Dafür werden die ermittelten Metriken bewertet, wie es Marc Philipp und Nicole Rauch in ihrem Artikel \cite{EclipseMagUsus} beschreiben. In diesem Unterabschnitt werden die verscheiden Statistiken vorgestellt und auf ihre Bewertung eingegangen. Weiterhin werden die Schwellwerte der Statistiken definiert, anhand derer eine Klasse, Methode oder Paket als Hotspot (siehe Unter-Unterabschnitt \ref{subsec:usushotspots}) eingestuft wird.
\subsubsection{Durchschnittliche kumulierte Komponentenabhängigkeit}
\label{subsubsec:acd}
Die Metrik \textit{Durchschnittliche kumulierte Komponentenabhängigkeit} (engl. Average Component Dependency) ACD ist laut Peter Grogono \cite{SoftwareQControl} wie \emph{Kumulierte Komponentenabhängigkeit} (siehe Unter-Unterabschnitt \ref{subsubsec:ccd}) eine Metrik, die für Systeme und Untersysteme ermittelt wird. Dabei wird der Mittelwert des CCD-Werts des Systems wie in Formel \ref{eq:averagecomponentdependency1} berechnet, wobei $n$ die Anzahl der Klassen im System ist.
\begin{equation}
	acd = \frac{ccd}{n}
\label{eq:averagecomponentdependency1}
\end{equation}
Da Usus die CCD-Werte nicht für Systeme oder Untersysteme ermittelt, sondern die CCD-Werte der Klassen bestimmt ohne sie aufzusummieren (siehe Unter-Unterabschnitt \ref{subsubsec:ccd}), kann der ACD-Wert anhand einer Menge von Klassen $Cs$ berechnet werden, wie in Formel \ref{eq:averagecomponentdependency2} dargestellt. Die Rechnung ist äquivalent zu Formel \ref{eq:averagecomponentdependency1}.
\begin{equation}
	acd(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} ccd(C)}{|Cs|}
\label{eq:averagecomponentdependency2}
\end{equation}
Peter Grogono beschreibt die Bedeutung des ACD-Werts als durchschnittliche Anzahl an Komponenten, die durch eine Änderung einer Komponente betroffen sind und eventuell ebenfalls geändert werden müssen. Der ACD-Wert wird im Usus Cockpit als Statistik in Prozent angezeigt. Dazu wird nochmal der Mittelwert über die betrachteten Klassen gebildet, wie in Formel \ref{eq:averagecomponentdependency3} zu sehen ist und der Bewertungsfunktion von Philipp und Rauch entspricht.
\begin{equation}
	acd'(Cs) = \frac{acd(Cs)}{|Cs|}
\label{eq:averagecomponentdependency3}
\end{equation}
Eine Klasse wird von Usus dann als Hotspot betrachtet, wenn ihr CCD-Wert über einer Schwelle liegt, die von der Projektgröße abhängig ist. Die Projektgröße wird dabei an der Anzahl der Klassen festgelegt. Anhand der Tooltip-Erklärung im Usus Cockpit liegt diese Schwelle für kleine Projekte bei 15\% der Klassenanzahl, während bei großen Projekten 5\% der Klassenanzahl verwendet wird. Dafür haben Philipp und Rauch Formel \ref{eq:averagecomponentdependency4} mithilfe von Erfahrungswerten definiert um die Berechnung des CCD-Schwellwert-Faktors $L_{ccd}$ anhand der Menge aller Klassen $Cs$ im System durchführen zu können.
\begin{equation}
	L_{ccd}(Cs) = \frac{1,5}{2^{\displaystyle (\log_{5} |Cs|)}}
\label{eq:averagecomponentdependency4}
\end{equation}
Um den tatsächlichen Schwellwert für eine Menge von Klassen $Cs$ zu bestimmen, muss der Faktor $L_{ccd}(Cs)$ noch mit der Anzahl der Klassen $|Cs|$ multipliziert werden.
\subsubsection{Durchschnittliche Klassengröße}
Eine Klasse wird von Usus als Hotspot gesehen, sobald die in Unter-Unterabschnitt \ref{subsubsec:classsize} beschriebene Klassengröße den Schwellwert 12 übersteigt. Das haben Philipp und Rauch festgelegt. Die im Usus Cockpit angezeigte durchschnittliche Klassengröße betrachtet nur die Klassen, die bereits als Hotspot markiert wurden. Das liegt an der Bewertungsfunktion $rating_{cs}$ von Philipp und Rauch, die in Formel \ref{eq:averageclasssize1} angegeben ist.
\begin{equation}
	rating_{cs}(cs) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{cs}{12}\bigg) - 1, & \text{wenn }cs > 12\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averageclasssize1}
\end{equation}
Die Bewertungsfunktion der Klassengröße $cs$ ist direkt von dem Schwellwert 12 abhängig und bewertet alle Klassen, dessen Größe 12 oder weniger beträgt mit 0. Um die durchschnittliche Klassengröße $acs$ einer Menge von Klassen $Cs$ zu berechnen, bildet Usus den Mittelwert aller bewerteter Klassengrößen. Dazu wird die Formel \ref{eq:averageclasssize2} verwendet.
\begin{equation}
	acs(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} rating_{cs}(c)}{|Cs|}
\label{eq:averageclasssize2}
\end{equation}
Dabei gehen die mit 0 bewerteten Klassengrößen ebenfalls in die Durchschnittsberechnung ein.
\subsubsection{Durchschnittliche zyklomatische Komplexität}
Die Berechnung der durchschnittlichen zyklomatischen Komplexität findet auf ähnliche Weise statt. Philipp und Rauch haben hier den Schwellwert 4 gewählt. Damit werden Methoden ignoriert, die vier oder weniger unabhängige Ablaufpfade besitzen oder anders ausgedrückt, weniger als vier verschiedene Entscheidungen treffen. Die Bewertungsfunktion $rating_{cc}$ eines wie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} berechneten zyklomatischen Komplexitäts-Wert sieht damit folgendermaßen aus.
\begin{equation}
	rating_{cc}(cc) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{cc}{4}\bigg) - 1, & \text{wenn }cc > 4\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagecyclomaticcomplexity}
\end{equation}
Anschließend kann der Mittelwert der bewerteten Komplexitäten gebildet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Durchschnittliche Methodenlänge}
Auch die Berechnung der durchschnittlichen Methodenlänge findet ähnlich statt. Der Schwellwert für die in Unter-Unterabschnitt \ref{subsubsec:methodlength} berechnete Metrik wurde hier auf 9 festgelegt. Methoden mit 9 oder weniger Anweisungen werden damit ignoriert. Die Bewertungsfunktion $rating_{ml}$ sieht dann folgendermaßen aus.
\begin{equation}
	rating_{ml}(ml) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{ml}{9}\bigg) - 1, & \text{wenn }ml > 9\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagemethodlength}
\end{equation}
Aus den bewerteten Längen kann dann wieder der Mittelwert berechnet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Anzahl nicht-statischer öffentlicher Felder}
\label{subsubsec:nonstaticpublicfields}
Wenn eine Klasse mindestens ein öffentliches Feld hat, das nicht statisch oder eine Konstante ist, dann betrachtet Usus diese Klasse als einen Hotspot. Dabei wird jede Klasse mit 1 bewertet, die mindestens eines dieser Felder besitzt. Der Schwellwert ist ebenfalls 1. Die Anzahl der betroffenen Klassen wird wie jede andere Metrik im Usus Cockpit über die Anzahl aller Klassen gemittelt und somit als Prozent dargestellt.
\subsubsection{Pakete mit zyklischen Abhängigkeiten}
\label{subsubsec:packetswithcyclicdependencies}
Für Klassen wurde in Unter-Unterabschnitt \ref{subsubsec:ccd} ein Abhängigkeitsgraph unabhängig vom Paket ermittelt, in dem sich die betrachtete Klasse befindet. Um Pakete mit zyklischen Abhängigkeiten zu identifizieren, müssen alle Klassen-Knoten eines Paket in dem Abhängigkeitsgraph zu einem Paket-Knoten in einem neuen Abhängigkeitsgraph auf Paketebene zusammengefasst werden. Die Kanten zwischen den Klassen werden zu Kanten zwischen den Paketen. Anschließend können alle trivialen Kreise im Paket-Abhängigkeitsgraph entfernt und Zyklen gesucht werden. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} den Algorithmus \emph{Strongly Connected Components} (Starke Zusammenhangskomponenten) für diesen Zweck. Mit diesem Algorithmus können alle starken Zusammenhangskomponenten (SCCs) eines Graphen ermittelt werden. Da per Definition von Cormen und co alle Knoten in einer SCC sich gegenseitig erreichen können, handelt es sich um Kreise. Folglich enthalten alle starken Zusammanhangskomponenten, die mehr als eine Paket beinhalten, Pakete, die auf einem Kreis im Abhängigkeitsgraph liegen. %Seite 615, 617
\begin{equation}
	cyclicPackages(pdG) = \sum_{\displaystyle scc \in SCCs(pdG)}
	\begin{cases}
		| scc |, & \text{wenn }|scc| > 1\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:packageswithcyclicdependencies}
\end{equation}
\begin{eqnarray*}
pdG&=&\text{Paket-Abhängigkeitsgraph}\\
SCCs(pdG)&=&\text{Menge aller starken Zusammenhangskomponenten in }pdG\\
scc&=&\text{Starke Zusammenhangskomponente als Menge von Paketen}\\
cyclicPackages(pdG)&=&\text{Anzahl aller Pakete in allen starken Zusammenhangskomponenten in }pdG\\
\label{eq:packageswithcyclicdependenciesagenda}
\end{eqnarray*}
Formel \ref{eq:packageswithcyclicdependencies} zeigt dabei die Aufsummierung aller Pakete in nicht-trivialen starken Zusammenhangskomponenten eines Paket-Abhängigkeitsgraph. Abschließend kann der $cyclicPackages$-Wert durch die Anzahl der betrachteten Pakete dividiert werden, um einen durchschnittlichen Paket-Zyklus-Wert zu bestimmen, der im Usus Cockpit angezeigt wird. Alle Pakete, die 2 oder mehr zyklische Abhängigkeiten besitzen werden als Hotspots behandelt.




\chapter{Andere Tools}
Nachdem in dem vorherigen Kapitel das Eclipse Plugin Usus vorgestellt wurde, werden in diesem Kapitel einige andere Werkzeuge beschrieben, die ebenfalls eine statische Code-Analyse durchführen. Während Usus die direkte Inspiration für das in dieser Master-Thesis zu entwickelnde Tool darstellt, werden in diesem Kapitel einige Visual Studio Erweiterungen behandelt. Diese Erweiterungen versuchen bereits, die in Kapitel \ref{chap:requirements} definierten Anforderungen zu erfüllen und sind dabei auf Projekte spezialisiert, die für das .NET-Framework entwickelt werden.


\section{Visual Studio Metrics}
In diesem Abschnitt sollen die Möglichkeiten beschrieben werden, die Visual Studio von Haus aus bietet um Software zu analysieren. Ab Visual Studio 2010 Premium können zu jeder Solution (Menge von Projekten) verschiedene Code-Metriken direkt berechnet werden. Die Ergebnis-Anzeige ist in Abbildung \ref{fig:vsmetricsresult} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/vsmetricsresult.png}
	\caption{Code-Metriken Ergebnis-Fenster in Visual Studio 2010 Premium}
	\label{fig:vsmetricsresult}
\end{figure}
Bei den berechneten Metriken handelt es sich um \emph{Lines of Code} (eigentlich \emph{Number of Statements}), \emph{Class Coupling} (direkte Klassen-Abhängigkeiten), \emph{Cyclomatic Complexity} und \emph{Maintainability Index} (Microsofts Indikator für Wartbarkeit). Jede dieser Metriken wird auf Methoden-Ebene erhoben und Zusammenfassend in der hierarchischen Struktur nach oben (Klasse, Paket, Assembly) propagiert. Zusätzlich wird die Metrik \emph{Depth of Inheritance} (Anzahl an direkten und indirekten Oberklassen ohne Interfaces) auf Klassenebene bestimmt und ebenfalls nach oben aggregiert. Der Wartbarkeits-Index sowie dessen Berechnung wird von Zain Naboulsi in seinem Artikel \cite{VSMaintainabilityIndex} umfangreich erläutert. Neben der einfachen Darstellung erlaubt Visual Studio das Filtern der Methoden und Klassen anhand der Metriken und zeigt neben der Ausprägung des Wartbarkeits-Indexes eine Ampel an, die nach Microsofts Empfinden die Methode/Klasse als gut wartbar, weniger gut wartbar und nicht so gut wartbar klassifiziert.
\paragraph{}
In Visual Studio 2010 Ultimate können zudem mehrere grafische Funktionen genutzt werden. So lassen sich zum Beispiel Methoden automatisch als Sequenz-Diagramme darstellen, was einen Hinweis auf deren Komplexität und Abhängigkeiten geben kann. Zusätzlich kann der Abhängigkeitsgraph einer Solution mithilfe des Architektur-Explorer visualisiert und so zyklische Abhängigkeiten von Klassen und Pakten schnell gefunden werden. Abbildung \ref{fig:vsarchitecturenamespaces} zeigt das Ergebnis der Visualisierung, die neben der Graphen-Form auch in Form einer Matrix dargestellt werden kann.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/vsarchitecturenamespaces.png}
	\caption{Architektur-Diagramm in Visual Studio 2010 Ultimate auf Basis von Paketen, aufklappbar bis Methoden-Ebene}
	\label{fig:vsarchitecturenamespaces}
\end{figure}
Leider sind diese Funktion zur Metrik-Berechnung und zur Visualisierung in der am weitesten verbreiten Professional Version von Visual Studio nicht verfügbar. Zwei kostenlose Programme, die das Bestimmen der gleichen Menge von Code-Metriken erlauben werden in den folgenden Unterabschnitten vorgestellt.

\subsection{Visual Studio Code Metrics Power Tool}
\label{subsec:vscodemetricspowertool}
Das Kommandozeilenwerkzeug \emph{Visual Studio Code Metrics Power Tool}\footnote[1]{Download: "`Visual Studio Code Metrics PowerTool 10.0"' \url{http://www.microsoft.com/download/en/details.aspx?id=9422}} wird kostenfrei von Microsoft zum Download angeboten. Es erlaubt die Berechnung der gleichen Metriken wie die in Visual Studio 2010 Premium integrierte Funktionalität und erzeugt eine XML-Datei. Diese Datei enthält die Metriken für Projekte, Namensräume, Typen und Methoden in hierarchischer Form.

\subsection{Code Metrics Viewer}
Die Erweiterung \emph{Code Metrics Viewer}\footnote[2]{Download: "`Code Metrics Viewer extension"' \url{http://visualstudiogallery.msdn.microsoft.com/9f35524b-a784-4dbc-bd7b-6babd7a5a3b3}} für Visual Studio 2010 wird von Matthias Friedrich zum kostenlosen Download angeboten. Das Tool nutzt das Kommandozeilenwerkzeug \emph{Visual Studio Code Metrics Power Tool} um Metriken direkt in der Entwicklungsumgebung grafisch anzeigen zu können. In einem Visual Studio-Fenster, das dem aus Abbildung \ref{fig:vsmetricsresult} nachempfunden ist, wird der Inhalt der durch das Power Tool erzeugten XML-Datei visualisiert. Es lassen sich ebenfalls verschiedene Filter einstellen. Der Hauptunterschied zu der integrierten Funktionalität besteht darin, das die Ampel zu jeder Metrik angezeigt wird.


\section{NDepend}
\label{sec:ndepend}
Für die grafische Darstellung des Abhängigkeitsgraphen kann das kommerzielle Werkzeug NDepend\footnote[1]{NDepend "`Tutorial with explanations and screenshots"' \url{http://www.ndepend.com/GettingStarted.aspx\#Tuto}} (299\EUR für eine Einzelplatz-Lizenz) genutzt werden. Dieses Tool ist neben der umfangreichen Darstellung von Zusammenhängen und Abhängigkeiten in der Lage, viele verschiedene Metriken auf Anwendungs-, Projekt-, Namesraum-, Klassen- und Methoden-Ebene zu berechnen. Die Abhängigkeiten können, wie im Architektur-Explorer in Visual Studio Ultimate, in Form einer Matrix oder in Form eines Diagrams veranschaulicht werden. Dafür analysiert NDepend genau wie das Code Metrics Power Tool die pro Projekt von dem Compiler erzeugten Assembly-Dateien (exe oder dll). Das Programm ist neben .NET auch für Java und C++ erhältlich und kann als eigenständige Anwendung oder als Visual Studio Addin verwendet werden.

\subsection{Code Query Language}
Abhängig von der Metrik- und Abhängigkeitsberechnung kann NDepend Warnungen und Hinweise anzeigen, die den Programmierer rechtzeitig auf schwierige Stellen im Code hinweisen und es ihm erlauben, dort gezielt einzugreifen. Es lassen sich auch eigene Warnungen und Berichte mithilfe der deklarativen Sprache CQL (Code Query Language) erstellen und ausführen.

\subsection{Abstraktheit und Instabilität}
Eine sehr interessante Metrik im NDepend Metrik-Portfolio ist "`Abstraktheit und Instabilität"'. Diese Metrik-Kombination geht auf einen Artikel von Robert C. Martin \cite{OODesignMetrics} zurück. In diesem Artikel beschreibt Martin verschiedene Metriken zum Messen von Abhängigkeiten in Bezug auf eine Klassen-Kategorie. Eine Kategorie definiert er als Gruppe zusammenhängender Klassen, die gemeinsam benutzt werden. Diese Definition kann somit auf Pakete (Namensräume) oder auf Assemblies (Projekte) angewendet werden. Als erste Metrik stellt Martin \emph{Afferent Couplings} (hinführende Kupplungen $Ca(k)$) einer Kategorie $k$ als Anzahl der Klassen vor, die nicht in der Kategorie sind und eine Abhängigkeit von Klassen in der Kategorie haben. Daraus ergibt sich Formel \ref{eq:afferentcouplings}.
\begin{equation}
	Ca(k) = \sum_{\displaystyle c_o \in Cs \setminus Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_o, c_i) \in dG \mid c_i \in Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:afferentcouplings}
\end{equation}
\begin{eqnarray*}
Cs&=&\text{Menge aller Klassen im System}\\
Cs(k)&=&\text{Menge aller Klassen in der Kategorie }k\\
dG&=&\text{Abhängigkeitsgraph des Systems}\\
\label{eq:afferentcouplingsagenda}
\end{eqnarray*}
Martin bezieht sich auf die Abhängigkeiten zwischen Kategorien. In Formel \ref{eq:afferentcouplings} und den folgenden Formeln wird der bereits aus Unterabschnitt \ref{subsec:perclass} bekannte Abhängigkeitsgraph $dG$ auf Klassen-Ebene verwendet um die Abhängigkeiten abzubilden. Die Kategorie-Grenze einer Kategorie $k$ wird in Bezug auf die Klassen-Abhängigkeiten durch die Funktion $Cs(k)$ bestimmt. Während Formel \ref{eq:afferentcouplings} alle Abhängigkeiten in Richtung der betrachteten Kategorie beschreibt, definiert Formel \ref{eq:efferentcouplings} alle Abhängigkeiten aus der Richtung der betrachteten Kategorie. Die Metrik \emph{Efferent Couplings} (wegführende Kupplungen $Ce(k)$) bezeichnet die Anzahl der Klassen innerhalb einer Kategorie $k$, die Abhängigkeiten zu Klassen außerhalb der Kategorie besitzen.
\begin{equation}
	Ce(k) = \sum_{\displaystyle c_i \in Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_i, c_o) \in dG \mid c_o \in Cs \setminus Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:efferentcouplings}
\end{equation}
Die Formeln \ref{eq:afferentcouplings} und \ref{eq:efferentcouplings} besitzen die gleiche Struktur und unterscheiden sich nur durch die Richtung der gesuchten Kante im Abhängigkeitsgraph $dG$ und der Menge der Klassen, die gezählt werden soll.
\paragraph{}
Mit der Anzahl der hinführenden und wegführenden Abhängigkeiten kann jetzt die Metrik \emph{Instability} (Instabilität $I(k)$) einer Kategorie $k$ wie in Formel \ref{eq:instability} bestimmt werden. Martin beschreibt diese Metrik als Maß dafür, wie sich die betrachtete Kategorie anpassen muss, wenn sich das restliche System ändert.
\begin{equation}
	I(k) = \frac{Ce(k)}{Ca(k) + Ce(k)}
\label{eq:instability}
\end{equation}
Eine Instabilität von 1.0 bedeutet maximale Instabilität und wird erreicht, wenn nur wegführende Abhängigkeiten vorhanden sind, also die Klassen innerhalb der Kategorie von Klassen außerhalb abhängig sind. Im Falle einer Änderung im restlichen System ist diese Kategorie sehr wahrscheinlich ebenfalls betroffen. Eine Instabilität von 0.0 bedeutet maximale Stabilität, da keine wegführenden Abhängigkeiten vorhanden sind und Abhängigkeiten nur von Klassen außerhalb der Kategorie zu Klassen in der Kategorie bestehen. Eine Änderung des restlichen Systems hätte also keinen Einfluss auf die betrachtete Kategorie. Instabilität kann nur bestimmt werden, wenn mindestens ein Abhängigkeit (wegführend oder hinführend) vorhanden ist.
\paragraph{}
Robert C. Martin erläutert in seinem Artikel zudem den Zusammenhang von Instabilität und Abstraktheit. Dafür schreibt er, dass Abhängigkeiten von instabilen Kategorien zu vermeiden sind. Da Kategorien mit abstrakten Klassen und Schnittstellen hinführende Abhängigkeit einer externen Klasse motivieren, empfiehlt er keine abstrakten Typen innerhalb einer instabilen Kategorie zu positionieren. Um den Grad der Abstraktheit $A(k)$ einer Kategorie $k$ zu bestimmen, hat Martin die Metrik \emph{Abstractness} als Verhältnis zwischen abstrakten Klassen und Schnittstellen zu konkreten Klassen beschrieben. Dieses Verhältnis kann mit Formel \ref{eq:abstractness} berechnet werden.
\begin{equation}
	A(k) = \frac{|aCs(k)|}{|Cs(kp)|}
\label{eq:abstractness}
\end{equation}
\begin{eqnarray*}
aCs(k)&=&\text{Menge der abstrakten Klassen und Schnittstellen in der Kategorie }k\\
\label{eq:abstractnessagenda}
\end{eqnarray*}
Genau wie bei der Instabilität liegt auch die Ausprägung der Abstraktheit zwischen 0.0 und 1.0. Eine Abstraktheit von 0.0 entspricht einer konkreten Kategorie ohne abstrakte Typen, während eine Abstraktheit von 1.0 für eine Kategorie mit ausschließlich abstrakten Typen steht.
\paragraph{}
Die Abstraktheit und die Instabilität können kombiniert werden. NDepend greift die Idee von Martin auf und trägt jede Assembly der betrachteten Projektumgebung in einem Diagramm ähnlich Abbildung \ref{fig:abstractnessinstability} entsprechend ein.
\begin{figure}[h]
	\centering
		\includegraphics[width=7cm]{images/abstractnessinstability.jpg}
	\caption{Schematische Darstellung des "`Abstraktheit und Instabilität"'-Diagramm in NDepend}
	\label{fig:abstractnessinstability}
\end{figure}
Robert C. Martin beschreibt eine Kategorie, die in der Haupt-Sequenz liegt, als ausgeglichen, da sie zum Teil erweiterbar und zum Teil stabil ist. Laut Martin sind die beiden Endpunkte der Haupt-Sequenz die optimalen Punkte. Nach seiner Erfahrung können nur ungefähr die Hälfte der Kategorien in einem System diese optimalen Positionen einnehmen. Die andere Hälfte sollte möglichst nah an der Haupt-Sequenz liegen, was durch eine weitere Metrik in Form einer Abstandsberechnung festgehalten werden könnte.


\section{CCD-Addin}
In Kapitel \ref{chap:requirements} wurde im Rahmen der Anforderungsanalyse der Anwendungsfall "`Clean Code Hilfe bekommen"' identifiziert. Das Visual Studio Addin \emph{CcdAddIn}\footnote[1]{"`CcdAddIn is a visual Studio Add-In that displays the CCD values according to your current CCD Grade"' \url{https://github.com/AlexZeitler/CcdAddIn}} von Alexander Zeitler versucht eine solche Hilfestellung in passiver Form zu geben. In Unterabschnitt \ref{subsec:cleancode} wurde die Idee von Clean Code bereits erläutert und auf das sieben-Grade-System von Ralf Westphal und Stefan Lieser \cite{CleanCodeDeveloper} eingegangen. Das Programm integriert sich in die IDE und zeigt zu jedem Grad die entsprechenden Prinzipien und Praktiken an, sodass der Entwickler immer an seinen aktuellen Grad und an die damit verbundenen "`Regeln"' erinnert wird. Jede Praktik und jedes Prinzip ist anklickbar, sodass das Addin weitere Informationen anzeigen kann. Leider zeigt das Addin die Informationen nur an und bietet sonst kein weitere Hilfestellung.

\subsection{Prinzipien}
In diesem Unterabschnitt werden die einzelnen Grade vorgestellt. Da der \emph{schwarze} Grad lediglich einer Interessenbekundung entspricht und der \emph{weiße} Grad das komplette Spektrum abdeckt, werden im Folgenden nur die verbleibenden fünf Grade erwähnt. Die folgenden Prinzipien wurden direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen.
\begin{description}
	\item[Rot] \emph{Don´t Repeat Yourself} (DRY), \emph{Keep it simple, stupid} (KISS), Vorsicht vor Optimierungen!, \emph{Favour Composition over Inheritance} (FCoI)
	\item[Orange] \emph{Single Level of Abstraction} (SLA), \emph{Single Responsibility Principle} (SRP), \emph{Separation of Concerns} (SoC), Source Code Konventionen
	\item[Gelb] \emph{Interface Segregation Principle} (ISP), \emph{Dependency Inversion Principle} (DIP), \emph{Liskov Substitution Principle} (LSP), \emph{Principle of Least Astonishment} (PLA), \emph{Information Hiding Principle} (IHP)
	\item[Grün] \emph{Open Closed Principle} (OCP), \emph{Tell, don´t ask} (TDA), \emph{Law of Demeter} (LD)
	\item[Blau] Entwurf und Implementation überlappen nicht, Implementation spiegelt Entwurf, \emph{You Ain´t Gonna Need It} (YAGNI)
\end{description}

\subsection{Praktiken}
Neben den Prinzipien existieren zu jedem Grad auf Praktiken, die ebenfalls direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen wurden.
\begin{description}
	\item[Rot] die Pfadfinderregel beachten, \emph{Root Cause Analysis}, ein Versionskontrollsystem einsetzen, einfache Refaktorisierungsmuster anwenden, Täglich reflektieren
	\item[Orange] Issue Tracking, Automatisierte Integrationstests, Reviews, Lesen, Lesen, Lesen
	\item[Gelb] Automatisierte Unit Tests, Mockups (Testattrappen), Code Coverage Analyse, Teilnahme an Fachveranstaltungen, Komplexe Refaktorisierungen
	\item[Grün] Continuous Integration, Statische Codeanalyse (Metriken), \emph{Inversion of Control} (IOC) Container, Erfahrung weitergeben, Messen von Fehlern
	\item[Blau] Continuous Delivery, Iterative Entwicklung, Komponentenorientierung, Test first
\end{description}




\chapter{Technologie Evaluierung}
\label{chap:techeval}
Nachdem in Kapitel \ref{chap:requirements} die Anforderungen an die zu entwickelnde Visual Studio Erweiterung beschrieben wurden, werden in diesem Kapitel verschiedene Technologien in Betracht gezogen um ein Werkzeug zu entwickeln, das einen ähnlichen Funktionsumfang wie das in Kapitel \ref{chap:usus} beschrieben Usus-Plugin besitzt. Der Schwerpunkt in diesem Kapitel liegt auf der statischen Code-Analyse, die durchgeführt werden muss um Metriken und alles weitere Feedback zu berechnen. Zu diesem Zweck werden Möglichkeiten untersucht um Quellcode zu analysieren und um die Rohdaten zu ermitteln, die für die Berechnung der vorgestellten Metriken benötigt werden. Dieser Analyse-Schritt wird auch von Artur Wagner in seiner Ausarbeitung \cite{IntroStaticCodeAnalysis} auch mit den Analyse-Schritten eines Compilers verglichen. Allerdings ist es möglich eine statische Code-Analyse auch nach dem Kompilieren durchzuführen, indem das Kompilat betrachtet wird. Dies ist im Fall von Java und .NET möglich, da es sich bei dem erzeugten Format um eine Zwischensprache handelt, die erst unmittelbar vor dem Ausführen in Maschinensprache übersetzt wird. Die Technologien, die in diesem Kapitel behandelt werden, nutzen entweder den Quellcode oder das Compiler-Ergebnis um eine statische Code-Analyse durchzuführen.
\paragraph{}
Um die Technologien anhand ihrer Eignung zu evaluieren, wird die Bewertung nach verschiedenen Kriterien vorgenommen. Die Kriterien sind in Form von Fragen so formuliert, dass eine bejahende Antwort als positiv gilt. Die Kriterien sind nach Wichtigkeit absteigend sortiert.
\begin{enumerate} 
\item Können alle Informationen gesammelt werden, die benötigt werden um die von Usus berechneten Metriken zu berechnen?
\item Ist die Technologie allgemein verfügbar und kann als Bestandteil einer Anwendung veröffentlicht werden?
\item Ist die Technologie kostenfrei verwendbar?
\item Ist die Technologie einfach zu verwenden und kann leicht eingesetzt werden?
\item Unterstützt die Technologie alle Versionen der .NET Laufzeitumgebungen unter Windows?
\item Ist die Technologie unabhängig von anderen Laufzeitumgebungen und anderen externen Komponenten?
\item Kann die Technologie ein unvollständiges System verarbeiten, das Klassen und Pakete verwendet, die nicht im betrachteten System definiert sind?
\item Ist die Technologie in der Lage ein System zu analysieren, dass nicht nur mit C$\#$ entwickelt wurde sondern auch in VB.net?
\item Kann die Technologie mit dem kompilierten Quellcode, also der Assembly, arbeiten?
\item Kann die Technologie mit dem unkompilierten Quellcode arbeiten?
\end{enumerate}
Anhand dieser Kriterien können verschiedene Technologien, die in den folgenden Abschnitten beschrieben werden, evaluiert werden. Das Ergebnis wird abschließend im letzten Abschnitt dieses Kapitels in Form einer Zusammenfassung vorgestellt. Die Auswahl der betrachteten Technologien wurde abhängig vom subjektiven Bekanntheitsgrad eingeschränkt und ist nicht vollständig.


\section{FxCop}
\label{sec:fxcop}
Jason Kresowaty beschreibt \emph{FxCop} in seiner Ausarbeitung \cite{FxCopCustomRules} als Werkzeug zur statischen Code-Analyse für Assemblies, die mit C\#, VB.NET und allen anderen .NET-Sprachen entwickelt wurden. \emph{FxCop} analysiert die vom Compiler erzeugten Binärdateien in \emph{Common Intermediate Language} (CIL) und führt Regeln aus, die nach Problemen im Sinne von Verletzungen von Konventionen und Richtlinien suchen.

\subsection{Umgebung}
Die \emph{FxCop}-Technologie besteht aus zwei Teilen. Der erste Teil ist die \emph{Microsoft FxCop} Anwendung und der zweite Teil sind die Regeln, die genutzt werden um die statische Analyse zu nutzen. Microsoft veröffentlicht mit dem Programm eine Menge von Regeln, um Assemblies anhand den von Krzysztof Cwalina und Brad Abrams veröffentlichten Konventionen und Richtlinien \cite{FrameworkDesignGuidelines} zu untersuchen. Eine Regel, die eine Berechnung von Metriken zur späteren Verwendung durchführt ist nicht vorhanden. Es lassen sich allerdings eigene Regeln definieren, die \emph{FxCop} genauso ausführen kann, und mit der das Programm beliebig erweitert werden kann. Eine solche eigene Regel könnte alle notwendigen Informationen sammeln um ein Programm mit einem Usus-ähnlichen Funktionsumfang zu entwickeln. Kresowaty beschreibt in seiner Ausarbeitung \cite{FxCopCustomRules} wie so eine Regel erstellt werden kann. Regeln lassen sich auch automatisiert ausführen, wenn eine Analyse mit der grafischen Oberfläche, die in Abbildung \ref{fig:fxcoprunner} dargestellt ist, nicht sinnvoll ist. Abbildung \ref{fig:fxcopcmdrunner} zeigt die Kommandozeilenversion des \emph{FxCop} Runners.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/fxcoprunner.png}
	\caption{FxCop Runner}
	\label{fig:fxcoprunner}
\end{figure}
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/fxcopcmdrunner.png}
	\caption{FxCop Kommandozeilen Runner}
	\label{fig:fxcopcmdrunner}
\end{figure}
\paragraph{}
Eine \emph{FxCop} Regel entspricht einer Klassenbibliothek, die eine Regel-Klasse und eine Regel-Konfigurationsdatei enthält. Während \emph{FxCop} den Code analysiert, erzeugt es Instanzen der Regel-Klasse und nutzt diese um in der Codebasis Problemfälle zu finden. Problemfälle können dann von der Regel-Klasse in Problem-Listen eingetragen werden, die \emph{FxCop} entweder grafisch anzeigt oder in Form einer Report-Datei erzeugt. Zusätzlich können Problemfälle als kritisch gekennzeichnet und mit verschiedenen Texten und Beschreibungen versehen werden um eine möglichst detaillierte Beschreibung der Schwierigkeit zu ermöglichen. \emph{FxCop} ist also auf das Finden von Problemen und nicht auf objektive Datensammlung spezialisiert. Um eine Assembly möglichst schnell analysieren zu können, erzeugt \emph{FxCop} mehrere Instanzen einer Regel und führt diese in mehreren Threads parallel aus. Jason Kresowaty betont in seiner Ausarbeitung \cite{FxCopCustomRules}, dass sich die Regeln nicht Thread-sicher verhalten. Damit mit \emph{FxCop} weiterverwendbare Daten gesammelt werden können, müssen diese auf eine geeignete Weise exportiert werden. Entweder können diese Daten in Form von Zeichenketten als Probleme verpackt oder direkt an ein Ziel gespeichert werden. Diese beiden Lösungen sind umständlich und nicht intuitiv und werden von der Nebenläufigkeit von \emph{FxCop} noch erschwert.

\subsection{API}
Regeln für \emph{FxCop} können mit C$\#$ in Form einer Klassenbibliothek entwickelt, wie es Jason Kresowaty in seiner Ausarbeitung \cite{FxCopCustomRules} vorstellt, und als \emph{Dynamic Link Library} (DLL) von \emph{FxCop} verwendet werden. Dazu muss die DLL über eine spezielle Metadaten-Datei als eingebettete Ressource verfügen, die die Regel dem Runner bekanntmacht. Die Regel selbst wird in einer Klasse implementiert, die von einer abstrakten Regel-Oberklasse abgeleitet ist und somit Analyse-Methoden überladen kann. Mit diesen Methoden kann das Objektmodell der zu analysierenden Assembly untersucht werden. Alle Basisklassen und Klassen, die das Objektmodell repräsentieren befinden sich im Namensraum \texttt{Microsoft.FxCop.Sdk}. Das \emph{Application Programming Interface} (API) um \emph{FxCop}-Regeln zu programmieren enthält Teile die dem in das .NET-Framework integrierten \texttt{System.Reflection} API ähnlich sind. Beide enthalten Klassen um das Objektmodell zu repräsentieren.
\paragraph{}
Um Operationen von einer Datenstruktur zu trennen, beschreiben Erich Gamma, Richard Helm, Ralph E. Johnson und John Vlissidest das Besuchermuster (Visitor Pattern) in \cite{DesignPatterns}. Mit dem Besuchermuster ermöglicht die \emph{FxCop} API die gleiche Datenstruktur (Objektmodell) mit vielen Regeln (Besuchern) zu analysieren. In der Regel-Klasse, die von \texttt{BaseIntrospectionRule} abgeleitet ist können oberflächliche Besuchermethoden überladen werden. Diese oberflächlichen Methoden bestimmen, an welcher Stelle im Objektmodell eine weitere Überprüfung vorgenommen werden soll. Zum Beispiel wird die \texttt{Check(Member)}-Methode in Listing \ref{listing:fxcopapisample} für jedes Property oder Methode in jeder Klasse aufgerufen. Die \texttt{Check(TypeNode)}-Methode wird zusätzlich für jede Klasse oder Interface ausgeführt.
\begin{lstlisting}[caption={FxCop API Beipiele},label={listing:fxcopapisample}]
ProblemCollection Check(Member member) {...}
ProblemCollection Check(TypeNode type) {...}
void VisitMemberBinding(MemberBinding memberBinding) {...}
void VisitBranch(Branch branch) {...}
void VisitAssignmentStatement(AssignmentStatement assignment) {...}
\end{lstlisting}
Nachdem sich die Regel mit einer dieser oberflächlichen \texttt{Check}-Methoden an dem Kontrollfluss der Analyse beteiligt, kann eine tiefgehende Analyse von der oberflächlichen Stelle ausgehend erfolgen. Dazu wird ein weiterer Besucher beispielsweise vom Typ \texttt{BinaryReadOnlyVisitor} erstellt, der die aktuelle Stelle im Objektmodell detaillierter besuchen kann. In einer von \texttt{BinaryReadOnlyVisitor} abgeleiteten Unterklasse können jetzt \texttt{Visit}-Methoden überladen werden, die ebenfalls in Listing \ref{listing:fxcopapisample} dargestellt sind. Beispielsweise kann in der Methode \texttt{VisitMemberBinding} jeder Methodenaufruf und mit \texttt{VisitAssignmentStatement} jede Zuweisung analysiert werden. Auf diese Weise und mit sämtlichen Parameter- und Rückgabetypen kann aus dem Objektmodell der für die zu berechnenden Metriken erforderliche Abhängigkeitsgraph erstellt werden. Die Anzahl der Anweisungen pro Methode kann entweder im Sinne der \emph{Common Intermediate Language} (CIL, die vom Compiler erzeugte Zwischensprache) oder im Sinne von einem \textit{FxCop} \texttt{Statement} erfolgen. Während die CIL-Anweisungen die C$\#$-Anweisungen sehr viel granulärer abbilden, entsprechen die FxCop-Anweisungen zusammengefassten CIL-Anweisungen. Eine Entsprechung der C$\#$-Anweisungen konnte ohne detaillierte Betrachtung der konkreten \texttt{Statement}-Typen nicht ermittelt werden. Die Anzahl der Zeilen kann dafür auf eine sehr einfach Weise bestimmt werden, da jedes \texttt{Statement} über einen \texttt{SourceContext} und dort über Start- und Endzeilennummern verfügt. Anhand der Liste aller Anweisungen kann die erste Zeile als kleinste Startzeile und die letzte als größte Endzeile gesucht und mittels der Differenz die Methodenlänge berechnet werden. Die zyklomatische Komplexität kann bestimmt werden, da jede Verzweigung im Code von der \texttt{VisitBranch}-Methode besucht wird.


\section{Common Compiler Infrastracture}
\label{sec:cci}
Die \emph{Common Compiler Infrastructure} (CCI) ist eine Sammlung von Bibliotheken, die Compiler-ähnliche Funktionen bereitstellen und von Microsoft Research entwickelt wurde \cite{CCI}. Auf Codeplex lässt sich die Komponente \textit{CCI Metadata} finden. Guy Smith beschreibt sie als Obermenge von \texttt{System.Reflection}, \texttt{System.Reflection.Emit} und \texttt{System.CodeDom}, also den Reflektions- und Code-Erzeugungs-Mechanismen des .NET-Framework zur Laufzeit \cite{CCIMetadata}. Smith beschreibt \textit{CCI Metadata} als Werkzeug, das mir den vom Compiler erzeugten CIL-Anweisungen arbeitet. Um einfacher mit Methoden zu arbeiten, stellt Smith mit \emph{CCI Code and AST Components} eine weitere Komponente vor \cite{CCICode}. \emph{CCI Code} erleichtert das Arbeiten mit Methoden, da es von den CIL-Anweisungen abstrahiert und Quellcode-ähnliche Bäume nutzt. Beide Komponenten sind unter der Microsoft Public License veröffentlicht. Die CCI wird in einer ähnlichen Variante unter anderem von dem Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} und FxCop aus Abschnitt \ref{sec:fxcop} genutzt. Die Assembly Microsoft.Cci.dll, die mit diesen Tools ausgeliefert wird, besitzt viele Funktionen nur intern oder von erlaubten Assemblies aufrufbar sind. Funktionen, die beispielsweise konkrete Methoden-Metriken berechnen, sind nur von Programmen aufrufbar, die in der CCI-Assembly aufgelistet sind, wie in Abbildung \ref{fig:cciinternalsvisible} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=14cm]{images/cciinternalsvisible.png}
	\caption{Micorsoft.Cci.dll \texttt{InternalsVisibleTo}-Attribute}
	\label{fig:cciinternalsvisible}
\end{figure}

\subsection{CCI Metadata}
\label{subsec:ccimetadata}
Im Gegensatz zu der \emph{FxCop} API kann eine .NET-Assembly mit CCI direkt untersucht werden, ohne das die Analyse in Form einer einschränkenden Regel parallelisiert erfolgt. CCI überlässt dem Verwender der Bibliothek ob und wie die Untersuchung stattfinden soll. Mit einem \texttt{PeReader.DefaultHost} können Assemblies eingelesen werden, die von CCI als PE-Dateien bezeichnet werden. PE-Dateien werden hier wie folgt definiert.
\begin{definition}[Portable Executable]
Eine \emph{Portable Executable}-Datei (PE-Datei), also eine transportierbare und ausführbare Datei, ist das Ergebnis einer Kompilierung eines Visual Studio .NET-Projekts. Die Datei ist entweder eine Bibliothek (dll-Datei) oder eine direkt ausführbare Datei (exe-Datei).
\end{definition}
Zusätzlich kann die vom Compiler erzeugte pdb-Datei mit einem \texttt{PdbReader} importiert werden. Eine pdb-Datei wird hier wie folgt definiert.
\begin{definition}[Program Database]
Die \emph{Program Database}-Datei (pdb-Datei) enthält die Datei- und Zeilenzuordnung der kompilierten Typen und Funktionen in einer PE-Datei. Laut Microsoft \cite{PDBFile} enthält sie generell Debug- und Projekt-Information.
\end{definition}
Mit der \texttt{IAssembly.GetAllTypes()}-Methode können alle Typen ermittelt werden. Alle Methoden und Properties eines Typs, können mit \texttt{INamedTypeDefinition.Methods} bestimmt werden. Der Inhalt von Methoden und Properties kann in Form von CIL-Anweisungen mit \texttt{IMethodBody.Operations} genauer betrachtet werden. So lassen sich beispielsweise alle lokalen Variablen und Methodenaufrufe lokalisieren, um Abhängigkeiten der Methode zu anderen Typen zu finden. Die CIL-Anweisung eines Methodenaufrufs enthält immer auch den Typ, der das Aufrufziel darstellt. Zusammen mit Attributen, Parametern und Rückgabewerten kann der Abhängigkeitsgraph eines Typs ermittelt werden. Die zyklomatische Komplexität einer Methode kann ebenfalls über die CIL-Anweisungen bestimmt werden, was durch das Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} sowie Steve Gilham \cite{CCperCIL} demonstriert wird. Um die Methodenlänge einer Funktion aus den CIL-Anweisungen zu ermitteln, kann auch hier die Funktionalität durch das Code Metrics Power Tool inspiriert werden. Wenn zu der .NET-Assembly zusätzlich eine pdb-Datei existiert, kann außerdem die Start- und Endzeile jeder Anweisung auf die Methode bezogen werden, ähnlich der Lösung für die \emph{FxCop} Regel.

\subsection{CCI Code and AST Components}
Soweit wurden nur Funktionen von \emph{CCI Metadata} betrachtet. \emph{CCI Code and AST Components} erlaubt es das Quellcode-Modell einer Methode in Form eines abstrakten Syntax-Baums (AST) zu analysieren. Philip Newcomb beschreibt einen AST in seinem Tutorial über den AST Metamodel Standard \cite{ASTMetamodel}. In der vorliegenden Master-Thesis wird ein AST wie folgt definiert.
\begin{definition}[Abstrakter Syntax-Baum]
Ein abstrakter Syntax-Baum (engl. Abstract Syntax Tree) ist einer formale Repräsentation der syntaktischen Struktur einer Software auch innerhalb Methoden. Besonders in Methoden enthält der AST einen Knoten für jede Anweisung. Wenn diese Anweisung aus mehreren anderen Anweisungen besteht, besitzt der Knoten für diese Anweisungen entsprechende Unter-Knoten.
\end{definition} 
Um einen solchen Baum zu betrachten, können Besucher verwendet werden. Beispielsweise erlaubt eine Objekt vom Typ \texttt{CodeTraverser} jede strukturelle Stelle der Assembly mit überladbaren Methoden, von denen einige in Listing \ref{listing:ccicodeastsample} aufgeführt sind, zu besuchen.
\begin{lstlisting}[caption={\emph{CCI Code and AST Components} \texttt{CodeTraverser}-Methoden},label={listing:ccicodeastsample}]
TraverseChildren(IConditionalStatement conditionalStatement) {...}//if
TraverseChildren(IConditional conditional) {...}//bool expression
TraverseChildren(IForStatement forStatement) {...}
TraverseChildren(ISwitchStatement switchStatement) {...}
\end{lstlisting}
Für jede Stelle im Code leitet \texttt{CodeTraverser} den Aufruf an Objekte vom Typ \texttt{ICodeVisitor} weiter, und ermöglicht so einfache Erweiterungen auf mehrere Weisen vorzunehmen. \texttt{ICodeVisitor} besitzt für jede \texttt{Traverse}-Methode eine entsprechende \texttt{Visit}-Methode. Da \texttt{CodeTraverser} das Code-Modell von links nach rechts und "`Depth First"' besucht, können zwei Besucher registriert werden. Einer wird aufgerufen bevor ein Syntax-Element im Baum besucht wird und der andere wird aufgerufen nachdem der Besuch beendet ist. 
\paragraph{}
\emph{CCI Code and AST Components} ermöglicht das syntaktische besuchen von Sprachelementen, indem von CIL abstrahiert wird. Es existieren Besucher-Methoden für alle Sprachelemente, die aus C$\#$ 4.0 bekannt sind, wie beispielsweise Lambda-Ausdrücke, Generics, Attribute und vielen mehr. Die herunterladbare \textit{CCI Code and AST Components} Visual Studio Solution enthält ein Beispiel (PeToTextViaCodeModel), das sämtliche Strukturelemente einer dll- oder exe-Datei besucht und wieder C$\#$-Quelltext erzeugt. Das Ergebnis entspricht Code, der dem Original sehr ähnlich ist und an professionelle Decompiler erinnert. Die CCI erlaubt es außerdem eine geladene Assembly zu verändern und anschließend wieder zu exportieren.


\section{NRefactory}
\label{sec:nrefactory}
Auch in der Mono-Welt existieren Werkzeuge für Compiler-ähnliche Funktionen. Das Team hinter Mono beschreibt Mono als Implementierung des .NET-Frameworks für Windows, Linux, Mac OS und verschiedene mobile Plattformen \cite{Mono}. In diesem Umfeld ist \textit{NRefactory} Teil der freien .NET-Entwicklungsumgebung SharpDevelop\footnote[1]{"`The Open Source Development Environment for .NET"' \url{http://www.icsharpcode.net/OpenSource/SD/}} und arbeitet im Gegensatz zur CCI und FxCop nicht nur auf Assembly-Ebene, sondern hauptsächlich mit Quellcode.

\subsection{AST aus Quellcode}
Mit \emph{NRefactory} ist es möglich einen AST aus C$\#$-Quelltext zu erzeugen. Unterstützung für VB.net ist nach Angaben in der Funktionsbeschreibung der Bibliothek \cite{NRefacRepo} noch nicht implementiert. Anschließend können AST-Besucher als direkte Implementierung der \texttt{IAstVisitor}-Schnittstelle oder als Ableitung von \texttt{DepthFirstAstVisitor} erstellt werden und mit dem abstrakten Syntax-Baum arbeiten. Listing \ref{listing:nrefacastsample} zeigt einige wenige Methoden, die in \texttt{IAstVisitor} definiert sind.
\begin{lstlisting}[caption={\emph{NRefactory} \texttt{IAstVisitor}-Methoden},label={listing:nrefacastsample}]
VisitIfElseStatement(IfElseStatement ifElseStatement) {...}
VisitBinaryOperatorExpression(BinaryOperatorExpression binaryOperatorExpression) {...}
VisitPrimitiveExpression(PrimitiveExpression primitiveExpression) {...}
VisitNewLine(NewLineNode newLineNode) {...}
VisitInvocationExpression(InvocationExpression invocationExpression) {...}
\end{lstlisting}
Mit einem solchen Besucher können strukturelle Code-Elemente wie if-Anweisungen sehr gut besucht werden, was die Berechnung der zyklomatischen Komplexität ermöglicht, ohne kompiliern zu müssen. Wie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben, brauchen dafür nur alle Entscheidungsstellen besucht und aufsummiert werden. Die Methodenlänge kann ebenfalls einfach bestimmt werden. Es ist möglich entweder alle Statements oder alle Zeilenumbrüche zu besuchen und aufzusummieren. Der AST kann auch verändert und anschließend neuer Code erzeugt werden. Allerdings kann der Abhängigkeitsgraph nicht durch die alleinige Erzeugung des AST erstellt werden.

\subsection{Mono.Cecil}
\emph{NRefactory} ordnet Methodenaufrufe in Form von \texttt{InvocationExpression}-Objekten erst dann der definierenden Stelle zu, wenn alle Typen und Methoden im AST mit einem \texttt{CSharpAstResolver} komplett aufgelöst werden. Dazu verwendet \emph{NRefactory} die \emph{Mono.Cecil}-Bibliothek, die Jean-Baptiste Evain als API zum Erzeugen, Analysieren und Verändern von .NET-Assemblies beschreibt \cite{MonoCecil}. Die Assemblies, in denen sich die Typen befinden auf die der Code zugreift, werden von \emph{Mono.Cecil} geladen. Listing \ref{listing:nrefacastresolvercreation} zeigt wie ein \texttt{CSharpAstResolver}-Objekt zur Auflösung des abstrakten Syntaxbaums erzeugt werden kann.
\begin{lstlisting}[caption={\emph{NRefactory} Erzeugung von \texttt{CSharpAstResolver}},label={listing:nrefacastresolvercreation}]
CSharpAstResolver CreateResolver(CompilationUnit parsed, params Type[] types)
{
    IProjectContent project = new CSharpProjectContent();
    CSharpParsedFile parsedFile = parsed.ToTypeSystem();
    project = project.UpdateProjectContent(null, parsedFile);
    project = project.AddAssemblyReferences(LoadAssemblies(types));
    return new CSharpAstResolver(project.CreateCompilation(), parsed, parsedFile);
}
\end{lstlisting}
Der Code orientiert sich an dem Demo Beispiel von Daniel Grunwald in dem \emph{NRefactory}-Repository \cite{NRefacRepo}. Das übergebene \texttt{CompilationUnit}-Objekt ist der Wurzelknoten eines \textit{NRefactory}-AST, der aus Quellcode-Fragment erstellt wurde. Dieser AST wird für die Typ-Zuordnung vorbereitet und gemeinsam mit allen anderen Assemblies, die für die Auflösung von externen Typen verwendet werden sollen, in Form eines \texttt{CSharpProjectContent}-Objekts zusammengefasst. Um diese Assemblies zu finden, wird jede durch einen in ihr enthaltenen, nicht weiter relevanten Typ identifiziert. Für die Erzeugung des \texttt{CSharpAstResolver}-Objekts, wird der unvorbereitete AST, der vorbereitete AST und das Kompilat des \texttt{CSharpProjectContent}-Objekts übergeben. Die eigentliche Auflösung wird dann über einen Aufruf der Methode \texttt{CSharpAstResolver.ApplyNavigator} synchron durchgeführt. Diese Funktion erwartet ein Objekt vom Typ \texttt{IResolveVisitorNavigator} und teilt diesem alle aufgelösten Details zu allen Knoten im AST mit. Ähnlich wie die CCI erlaubt auch \emph{Mono.Cecil} das manuelle Einlesen von Assemblies und \emph{Program Database}-Dateien um diese anhand der CIL-Anweisungen zu analysieren. Assemblies und pdb-Dateien können verändert und gespeichert werden.


\section{Codename "`Roslyn"'}
\label{sec:roslyn}
Karen Ng, Matt Warren, Peter Golde und Anders Hejlsberg beschreiben in ihrem Dokument \cite{RoslynOverview} ein Projekt um den C$\#$- und den VB.net-Compiler als Dienst zur Verfügung zu stellen. Sie beschreiben das Problem, dass Compiler viel isoliertes und ungeteiltes Wissen über die zu kompilierende Sprache besitzten. Dieses Wissen ist auch für andere Anwendungen, wie beispielsweise Entwicklungsumgebungen, Refactoring-Werkzeuge und Code-Analyse-Tools von bedeutung. Momentan müssen diese Programme das Wissen der Compiler neu erfinden und Teile des Compilers neu implementieren. Im Rahmen des Projekt \emph{Roslyn} sollen die Compiler ihr Wissen teilen können. Dazu werden sie als Dienste zur Verfügung gestellt und bieten APIs an. Diese APIs können dann von sämtlichen Code-orientierten Werkzeugen genutzt werden. Kirill Osenkov stellt in seinem Blog-Post \cite{RoslynCTPIntro} die CTP\footnote[1]{"`Microsoft Roslyn October 2011 CTP"' \url{http://msdn.com/roslyn}} (Community Technology Preview) von \emph{Roslyn} vor und erwähnt ein weiteres Ziel. Die bisherigen Compiler sollen in einer Sprache, die auf der CLR (Common Language Runtime) ausgeführt wird, neu geschrieben werden. Auf diese Weise soll das Team hinter Visual Studio schneller und bessere Features entwickeln können.

\subsection{Schichten}
In dem Dokument \cite{RoslynOverview} beschreiben Hejlsberg und co die traditionelle Compiler Pipeline der .net-Umgebung. Die \emph{Roslyn}-Compiler werden diese Pipeline ebenfalls haben. Ein Parser erzeugt einen Syntax-Baum anhand der Grammatik der Sprache. Darauf folgt die Deklarierungsphase. In dieser Phase werden die Deklarierungen im Code zusammen mit importierten Metadaten in Form von benannten Einheiten, sogenannten Symbols, erstellt. Danach folgt die Binder-Phase, in der Typen im Syntax Baum den Symbols zugeordnet werden. In der letzten Phase wird alle vom Compiler angesammelte Information in Form von CIL-Anweisungen in eine Assembly-Datei exportiert. Project \emph{Roslyn} bietet für jede dieser Phasen eine entsprechende API im Rahmen einer Compiler API Schicht, die auf der Compiler Pipeline aufbaut. Auf diese Compiler API Schicht setzt \emph{Roslyn} noch eine Language Service Schicht, die mit dem Objektmodell der Compiler Phasen arbeitet und beispielsweise Refactorings unterstützt.
\paragraph{}
Hejlsberg und co unterscheiden noch zwischen verschiedenen Architekturschichten, die getrennt von den oben beschrieben Schichten über der Compiler Pipeline beschrieben werden. Die Compiler APIs erlauben den Zugriff auf das syntaktische und semantische Objektmodell, das durch die Compiler Pipeline zur Verfügung gestellt wird. Die nächste Schicht ist die Scripting API. Sie bietet eine Umgebung für das Ausführen von Code-Schnippseln in Form von Ausdrücken und Anweisungen. Mit dieser Umgebung kann ein REPL (Read Eval Print Loop) realisiert werden. Die Workspace API stellt die nächste Schicht dar und ermöglicht eine Analyse auf der Basis von kompletten Visual Studio Solutions. Die letzte Schicht ist die Services API. Sie ist die einzige, die eine Abhängigkeit von Visual Studio hat. Sämtliche Funktionen wie Visual Studio \emph{IntelliSense}, Refactorings und Fomratierungsfunktionen befinden sich in dieser Schicht.

\subsection{Syntax Tree}
\label{subsec:roslynsyntaxtree}
In diesem Unterabschnitt werden die Möglichkeiten beschrieben, wie der Syntax-Baum der Compiler API verwendet werden kann. Interessant ist zu sehen, dass \emph{Roslyn} im Gegensatz zu \emph{NRefactory} die Datenstruktur nicht als abstrakten Syntax-Baum bezeichnet, sondern lediglich als Syntax-Baum. Philip Newcomb beschreibt in seiner Präsentation über den "`AST Metamodel Standard"' \cite{ASTMetamodel} den Unterschied als Nähe zum tatsächlichen Quellcode. Der Syntax Tree von \emph{Roslyn} orientiert sich sehr am Quellcode. Hejlsberg und co legen in ihrem Dokument \cite{RoslynOverview} besonderen Wert auf die Vollständigkeit des Baums, in dem jedes Leerzeichen und sogar synatktische Fehler Bestandteil des Syntax-Baum sind.
\paragraph{}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt die Erzeugung eines Syntax-Baum aus einem Quellcode-Ausschnitt, der in der Variable \texttt{sourceText} enthalten ist. Ähnlich wie \emph{NRefactory} bietet auch \emph{Roslyn} die Möglichkeit den Baum mit LINQ-Abfragen zu analysieren, da \texttt{DescendentNodes} ein \texttt{IEnumerable} zurückliefert. LINQ\footnote[1]{Mehr über "`LINQ (Language-Integrated Query, sprachintegrierte Abfrage)"' \url{http://msdn.microsoft.com/de-de/library/bb397926.aspx}} ist ein Sprachkonstrukt, das es erlaubt mit Keywords wie beispielsweise \texttt{from}, \texttt{where} und \texttt{select} SQL-ähnliche Abfragen direkt in C$\#$ oder VB.net zu schreiben.
\begin{lstlisting}[caption={Erzeugung eines Syntax Tree mit der \emph{Rosyln} Compiler API},label={listing:roslynsyntaxtreecreation}]
SyntaxTree tree = SyntaxTree.ParseCompilationUnit(sourceText);
var methods = tree.Root.DescendentNodes().OfType<MethodDeclarationSyntax>();
...
var ifs = method.DescendentNodes().OfType<IfStatementSyntax>();
var invocations = method.DescendentNodes().OfType<InvocationExpressionSyntax>();
\end{lstlisting}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt ebenfalls wie alle Methoden, die in \texttt{sourceText} deklariert werden gefunden werden. In jeder dieser Methoden kann anschließend nach \texttt{if}-Anweisungen und ähnlichen Entscheidungsträgern gesucht werden, um die zyklomatische Komplexität, wie sie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben wurde, auszurechnen. Um die Typen zu finden, von denen eine Methode abhängig ist, können neben sämtlichen Variablen alle Methodenaufrufe gefunden werden. Daraus kann anschließend der Abhängigkeitsgraph bestimmt werden. Ähnlich zu \emph{NRefactory} kann auch für den \emph{Roslyn}-Baum ein Besucher als Ableitung von \texttt{SyntaxWalker} erstellt werden. Über entsprechende Überladungen kann dann auf alle Knoten im Syntax-Baum reagiert werden. Leerzeichen, Zeilenumbrüche und andere Elemente, die keine nicht syntaktische Relevanz haben, sind im Baum in Form von \texttt{Trivia}-Objekten vorhanden und lassen sich ebenfalls finden. Eine Manipulation des Code-Baums ist auch möglich indem ein neuer Baum erzeugt wird. Bestehende Bäume sind laut Hejlsberg und co unveränderlich.

\subsection{Semantik}
\label{subsec:roslynsemanticmodel}
In diesem Unterabschnitt wird beschrieben, wie die Compiler API die Semantik von Code verwaltet. Nach der Erzeugung der syntaktischen Repräsentation von Code, dem Syntax Tree, werden beispielsweise die Methodenaufrufe nicht automatisch der Stelle zugeordnet, die sie deklarieren. Ähnlich wie bei \emph{NRefactory} wird dazu eine Auflösung benötigt, die den Baum mit den Symbols verbindet. Listing \ref{listing:rosylnsemanticmodelcreation} zeigt wie ein Syntax-Baum kompiliert werden kann. Durch die Kompilierung werden alle Verweise, die sich wie im Beispiel auf die \texttt{mscorlib} (Bibliothek der Basistypen wie \texttt{object}, \texttt{string}, \texttt{DateTime}, usw) beziehen, aufgelöst.
\begin{lstlisting}[caption={Erzeugung eines semantischen Modells aus Syntax-Bäumen},label={listing:rosylnsemanticmodelcreation}]
Compilation compilation = Compilation.Create(name)
				.AddReferences(mscorlib)
				.AddSyntaxTrees(tree);
SemanticModel semanticModel = compilation.GetSemanticModel(tree);
\end{lstlisting}
Das Kompilieren findet im Speicher statt und das Ergebnis wird nicht in Form einer Assembly in eine Datei geschrieben. Aus dem Kompilat kann das semantische Modell erzeugt werden. Dieses Modell kann anschließend genutzt werden um zu sämtlichen syntaktischen Elementen im Syntax Tree semantische Eigenschaften zu erhalten.
\begin{lstlisting}[caption={Ermitteln der semantischen Information eines Methodenaufrufs},label={listing:roslynsemanticmodelusage}]
SemanticInfo invocationSymbols = semanticModel.GetSemanticInfo(invocation);
string typeName = invocationSymbols.Symbol.ContainingType.Name;
\end{lstlisting}
Dafür kann die \texttt{GetSemanticInfo}-Methode mit dem entsprechenden Element aufgerufen werden, wie in Lisiting \ref{listing:roslynsemanticmodelusage} dargestellt. Das semantische Modell enthält alle Symbols des Kompilats und nicht nur die, die für die Auflösung der Typen benötigt werden die im Syntax-Baum deklariert wurden. Wenn also über alle Typen im semantischen Modell iteriert wird, werden nicht nur die Typen aus dem Baum, sondern auch alle Typen aller Referenz-Assemblies, betrachtet.

\subsection{Workspace}
In diesem Unterabschnitt werden die Möglichkeiten der Compiler API in Bezug auf die Analyse von ganzen Visual Stuido Solutions beschrieben. Eine Solution ist eine Datei, die es Visual Studio ermöglicht mehrere Projekte mit mehreren Quellcode-Dateien zu verwalten und zu kompilieren. In einer Solution sind in der Regel alle Abhängigkeiten der beinhalteten Projekte entweder durch andere beinhaltete Projekte oder durch Referenz-Assemblies auflösbar. Die \emph{Roslyn} Services API erlaubt es im Kontext einer laufenden Visual Studio Instanz einen sogenannten Workspace zu verwenden, der die Visual Studio Umgebung Repräsentiert und den Syntax-Baum ändert, sobald der Quellcode ändert. Ein Workspace kann auch ohne Abhängigkeit von Visual Studio erzeugt werden, indem die Solution-Datei direkt geladen wird, wie in Listing \ref{listing:roslynsolutionworkspacecreation} zu sehen ist.
\begin{lstlisting}[caption={Erzeugung eines Workspace aus einer Visual Studio Solution-Datei},label={listing:roslynsolutionworkspacecreation}]
IWorkspace workSpace = Workspace.LoadSolution(solutionFile);
ISolution solution = ws.CurrentSolution;
...
SyntaxTree tree = document.GetSyntaxTree();
SemanticModel semantic = document.GetSemanticModel();
\end{lstlisting}
In einem \texttt{ISolution}-Objekt kann über alle enthaltenen Projekte iteriert werden. In jedem Projekt können alle Dokumente als \texttt{IDocument}-Objekte betrachtet werden. Zu jedem Dokument kann der zugehörige Syntax-Baum und das semantische Modell bestimmt werden. Da die Workspace-Repräsentation das Erzeugen und Kompilieren der Dateien übernimmt, kann die Code-Analyse direkt auf Solution-Ebene erfolgen, indem das Syntax-Baum und das semantische Modell wie in den Unterabschnitten \ref{subsec:roslynsyntaxtree} und \ref{subsec:roslynsemanticmodel} beschrieben wurde.


\section{Zusammenfassung}
In den oberen Abschnitten wurden die vier Technologien \emph{FxCop}, CCI, \emph{NRefactory} und Projekt \emph{Roslyn} kurz vorgestellt. Zu jeder Technologie wurden Eigenheiten und Besonderheiten beschrieben, die sich mehr oder weniger auf die Eignung der Technologie in Bezug auf ein Usus-ähnliches Programm für .NET auswirken. Abbildung \ref{fig:techevalsummary} visualisiert die sich daraus ergebenen bewerteten Verbindungen zwischen den Technologien und den Eingangs festgelegten Fragen.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/techevalsummary.png}
	\caption{Tabellarisches Ergebnis der Technologie Evaluierung}
	\label{fig:techevalsummary}
\end{figure}
Es ist zu sehen, dass die für die Berechnung der Metriken erforderlichen Informationen von allen untersuchten Lösungen ermittelt werden können. Bei zwei Lösungen allerdings mit Vorbedingung.
\paragraph{}
Zuerst wurde in Abschnitt \ref{sec:fxcop} \emph{FxCop} betrachtet. Diese Technologie wird im Rahmen der Evaluierung als nicht tauglich bewertet. Der Grund dieser Entscheidung ist auf die Umgebung zurückzuführen. Die eigentliche Code-Analyse wird von einer eigenen speziellen Regel durchgeführt, die im Kontext der \emph{FxCop} Runner-Anwendung ausgeführt wird. Dadurch wird die Kommunikation zwischen Regel und aufrufendem Programm erschwert was zu einer größeren Distanz zwischen Informationssammlung und Informationsaufbereitung führt.
\paragraph{}
Anschließend wurde in Abschnitt \ref{sec:cci} die \emph{Common Compiler Infrastructure} (CCI) betrachtet. Im Rahmen der Evaluierung wird diese Technologie als sehr geeignet erachtet. Als einzigen Nachteil wurde festgestellt, dass CCI mit Assemblies und CIL-Anweisungen arbeitet und daher keinen direkten Bezug zu dem Original-Quellcode hat. Da das zu analysierende Programm in Form einer Assembly vorliegen muss, wurden alle Abhängigkeiten bereits zur Kompilierzeit aufgelöst und Ziele von Methodenaufrufen bestimmt. CCI kann diese auslesen und brauch nicht selbst zu kompilieren.
\paragraph{}
Weiter wurde in Abschnitt \ref{sec:nrefactory} \emph{NRefactory} untersucht. Diese Technologie wird in der Evaluierung als geeignet angesehen. Die Besonderheit von \emph{NRefactory} ist, dass diese Bibliothek Unterstützung für die Analyse von Quelltext bietet (zumindest für C$\#$, VB.net kommt wahrscheinlich bald dazu). Diese Form der Analyse hat einige Einschränkungen. Beispielsweise kann das tatsächliche Aufrufziel eines Methodenaufrufs durch die alleinige Betrachtung von Quelltext nicht ermittelt werden. Dafür muss \emph{NRefactory} kompilieren, was dann nur in einer vollständigen Umgebung möglich ist. Um mit Assemblies zu arbeiten wird \emph{Mono.Cecil} genutzt, das hier in Verbindung mit \emph{NRefactory} gesehen wird. Während der Evaluierung wurden die Möglichkeiten der Assembly-Analyse mithilfe von CCI als umfangreicher festgestellt.
\paragraph{}
Abschließend wurde in Abschnitt \ref{sec:roslyn} das Projekt mit dem Codenamen \emph{Roslyn} vorgestellt. Im dieser Evaluierung wurde diese Technologie als nicht geeignet bewertet. Diese Entscheidung wurde aufgrund der Tatsache getroffen, dass \emph{Roslyn} noch nicht offiziell verfügbar ist sondern derzeitig nur als CTP bezogen werden kann (was sich nach dieser Master-Thesis wahrscheinlich bald ändert). Weiterhin ist die Installation der \emph{Roslyn} Umgebung erforderlich. Langfristig ist diese Technologie die bessere Lösung, da sie direkt von Microsoft kommt und im Gegensatz zu \emph{NRefactory} wesentlich umfangreichere Möglichkeiten, wie beispielsweise die Workspace API, bietet. \emph{Roslyn} arbeitet mit Quellcode und muss zur Auflösung von Methodenaufrufen ebenfalls kompilieren was wieder nur in einer vollständigen Umgebung funktioniert. Dank der Workspace API wird diese aber automatisch verwaltet.
\paragraph{}
Zusammenfassend ist zu sagen, das die \emph{Common Compiler Infrastructure} (CCI) derzeitig die beste Möglichkeit darstellt eine statische Code-Analyse, oder besser gesagt Assembly-Analyse durchzuführen. Sollte die Analyse von reinem Quellcode in einem Sonderfall erforderlich werden, kann eine Kombination mit \emph{NRefactory} genutzt werden. Sobald Projekt \emph{Roslyn} allerdings einen offiziellen Zustand erreicht, sollte eine mögliche Technologieersetzung möglich sein. Bis dahin unterstützt die Tatsache, dass \emph{FxCop} und andere Programme ebenfalls die CCI verwenden, diese Entscheidung.




\chapter{Usus.net}
Nachdem das Usus-Plugin für Java einfach \emph{Usus} heißt, wird die Visual Studio Erweiterung, die in der vorliegenden Master-Thesis entwickelt wird, im weiteren Verlauf als \emph{Usus.net} bezeichnet. Die Architektur von Usus.net, das in Abschnitt \ref{sec:architecture} noch grob als System bezeichnet wurde, besteht aus drei Teilen, die in Abbildung \ref{fig:architecture2} abgebildet sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=8cm]{images/architektur2.jpg}
	\caption{Architektur von Usus.net}
	\label{fig:architecture2}
\end{figure}
\texttt{Usus.net} als Visual Studio Erweiterung verwendet Oberflächen-Elemente, die in einer Bibliothek zusammengefasst und unabhängig von Visual Studio sind. Die Oberflächen sind Bestandteil der Bibliothek \texttt{Usus.net.View}. Diese verwendet eine weitere Bibliothek, die den allgemeinen Funktionsumfang von Usus darstellt: \texttt{Usus.net.Core} übernimmt die statische Code-Analyse von Assemblies, die Bewertung der Metriken und die Hotspot-Analyse. Diese Bibliothek kann sowohl über die Kommandozeile bedient werden, als auch in andere Anwendungen integriert werden. In diesem Kapitel wird Usus.net aus der Perspektive von \texttt{Usus.net.Core} vorgestellt. Dafür wird die konkrete Berechnung der Metriken mit der \emph{Common Compiler Infrastructure} beschrieben, sowie auf das zugrunde liegende Objektmodell eingegangen. Das Objektmodell dient dazu die Ergebnisse der Analyse weiter zu verarbeiten. Abschließend wird das Usus.net Verifikations-Framework vorgestellt, mit dem \texttt{Usus.net.Core} selbst getestet wurde.


\section{Metrikberechnung}
\label{sec:metriccalc}
In diesem Abschnitt wird vorgestellt, wie die Usus-Metriken aus Abschnitt \ref{sec:metrics} von Usus.net berechnet werden. In Abschnitt \ref{sec:cci} wurde erklärt das CCI Assemblies analysiert. Deswegen beginnt auch die Berechnung der Metriken mit einem Pfad zu einer \emph{Portable Executable}-Datei, wie sie in Unterabschnitt \ref{subsec:ccimetadata} definiert wurde. Abbildung \ref{fig:metriccalc} zeigt die Klassen, die an der Berechnung beteiligt sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=17cm]{images/metriccalc.jpg}
	\caption{Klassen, die an der Metrikberechnung von Usus.net beteiligt sind}
	\label{fig:metriccalc}
\end{figure}
Ein \texttt{AssemblyVisitor}-Objekt ist in der Lage eine PE-Datei einzulesen und definierte Typen und Methoden zu lokalisieren. Dies ist mit \emph{CCI Metadata} möglich. \texttt{MetricCollector} erbt die Analyse-Funktionalität von \texttt{AssemblyVisitor} und berechnet für die gefundenen Typen und Methoden die Metriken, die ohne den Kontext berechenbar sind. Für Methoden sind dies \emph{zyklomatische Komplexität}, \emph{Anzahl der Anweisungen}, \emph{Anzahl der tatsächlichen Codezeilen}, \emph{Anzahl der logischen Codezeilen} und \emph{Abhängigkeiten von Typen}. Als Klassenmetriken sind \emph{Anzahl der nicht-statischen öffentlichen Felder}, \emph{Anzahl der Methoden} und \emph{direkte Abhängigkeiten von Typen} kontextfrei. Alle weiteren Metriken sind nur dann berechenbar, wenn die kontextfreien Metriken vollständig bestimmt wurden. So lassen sich beispielsweise die \emph{interessanten direkten Typ-Abhängigkeiten} einer Klasse erst ermitteln, wenn alle selbst-deklarierten Typen im System bekannt sind. Das gleiche gilt für die \emph{zyklischen Abhängigkeiten von Namensräumen}, die nur in einem vollständigen Graph der Namensräume gefunden werden können. Diese kontext-sensitiven Metriken werden von Usus.net im Rahmen einer nachträglichen Bearbeitung der Metriken berechnet. Dazu wird zum einen die Klasse \texttt{PostProcessTypeDependencies} verwendet, die aus allen interessanten Abhängigkeiten den Abhängigkeitsbaum erzeugt um anschließend die kumulierte Komponentenabhängigkeit zu bestimmen. Zum anderen wird die Klasse \texttt{PostProcessNamespaceDependencies} genutzt um aus dem Abhängigkeitsbaum der Typen einen Abhängigkeitsbaum der Namespaces zu erstellen, der dann genutzt werden kann um die zyklischen Abhängigkeiten der Namespaces zu suchen.
\paragraph{}
Für jede zu bestimmende Metrik existiert eine Klasse, die die Berechnung durchführen kann. Alle Ergebnisse werden in einem \texttt{MetricsReport}-Objekt gesammelt und in Form eines Berichts im \texttt{MetricCollector}-Objekt hinterlegt. Der Aufrufer kann diesen Bericht jederzeit einsehen. Abschnitt \ref{sec:ususobjectmodel} beschreibt diesen Bericht als Bestandteil des Objektmodells ausführlicher, während Listing \ref{listing:ususnetcoreusage} einen vereinfachten Codeausschnitt aus \texttt{Usus.net.Console} zeigt, der die statische Code-Analyse durchführt und sämtliche Metriken aller Methoden einfach auf der Console ausgibt.
\begin{lstlisting}[caption={Aufruf der Code-Analyse von \texttt{Usus.net.Core} in \texttt{Usus.net.Console}},label={listing:ususnetcoreusage}]
var metrics = Analyze.PortableExecutable(assemblyToAnalyze);
//alternativ: Analyze.Me();
foreach (var method in metrics.Methods) {
	Console.WriteLine("Signature: " + method.Signature);
	Console.WriteLine("CyclomaticComplexity: " + method.CyclomaticComplexity);
	...
}
\end{lstlisting}
Nachdem die Infrastruktur der Metrikberechnung hiermit beschrieben wurde, werden in den folgenden Unterabschnitten die konkreten Berechnungen der einzelnen Metriken vorgestellt.

\subsection{Zyklomatische Komplexität}
Die zyklomatische Komplexität einer Methode gibt an, wie viele unterschiedliche Ablaufpfade durch eine Methode existieren. In Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} wurde diese Metrik ausführlicher erklärt. In Usus.net kann die Berechnung auf zwei verschiedene Arten durchgeführt werden. Zum einen kann ausschließlich \emph{CCI Metadata} verwendet und alle CIL-Anweisungen die eine Entscheidung treffen aufsummiert werden. Die Klasse \texttt{CyclomaticComplexityOfIl} implementiert diesbezüglich eine einfache Abwandlung des Algorithmus, der unter anderem von Steve Gilham vorgestellt wurde \cite{CCperCIL} und laut ihm angeblich auch in frühen Versionen von NDepend (Abschnitt \ref{sec:ndepend}) verwendet wurde. Die andere Variante, die in Usus.net standardmäßig verwendet wird, nutzt \emph{CCI Code and AST Components}. Die Klasse \texttt{CyclomaticComplexityOfAst} erzeugt ein spezielles Besucher-Objekt vom Typ \texttt{CyclomaticComplexityCalculator}, das den aus dem Methodenrumpf erzeugten abstrakten Syntaxbaum besucht. Die Erzeugung des AST aus der Methoden-Definition übernimmt CCI. Listing \ref{listing:cyclomaticcomplexityofast} zeigt den Code der die zyklomatische Komplexität in \texttt{Usus.net.Core} bestimmt.
\begin{lstlisting}[caption={Statement-Analyse zur Bestimmung der zyklomatischen Komplexität},label={listing:cyclomaticcomplexityofast}]
var methodBody = method.Decompile(pdb, host);
var cyclomaticComplexityCalculator = new CyclomaticComplexityCalculator();
cyclomaticComplexityCalculator.Traverse(methodBody.Statements());
var result = cyclomaticComplexityCalculator.Result;
\end{lstlisting}
Das \texttt{CyclomaticComplexityCalculator}-Objekt erbt die Funktionalität, sämtliche Anweisungen (engl. Statements) in einem Methodenrumpf zu besuchen, von \texttt{CodeTraverser}, einer Klasse in der CCI. Jede Bedingung, jede \texttt{if}-, \texttt{while}-, \texttt{for}-, \texttt{case}- und \texttt{catch}-Anweisung erhöht einen anfangs mit 1 initiierten Zähler. Obwohl \texttt{CodeTraverser} auch eine Behandlungsroutine für \texttt{foreach}-Anweisungen anbietet, ist die CCI momentan nicht in der Lage diese als solche erfolgreich zu erkennen. Dies hat zur Folge, das \texttt{foreach}-Anweisungen, die vom Compiler in \texttt{while}/\texttt{if}/\texttt{finally}-Anweisungen übersetzt werden, auch also solche erkannt werden. Durch das \texttt{while} und das \texttt{if} entstehen also zwei Stellen, die eine Entscheidung treffen, während im Quellcode mit \texttt{foreach} nur eine erkennbar ist. Die in Usus.net berechnete zyklomatische Komplexität einer Methode entspricht also der Komplexität, die der Compiler generiert und nicht der, die durch den Quellcode suggeriert wird.

\subsection{Methodenlänge}
Die Länge einer Methode sagt etwas darüber aus, wie viele Dinge diese Methode ausführt. Eine kurze Methode ist einfacher zu verstehen und zu verändern als eine lange. In Unter-Unterabschnitt \ref{subsubsec:methodlength} wurde diese Metrik und ihre Varianten genauer beschrieben. Usus.net bestimmt drei verschiedene Methodenlängen.
\paragraph{}
Als sehr nachvollziehbare Längenangabe wird wohl die Anzahl der Codezeilen gesehen, die Logik enthalten. Dieser Wert wird von der Klasse \texttt{NumberOfLogicalLines} bestimmt und ausschließlicher Verwendung von \emph{CCI Metadata}. Alle CIL-Anweisungen, außer leeren Anweisungen (\texttt{Nop}), Block-Verlassen-Anweisungen (\texttt{Leave.S}) und Methoden-Rückgabe-Anweisungen (\texttt{Ret}) werden dabei betrachtet. Listing \ref{listing:numberoflogicallines} zeigt den Code, der die Codezeilen der betroffenen CIL-Anweisungen (Operationen) findet, doppelte Werte entfernt und deren Anzahl bestimmt.
\begin{lstlisting}[caption={Operation-Analyse zur Bestimmung der Anzahl der logischen Codezeilen},label={listing:numberoflogicallines}]
var locations = method.LocatedOperations(pdb);
var result = locations.GetAllStartLinesOfInterestingOpCodes().Distinct().Count();
\end{lstlisting}
Die Zuordnung der Codezeilen des Quelltexts vor der Kompilierung zu den CIL-Anweisungen danach kann nur durchgeführt werden, wenn zu der zu analysierenden PE-Datei eine pdb-Datei existiert. Wie in Unterabschnitt \ref{subsec:ccimetadata} definiert, beinhaltet die pdb-Datei die erforderlichen Zeilenangaben. Die CCI unterstützt die Analyse dieser Dateien ebenfalls mithilfe der Klasse \texttt{PdbReader}. Sollte keine pdb-Datei zur Verfügung stehen, bestimmt Usus.net den Ergebniswert der \texttt{NumberOfLogicalLines}-Metrik mit -1.
\paragraph{}
Standardmässig verwendet Usus.net die Anzahl der logischen Codezeilen als Methodenlänge. Sollte deren Bestimmung aufgrund einer fehlenden pdb-Datei nicht möglich sein, wird die Anzahl der Anweisungen verwendet. Die Klasse \texttt{NumberOfStatements} verwendet \emph{CCI Code and AST Components} um den Methodenrumpf zu dekompilieren und einen AST zu erzeugen. Dieser kann anschließend analysiert und sämtliche Anweisungen besucht werden. Dieses Vorgehen ist vergleichbar mit der Bestimmung der zyklomatischen Komplexität. Listing \ref{listing:numberofstatements} zeigt wie dafür ein \texttt{StatementCollector}-Objekt verwendet wird.
\begin{lstlisting}[caption={Statement-Analyse zur Bestimmung der Anzahl der Anweisungen},label={listing:numberofstatements}]
var methodBody = method.Decompile(pdb, host);
var statementCollector = new StatementCollector(pdb);
statementCollector.Traverse(methodBody.Statements());
var result = return statementCollector.Result.Count();
\end{lstlisting}
Neben der Anzahl der Anweisungen kann Usus.net auch die Anzahl der CIL-Anweisungen, den sogenannten Operationen, bestimmen. Dafür wird kein AST erzeugt, sodass nur die \emph{CCI Metadata}-Infrastruktur benötigt wird. Allerdings besteht eine Methode aus einer Vielzahl von Operationen, die keinen direkten Zusammenhang mit dem Quellcode vor dem Kompilieren erkennen lassen.
\paragraph{}
Als dritte Möglichkeit die Methodenlänge zu bestimmen, kann Usus.net die Anzahl der tatsächlichen Zeilen einer Methode ausrechnen. Genau wie bei der Anzahl der logischen Codezeilen ist hierfür \emph{CCI Metadata} sowie eine pdb-Datei erforderlich. In der Klasse \texttt{NumberOfRealLines} werden die Zeilen aller Operationen eines Methodenrumpfs ermittelt. Durch die Differenz der ersten und letzten Zeile kann die Anzahl der Zeilenumbrüche bestimmt werden. Listing \ref{listing:numberofreallines} zeigt diese Berechnung.
\begin{lstlisting}[caption={Operation-Analyse zur Bestimmung der Anzahl der tatsächlichen Zeilen},label={listing:numberofreallines}]
var locations = method.LocatedOperations(pdb);
var firstLine = locations.GetAllValidLines(l => l.EndLine).Min();
var lastLine = locations.GetAllValidLines(l => l.EndLine).Max();
var result = Math.Max(0, lastLine - firstLine - 1);
\end{lstlisting}
Wenn die pdb-Datei nicht existiert, wird der Wert der \texttt{NumberOfRealLines}-Metrik auf -1 gesetzt.

\subsection{Kumulierte Komponentenabhängigkeit}
\label{subsec:ccdcode}
Die Anzahl aller Klassen, von denen eine Klasse direkt und indirekt abhängig ist, ist auch als kumulierte Komponentenabhängigkeit (CCD) bekannt und wurde bereits ausführlich in Unter-Unterabschnitt \ref{subsubsec:ccd} vorgestellt. Damit die direkten Abhängigkeiten einer Klasse bestimmt werden können müssen zunächst die direkten Klassenabhängigkeiten pro Methoden ermittelt werden. Jede Verwendung eines Typs innerhalb der Methodensignatur sowie dem Methodenrumpf muss erkannt werden. Usus.net verwendet dazu die Klasse \texttt{TypeDependencies}. Mithilfer der \emph{CCI Metadata}-Infrastruktur werden die CIL-Anweisungen der Methode nach Referenzen auf Typen untersucht. Die dabei verwendeten Strategien sind in Listing \ref{listing:typedependencies} zu sehen. Die Ergebnisse dieser Strategien werden in einer Liste konsolidiert, wobei doppelte Vorkommen ignoriert werden.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Klassenabhängigkeiten einer Methode},label={listing:typedependencies}]
var result = Enumerable.Empty<string>()
		.Union(TypeDependenciesOfSignature.Of(method))
		.Union(TypeDependenciesOfVariables.Of(method))
		.Union(TypeDependenciesOfCallOperations.Of(method))
		.Union(TypeDependenciesOfNewOperations.Of(method))
		.Union(TypeDependenciesOfCatches.Of(method))
		.Union(TypeDependenciesOfTypeMentions.Of(method));
\end{lstlisting}
Nachdem zu jeder Methode alle Abhängigkeiten bestimmt wurden, können die Abhängigkeiten einer Klasse einfach bestimmt werden, indem die Abhängigkeitslisten der Methoden zusammengefasst werden. Dafür verwendet Usus.net die Klasse \texttt{DirectDependencies}. Um Typen wie \texttt{object}, \texttt{string} und \texttt{int}, die in der Base Class Library (BCL) definiert sind zu ignorieren, brauchen nur die interessanten Typen betrachtet werden. Dies sind Klassen, die in der analysierten Assembly selbst deklariert und definiert wurden. Dieser Filter ist in der Klasse \texttt{InterestingDirectDependencies} definiert. Da zu diesem Zeitpunkt alle deklarierten Typen des Systems bereits bekannt sein müssen, kann der Filter erst im Rahmen der nachträglichen Bearbeitung durch die \texttt{PostProcessTypeDependencies}-Klasse angewendet werden. Jeder in der Assembly deklarierte Typ ist anschließend nur noch von anderen in der Assembly deklarierten Typen abhängig. Aus diesem Netz der Abhängigkeiten erzeugt Usus.net mithilfe der QuickGraph\footnote[1]{QuickGraph: "`Generic Graph Data Structures and Algorithms for .NET"' \url{http://quickgraph.codeplex.com/}} Bibliothek einen Abhängigkeitsgraphen auf Typ-Ebene. Um jetzt alle direkten und indirekten Abhängigkeiten einer Klasse \texttt{type} zu bestimmen, kann wie Unter-Unterabschnitt \ref{subsubsec:ccd} hergeleitet der Algorithmus \emph{Depth First Search} verwendet werden, um die Erreichbarkeitsmenge des Knoten von \texttt{type} zu finden. Wie in Listing \ref{listing:cumulatedcomponentdependency} dargestellt, ist die kumulierte Komponentenabhängigkeit einer Klasse \texttt{type} die Anzahl der nicht vom Kompiler erzeugten Typen, in der Erreichbarkeitsmenge von \texttt{type}.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der kumulierten Komponentenabhängigkeit},label={listing:cumulatedcomponentdependency}]
var result = typeGraph.Reach(type).Vertices
		      .Count(t => !t.CompilerGenerated);
\end{lstlisting}
Die Implementierung der \texttt{Reach}-Funktion verwendet die \texttt{DepthFirstSearchAlgorithm<T, Edge<T>>}-Klasse von QuickGraph und setzt den Startknoten auf $type$. Zusätzlich wird die Suche abgebrochen, nachdem die Erreichbarkeitsmenge des Startknotens gefunden wird.

\subsection{Klassengröße}
Die Klassengröße gehört zu den Metriken die kontextfrei bestimmt werden können. In Unter-Unterabschnitt \ref{subsubsec:classsize} wurde die Klassengröße in Usus als Anzahl der Methoden festgelegt. Die API der \emph{CCI Metadata} erlaubt eine bedingte Aufsummierung aller Methoden in einer Typ-Definiton, wie in Listing \ref{listing:numberofmethods} gezeigt.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Anzahl der Methoden},label={listing:numberofmethods}]
var result = type.Methods.Count(m => !m.IsDefaultCtor());
\end{lstlisting}
Da jeder nicht-statische Typ immer einen Default-Konstruktor enthält, wird dieser in der Klassengröße nicht berücksichtigt. Neben Konstruktoren erzeugt der .NET-Kompiler auch aus Properties, Indexern und Events Methoden.

\subsection{Nicht-statische öffentliche Felder}
Die Anzahl der öffentlichen Felder, die nicht statisch sind, kann ebenfalls im Rahmen der kontextfreien Bestimmung der Klassenmetriken ermittelt werden. Diese Metrik wurde bereits in Unter-Unterabschnitt \ref{subsubsec:nonstaticpublicfields} vorgestellt. Listing \ref{listing:nonstaticpublicfields} zeigt diese bedingte Aufsummierung der Felder einer Klasse.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der nicht-statischen öffentlichen Felder},label={listing:nonstaticpublicfields}]
var result = type.Fields.Count(f => !f.IsStatic 
	     && f.Visibility == TypeMemberVisibility.Public);
\end{lstlisting}
Auch hier ermöglicht die API der \emph{CCI Metadata} eine Iteration über alle Felder einer Typ-Definition.

\subsection{Namespaces mit zyklischen Abhängigkeiten}
\label{subsec:namespaceswithcyclicdependencies}
Die einzige Metrik die Usus.net für Namespaces bestimmt, ist die Anzahl der zyklischen Abhängigkeiten. In Unter-Unterabschnitt \ref{subsubsec:packetswithcyclicdependencies} wurde hergeleitet, das dafür der Algorithmus \textit{Strongly Connected Components} verwendet werden kann. Die Berechnung setzt also den vollständigen Abhängigkeitsgraphen auf Namespace-Ebene voraus. Der Abhängigkeitsgraph auf Typen-Ebene wurde von Usus.net bereits für die Berechnung der kumulierten Komponentenabhängigkeit in \ref{subsec:ccdcode} erstellt. Aus diesem Graph kann der Namespace-Graph reduziert werden. Damit ist offensichtlich, das auch diese Metrik im Rahmen der nachträglichen Bearbeitung kontextabhängig bestimmt wird. Die Klasse \texttt{PostProcessNamespaceDependencies} führt die nötigen Berechnungen durch, indem zuerst der Abhängigkeitsgraph auf Namespace-Ebene erstellt wird. Danach werden die Kreise ermittelt und den entsprechenden Namespaces zugewiesen.
\subsubsection{Namespace-Graph}
Die Erstellung des Graphen aller Namespaces geschieht wie in Listing \ref{listing:namespacegraphcreation} dargestellt.
\begin{lstlisting}[caption={Erzeugung des Abhängigkeitsgraphen auf Namespace-Ebene},label={listing:namespacegraphcreation}]
namespaceGraph = metrics.GraphOfTypes.Cast(t => t.AsNamespaceWithTypes());
foreach (var namespaceGroup in namespaceGraph.Vertices
	.GroupBy(n => n.Itself.Name)) {
	namespaceGraph.Reduce(
		namespaceGroup.AsNamespaceWithTypes(), 
		namespaceGroup);
}
\end{lstlisting}
Der Abhängigkeitsgraph auf Klassen-Ebene vom Typ \texttt{MutableGraph<TypeMetricsReport>} wird zunächst in einen neuen Graphen vom Typ \texttt{MutableGraph<NamespaceMetricsWithTypeMetrics>} überführt. Dies ist notwendig, da Knoten im nächsten Schritt zusammengefasst werden und alle Knoten in einem Graph den gleichen Knotentyp haben müssen. Jeder \texttt{TypeMetricsReport}-Knoten wird zu einen \texttt{NamespaceMetricsWithTypeMetrics}-Knoten umgestaltet. Das Ergebnis dieser \texttt{Cast}-Operation ist also ein identischer Graph mit einem unterschiedlichen Knotentyp. Anschließend können alle Knoten, die den gleichen Namespace (\texttt{n.Itself.Name}) besitzen zusammengefasst werden. Alle diese gruppierten Knoten (Typen) des gleichen Namespace können dann mit der \texttt{Reduce}-Operation des Graphen zu einem einzigen Knoten zusammengefasst werden, der alle Typen des Namespace repräsentiert. Der erste Parameter von \texttt{Reduce} ist der neue Knoten, der die Knoten in der Menge, die als zweiter Parameter übergeben wird, ersetzen soll. Selbstverständlich müssen alle Kanten zwischen Knoten außerhalb und Knoten innerhalb der zu reduzierenden Menge zu Kanten zwischen dem neuen Knoten und den Knoten außerhalb der reduzierten Menge umgestaltet werden. In der QuickGraph Bibliothek konnte kein Algorithmus gefunden werden, der diesen Reduktionsvorgang komplett übernimmt. QuickGraph bietet lediglich die \texttt{MergeVertex}-Operation an, die es erlaubt einen einzigen Knoten aufzulösen und die Knoten seiner eingehenden Kanten mit den Knoten seiner ausgehenden Kanten zu verbinden. Auf dieser Basis kann der Algorithmus in Listing \ref{listing:vertexreduction}, der in der vorliegenden Master-Thesis als \textit{Vertex Reduction} bezeichnet wird, aufgebaut werden.
\begin{lstlisting}[caption={\textit{Vertex Reduction} - Reduktion von Knotenmengen in einem Digraph},label={listing:vertexreduction}]
graph.AddVertex(reducedVertex);
foreach (var vertex in vertices) {
	graph.AddEdge(new Edge<T>(reducedVertex, vertex));
	graph.AddEdge(new Edge<T>(vertex, reducedVertex));
	graph.MergeVertex(vertex, (s, t) => new Edge<T>(s, t));
}
\end{lstlisting}
Der erste Parameter dieses Algorithmus ist der neue Knoten, der eine Menge an anderen Knoten zusammenfassen soll und in \texttt{reducedVertex} vorliegt. Der zweite Parameter des Algorithmus sind die Knoten, die zusammengefasst werden sollen, welche als Menge von Knoten in \texttt{vertices} vorliegen. Der neue Knoten wird in den Graph eingefügt und mit allen Knoten, die er ersetzen soll, \textit{stark} verbunden. Anschließend können alle Knoten, die ersetzt werden sollen mithilfe der \texttt{MergeVertex}-Operation aufgelöst werden. Durch die beidseitigen Verbindungen der aufzulösenden Knoten mit dem neuen Knoten werden alle Kanten der alten Knoten auf den neuen Knoten umgebogen. Abbildung \ref{fig:vertexreduction} zeigt die schematische Funktionsweise des Algorithmus \textit{Vertex Reduction} an einem Beispiel.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/vertexreduction.jpg}
	\caption{Schematische Darstellung der Funktionsweise des \textit{Vertex Reduction}-Algorithmus}
	\label{fig:vertexreduction}
\end{figure}
Die beiden mittleren Knoten sollen zu einem zusammengefasst werden, ohne das die Kanten verloren gehen. Diese Graphenreduktion, wie sie für die Erstellung des Abhängigkeitsgraph auf Namespace-Ebene erforderlich ist, kann mit der wiederholten Anwendung des \textit{Vertex Reduction}-Algorithmus erreicht werden. Bei jeder Anwendung wird dem Graph ein neuer \texttt{NamespaceMetricsWithTypeMetrics}-Knoten hinzugefügt, der alle \texttt{NamespaceMetricsWithTypeMetrics}-Knoten des gleichen Namespace ersetzt. Sobald der Algorithmus für alle Gruppen von Typen, die sich im gleichen Namespace befinden angewendet wurde, ist der Abhängigkeitsgraph auf Namespace-Ebene vollständig.
\subsubsection{Namespace-Kreise}
Die QuickGraph Bibliothek bietet eine Implementierung des Algorithmus zur Erkennung der starken Zusammenhangskomponenten. Dieser Algorithmus lässt sich über die \texttt{StronglyConnectedComponents}-Methode auf dem QuickGraph-Graphen vom Typ \texttt{BidirectionalGraph<V, Edge<V>>} aufrufen. Das Ergebnis ist eine Zuordnung von Knoten \texttt{V} zu der eindeutigen Identifikationsnummer der \textit{Strongly Connected Component} in Form eines \texttt{IDictionary<V, int>}-Objekts. Um die Kreise den Knoten die sie enthalten zuordnen zu können, ist eine Zuordnung von Knoten zu einer Menge von Knoten (dem Kreis) erforderlich. Tabelle \ref{tab:sccfunctionalcomp} zeigt die Transformation der ursprünglichen Zuordnung um die gewünschte Abbildung von Knoten auf Knotenmenge zu erhalten. IE\textless{}$V$\textgreater{} steht für eine Sequenz von Objekten vom Typ $V$ und ist eine Abkürzung des Typen \texttt{IEnumerable<V>}. Die Transformation hat einen einmaligen Aufwand von $O(n)$, da die initiale Abbildung einmal vollständig invertiert werden muss.
\begin{table}
\centering
\begin{array}[t]{ l r c l l}
(1) & V & \rightarrow & int & \text{Ergebnis der \texttt{StronglyConnectedComponents}-Methode}\\
(2) & int & \rightarrow & IE<V> & \text{Umkehrung der Abbildung (1)}\\
(3) & V \rightarrow int & \rightarrow & int \rightarrow IE<V> & \text{Funktionale Komposition von (1) und (2)}\\
(4) & V & \rightarrow & IE<V> & \text{Reduktion der funktionalen Komposition (3)}\\
\end{array}
\caption{Abbildung von Knoten zu starker Zusammenhangskomponente zu anderen Knoten}
\label{tab:sccfunctionalcomp}
\end{table}
Diese neue Abbildung wird in einem Objekt vom Typ \texttt{StronglyConntectedComponents} gekapselt. Um die Anzahl der zyklischen Abhängigkeiten eines konkreten Namespace zu ermitteln muss die Methode \texttt{StronglyConntectedComponents}-Methode auf dem Abhängigkeitsgraph auf Namespace-Ebene aufgerufen werden. Auf das Ergebnis kann die in Tabelle \ref{tab:sccfunctionalcomp} gezeigte Transformation angewendet werden um ein \texttt{StronglyConntectedComponents<NamespaceMetricsWithTypeMetrics>}-Objekt zu erhalten. Dieses Objekt kann jederzeit nach allen oder speziellen Kreisen gefragt werden. Die zyklischen Abhängigkeiten eines Namespace werden in der nachträglichen Bearbeitung der Metriken von der Klasse \texttt{CyclicDependencies} bestimmt. Listing \ref{listing:namespacedependencies} zeigt wie das Objekt, dass die starken Zusammenhangskomponenten repräsentiert (also das Kompositions-Ergebnis aus Tabelle \ref{tab:sccfunctionalcomp}) nach dem Kreis gefragt wird, auf dem sich der Knoten des Namespace \texttt{namespaceWithTypes} befindet.
\begin{lstlisting}[caption={Namespace-Analyse zur Bestimmung der zyklischen Abhängigkeiten},label={listing:namespacedependencies}]
var result = from n in cycles.OfVertex(namespaceWithTypes).Vertices
	     select n.Itself;
\end{lstlisting}
Nachdem alle Namespaces Informationen über die Kreise, auf denen sie sich eventuell befinden, erhalten haben, ist die nachträgliche Bearbeitung der Metrik-Analyse beendet. Das vollständige MetrikReport-Objekt steht dem Aufrufer der Analysemethoden der \texttt{Analyze}-Klasse zur Verfügung.


\section{Objektmodell}
\label{sec:ususobjectmodel}
Im vorherigen Abschnitt wurde die Berechnung der Metriken ausführlich beschrieben. Dieser Abschnitt stellt das Objektmodell des Metrikberichts näher vor. Abbildung \ref{fig:metriccalc} zeigt, dass das zentrale Datenobjekt \texttt{MetricsReport} ist. Wie in Abschnitt \ref{sec:metriccalc} beschrieben, wird dieses Objekt zunächst mit den Daten befüllt, die das \texttt{MetricsCollector}-Objekt sammelt. Anschließend werden im Rahmen der nachträglichen Bearbeitung weitere Berechnungen vorgenommen um auch die kontextabhängigen Metriken zu bestimmen. Diese komplette Metrik-Analyse wird durch die statischen Methoden der \texttt{Analyze}-Klasse gestartet. Diese Methoden liefern das \texttt{MetricsReport}-Objekt als Ergebnis an den Aufrufer zurück. In diesem Abschnitt wird genau dieses Objekt genauer betrachtet. Abbildung \ref{fig:metricsreport} zeigt alle Klassen, aus denen dieser Bericht besteht.
\begin{figure}[h]
	\centering
		\includegraphics[width=17cm]{images/metricsreport.jpg}
	\caption{Objektmodell und Klassen des vollständigen Metrikberichts}
	\label{fig:metricsreport}
\end{figure}

\subsection{Methodenberichte}
Der Metrikbericht besteht aus mehreren Methodenberichten. Diese \texttt{MethodMetricsReport}-Objekte enthalten alle relevanten Daten und Metriken jeder im System gefundenen Methode. Die eindeutige Zuordnung von Methode zu Methodenbericht ist über die Eigenschaft \texttt{Signature} möglich. Die Signatur einer Methode macht sie im System eindeutig, da neben Methodenname auch Typ- und Namespace-Name, sowie vollständige Namen des Rückgabetypen und aller Parametertypen enthalten sind. Neben der Menge aller Methodenberichte kann der Bericht zu einer bestimmten Methode in \texttt{MetricsReport} auch gesucht werden. Dazu existieren mehrere Extension Methods, die wie in Listing \ref{listing:methodpropertysearch} dargestellt, benutzt werden können. Die Variable \texttt{metrics} enthält die Referenz zu dem \texttt{MetricsReport}-Objekt.
\begin{lstlisting}[caption={Methoden- und Property-Suche in einem \texttt{MetricsReport}-Objekt},label={listing:methodpropertysearch}]
//Methoden
methodMetrics = metrics.ForMethod(
  "System.Void andrena.Usus.net.Console.Analyzer.AnalyzeFile(System.String)");
methodMetrics = metrics.ForMethod(() => AnalyzeFile(null));
//Properties
propertyMetrics = metrics.ForProperty(() => Name);
methodMetrics = metrics.ForMethod(
  "System.String andrena.Usus.net.Console.Analyzer.Name.get()");
\end{lstlisting}
Methodenberichte sind vom Typ \texttt{MethodMetricsReport} und lassen sich zum einen über die \texttt{Signature}-Eigenschaft der Methode finden, wie Zeile 2 zeigt. Wenn die zu suchende Methode im Scope ist (also in der Assembly deklariert ist, die den Code ausführt), kann sie wie in Zeile 4 auch über einen \texttt{Expression}-Ausdruck angegeben werden. Microsoft beschreibt dieses Konzept in Verbindung mit den in C$\#$ integrierten Lambda-Ausdrücken in einem eigenen Artikel in der MSDN Library \cite{MSDNExpressions}. Dadurch bleibt die Methodenreferenz, im Gegensatz zur Verwendung von Strings, Ziel von automatisierten Refactorings. Eine dritte Möglichkeit erlaubt das Suchen von Methodenberichten per \texttt{MethodInfo}-Objekt aus dem .NET Framework. Das gleiche gilt auch für Properties. Da der C$\#$-Kompiler den \texttt{get}- und \texttt{set}-Teil eines Properties als Methoden kompiliert, werden diese ebenfalls auf \texttt{MethodMetricsReport}-Objekte abgebildet. Wie in Zeile 6 in Listing \ref{listing:methodpropertysearch} gezeigt, lassen sich Properties auch über einen \texttt{Expression}-Ausdruck suchen. Das resultierende \texttt{PropertyMetricsReport}-Objekt ist einfach eine Zusammenfassung zweier \texttt{MethodMetricsReport}-Objekte, nämlich eins für den \texttt{get}- und eins für den \texttt{set}-Teil des Properties. Diese \texttt{MethodMetricsReport}-Objekte der Properties lassen sich aber auch direkt über die Signatur finden, wie Zeile 7 zeigt.

\subsection{Klassenberichte}
Da die Methoden, zu denen \texttt{MetricsReport} die Methodenberichte enthält, in einer Klasse deklariert sind, existiert auch ein Bericht für eben diese Klasse. Die Abbildung von Klasse zu Methode ist im Usus.net Objektmodell als Abbildung von \texttt{TypeMetricsReport}-Objekt zu \texttt{MethodeMetricsReport}-Objekten realisiert. Der Codeausschnitt in Listing \ref{listing:classmethodsearch} zeigt in Zeile 4 wie mithilfe der \texttt{MethodsOfType}-Methode alle Methodenberichte, die zu einem Klassenbericht gehören, ermittelt werden können. Die Variable \texttt{metrics} enthält wieder die Referenz zu dem \texttt{MetricsReport}-Objekt.
\begin{lstlisting}[caption={Klassen- und Methoden-Suche in einem \texttt{MetricsReport}-Objekt},label={listing:classmethodsearch}]
typeMetrics = metrics.ForType<Analyzer>();
typeMetrics = metrics.ForType(typeof(Analyzer));
typeMetrics = metrics.ForType("andrena.Usus.net.Console.Analyzer");
foreach (var methodMetrics in metrics.MethodsOfType(typeMetrics)) {...}
\end{lstlisting}
Zeile 1 und 2 zeigen wie der Klassenbericht für einen Typ gesucht werden kann, der in der Assembly liegt, die den Code ausführt. Der Klassenname kann damit weiterhin von automatisierten Refactorings erreicht werden. In Zeile 3 wird der Bericht anhand der \texttt{Fullname}-Eigenschaft des Klassenberichts gesucht. Diese Eigenschaft enthält den Namespace, den Klassennamen sowie eventuelle generische Parameter und ist damit eindeutig.
\paragraph{}
Die Metriken auf Klassenebene, die im \texttt{TypeMetricsReport} enthalten sind, beinhalten auch die Menge aller direkten Abhängigkeiten. In Unterabschnitt \ref{subsec:ccdcode} wurde beschrieben, dass daraus ein Abhängigkeitsgraph auf Klassenebene erstellt wird. Dieser Klassengraph steht anschließend in einem schreibgeschützten Format im \texttt{MetricsReport}-Objekt zur Verfügung. Der nach außen sichtbare Typ des Graphen ist \texttt{IGraph<TypeMetricsReport>}, also ein \texttt{IGraph<V>} mit Knoten vom Typ \texttt{TypeMetricsReport}. Neben der Liste von Knoten besteht der Graph auch aus einer Liste von Kanten zwischen diesen Knoten. Eine Kante ist vom Typ \texttt{Tuple<TypeMetricsReport, TypeMetricsReport>}. Das erste Element in diesem Tuple stellt die Quelle, das zweite das Ziel der Verbindung dar. Beide Listen sind schreibgeschützt, sodass der Graph nicht ohne weiteres von außen verändert werden kann. Intern verwendet Usus.net den Typ \texttt{MutableGraph<V>}, der das \texttt{IGraph<V>}-Interface implementiert. Dieser Typ ist nicht mehr schreibgeschützt und erlaubt einige weitere Operationen. Beispielsweise lassen sich Kreise ermitteln, Erreichbarkeitsmengen bestimmen und Knoten reduzieren. Der Graph ist Bestandteil des Metrikberichts um eine Abbildung der Beziehungen zwischen den Klassen zu haben.

\subsection{Namespace-Berichte}
Neben den Methoden- und Klassenberichte enthält das \texttt{MetricsReport}-Objekt auch Namespace-Berichte vom Typ \texttt{NamespaceMetricsReport}. Diese Objekte enthalten im Vergleich zu den anderen Berichten vom Typ \texttt{TypeMetricsReport} und \texttt{MethodMetricsReport} nur wenige Informationen. Doch auch Namensräume haben einen eindeutigen Namen. Diese \texttt{Name}-Eigenschaft des Berichts wird für die Suche verwendet, wie Listing \ref{listing:namespaceclasssearch} in Zeile 1 zeigt.
\begin{lstlisting}[caption={Namespace- und Klassen-Suche in einem \texttt{MetricsReport}-Objekt},label={listing:namespaceclasssearch}]
namespaceMetrics = metrics.ForNamespace("andrena.Usus.net.Console");
foreach (var typeMetrics in metrics.TypesOfNamespace(namespaceMetrics)) {...}
\end{lstlisting}
Da Namespaces mehrere Klassen enthalten lässt sich diese Zuordnung auch unter den Berichten auflösen. Die Schleife in Zeile 2 iteriert über alle Klassenberichte eines Namespace-Berichts, indem die \texttt{TypesOfNamespace}-Methode verwendet wird.
\paragraph{}
Neben dem Abhängigkeitsgraphen auf Klassenebene steht auch der Abhängigkeitsgraph auf Namespace-Ebene zur Verfügung. In Unterabschnitt \ref{subsec:namespaceswithcyclicdependencies} wurde beschrieben, wie dieser Graph aus dem Klassengraph erzeugt wird. Der Namespace-Graph besteht aus Kanten zwischen Knoten vom Typ \texttt{IGraph<NamespaceMetricsReport>}. Im Gegensatz zum Graph auf Typ Ebene verwendet Usus.net intern nicht direkt einen Graphen vom Typ \texttt{MutableGraph<NamespaceMetricsReport>} sondern einen Graphen, dessen Knoten vom Typ \texttt{NamespaceMetricsWithTypeMetrics} sind. Dies ist der Fall, da der Namespace-Graph aus dem Graph mit Klassenberichten als Knoten erzeugt wird. Um trotzdem einen schreibgeschützten Graphen vom Typ \texttt{IGraph<NamespaceMetricsReport>} zur Verfügung stellen zu können, ohne das ein neuer Graphen erzeugt werden muss, verwendet Usus.net eine Projektion des Knotentypen. Für diese Projektion wird ein Objekt vom Typ \texttt{GraphSurrogate<V, R>} verwendet, der das Interface \texttt{IGraph<V>} implementiert und einen Objekt vom Typ \texttt{IGraph<R>} kapselt. Die Knoten- und Kantenliste in diesem Typ werden über die Projektion von $R \rightarrow V$ also an den Zieltyp angepasst. Über diesen Adapter ist es möglich einen Graphen mit Knoten vom Typ \texttt{NamespaceMetricsWithTypeMetrics} als Graphen mit Knoten vom Typ \texttt{NamespaceMetricsReport} zu behandeln. Dies ist allerdings nur möglich, wenn es Abbildung von $R$ nach $V$ existiert. Da ein \texttt{NamespaceMetricsWithTypeMetrics}-Objekt den eigentlichen Namespace-Bericht sowie alle Klassenberichte in diesem Namespace enthält, ist die Abbildung einfach zu realisieren.


\section{Metrikgewichtung}
Nachdem in den vorherigen beiden Abschnitten beschrieben wurde, wie die Berechnung der Metriken funktioniert und in welcher Struktur das Ergebnis präsentiert wird, beschäftigt sich dieser Abschnitt mit der Weiterverarbeitung dieser Ergebnisse. Usus verwendet die Metriken beispielsweise für die in Unterabschnitt \ref{subsec:ususcockpit} vorgestellte Cockpit-Ansicht und in der in Unterabschnitt \ref{subsec:usushotspots} betrachteten Hotspots-Ansicht. Für diese beiden Ansichten werden die ermittelten Metriken gewichtet, mit Schwellwerten verglichen und Mittelwerte gebildet. Wie dies geschieht, wurde bereits in Unterabschnitt \ref{subsec:allprojectsmetrics} ausführlich beschrieben.
\subsection{Hotspots}
Hotspots sind Methoden, Klassen und Namespaces dessen Metriken über einer Schwelle liegen. Usus.net kann diese Hotspots in Form eines \texttt{MetricsHotspots}-Objekts aus einem \texttt{MetricsReport}-Objekt bestimmen. Listing \ref{listing:hotspots} zeigt dies in Zeile 1. Die Variable \texttt{metrics} enthält wieder eine Referenz zu einem \texttt{MetricsReport}-Objekt. Anschließend können alle Berichte der Methoden, Klassen und Namespaces ermittelt werden, dessen Metriken über den Schwellen liegen, die in Unterabschnitt \ref{subsec:allprojectsmetrics} erwähnt wurden.
\begin{lstlisting}[caption={Methoden-, Klassen- und Namespace-Hotspots in einem \texttt{MetricsReport}-Objekt},label={listing:hotspots}]
MetricsHotspots hotspots = metrics.Hotspots();
methodHotspots = hotspots.OfMethodLength();
classHotspots = hotspots.OfClassSize();
classHotspots = hotspots.OfCumulativeComponentDependency();
classHotspots = hotspots.OfNumberOfNonStaticPublicFields();
namespaceHotspots = hotspots.OfNamespacesInCycle();
\end{lstlisting}
Wenn wie beispielsweise in Zeile 2 alle \texttt{MethodMetricsReport}-Objekte bestimmt werden, dessen \texttt{MethodLength}-Eigenschaft über der definierten Schwelle liegt, iteriert Usus.net über alle Methoden im \texttt{MetricsReport}-Objekt. Dabei werden nur Berichte zurückgegeben, dessen Methodenlänge über dem Ergebnis der Schwellwertfunktion für Methodenlängen liegen. Die Schwellwerte der Metriken müssen nicht konstant sein. Der Schwellwert kann sich auch abhängig von der Projektgröße ändern, wie es beispielweise bei der durchschnittlichen kumulierten Komponentenabhängigkeit ACD der Fall ist (siehe Unter-Unterabschnitt \ref{subsubsec:acd}). Daher verwendet Usus.net das Konzept einer Schwellwertfunktion. Alle Schwellwertfunktionen können bei Bedarf auch zur Laufzeit geändert werden. Dafür lässt sich das \texttt{RatingFunctionLimits}-Objekt, welches die Funktionen definiert, über die statische Eigenschaft \texttt{RatingFunctions.Limits} erreichen. Listing \ref{listing:limitfunctions} zeigt die Deklaration und Definition der Schwellwertfunktionen für Methodenlänge und kumulierte Komponentenabhängigkeit mit Lambda-Ausdrücken.
\begin{lstlisting}[caption={Schwellwertfunktionen sind abhängig von Daten eines \texttt{MetricsReport}-Objekts},label={listing:limitfunctions}]
//Deklarationen
Func<CommonReportKnowledge, int> MethodLength { get; set; }
Func<CommonReportKnowledge, int> CumulativeComponentDependency { get; set; }
...
//Definitionen
MethodLength = ck => 9;
CumulativeComponentDependency = ck => ck.NumberOfClasses * 
	(1.5 / Math.Pow(2, (Math.Log(ck.NumberOfClasses) / Math.Log(5))));
...
\end{lstlisting}
Die Formel der Schwellwertfunktion \texttt{CumulativeComponentDependency} entspricht der bereits beschriebenen Formel \ref{eq:averagecomponentdependency4}. Alle Schwellwertfunktionen sind Abbildungen von einem Objekt vom Typ \texttt{CommonReportKnowledge} auf eine Ganzzahl. \texttt{CommonReportKnowledge} ist Teil des Objektmodells des vollständigen Metrikberichts und wurde bereits in Abbildung \ref{fig:metricsreport} gezeigt. Dieses Objekt enthält einige allgemeine Daten der Metrik-Analyse wie beispielsweise die Anzahl der analysierten Klassen und Namespaces.

\subsection{Statistiken}
Die Unterscheidung zwischen Metrik und Statistik der Metrik wurde bereits in Unterabschnitt \ref{subsec:staticcodeanalysis} definiert. Die Theorie, also wie diese Statistiken in Usus entstehen und berechnet werden können, wurde in Unterabschnitt \ref{subsec:allprojectsmetrics} vorgestellt. In Usus.net lassen sich die gleichen Werte über ein \texttt{RatedMetrics}-Objekt bestimmen, welches wie in Listing \ref{listing:statistics} in Zeile 1 gezeigt, über die \texttt{Rate}-Methode erzeugt werden kann. Die Variable \texttt{metrics} enthält wieder eine Referenz eines \texttt{MetricsReport}-Objekts.
\begin{lstlisting}[caption={Statistiken aller Berichte in einem \texttt{MetricsReport}-Objekt},label={listing:statistics}]
RatedMetrics statistics = metrics.Rate();
acd = statistics.AverageComponentDependency;
acs = statistics.AverageRatedClassSize;
acc = statistics.AverageRatedCyclomaticComplexity;
aml = statistics.AverageRatedMethodLength;
anf = statistics.AverageRatedNumberOfNonStaticPublicFields;
ncn = statistics.NamespacesWithCyclicDependencies;
\end{lstlisting}
Diese Statistiken entstehen durch eine Gewichtung der Methoden-, Klassen und Namespace-Berichte, die anschließend gezählt oder gemittelt werden. Die Berichte können auch unabhängig von einander gewichtet werden. Die \texttt{Rate}-Methode existiert für die einzelnen Berichte ebenfalls und erzeugt Objekte vom Typ \texttt{RatedMethodMetrics} für Methoden, \texttt{RatedTypeMetrics} für Klassen und \texttt{RatedNamespaceMetrics} für Namespaces. Tatsächlich ruft Usus.net diese Methode für jeden Bericht auf und speichert die dadurch erzeugten Objekte in einem \texttt{RatedMetrics}-Objekt. Dort können dann die Mittelwerte der einzelnen gewichteten Metriken als projektübergreifende Statistiken bestimmt werden. Sämtliche Gewichtungsfunktionen implementieren die Formeln aus Unterabschnitt \ref{subsec:allprojectsmetrics} und sind in der Klasse \texttt{RatingFunctions} definiert. Listing \ref{listing:statisticscalc} zeigt die Berechnung der der durchschnittlichen Methodenlänge in Zeile 1, der durchschnittlichen kumulierten Komponentenabhängigkeit in den Zeilen 2 bis 4 sowie der Anzahl der Namespaces mit zyklischen Abhängigkeiten in den Zeilen 5 bis 7.
\begin{lstlisting}[caption={Statistik-Berechnung in einem \texttt{RatedMetrics}-Objekt},label={listing:statisticscalc}]
AverageRatedMethodLength = RatedMethods.AverageAny(m => m.RatedMethodLength);
AverageComponentDependency = 
	RatedTypes.AverageAny(m => m.CumulativeComponentDependency) 
	/ metrics.CommonKnowledge.NumberOfClasses;
NamespacesWithCyclicDependencies = 
	RatedNamespaces.CountAny(m => m.IsInCycle) 
	/ metrics.CommonKnowledge.NumberOfNamespaces;
...
\end{lstlisting}
Obwohl die Berechnungen einfach lesbar sind, ist der Aufwand zur Bestimmung jeder Statistik $O(n)$. Für jede Statistik müssen alle Berichte des entsprechenden Typen berücksichtigt werden.

\section{Testen}
Nachdem in den vergagenen Abschnitten die Metrik-Analyse, das Objektmodell sowie die Statistiken von Usus.net erläutert wurden, beschäftigt sich dieser Abschnitt mit einer Möglichkeit Metriken mit Quellcode zu verbinden. !Usus.net.Core! stellt dafür eine Infrastruktur zur Verfügung, die in dieser Master-Thesis als !Verification Framework! bezeichnet wird. Das Verification Framework besteht aus einer Menge an Attributen, mit denen Methoden und Klassen dekoriert werden können. Diese Attribute beschreiben Erwartungen in Form von Metriken an die betroffene Methode oder Klasse.

//Beispiel mit Methode und Attribute
//Beispiel mit Klasse und Attribute

Diese Erwartungen können mithilfe der Methoden der Klasse !Verify! überprüft werden. Dazu ist ein !MetricReport!-Objekt erforderlich, welches auf einfache Weise mit !Analyse.Me()! ermittelt werden kann. !Verify! ermittelt dann alle Methoden und Klassen in der aktuellen Assembly, die mit einem solchen Attribut dekoriert sind und sucht anhand der Signatur oder des Klassennamen den entsprechenden Bericht. Anschließend werden die Erwartungswerte, die über die Konstruktoren der Attribute angegeben werden, mit den tatsächlichen Metriken verglichen. Im Falle einer Abweichung wird eine !VerificationException! geworfen. Auf diese Weise können Metrik-Vorraussetzungen erzwungen werden. Dadurch kann erreicht werden, dass eine Methode oder Klasse Bedingungn an die eigene Implementierung stellt, die in Form einer Vorbedinungn auf Metrik-Basis formuliert werden können. Eine unabsichtliche Verletzung dieser Bedingungen wird dann sofort offensichtlich. Außerdem sind die erwarteten Metriken bereits im Quellcode sichtbar.
\paragraph{}
Usus.net nutzt das Verification Framework um die eigene Metrikberechnung und das Objektmodell zu testen. So bestehen die Integrationstests von !Usus.net.Core! aus beispielhaften Klassen, dessen tatsächliche Metriken künstlich erzeugt und mit den erwarteten Werten der Attribute verglichen werden. Snd die Werte nicht kongruent schlagen die Testfälle fehl, die die !Verify!-Klasse verwenden und ein eventueller Fehler in der Metrikberechnung wurde gefunden. Entsprechen die tatsächlichen Metriken den Werten in den Attributen, laufen die Tests erfolgreich durch und bestätigen so die Berechnungen der Metriken. Die erwähnten Integrationstests befinden sich im Projekt !Usus.net.Core.IntegrationTests!. Ein weiterer Anwendungsfall ist ein Konzept, das in dieser Master-Thesis als !Metrics Meta Testing! bezeichnet wird. Damit sind Testfälle gemeint, die die Metriken von Testfällen testen. Zum Beispiel schreibt Roy Osherove in seinem Buch !bla bla bla!, dass Testmethoden keine Logik enthalten sollen. Eine solche Anforderung an Tests kann einfach mit einem !ExpectCyclomaticComplexity(1)!-Attribut an allen Tests sichergestellt werden. Eine spezielle Testmethode erzeugt das !MetricsReport!-Objekt des Testprojekts mit !Analyze.Me()! und ruft die entsprechende Methoden auf der !Verify!-Klasse auf. Dieser spezielle Testfall testet also, ob alle Testmethoden mit dem Attribut auch wirklich keine Logik enthalten. Ein anderes Beispiel wäre die Sicherstellung, dass kein Testfall von einem bestimmten Objekt der Implementierung abhängig ist. Dafür kann die Testklasse um das Attribut !ExpectNoDirectDependencie("...")! mit dem vollständingen Klassennamen erweitert werden. Eine spezielle Testmethode würde wieder die entsprechende Methode der !Verify!-Klasse aufrufen und damit fehlschlagen, sobald eine Methode in der Klasse von dem Typ in dem Attribut abhängig ist. Das Verification Framework dient also dazu die Metriken, die eigentlich implizit im Code existieren, offen zu legen und einen Fehler zu erzeugen wenn die Implementierung nicht mit den erwarteten Metriken übereinstimmt. Der Entwickler bekommt so die Gelegenheit über ein eventuell fehlerhaftes Verhalten der Implementierung zu reflektieren und ein ansonsten verstecktes Problem schnell zu beheben.




\chapter{Usus.net als Visual Studio Erweiterung}
todo






















\chapter{Clean Code Unterstützung}
todo


\section{Achievements System}
todo


\section{Fallbeispiel Andrena-Kurs}
todo




\chapter{Code-Qualität Bewertung}
todo


\section{Histogram}
todo


\section{Exponentialverteilungen}
todo


\section{Heuristiken}
todo


\section{Andrena Software Qualitäts Index}
todo




\chapter{Zusammenfassung}
todo




\chapter{Fazit}
todo









\bibliography{masterthesis}
\bibliographystyle{alpha}

\end{document}
