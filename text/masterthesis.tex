\documentclass[
a4paper, 							% Papierformat
%10pt,								% Schriftgröße (12pt, 11pt (Standard))
%twoside,							% Doppelseiten
titlepage,						% Titelei auf eigener Seite
%normalheadings,			% Überschriften etwas kleiner (smallheadings)
%idxtotoc,						% Index im Inhaltsverzeichnis
%liststotoc,					% Abb.- und Tab.verzeichnis im Inhalt
%bibtotoc,						% Literaturverzeichnis im Inhalt
%leqno,   						% Nummerierung von Gleichungen links
%fleqn,								% Ausgabe von Gleichungen linksbündig
%draft								% überlangen Zeilen in Ausgabe gekennzeichnet
]
{scrreprt}
\usepackage[ngerman]{babel}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tipa}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm,includeheadfoot]{geometry}
\usepackage{marvosym}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=blue,
    urlcolor=blue
}
\usepackage{mathtools}
\usepackage{listings} \lstset{numbers=left, numberstyle=\tiny, numbersep=5pt, basicstyle=\fontsize{9}{13}\selectfont, xleftmargin=1cm, xrightmargin=1cm, frame=topline} \lstset{language=Java}
\usepackage{shadethm}
\usepackage[table]{xcolor}

\newshadetheorem{definition}{Definition}
\newshadetheorem{stakeholder}{Interessenvertreter}
\newshadetheorem{goal}{Ziel}
\definecolor{shadethmcolor}{rgb}{.95,.95,.95}   % Farbe des Hintergrundes  
\definecolor{shaderulecolor}{rgb}{0.7,0.7,0.7}   % Farbe des Rahmens
\setlength{\shadeboxrule}{1.0pt}   % Breite des Rahmens

\begin{document}



\thispagestyle{empty}
\begin{titlepage}
\begin{figure}[t]
	\centering
  \includegraphics[width=80mm]{images/HsKaLogoKlein.png}
	\vspace{2.5cm}
\end{figure}
\begin{center}
\title{Master-Thesis}
\textbf{\huge{Master-Thesis}} \\[0.5cm]
\textbf{Visual Studio Erweiterung zur statischen Code-Analyse} \\[4cm]
\textbf{andrena objetcs ag} \\[0.25cm]
\author{Manuel Naujoks} Manuel Naujoks\\[2.5cm]
Betreut durch \\[0.25cm] 
Prof. Dr. Thomas Fuchß \\[2.5cm]
Bischweier, den \today
\end{center}
\end{titlepage}



\pagenumbering{roman}
\setcounter{page}{1}
\begin{center}\textbf{\large Erklärung}\\[1cm]\end{center}
Hiermit versichere ich, dass ich die vorliegende Arbeit selbstständig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe, dass alle Stellen der Arbeit, die wörtlich oder sinngemäß aus anderen Quellen übernommen wurden, als solche kenntlich gemacht sind und dass die Arbeit in gleicher oder ähnlicher Form noch keiner Prüfungsbehörde vorgelegt wurde.
\\[4\baselineskip]
Bischweier, den \today \\
Manuel Naujoks
\newpage



\chapter*{Zusammenfassung}
Im Rahmen dieser Master-Thesis soll eine Visual Studio Erweiterung entwickelt werden, die direktes Entwickler-Feedback anhand von Software-Metriken geben kann. Dabei dient das Plugin Usus für Eclipse als Vorlage, welches bereits existiert. Die zu erstellende Erweiterung soll eine statische Code-Analyse von .NET-Projekten in Visual Stuido 2010 durchführen und für andrena relevante Code-Metriken berechnen können.
\newline
Die zu entwickelnde Erweiterung soll genutzt werden können, um Software-Entwickler aktiv zu unterstützen "`Clean code"' zu schreiben. Eine ähnliche Lösung zu Microsofts Achievements Extension mit Achievements in Bezug auf clean code best practices wäre denkbar. Dazu soll eine Evaluierung anhand von Beispielaufgaben aus einem andrena-Kurs zum Thema Refaktorisierung bearbeitet und die Veränderung in den Metriken entsprechend erfasst und dokumentiert werden.
\newline
Weiterhin soll in einer Metrik-Analyse nach Heuristiken oder Regeln mit statischer Signifikanz gesucht werden, die eventuell guten von schlechtem Code unterscheiden können. Lassen sich hier Muster beziehungsweise Strukturen aufzeigen? Ein Indiz hierfür ist, dass die Metriken oft einer Exponentialverteilung folgen. Dabei soll untersucht werden, ob und wenn möglich wie sich dies auf den Software Qualitäts Index (SQI) von andrena abbilden lässt.
\newpage



\chapter*{Abstract}
Objective of this master thesis is the development of a Visual Studio Extension that is capable of providing direct development feedback based on software metrics. The Eclipse plugin Usus, which already exists, is going to be used as orientation. The extension that is developed shall be able to perform static code analysis of .NET projects in Visual Studio 2010 in order to calculate the code metrics that are relevant for andrena.
\newline
As far as feedback is concerned, the extension shall be able to actively support developers to write "`clean code"'. A similar solution to Microsofts Achievements Extension could likely be found with achievements based on common clean code best practices. Therefore an evaluation with sample exercises of an andrena course on the topic of refactoring is done and the variation in the metrics is detected and documented.
\newline
Another metric analysis is performed in order to find heuristics or rules with static significance, which might be able to distinguish good code from bad code. Are there detectable patterns? One thing might be that metrics often follow an exponential distribution. An analysis shall show whether it is possible and if yes, how this can be mapped to the Software Quality Index (SQI) of andrena.
\newpage




\tableofcontents




\chapter{Einführung}
\pagenumbering{arabic}
\setcounter{page}{1}
\textcolor[rgb]{1,0,0}{bla bla bla Softwarequalität
bla bla bla Metriken
bla bla bla Entwicklerfeedback
bla bla bla Übersicht über Codebasis
bla bla bla direkt in Visual Studio
bla bla bla}

\section{andrena objects ag}
\label{sec:andrena}
Diese Master-Thesis wird bei dem Software-Unternehmen andrena objects ag durchgeführt. 
\textcolor[rgb]{1,0,0}{bla bla bla.}

\section{Aufbau der Thesis}
\textcolor[rgb]{1,0,0}{bla bla bla.}




\chapter{Grundlagen}
\label{chap:basics}
In diesem Kapitel sollen die Grundlagen vermittelt werden, die für ein Verständnis einer mit Quellcode arbeitenden Erweiterung für Visual Studio erforderlich sind. Dazu wird in Abschnitt \ref{sec:generalbasics} zunächst auf allgemeine Grundlagen wie Quellcode, sowie Entwicklungsumgebungen eingegangen. Anschließend werden in Abschnitt \ref{sec:technicalbasics} die technischen Grundlagen vorgestellt.


\section{Allgemeine Grundlagen}
\label{sec:generalbasics}
In diesem Abschnitt wird zunächst auf die Clean Code Idee von Robert C. Martin sowie einige seiner Prinzipien eingegangen. Anschließend werden die beiden Entwicklungsumgebungen Eclipse und Visual Studio vorgestellt. Beide Programme sind in dieser Master-Thesis von Bedeutung, da die zu entwickelnde Erweiterung bereits für Eclipse existiert und für Visual Studio ebenfalls erstellt werden soll.

\subsection{Clean Code}
\label{subsec:cleancode}
Ein Softwaresystem wird in Form von Quellcode erstellt. Dieser Code wird anschließend kompiliert um eine ausführbares Programm zu erhalten. Robert C. Martin beschreibt Code in seinem Buch "`Clean Code"' als Sprache, in der wir die Anforderungen an die Software maschinenlesbar zum Ausdruck bringen \cite{CleanCode}. Weiter beschreibt er in seinem Buch auch Prinzipien und Best Practices, die das Erstellen von verständlicherem und wartbareren Quellcode unterstützen. Die selben Prinzipien wurden auch von Ralf Westphal und Stefan Lieser aufgegriffen und im Rahmen eines Wertesystems mit sieben Graden vorgestellt \cite{CleanCodeDeveloper}. Martin's "`Clean Code"' Buch bleibt auch für Westphal und Lieser die grundlegende Lektüre.
\paragraph{}
Die Prinzipien und Best Practices der Clean Code Bewegung umfassen viele Aspekte, die bereits durch Kent Beck in seinem Buch über die Methodik \textit{Extreme Programming} (XP) \cite{XP} eingeführt wurden. Drei wichtige Bestandteile von XP, die ebenfalls in den Graden des Clean Code Wertesystems von Westphal und Lieser auftreten, werden jetzt wie folgt definiert.
\begin{definition}[Automatisiertes Testen]
Automatisiertes Testen ist eine der wichtigsten Praktiken in der Clean Code Bewegung. Nach Robert C. Martin ist es die Aufgabe eines Entwicklers keinen Schaden in einem Softwaresystem anzurichten. Damit meint er Schaden an der Funktionalität und Schaden an der Struktur der Anwendung. Beides kann mit automatisierten Testfällen sichergestellt werden.
\end{definition}
\begin{definition}[Ständiges Refactoring]
Ständiges Refactoring ist der effektivste Schutz gegen Schaden an der Struktur eines Softwaresystems bedingt durch evolutionäres Wachstum und vielen Anpassungen. Durch Tests kann dabei sichergestellt werden, dass Umstrukturierungen den Funktionsumfang nicht beeinträchtigen. Martin Fowler beschreibt ein solches Refactoring in seinem Buch \cite{Refactoring}.
\end{definition}
\begin{definition}[Schnelle Code Reviews]
Schnelle Code Reviews sind eine weitere Voraussetzung um Clean Code entwickeln zu können. Der entscheidende Punkt ist das Feedback. Je schneller der Entwickler Feedback bekommt um so früher können Probleme im Quellcode erkannt und mit relativ wenig Aufwand korrigiert werden.
\end{definition}

\subsection{Eclipse}
\label{subsec:eclipse}
Eclipse\footnote[1]{"`Eclipse - The Eclipse Foundation open source community website"' \url{http://www.eclipse.org/}} ist eine integrierte Entwicklungsumgebung (IDE) der Eclipse Foundation. Die Anwendung ist eine kostenfreies open source Programm und wird hauptsächlich für die Entwicklung von Software mit der Programmiersprache Java\footnote[2]{"`Oracle and Java"' \url{http://www.oracle.com/us/technologies/java/index.html}} verwendet. Eclipse unterstützt externe Erweiterungen in Form von Plugins.

\subsection{Visual Studio}
\label{subsec:visualstudio}
Visual Studio\footnote[3]{"`Die Microsoft Visual Studio 2010 Produktfamilie"' \url{http://www.microsoft.com/germany/visualstudio/products/default.aspx}} ist eine integrierte Entwicklungsumgebung von Microsoft. Im Gegensatz zu Eclipse ist Visual Studio ab der Professional Version ein kommerzielles Produkt. Die Entwicklung für das .NET-Framework\footnote[4]{"`Microsoft .NET Framework"' \url{http://www.microsoft.com/net}} von Microsoft kann mit Visual Studio durchgeführt werden, wobei mehrere Programmiersprachen unterstützt werden. Zu den bekanntesten und am weitesten verbreiteten Sprachen für das .NET-Framework zählen C\# und Viusal Basic.NET.
\paragraph{}
Visual Studio erlaubt die Installation von externen Erweiterungen als Addin oder Erweiterung ab der Professional Version. Die kostenfreie Express Edition besitzt einen sehr eingeschränkten Funktionsumfang. Der Unterschied zwischen einem Visual Studio Addin und einer Visual Studio Erweiterung ist der, dass Addins bereits in früheren Versionen unterstützt wurden und ein Entwickler die Schnittstellen in Visual Studio direkt anprogrammieren kann. Die Erweiterungen werden ab Visual Studio 2010 unterstützt und benötigen zur Entwicklung das \textit{Visual Studio 2010 SDK}\footnote[5]{Download: "`Visual Studio 2010 SP1 SDK"' \url{http://www.microsoft.com/download/en/details.aspx?id=21835}}, erlauben aber eine modernere Klassenbibliothek. Aaron Marten beschreibt in seinem Artikel \cite{VSCustomExtensions} die Möglichkeiten, wie mit der neuen Erweiterungstechnologie (VSIX) Addin-ähnliche Erweiterungen erstellt werden können.


\section{Technische Grundlagen}
\label{sec:technicalbasics}
In diesem Abschnitt werden die technischen Grundlagen erläutert. Dazu wird zunächst der Begriff der Objektorientierung eingeführt, da sämtliche Software-Systeme, die in dieser Master-Thesis betrachtet werden, obejktorientiert sind. Anschließend werden Graphen und Bäume beschrieben, da verschiedene Software-Metriken anhand dieser Datenstruktur berechnet werden können. Abschließend wird das Konzept der statischen Code-Analyse vorgestellt, da die zu entwickelnde Erweiterung eben diese durchführen können soll.

\subsection{Objektorientierung}
\label{subsec:oo}
Die Objektorientierung als Methode ermöglicht laut Benrd Oestereich die hohe Komplexität von Softwaresystemen zu beherrschen \cite{OOSE}. Das ist möglich, da diese Methode die Dinge der realen Welt als Objekte sieht und dadurch die Problemdomäne verständlich und anschaulich macht. Ein objektorientiertes Softwaresystem besteht aus fünf wesentlichen Komponenten, die jetzt wie folgt definiert werden.

\begin{definition}[Klasse]
Klasse kommt aus dem lateinischen von \emph{classis} und bedeutet "`Aufgebot"'. Damit ist laut Oestereich eine Teilmenge von Objekten der gleichen Struktur gemeint. Eine Klasse ist folglich auch der Typ aller seiner Objekte. Klassen können auch abstrakt sein. Eine abstrakte Klasse, oder auch genannt Schnittstelle, kann nicht als Objekt erzeugt werden. Eine nicht abstrakte Klasse, also eine konkrete Klasse, muss von dieser Klasse eine Vererbung der Struktur und des Verhaltens durchführen. Von dieser erbenden und konkreten Klasse kann dann ein Objekt erzeugt werden, das sowohl vom Typ der konkreten Klasse als auch vom Typ der abstrakten Klasse ist.
\end{definition}
\begin{definition}[Objekt]
Objekt kommt ebenfalls aus dem lateinischen von \emph{obicere} und bedeutet "`entgegenhalten"'. Bernd Oestereich beschreibt es als "`Gegenstand der Erkenntnis und Wahrnehmung, des Denkens und Handelns"' und bezieht sich dabei auf das Brockhaus Lexikon. Ein Objekt ist eine Instanz einer Klasse.
\end{definition}
\begin{definition}[Attribut]
Attribut kommt auch aus dem lateinischen von \emph{attributum} und bedeutet "`das Beigefügte"', was einer Eigenschaft oder einem Kennzeichen einer Sache entspricht. Die Daten, die ein Objekt ausmachen, werden anhand von Attributen gespeichert, auf die von den Operationen des Objekts aus zugegriffen werden kann. Attribute werden auch als Felder bezeichnet und lassen sich in Klassen-Felder und Instanz-Felder unterscheiden. Klassen-Felder können von allen Objekten der Klasse gemeinsam genutzt werden, während Instanz-Felder unterschiedliche Werte für konkrete Objekte haben können.
\end{definition}
\begin{definition}[Operation]
Operation kommt aus dem lateinischen von \emph{operatio} und bedeutet "`Handlung"'. Eine konkrete Aktion, die anhand einer definierten Vorschrift durchgeführt wird bezeichnet Oestereich in diesem Sinne als Operation. Das Verhalten von Objekten wird anhand ihrer Operationen festgelegt. Andere Bezeichnungen für Operation ist Funktion oder Methode. Methoden lassen sich in Klassen-Methoden und Instanz-Methoden aufteilen. Klassen-Methoden können nicht auf die Instanz-Felder sondern nur auf die Klassen-Felder zugreifen. Instanz-Methoden können auf Instanz-Felder und auf Klassenfelder zugreifen.
\end{definition}
\begin{definition}[Paket]
Paket wird von Oestereich als eine Ansammlung von Modellelementen bezeichnet. Dabei sind Modellelemente Klassen oder andere Pakete und dienen der besseren Strukturierung des Systems. Pakete werden auch als Namensräume bezeichnet, da sie eine benannte Zusammenfassung von Klassen und anderen Namensräumen sind.
\end{definition}
Zusätzlich beschreibt Oerstereich zwei weitere Mittel von objektorientierten Softwaresystemen, die der Abstraktion dienen und die es erlauben irrelevant Dinge wegzulassen. Beide Konzepte werden jetzt ebenfalls definiert.
\begin{definition}[Assoziation]
Assoziation kommt aus dem lateinischen von \emph{associare} und bedeutet "`verbinden"'. Nach Oestereich entspricht dies einer \emph{Hat-eine-Beziehung} und gibt an, dass eine Klasse mit einer anderen Klasse zusammenarbeitet. Objekte der Klasse können auf Objekte der verbundenen Klasse zugreifen. Damit ist die Klasse, von der die Assoziation ausgeht, von der anderen Klasse abhängig. Anders ausgedrückt hat diese Klasse eine Abhängigkeit von der anderen.
\end{definition}
\begin{definition}[Vererbung]
Vererbung entspricht einer \emph{Ist-ein-Beziehung} und gibt an, dass eine Klasse das Verhalten und die Struktur einer anderen Klasse erbt oder spezialisiert. Ein Objekt der erbenden Klasse ist damit auch ein Objekt der gerbten Klasse und hat somit auch eine Abhängigkeit von ihr.
\end{definition}
Mit diesen sieben Konzepten kann eine Softwaresystem objektorientiert beschrieben werden.

\subsection{Graphentheorie}
\label{subsec:graphs}
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben einen Graph in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} als Tupel \begin{math}G = (V, E)\end{math}. Der erste Wert, $V$, ist eine endliche Menge an Knoten und der zweite, $E$, ist eine endliche Menge an Kanten zwischen diesen Knoten. Eine Kante ist ein Paar aus \begin{math}V \times V\end{math} und beinhaltet die beiden Knoten, die sie verbindet. Cormen und co unterscheiden in gerichtete und ungerichtete Graphen. Bei letzterem verbindet eine Kante die Knoten in beiden Richtungen, wobei eine gerichtete Kante die Verbindungsrichtung anhand der Knoten-Reihenfolge im Kanten-Tupel vorgibt. Ein gerichteter Graph wird auch als Digraph bezeichnet. Weiter definieren Cormen und seine Koautoren einen Baum als zusammenhängenden azyklischen Graph, indem jeder Knoten von einem Wurzelknoten aus erreichbar ist. %Seite 1168, 1173

\subsection{Statische Code-Analyse}
\label{subsec:staticcodeanalysis}
Artur Wagner beschreibt in seiner Seminar-Ausarbeitung \cite{IntroStaticCodeAnalysis} die statische Codeanalyse als Prozess, der von einem Programm ähnlich einem Compiler gestartet wird. Dieses Programm führt den Code nicht aus und erzeugt auch keinen ausführbaren Code, sondern ein nimmt eine Analyse vor. Wagner erwähnt noch, das eine statische Code-Analyse keinen Korrektheitsnachweis liefert sondern lediglich eine Art Systemzusammenfassung erzeugt. Eine solche Analyse des Codes findet dabei automatisiert statt. Christof Ebert, Reiner Dumke, Manfred Bundschuh und Andreas Schmietendorf stellen ebenfalls den Vergleich mit einem Compiler an. In ihrem Buch \cite{BPSoftwareMeasurement} erwähnen sie zusätzlich noch ein Qualitätsmodell, das mit dem Analyseergebnis in Verbindung gebracht wird und so eine einfache Interpretierbarkeit des analysierten Systems ermöglicht. Zusätzlich beschreiben sie den Vorgang als Sammeln von Metriken und deren Bewertung anhand von Kriterien.
\paragraph{}
Nadine Vehring beschreibt eine \emph{Metrik} in ihrer Seminar-Ausarbeitung \cite{TestabilityMetrics} als Maß dafür, wie sehr eine \emph{Entität} ein \emph{Attribut} erfüllt. Als \emph{Entität} bezeichnet Vehring einen Teil des analysierten Systems, also beispielsweise eine Methode, Klasse oder eine Menge von Klassen. Weiterhin beschreibt sie ein \emph{Attribut} als Eigenschaft, die im betrachteten System, also bei den \emph{Entitäten} gemessen werden soll. In der vorliegenden Master-Thesis wird der Metrik-Begriff wie folgt definiert.
\begin{definition}[Metrik]
Die Metrik ist der Begriff für eine bestimmte und tatsächlich gemessene Eigenschaft die Methoden, Klassen, Paketen oder Mengen von Klassen im zu analysierenden System besitzen. Er entspricht damit dem direkten Ergebnis einer statischen Code-Analyse. Dieser Begriff wird manchmal Synonym für die Eigenschaft verwendet, die gemessen werden soll.
\end{definition}
\begin{definition}[Statistik der Metrik]
Die Statistik der Metrik ist die Bezeichnung für die zusammengefassten Werte aller Komponenten im System, für die eine bestimmte Metrik ausgerechnet werden kann. Zusätzlich können Metriken vor und nach der Aggregation gewichtet und bewertet werden. Ob ein Wert in einer Statistik berücksichtigt wird kann ebenfalls festgelegt werden. Marc Philipp und Nicole Rauch unterscheiden Metrik und Statistik in ihrem Artikel \cite{EclipseMagUsus} ebenfalls.
\end{definition}
Die Metriken eines Systems können auch manuell bestimmt werden. In dieser Master-Thesis werden Metriken aber immer als automatisiert bestimmbar und damit als Ergebnis einer automatisierten statischen Code-Analyse betrachtet. Das Konzept der statische Code-Analyse kann auch genutzt werden, um subjektive explizite Probleme im Code zu lokalisieren, wie beispielsweise die Verwendung von obsoleten Klassen und Methoden, sowie fehlende Klassenkommentare. In dieser Master-Thesis wird die statische Code-Analyse ausschließlich für die Bestimmung der Metriken genutzt.




\chapter{Anforderungen}
\label{chap:requirements}
In diesem Kapitel werden die Anforderungen an die Visual Studio Erweiterung zur statischen Code-Anaylse beschrieben, die im Rahmen dieser Master-Thesis entwickelt werden soll. Dabei werden die Anforderungen in einem agilen Kontext bestimmt und in Form von Sprint 0 wie in Scrum definiert\footnote[1]{Agile Anforderungsanalyse in Scrum: "`10 Things to do in Sprint 0"' \url{http://www.pmscrum.com/blog/2011/06/10-things-do-sprint-0}}. Dieses Kapitel gibt damit eine Antwort auf die Frage, was während dieser Master-Thesis gemacht werden soll.


\section{Interessenvertreter}
\label{sec:stakeholder}
Die Interessenvertreter (engl. \textit{Stakeholder}) im Kontext dieser Master-Thesis sind Gruppen von Personen, die einen Einfluss auf Anforderungen des Systems haben können. Die folgenden vier Gruppen wurden dafür identifiziert.
\begin{stakeholder}[andrena objects ag] Als Arbeitgeber stellt andrena das Umfeld dar, indem das Projekt durchgeführt und das System implementiert wird. Sie legt Wert auf agile Softwareentwicklung und möchte Entwicklungsprozesse und Praktiken gewinnbringend einsetzen. Die andrena objects ag hat bereits ein Plugin zur statischen Code-Analyse für Java und Eclipse entwickelt und möchte ihren Entwicklern ein ähnliches Programm auch für die .NET-Umgebung zur Verfügung stellen können.
\end{stakeholder}
\begin{stakeholder}[Leser dieser Thesis] Die Leser der vorliegenden Thesis haben ebenfalls ein Interesse an dem zu entwickelnden Produkt, das hauptsächlich theoretischer Natur ist. Sie haben einen Informatik-artigen Hintergrund und möchten einen Einblick in die Algorithmen und die Implementierungsdetails sämtlicher implementierten Aspekte des Systems erhalten.
\end{stakeholder}
\begin{stakeholder}[.NET-Entwickler mit wenig Erfahrung] Entwickler mit wenig Erfahrung arbeiten an kleineren Codebasen und wollen auf einfache Weise einen Überblick über Problemfälle des Systems behalten. Mithilfe des Systems wollen sie diese rechtzeitig beseitigen und sicherstellen, dass dadurch keine neuen Probleme entstehen.
\end{stakeholder}
\begin{stakeholder}[.NET-Entwickler mit viel Erfahrung] Entwickler mit viel Erfahrung arbeiten an großen und komplizierten Codebasen und möchten das System einsetzen um Tendenzen im System zu erkennen und Spezialfälle zu analysieren. Auch sie wollen einen besseren Überblick erhalten und das System aus möglichst vielen verschiedenen Perspektiven sehen.
\end{stakeholder}
\begin{stakeholder}[.NET, Clean Code-Entwickler] Clean Coder legen sehr viel Wert auf Quellcode, der möglichst einfach zu verstehen ist und damit schnell an neue Anforderungen angepasst werden kann. Sie erwarten von dem System Feedback und Unterstützung bei der Entwicklung von sauberem Code. Außerdem möchten sie auf Stellen im Code hingewiesen werden, die nicht ihren Vorstellungen entsprechen.
\end{stakeholder}
Die Beschreibungen der Interessengruppen sind grob und allgemein gehalten, während versucht wurde, die direkten Bedürfnisse der jeweiligen Gruppe zu benennen. Natürlich ist die Erklärung damit nicht vollständig oder exklusiv. So kann beispielsweise auch ein erfahrener .NET-Entwickler ein Interesse an Clean Code haben.


\section{Ziele}
\label{sec:goals}
Nachdem die beteiligten Interessengruppen definiert wurden, werden in diesem Abschnitt die Ziele des zu entwickelnden Systems beschrieben. Peter Hruschka und Chris Rupp erklären in ihrem Buch \cite{AgileSEUML} ein Ziel als "`ein erstrebenswerter Zustand"' in der Zukunft, den es zu erreichen gilt\footnote[1]{Seite 26}. Damit ist ein Ziel eine abstrakte Form einer Anforderung an das System, die sich auch in einem agilen Projekt nicht so schnell ändert wie spezielle Anforderungen. In der vorliegenden Arbeit werden nun die folgenden vier Ziele definiert.
\begin{goal}[Einsicht in die Codebasis]
Große Entwicklungsprojekte haben eine große Codebasis, die es den Entwicklern erschwert Aussagen über den Quellcode des Systems zu machen. Mithilfe statischer Code-Analyse kann eine Einsicht in diesen Quellcode gewährleistet und so zum Vorteil aller Interessenvertreter genutzt werden. Eigenschaften des Quellcodes werden als können als Metriken berechnet und bewertet werden. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Eigenschaften des Codes erkennen und darauf reagieren kann.
\end{goal}
\begin{goal}[Erkennen von Problemfällen]
In einer vorhandenen Codebasis besteht die Gefahr, den Überblick über Problemfälle zu verlieren. Ein Problem kann beispielsweise eine Klasse sein, die zu viele Abhängigkeiten zu anderen Klassen hat, oder eine Methode, die zu viel Funktionalität besitzt. Das Erkennen und Anzeigen dieser Stellen ist ein Vorteil, von dem alle Interessenvertreter profitieren können, und der es ermöglicht, Schwachstellen systematisch zu entfernen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, Probleme im Code erkennen und darauf reagieren kann.
\end{goal}
\begin{goal}[Förderung von Clean Code]
Das Entwickeln von Code kann auf eine sehr rücksichtslose Art und Weise geschehen, sodass spätere Anpassungen nur schwer vorzunehmen sind. Durch Feedback und Unterstützung während der Programmierung kann die Entwicklung von Clean Code gefördert werden, was zu einer Codebasis führt, die flexibler auf Anpassungen reagieren kann. Dieses Ziel ist erreicht, sobald ein Entwickler mehr Clean Code Praktiken beachtet und einhält, als er dies ohne Unterstützung des Systems getan hätte.
\end{goal}
\begin{goal}[Interpretation der Software-Qualität]
Eine bestehende Codebasis zu bewerten erfordert detaillierte Kenntnis über alle Klassen, deren Interaktionen und vielem mehr. Außerdem muss eine menschliche Bewertung manuell jedes mal neu erfolgen, ist subjektiv und fehleranfällig. Eine teilweise automatisierte Interpretation anhand von Regeln und Gewichtungen, die auf Erfahrungen basieren, kann die menschliche Bewertung optimieren und einem Entwickler jederzeit mit verhältnismäßig geringem Aufwand eine Qualitätsinterpretation ermöglichen. Dieses Ziel ist erreicht, sobald ein Entwickler, der die Codebasis nicht oder nur unzureichend kennt, die Qualität des Quellcodes durch Interpretation einschätzen und mit anderen Systemen vergleichen kann.
\end{goal}


\section{Architektur}
\label{sec:architecture}
In diesem Abschnitt wird die grundlegende Architektur des zu entwickelnden Systems erläutert. Im Rahmen dieser Master-Thesis soll ein System entwickelt werden, dass die in Abschnitt \ref{sec:goals} genannten Ziele erreicht. Zusätzlich soll dieses System als Erweiterung in Visual Studio laufen und den Quelltext (kompiliert und/oder unkompiliert) in einer .NET-Sprache, wie beispielsweise C\#, analysieren. Abbildung \ref{fig:architecture} zeigt die beiden Komponenten \emph{Visualisierung} und \emph{statische Code-Analyse}, um die es sich im weiteren Verlauf handeln wird.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/architektur.jpg}
	\caption{Grobe Architektur des zu entwickelnden Systems}
	\label{fig:architecture}
\end{figure}
Die Komponente, die die statische Code-Analyse durchführt, verwendet drei Aktionen, die einem kompletten Analyse-Prozess entsprechen. Die schwarzen Pfeile symbolisieren dabei Zugriffe auf Daten. Die Aktion \emph{Berechnung} betrachtet das Softwaresystem und kann dafür auf den Quellcode und das erzeugte Kompilat zugreifen. Das Ergebnis dieser Betrachtung wird in Form von Metriken in einer Datenbank gespeichert und stellt Daten für die Aktion \emph{Gewichtung} bereit. Diese gewichtet die Daten und erzeugt Statistiken, die ebenfalls in der Datenbank hinterlegt werden. Die Aktion \emph{Bewertung} versucht anhand der gewichteten Daten eine Aussage über die Qualität des Softwaresystems zu treffen. Nachdem diese drei Aktionen abgelaufen sind, ist der Analyse-Prozess beendet. Die Komponente \emph{Visualisierung}, die in Visual Studio ausgeführt wird, kann diesen Analyse-Prozess starten und auf dessen Daten zugreifen. Sie zeigt die berechneten Metriken in geeigneten Kontexten an und gibt basierend auf der Bewertung ein entsprechendes Entwickler-Feedback. Dieses Feedback entsteht dabei genau dort, wo der Quellcode entstanden ist, der von dem Analyse-Prozess verarbeitet wurde. Nach einer entsprechenden Veränderung des Quelltext kann der Prozess erneut gestartet werden, um auch diese Veränderung zu analysieren. So entsteht theoretisch ein kontinuierlicher Verbesserungskreislauf. Dieser Zyklus wird durch die breiten transparenten Pfeile angezeigt und entspricht dem Informationsfluss in dieser Umgebung.


\section{Use Cases}
Aus den in Abschnitt \ref{sec:goals} definierten Zielen dieses Projekts lassen sich zunächst vier Anwendungsfälle bestimmen, die in Abbildung \ref{fig:usecases} dargestellt sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/usecases.jpg}
	\caption{Anwendungsfälle des zu entwickelnden Systems}
	\label{fig:usecases}
\end{figure}
Die Akteure entsprechen ungefähr den in Abschnitt \ref{sec:stakeholder} definierten Interessenvertretern. Alle Akteure sind .NET-Entwickler und unterscheiden sich durch ihr Interesse. .NET-Entwickler mit \emph{Interesse an Metriken} entspricht ungefähr dem Interessenvertreter mit wenig .NET Erfahrung. Seine Interaktion mit dem System beschränkt sich auf die Bestimmung von Code-Metriken sowie der Identifizierung von Code-Problemen als Verletzung definierter Metrik-Grenzen. Der Interessenvertreter mit viel Erfahrung findet sich im Entwickler-Akteur mit \emph{Interesse an Qualitätsinterpretation} wieder. Er benutzt das System um eine Interpretation der Qualität zu erhalten, die anhand der Code-Metriken vorgenommen wird. Der Akteur .NET-Entwickler mit \emph{Interesse an Clean Code} ist an den Interessenvertreter Clean Coder angelehnt. Er lässt sich durch das System bei der Erzeugung von Clean Code, wie er in Unterabschnitt \ref{subsec:cleancode} beschrieben wurde, unterstützen. Diese Hilfestellung geschieht anhand der Code-Probleme, die durch Code-Metriken erkannt werden. Es ist ebenfalls zu sehen, dass der Anwendungsfall \emph{Code-Metriken bestimmen} alle anderen Anwendungsfälle direkt oder indirekt ergänzt. Damit ist er ein entscheidender Bestandteil des Systems, wenn nicht sogar der wichtigste. Die Interessenvertreter \emph{andrena objects ag} und \emph{Leser des Thesis} haben keine direkte Interaktion mit dem System und werden bei der Betrachtung der Use Cases ignoriert. 


\section{Produkt-Backlog}
\label{sec:productbacklog}
Die Anwendungsfälle lassen sich in User Stories (\emph{Anwendererzählungen}) unterteilen. Abbildung \ref{fig:productbacklog} zeit diese Aufteilung in der horizontalen und die Verteilung auf geplante Sprints in der vertikalen Dimension. Dieses zwei-dimensionale Backlog stellt die konkreten Anforderungen aus Benutzersicht an das komplette System dar.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/backlog.jpg}
	\caption{Produkt-Backlog des zu entwickelnden Systems}
	\label{fig:productbacklog}
\end{figure}
Die User Stories sind allgemein gehalten, da auf ein großes Design vor der Implementierung aus Agilitätsgründen verzichtet wurde. Pro Sprint werden die User Stories dann in konkrete Entwicklungs-Aufgaben unterteilt. Die Begründung jeder Story wurde nicht explizit aufgeschrieben, da die Beziehung zu den Use Cases und damit den Zielen aus Abschnitt \ref{sec:goals} erhalten und somit offensichtlich geblieben ist. Eine Priorisierung ist ebenfalls implizit durch das Aufteilen auf die Sprints entstanden, sodass eine explizite Business Value Analyse nicht notwendig ist. Da die Entwicklungsgeschwindigkeit noch nicht bekannt ist, ist die Sprint-Planung vorläufig. Eine Änderung kann also jederzeit erfolgen, wenn neue Use Cases und User Stories dazukommen, andere wegfallen oder nicht alle in einem Sprint geschafft werden. Zum Zeitpunkt dieser Planung lassen sich die bereits gefunden User Stories in schätzungswiese fünf Sprints implementieren. 
\paragraph{}
Was die Abnahmekriterien jeder Anwendererzählung betrifft, so wurde auch hier kein Mehrwert in der expliziten Definition gesehen. Pro Story kann ohne viel Aufwand ein exemplarischer manueller Akzeptanztest durchgeführt werden, der zeigt, ob das Ziel erreicht wurde. Zusätzlich können automatisierte Akzeptanztests zu Beginn des jeweiligen Sprints festgelegt werden.




\chapter{Vorgehensweise}
Nach dem die Anforderungen an das System, das in dieser Masther-Thesis entwickelt werden soll, in Kapitel \ref{chap:requirements} definiert wurden, wird in diesem Kapitel die grobe Vorgehensweise beschrieben. Dabei wird eine grobe Zeitplanung vorgestellt. Dieses Kapitel gibt damit eine Antwort auf die Frage, wann die Anforderungen realisiert werden sollen. Abbildung \ref{fig:plan_table} zeigt die zeitliche Aufteilung der Master-Thesis, während Abbildung \ref{fig:plan_gantt} das dazugehörige Gant-Chart darstellt. Die Thesis besteht aus einem praktischen und einen theoretischen Teil. Beide Teile überlagern sich, sodass eine Dokumentation der Implementierung zeitnah erfolgen kann und keine große Schreibphase gegen Ende des sechsmonatigen Zeitrahmen notwendig ist.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planningTable.png}
	\caption{Projektplan Tabelle}
	\label{fig:plan_table}
\end{figure}
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/planningGantt.png}
	\caption{Projektplan Gantt-Chart}
	\label{fig:plan_gantt}
\end{figure}


\section{Praktischer Teil}
Der praktische Teil besteht aus einer Evaluationsphase und der eigentlichen Implementierungsphase. Während der Evaluierung werden verschiedene Technologien betrachtet, mit denen eine statische Code-Analyse durchgeführt werden kann. Das Ergebnis der Evaluierung wird die Grundlage der nächsten Phase darstellen. In der zweiten Phase werden die User Stories aus Abschnitt \ref{sec:productbacklog} im Rahmen der Visual Studio-Erweiterung zur statischen Code-Analyse in fünf zweiwöchigen (10 Tage) Sprints implementiert.


\section{Theoretischer Teil}
Der theoretische Teil entspricht hauptsächlich der Dokumentation aller Ergebnisse und deren Beschreibung in Form der schriftlichen Ausarbeitung dieser Master-Thesis. So werden in einer Planungsphase zunächst Grundlagen (Kapitel \ref{chap:basics}) beschrieben, sowie eine agile Anforderungsanalyse (Kapitel \ref{chap:requirements}) durchgeführt. Außerdem wird das Usus-Programm, dessen Funktionsumfang einen maßgeblichen Einfluss auf das zu entwickelnde System haben soll, näher betrachtet und dessen Metriken beschrieben (Kapitel \ref{chap:usus}). Anschließend soll das Ergebnis der Evaluierungsphase beschrieben werden (Kapitel \ref{chap:techeval}), bevor die tatsächlichen Sprints in Form von zwei-tägigen schriftlichen Zusammenfassungen abgeschlossen werden. Nach der Zusammenfassung des vierten Sprints soll eine Fallstudio auf Basis eines andrena Kurs zum Thema Refactoring durchgeführt werden. Bei diesem Kurs soll das in dem praktischen Teil zu entwickelnde System eingesetzt und ermittelt werden, wie gut das Werkzeug einen Entwickler unterstützen kann. Unmittelbar vor dem fünften und vorläufig letzten Sprint soll eine Analyse von statischen Verteilungen der Metrik-Werte sowie deren Bedeutung erfolgen.
\paragraph{}
Da nach dem dritten Sprint eine genauere Vorstellung der Use Cases \emph{Clean Code Hilfe bekommen} und \emph{Software-Qualität interpretieren} existierte, wurde der Plan aktualisiert. Im Rahmen dieser Aktualisierung wurde der vierte Sprint um eine halbe Woche verschoben.

\textcolor[rgb]{1,0,0}{TODO: was wurde noch verschoben?}




\chapter{Usus}
\label{chap:usus}
Das Wort \emph{usus} kommt aus dem lateinischen und bedeutet "`das, was üblich ist"'. In diesem Kapitel wird das Usus-Plugin \cite{UsusEclipsePlugin} für die Java Entwicklungsumgebung Eclipse vorgestellt, sowie auf die Metriken, die es berechnet, eingegangen. Das Usus Programm ist im Rahmen einer Initiative von andrena (Abschnitt \ref{sec:andrena}) entstanden. Usus entspricht im Groben dem Werkzeug für Eclipse und Java, das im Rahmen dieser Master-Thesis auch für Visual Studio und .NET entwickelt werden soll. Aus diesem Grund wird dessen Funktionsumfang an dieser Stelle betrachtet um ihn besser in nachimplementieren zu können. Eine direkte Portierung ist anhand der Technologieunterschiede von Visual Studio und Eclipse, sowie .NET und Java wahrscheinlich nicht möglich, sodass diese Option in der vorliegenden Master-Thesis nicht in weiter verfolgt wird.


\section{Eclipse Plugin}
\label{sec:eclipseusus}
Das Usus-Plugin für Eclipse lässt sich über den Menü-Eintrag \texttt{Help / Install New Software} installieren, indem eine neue Software Site mit der Url \url{http://projectusus.googlecode.com/svn/updates/} hinzugefügt und anschließend \emph{Project Usus} ausgewählt wird. Nach der Installation steht die \emph{Project Usus perspective} zur Verfügung, die die folgenden Fenster enthält.

\subsection{Usus Cockpit}
\label{subsec:ususcockpit}
In diesem Fenster werden die Usus Metriken angezeigt, die für alle Projekte, die Usus betrachtet, gelten. Zusätzlich wird der Trend pro Metrik dargestellt, also ob sich die Ausprägung der Metrik verbessert oder verschlechtert hat. Die Verbesserung wird dabei zwischen zwei erstellten Snapshots gemessen, die entweder manuell oder durch einen neuen Speichervorgang ausgelöst werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_cockpit.png}
	\caption{Usus Cockpit zeigt Übersicht über alle Projekte}
	\label{fig:usus_cockpit}
\end{figure}
Die in Abbildung \ref{fig:usus_cockpit} dargestellten Statistiken der Metriken errechnen sich aus der Aggregation der Paket-, Klassen- oder Methoden-Eigenschaften.

\subsection{Usus Info}
\label{subsec:ususinfo}
Dieses Fenster lässt sich im Kontext einer Methode oder einer Klasse öffnen und zeigt Metriken, die anhand der Eigenschaften des Kontextes ermittelt werden können.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_info.png}
	\caption{Usus Info zeigt Übersicht über eine Methode oder Klasse}
	\label{fig:usus_info}
\end{figure}
Das in Abbildung \ref{fig:usus_info} gezeigte Info-Fenster lässt sich mit \texttt{Ctrl-U} öffnen und mit \texttt{Esc} wieder schließen.

\subsection{Usus Hotspots}
\label{subsec:usushotspots}
Dieses Fenster zeigt sogenannte Hotspots, also Stellen im Quellcode, dessen Metriken definierte Grenze oder einen Schwellwert überschreiten. Hotspots lassen sich für jede Metrik definieren, die im Usus Cockpit angezeigt wird. Zusätzlich wird der Trend pro Hotspot gezeigt, also ob sich der Hotspot verbessert oder verschlechtert.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_hotspots.png}
	\caption{Usus Hotspots zeigt die Stellen im Code, die eine besondere Metrikausprägung haben}
	\label{fig:usus_hotspots}
\end{figure}
Das in Abbildung \ref{fig:usus_hotspots} gezeigte Hotspot-Fenster zeigt Hotspots immer nur für eine Metrik an. Der Wechsel zu einer anderen Hotspot-Metrik erfolgt über einen Doppelklick auf die Metrikanzeige im Usus Cockpit. Über einen Doppelklick auf einen Hotspot lässt sich entweder zu der dazugehörigen Methode im Quelltext oder dem entsprechende Paket oder der Klasse in einem der beiden Usus Graph Ansichten navigieren.

\subsection{Usus Histogram}
Dieses Fenster zeigt die absolute Häufigkeitsverteilung der Ausprägungen einer Metrik über alle Projekte an, die Usus betrachtet. Die verwendete Metrik wird dabei auf der der x-Achse angezeigt, während die Anzahl der Ausprägungen auf der y-Achse dargestellt wird. Die Verteilung lässt sich für eine der Metriken definieren, die im Usus Cockpit angezeigt werden.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_histogram.png}
	\caption{Usus Histogram zeigt die statistische Verteilung der Ausprägungen der definierten Metrik}
	\label{fig:usus_histogram}
\end{figure}
Das in Abbildung \ref{fig:usus_histogram} gezeigte Histogramm-Fenster zeigt die Verteilung der Metrik an, die zuvor über einen Einfachklick im Usus Cockpit markiert wurde. Es zeigt immer nur die Daten für eine Metrik an. Die Ansicht kann vergrößert, verkleinert, skaliert und als Grafik gespeichert werden.

\subsection{Usus Class Graph \& Usus Package Graph}
\label{subsec:ususgraphs}
Dieses Fenster zeigt die Abhängigkeiten der betrachteten Projekte entweder auf Klassenebene oder auf Paketebene an. Auf Paketebene lassen sich optional nur die Pakete anzeigen, die sich in einem Zyklus von Abhängigkeiten zu anderen Paketen befinden. Auf Klassenebene lassen sich optional nur die Klassen anzeigen, die über eine Abhängigkeit über Paketgrenzen hinweg verfügen. Dabei werden auch nur eben diese Paketübergreifenden Abhängigkeiten angezeigt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/usus_graph.png}
	\caption{Usus Graph Schaubilder zeigen die Abhängigkeiten der Klassen oder Pakete voneinander an}
	\label{fig:usus_graph}
\end{figure}
Das in Abbildung \ref{fig:usus_graph} dargestellte Fenster besteht aus zwei Karteikarten. Eine Karteikarte zeigt den Usus Class Graph, während die andere den Usus Package Graph darstellt. Zwischen den beiden Ansichten kann beliebig gewechselt werden. Die Knoten in den Graphen lassen sich mit der Maus frei positionieren. Zusätzlich lassen sich die Graphen-Darstellungen auch automatisch anordnen.


\section{Metriken}
\label{sec:metrics}
In den Fenstern Usus Cockpit und Usus Info zeit das Eclipse Plugin die Werte verschiedener Metriken an. Das Usus Info Fenster zeigt im Kontext einer Methode neben den Metriken, die es zusätzlich für die Klasse anzeigt auch Methoden-Metriken. In diesem Abschnitt wird daher zuerst auf die Metriken eingegangen, die das Usus-Plugin für Methoden berechnet, bevor die Klassen-Metriken näher betrachtet werden. Abschließend werden die Usus Cockpit Metriken beschrieben. Diese Beschreibungen sind von Bedeutung, da sämtliche Metriken im Rahmen der Usus-Erweiterung für Visual Studio nach-implementiert werden sollen.

\subsection{Pro Methode}
Wenn das Usus Info Fenster im Kontext einer Methode geöffnet wird, wird die zyklomatische Komplexität sowie die Länge der Methode dargestellt.
\subsubsection{Zyklomatische Komplexität}
\label{subsubsec:cyclomaticcomplexity}
Die Metrik \emph{Cyclomatic Complexity} (CC) wurde von Thomas J. McCabe vorgestellt \cite{AComplexityMeasure} um Methoden anhand von linear unabhängigen Ablaufpfaden in Bezug auf Komplexität zu bewerten. McCabe bezieht sich in seinem Artikel auf die Graphentheorie und errechnet die Komplexität eines Ablaufgraphen wie folgt.
\begin{equation}
v(G) = e - n + 2p
\label{eq:cyclomaticcomplexity1}
\end{equation}
\begin{eqnarray*}
G&=&\text{Ablaufgraph}\\
v(G)&=&\text{zyklomatische Komplexität von $G$}\\
e&=&\text{Anzahl Kanten im Ablaufgraphen $G$}\\
n&=&\text{Anzahl Knoten im Ablaufgraphen $G$}\\
p&=&\text{Anzahl Zusammenhangskomponenten in $G$}\\
\label{eq:cyclomaticcomplexity1agenda}
\end{eqnarray*}
Ernest Wallmüller beschreibt die zyklomatische Komplexität in seinem Buch \cite{SoftwareQMPraxis} auch als Anzahl aller entscheidungstreffenden Stellen in der Methode. Im Falle einer Verkettung von binären Entscheidungen zu logischen Ausdrücken zählt jede Entscheidung als eine solche Stelle. Diese einfachere Rechnung ergibt sich als
\begin{equation}
	v(G) = 1 + \Big( \sum_{\displaystyle b \in Bs(G)} 1 \Big)
\label{eq:cyclomaticcomplexity2}
\end{equation}
wobei $Bs(G)$ die Menge aller binären Entscheidungen im Ablaufgraphen $G$ darstellt. Voraussetzung für diese Rechnung ist, das die Methode nur einen Eingang und nur einen Ausgang besitzt. Der Quellcode in Listing \ref{listing:simpleifs} soll die Grundlage für eine demonstrative Berechnung der zyklomatischen Komplexität darstellen.
\begin{lstlisting}[caption={Einfache if-Verschachtelung},label={listing:simpleifs}]
public void doSomething() {
   if (condition1) {
      if (condition2 || condition3)
         do1();
   }
}
\end{lstlisting}
Nach Formel \ref{eq:cyclomaticcomplexity2} ergeben sich drei Entscheidungsstellen, welche durch die drei binären Bedingungen dargestellt werden. Die zyklomatische Komplexität entspricht damit \begin{math}v(G) = 1 + 3 = 4\end{math}.
\begin{figure}[h]
	\centering
		\includegraphics[width=9cm]{images/cc.jpg}
	\caption{Ablaufgraph G des Quellcodes \ref{listing:simpleifs}}
	\label{fig:ccsamplegraph}
\end{figure}
Die Berechnung anhand Formel \ref{eq:cyclomaticcomplexity1} basiert auf der Struktur des Ablaufgraphen, der in Abbildung \ref{fig:ccsamplegraph} dargestellt ist. Hier entspricht die zyklomatische Komplexität \begin{math}v(G) = 10 - 8 + 2 * 1 = 4\end{math}. Die Ergebnisse beider Rechnungen sind identisch. Die Eigenschaften einer Methode, die für die Berechnung der \emph{Cyclomatic Complexity}-Metrik erforderlich sind, sind also entweder die Anzahl der binären Entscheidungen oder der vollständige Ablaufgraph.
\subsubsection{Methodenlänge}
\label{subsubsec:methodlength}
Die Länge einer Methode kann auf unterschiedliche Weise ermittelt werden. Eine Unterscheidung der Möglichkeiten wird von Mark Lorenz und Jeff Kidds in \cite{OOSMetrics} vorgenommen. In der vorliegenden Arbeit werden zwei Möglichkeiten wie folgt definiert.
\begin{definition}[Anzahl Code-Zeilen]
Die Anzahl der Code-Zeilen (engl. Lines of code) entspricht der tatsächlichen Anzahl an Zeilenumbrüchen ohne leere Zeilen und Kommentarzeilen. Diese Längenangabe ist stark vom Entwicklerstil abhängig und kann sich daher unterschiedlich ausprägen, je nachdem wie beispielsweise eine Parameterliste umgebrochen wird.
\end{definition} 
\begin{definition}[Anzahl der Anweisungen]
Die Anzahl der Anweisungen (engl. Number of statements) entspricht nach Lorenz und Kidds einer stabileren Längenangabe. Eine Anweisung ist jeder durch ein Semikolon abgeschlossene Ausdruck sowie Bedingungs- und Wiederholungsanweisungen.
\end{definition} 
Die im Usus Info Fenster angezeigte Methodenlänge entspricht der Anzahl der Anweisungen der Methode. Eine Berechnung kann daher über die Aufsummierung der Semikola und der if-, switch-, for-, while- und try-catch-Anweisungen erfolgen.

\subsection{Pro Klasse}
\label{subsec:perclass}
Wenn das Usus Info Fenster im Kontext einer Klasse geöffnet wird, wird die Klassengröße sowie die kumulierte Komponentenabhängigkeit der Klasse dargestellt.

\subsubsection{Klassengröße}
\label{subsubsec:classsize}
Ähnlich der Methodenlänge lässt sich auch die Größe einer Klasse auf verschiedene Weise berechnen. Lorenz und Jeff unterscheiden mehrere Möglichkeiten \cite{OOSMetrics}. In der vorliegenden Master-Thesis werden im folgenden zwei Varianten der Klassengröße definiert.
\begin{definition}[Anzahl der Methoden]
In dem die Anzahl der Methoden betrachtet wird, können Klassen erkannt werden, die zu viel oder zu wenig Funktionen erfüllen. Weitere Unterscheidungsmöglichkeiten sind Methoden in Klassen- und Instanz-Methoden aufzuteilen oder Methoden anhand der Sichtbarkeit zu klassifizieren. Ein Konstruktor würde sich wie eine statische Methode, also eine Klassen-Methode, verhalten.
\end{definition} 
\begin{definition}[Anzahl der Felder]
Die Anzahl der Felder zu betrachten erlaubt es Klassen zu erkennen, die zu viel Informationen verwalten. Auch hier ist eine weitere Unterteilung in Klassen- und Instanz-Felder möglich. Die Sichtbarkeit der Felder erlaubt eine weitere Einschränkung.
\end{definition}
Das Usus Info Fenster zeigt als Klassengröße die Anzahl der Instanz-Methoden, der Klassen-Methoden sowie der Konstruktoren an. Dabei wird die Sichtbarkeit der Methode oder des Konstruktors nicht berücksichtigt. Das Usus-Plugin fokussiert damit auf die Funktion der Klassen und nicht auf die Information und das Wissen einer Klasse, welches in den Feldern liegt. Die Klassengröße kann also berechnet werden, wenn alle Methoden und Konstruktoren einer Klasse ermittelt werden können.
\subsubsection{Kumulierte Komponentenabhängigkeit}
\label{subsubsec:ccd}
Die Metrik \emph{Kumulierte Komponentenabhängigkeit} (engl. Cumulative Component Dependency) CCD ist laut Peter Grogono \cite{SoftwareQControl} eine Metrik, die für Systeme und Untersysteme ermittelt wird. Dabei werden für jede Klasse (Komponente) in diesem System die Anzahl der Klassen ermittelt, von denen die betrachtete Klasse direkt und indirekt abhängt. Eine Klasse ist immer auch von sich selber abhängig. Marc Philipp und Nicole Rauch bezeichnen diese Abhängigkeiten in ihrem Artikel \cite{EclipseMagUsus} als reflexsiv und transitiv. Anschließend werden die Abhängigkeiten aller betrachteten Klassen aufsummiert und ergeben den CCD-Wert des Systems. In dem Usus Info Fenster wird der Abhängigkeitswert einer betrachteten Klasse als \emph{CCD (of class)} bezeichnet. Um die Anzahl der Klassen zu bestimmen, von denen eine betrachtete Klasse abhängig ist, ist mindestens der vollständige Abhängigkeitsgraph der Klasse erforderlich. Mit einem Durchmusterungsalgorithmus kann die Erreichbarkeitsmenge (Reach-Menge) der Klasse (Startknoten) in diesem Abhängigkeitsgraph mit linearer Laufzeit $O(V+E)$ ermittelt werden. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} die beiden Algorithmen \emph{Breadth First Search} BFS und \emph{Depth First Search} DFS für diesen Zweck. %Seite 594, 603
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/ccd.jpg}
	\caption{Abhängigkeitsgraph einer Klasse mit aufsummierten Abhängigkeiten}
	\label{fig:ccd}
\end{figure}
Abbildung \ref{fig:ccd} zeigt sieben Klassen, die in einer hierarchischen Abhängigkeitsstruktur stehen. Offensichtlich ist Klasse A von allen anderen Klassen abhängig und hat damit den CCD-Wert sieben. Dies entspricht der Kardinalität der Reach-Menge von A, \begin{math}\{A,B,C,D,E,F,G\}\end{math}, die ermittelt wird, indem BFS oder DFS mit Klasse A als Startknoten im Abhängigkeitsgraph gestartet wird. Dabei werden die durch den Algorithmus markierten Knoten als Ergebnis des Algorithmus behandelt. Bei dem Abhängigkeitsgraph muss es sich nicht um einen Baum handeln. Formel \ref{eq:cumulativecomponentdependencyofclass} zeigt die Berechnungsvorschrift unter Verwendung des DFS-Algorithmus. Die Berechnung des CCD-Werts einer Klasse kann also durchgeführt werden, sobald ein Abhängigkeitsgraph erzeugt werden kann. Um einen solchen Graphen zu erzeugen müssen die direkten Abhängigkeiten einer Klasse ermittelt werden können. Jede Klasse wird dann einem Knoten zugeordnet und jede Abhängigkeit einer gerichteten Kante. 
\begin{equation}
	ccd(c) = | DFS(dG, c) |
\label{eq:cumulativecomponentdependencyofclass}
\end{equation}
\begin{eqnarray*}
dG&=&\text{Abhängigkeitsgraph des Systems}\\
c&=&\text{Klasse im System}\in dG\\
ccd(c)&=&\text{CCD-Wert der Klasse } c\\
\label{eq:cumulativecomponentdependencyofclassagenda}
\end{eqnarray*}
Eine grafische Darstellung (siehe Unterabschnitt \ref{subsec:ususgraphs}) ist dann ebenfalls möglich. Die direkten Abhängigkeiten einer Klasse können bestimmt werden, wenn die Typen aller Felder, Methodenparameter, Oberklasse und Interfaces sowie sämtlicher Methodenaufrufe entfernter Klassen identifiziert werden können. Abhängigkeiten zu Klassen, wie beispielsweise \texttt{String} oder \texttt{Object}, die im Basis-Framework definiert sind, können ignoriert werden.

\subsection{Projektübergreifend}
\label{subsec:allprojectsmetrics}
Neben den Metriken, die Usus für Methoden und Klassen berechnet, werden im Usus Cockpit Statistiken zu der Codebasis angezeigt. Dafür werden die ermittelten Metriken bewertet, wie es Marc Philipp und Nicole Rauch in ihrem Artikel \cite{EclipseMagUsus} beschreiben. In diesem Unterabschnitt werden die verscheiden Statistiken vorgestellt und auf ihre Bewertung eingegangen. Weiterhin werden die Schwellwerte der Statistiken definiert, anhand derer eine Klasse, Methode oder Paket als Hotspot (siehe Unter-Unterabschnitt \ref{subsec:usushotspots}) eingestuft wird.
\subsubsection{Durchschnittliche kumulierte Komponentenabhängigkeit}
\label{subsubsec:acd}
Die Metrik \textit{Durchschnittliche kumulierte Komponentenabhängigkeit} (engl. Average Component Dependency) ACD ist laut Peter Grogono \cite{SoftwareQControl} wie \emph{Kumulierte Komponentenabhängigkeit} (siehe Unter-Unterabschnitt \ref{subsubsec:ccd}) eine Metrik, die für Systeme und Untersysteme ermittelt wird. Dabei wird der Mittelwert des CCD-Werts des Systems wie in Formel \ref{eq:averagecomponentdependency1} berechnet, wobei $n$ die Anzahl der Klassen im System ist.
\begin{equation}
	acd = \frac{ccd}{n}
\label{eq:averagecomponentdependency1}
\end{equation}
Da Usus die CCD-Werte nicht für Systeme oder Untersysteme ermittelt, sondern die CCD-Werte der Klassen bestimmt ohne sie aufzusummieren (siehe Unter-Unterabschnitt \ref{subsubsec:ccd}), kann der ACD-Wert anhand einer Menge von Klassen $Cs$ berechnet werden, wie in Formel \ref{eq:averagecomponentdependency2} dargestellt. Die Rechnung ist äquivalent zu Formel \ref{eq:averagecomponentdependency1}.
\begin{equation}
	acd(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} ccd(C)}{|Cs|}
\label{eq:averagecomponentdependency2}
\end{equation}
Peter Grogono beschreibt die Bedeutung des ACD-Werts als durchschnittliche Anzahl an Komponenten, die durch eine Änderung einer Komponente betroffen sind und eventuell ebenfalls geändert werden müssen. Der ACD-Wert wird im Usus Cockpit als Statistik in Prozent angezeigt. Dazu wird nochmal der Mittelwert über die betrachteten Klassen gebildet, wie in Formel \ref{eq:averagecomponentdependency3} zu sehen ist und der Bewertungsfunktion von Philipp und Rauch entspricht.
\begin{equation}
	acd'(Cs) = \frac{acd(Cs)}{|Cs|}
\label{eq:averagecomponentdependency3}
\end{equation}
Eine Klasse wird von Usus dann als Hotspot betrachtet, wenn ihr CCD-Wert über einer Schwelle liegt, die von der Projektgröße abhängig ist. Die Projektgröße wird dabei an der Anzahl der Klassen festgelegt. Anhand der Tooltip-Erklärung im Usus Cockpit liegt diese Schwelle für kleine Projekte bei 15\% der Klassenanzahl, während bei großen Projekten 5\% der Klassenanzahl verwendet wird. Dafür haben Philipp und Rauch Formel \ref{eq:averagecomponentdependency4} mithilfe von Erfahrungswerten definiert um die Berechnung des CCD-Schwellwert-Faktors $L_{ccd}$ anhand der Menge aller Klassen $Cs$ im System durchführen zu können.
\begin{equation}
	L_{ccd}(Cs) = \frac{1,5}{2^{\displaystyle (\log_{5} |Cs|)}}
\label{eq:averagecomponentdependency4}
\end{equation}
Um den tatsächlichen Schwellwert für eine Menge von Klassen $Cs$ zu bestimmen, muss der Faktor $L_{ccd}(Cs)$ noch mit der Anzahl der Klassen $|Cs|$ multipliziert werden.
\subsubsection{Durchschnittliche Klassengröße}
Eine Klasse wird von Usus als Hotspot gesehen, sobald die in Unter-Unterabschnitt \ref{subsubsec:classsize} beschriebene Klassengröße den Schwellwert 12 übersteigt. Das haben Philipp und Rauch festgelegt. Die im Usus Cockpit angezeigte durchschnittliche Klassengröße betrachtet nur die Klassen, die bereits als Hotspot markiert wurden. Das liegt an der Bewertungsfunktion $rating_{cs}$ von Philipp und Rauch, die in Formel \ref{eq:averageclasssize1} angegeben ist.
\begin{equation}
	rating_{cs}(cs) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{cs}{12}\bigg) - 1, & \text{wenn }cs > 12\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averageclasssize1}
\end{equation}
Die Bewertungsfunktion der Klassengröße $cs$ ist direkt von dem Schwellwert 12 abhängig und bewertet alle Klassen, dessen Größe 12 oder weniger beträgt mit 0. Um die durchschnittliche Klassengröße $acs$ einer Menge von Klassen $Cs$ zu berechnen, bildet Usus den Mittelwert aller bewerteter Klassengrößen. Dazu wird die Formel \ref{eq:averageclasssize2} verwendet.
\begin{equation}
	acs(Cs) = \frac{\displaystyle \sum_{c\text{ }\in\text{ }Cs} rating_{cs}(c)}{|Cs|}
\label{eq:averageclasssize2}
\end{equation}
Dabei gehen die mit 0 bewerteten Klassengrößen ebenfalls in die Durchschnittsberechnung ein.
\subsubsection{Durchschnittliche zyklomatische Komplexität}
Die Berechnung der durchschnittlichen zyklomatischen Komplexität findet auf ähnliche Weise statt. Philipp und Rauch haben dafür den Schwellwert 4 gewählt. Damit werden Methoden ignoriert, die vier oder weniger unabhängige Ablaufpfade besitzen oder anders ausgedrückt, weniger als vier verschiedene Entscheidungen treffen. Die Bewertungsfunktion $rating_{cc}$ eines wie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} berechneten zyklomatischen Komplexitäts-Wert sieht damit folgendermaßen aus.
\begin{equation}
	rating_{cc}(cc) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{cc}{4}\bigg) - 1, & \text{wenn }cc > 4\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagecyclomaticcomplexity}
\end{equation}
Anschließend kann der Mittelwert der bewerteten Komplexitäten gebildet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Durchschnittliche Methodenlänge}
Auch die Berechnung der durchschnittlichen Methodenlänge findet ähnlich statt. In Unter-Unterabschnitt \ref{subsubsec:methodlength} wurde der Schwellwert für diese Metrik auf 9 festgelegt. Methoden mit 9 oder weniger Anweisungen werden damit ignoriert. Die Bewertungsfunktion $rating_{ml}$ sieht dann folgendermaßen aus.
\begin{equation}
	rating_{ml}(ml) = 
	\begin{cases}
		\displaystyle	\bigg(\frac{ml}{9}\bigg) - 1, & \text{wenn }ml > 9\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:averagemethodlength}
\end{equation}
Aus den bewerteten Längen kann dann wieder der Mittelwert berechnet werden, indem durch die Anzahl der Methoden dividiert wird.
\subsubsection{Anzahl nicht-statischer öffentlicher Felder}
\label{subsubsec:nonstaticpublicfields}
Wenn eine Klasse mindestens ein öffentliches Feld hat, das nicht statisch oder eine Konstante ist, dann betrachtet Usus diese Klasse als einen Hotspot. Dabei wird jede Klasse mit 1 bewertet, die mindestens eines dieser Felder besitzt. Der Schwellwert ist ebenfalls 1. Die Anzahl der betroffenen Klassen wird wie jede andere Metrik im Usus Cockpit über die Anzahl aller Klassen gemittelt und somit als Prozent dargestellt.
\subsubsection{Pakete mit zyklischen Abhängigkeiten}
\label{subsubsec:packetswithcyclicdependencies}
Für Klassen wurde in Unter-Unterabschnitt \ref{subsubsec:ccd} ein Abhängigkeitsgraph unabhängig vom Paket ermittelt, in dem sich die betrachtete Klasse befindet. Um Pakete mit zyklischen Abhängigkeiten zu identifizieren, müssen alle Klassen-Knoten eines Paket in dem Abhängigkeitsgraph zu einem Paket-Knoten in einem neuen Abhängigkeitsgraph auf Paketebene zusammengefasst werden. Die Kanten zwischen den Klassen werden zu Kanten zwischen den Paketen. Anschließend können alle trivialen Kreise im Paket-Abhängigkeitsgraph entfernt und Zyklen gesucht werden. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest und Clifford Stein beschreiben in ihrem Buch "`Introduction to Algorithms"' \cite{GraphAlgorithms} den Algorithmus \emph{Strongly Connected Components} (Starke Zusammenhangskomponenten) mit linearer Laufzeit $O(V+E)$ für diesen Zweck. Mit diesem Algorithmus können alle starken Zusammenhangskomponenten (SCCs) eines Graphen ermittelt werden. Da per Definition von Cormen und co alle Knoten in einer SCC sich gegenseitig erreichen können, handelt es sich um Kreise. Folglich enthalten alle starken Zusammanhangskomponenten, die mehr als eine Paket beinhalten, Pakete, die auf einem Kreis im Abhängigkeitsgraph liegen. %Seite 615, 617
\begin{equation}
	cyclicPackages(pdG) = \sum_{\displaystyle scc \in SCCs(pdG)}
	\begin{cases}
		| scc |, & \text{wenn }|scc| > 1\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:packageswithcyclicdependencies}
\end{equation}
\begin{eqnarray*}
pdG&=&\text{Paket-Abhängigkeitsgraph}\\
SCCs(pdG)&=&\text{Menge aller starken Zusammenhangskomponenten in }pdG\\
scc&=&\text{Starke Zusammenhangskomponente als Menge von Paketen}\\
cyclicPackages(pdG)&=&\text{Anzahl aller Pakete in allen starken Zusammenhangskomponenten in }pdG\\
\label{eq:packageswithcyclicdependenciesagenda}
\end{eqnarray*}
Formel \ref{eq:packageswithcyclicdependencies} zeigt dabei die Aufsummierung aller Pakete in nicht-trivialen starken Zusammenhangskomponenten eines Paket-Abhängigkeitsgraph. Abschließend kann der $cyclicPackages$-Wert durch die Anzahl der betrachteten Pakete dividiert werden, um einen durchschnittlichen Paket-Zyklus-Wert zu bestimmen, der im Usus Cockpit angezeigt wird. Alle Pakete, die 2 oder mehr zyklische Abhängigkeiten besitzen werden als Hotspots behandelt.




\chapter{Andere Tools}
Nachdem in dem vorherigen Kapitel das Eclipse Plugin Usus vorgestellt wurde, werden in diesem Kapitel einige andere Werkzeuge beschrieben, die ebenfalls eine statische Code-Analyse durchführen. Während Usus die direkte Inspiration für das in dieser Master-Thesis zu entwickelnde Tool darstellt, werden in diesem Kapitel einige Visual Studio Erweiterungen behandelt. Diese Erweiterungen versuchen bereits, die in Kapitel \ref{chap:requirements} definierten Anforderungen zu erfüllen und sind dabei auf Projekte spezialisiert, die für das .NET-Framework entwickelt werden.


\section{Visual Studio Metrics}
In diesem Abschnitt sollen die Möglichkeiten beschrieben werden, die Visual Studio von Haus aus bietet um Software zu analysieren. Ab Visual Studio 2010 Premium können zu jeder Solution (Menge von Projekten) verschiedene Code-Metriken direkt berechnet werden. Die Ergebnis-Anzeige ist in Abbildung \ref{fig:vsmetricsresult} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=10cm]{images/vsmetricsresult.png}
	\caption{Code-Metriken Ergebnis-Fenster in Visual Studio 2010 Premium}
	\label{fig:vsmetricsresult}
\end{figure}
Bei den berechneten Metriken handelt es sich um \emph{Lines of Code} (eigentlich \emph{Number of Statements}), \emph{Class Coupling} (direkte Klassen-Abhängigkeiten), \emph{Cyclomatic Complexity} und \emph{Maintainability Index} (Microsofts Indikator für Wartbarkeit). Jede dieser Metriken wird auf Methoden-Ebene erhoben und Zusammenfassend in der hierarchischen Struktur nach oben (Klasse, Paket, Assembly) propagiert. Zusätzlich wird die Metrik \emph{Depth of Inheritance} (Anzahl an direkten und indirekten Oberklassen ohne Interfaces) auf Klassenebene bestimmt und ebenfalls nach oben aggregiert. Der Wartbarkeits-Index sowie dessen Berechnung wird von Zain Naboulsi in seinem Artikel \cite{VSMaintainabilityIndex} umfangreich erläutert. Neben der einfachen Darstellung erlaubt Visual Studio das Filtern der Methoden und Klassen anhand der Metriken und zeigt neben der Ausprägung des Wartbarkeits-Indexes eine Ampel an, die nach Microsofts Empfinden die Methode/Klasse als gut wartbar, weniger gut wartbar und nicht so gut wartbar klassifiziert.
\paragraph{}
In Visual Studio 2010 Ultimate können zudem mehrere grafische Funktionen genutzt werden. So lassen sich zum Beispiel Methoden automatisch als Sequenz-Diagramme darstellen, was einen Hinweis auf deren Komplexität und Abhängigkeiten geben kann. Zusätzlich kann der Abhängigkeitsgraph einer Solution mithilfe des Architektur-Explorer visualisiert und so zyklische Abhängigkeiten von Klassen und Pakten schnell gefunden werden. Abbildung \ref{fig:vsarchitecturenamespaces} zeigt das Ergebnis der Visualisierung, die neben der Graphen-Form auch in Form einer Matrix dargestellt werden kann.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/vsarchitecturenamespaces.png}
	\caption{Architektur-Diagramm in Visual Studio 2010 Ultimate auf Basis von Paketen, aufklappbar bis Methoden-Ebene}
	\label{fig:vsarchitecturenamespaces}
\end{figure}
Leider sind diese Funktion zur Metrik-Berechnung und zur Visualisierung in der am weitesten verbreiten Professional Version von Visual Studio nicht verfügbar. Zwei kostenlose Programme, die das Bestimmen der gleichen Menge von Code-Metriken erlauben werden in den folgenden Unterabschnitten vorgestellt.

\subsection{Visual Studio Code Metrics Power Tool}
\label{subsec:vscodemetricspowertool}
Das Kommandozeilenwerkzeug \emph{Visual Studio Code Metrics Power Tool}\footnote[1]{Download: "`Visual Studio Code Metrics PowerTool 10.0"' \url{http://www.microsoft.com/download/en/details.aspx?id=9422}} wird kostenfrei von Microsoft zum Download angeboten. Es erlaubt die Berechnung der gleichen Metriken wie die in Visual Studio 2010 Premium integrierte Funktionalität und erzeugt eine XML-Datei. Diese Datei enthält die Metriken für Projekte, Namensräume, Typen und Methoden in hierarchischer Form.

\subsection{Code Metrics Viewer}
Die Erweiterung \emph{Code Metrics Viewer}\footnote[2]{Download: "`Code Metrics Viewer extension"' \url{http://visualstudiogallery.msdn.microsoft.com/9f35524b-a784-4dbc-bd7b-6babd7a5a3b3}} für Visual Studio 2010 wird von Matthias Friedrich zum kostenlosen Download angeboten. Das Tool nutzt das Kommandozeilenwerkzeug \emph{Visual Studio Code Metrics Power Tool} um Metriken direkt in der Entwicklungsumgebung grafisch anzeigen zu können. In einem Visual Studio-Fenster, das dem aus Abbildung \ref{fig:vsmetricsresult} nachempfunden ist, wird der Inhalt der durch das Power Tool erzeugten XML-Datei visualisiert. Es lassen sich ebenfalls verschiedene Filter einstellen. Der Hauptunterschied zu der integrierten Funktionalität besteht darin, das die Ampel zu jeder Metrik angezeigt wird.


\section{NDepend}
\label{sec:ndepend}
Für die grafische Darstellung des Abhängigkeitsgraphen kann das kommerzielle Werkzeug NDepend\footnote[1]{NDepend "`Tutorial with explanations and screenshots"' \url{http://www.ndepend.com/GettingStarted.aspx\#Tuto}} (299\EUR für eine Einzelplatz-Lizenz) genutzt werden. Dieses Tool ist neben der umfangreichen Darstellung von Zusammenhängen und Abhängigkeiten in der Lage, viele verschiedene Metriken auf Anwendungs-, Projekt-, Namesraum-, Klassen- und Methoden-Ebene zu berechnen. Die Abhängigkeiten können, wie im Architektur-Explorer in Visual Studio Ultimate, in Form einer Matrix oder in Form eines Diagrams veranschaulicht werden. Dafür analysiert NDepend genau wie das Code Metrics Power Tool die pro Projekt von dem Compiler erzeugten Assembly-Dateien (exe oder dll). Das Programm ist neben .NET auch für Java und C++ erhältlich und kann als eigenständige Anwendung oder als Visual Studio Addin verwendet werden.

\subsection{Code Query Language}
Abhängig von der Metrik- und Abhängigkeitsberechnung kann NDepend Warnungen und Hinweise anzeigen, die den Programmierer rechtzeitig auf schwierige Stellen im Code hinweisen und es ihm erlauben, dort gezielt einzugreifen. Es lassen sich auch eigene Warnungen und Berichte mithilfe der deklarativen Sprache CQL (Code Query Language) erstellen und ausführen.

\subsection{Abstraktheit und Instabilität}
Eine sehr interessante Metrik im NDepend Metrik-Portfolio ist "`Abstraktheit und Instabilität"'. Diese Metrik-Kombination geht auf einen Artikel von Robert C. Martin \cite{OODesignMetrics} zurück. In diesem Artikel beschreibt Martin verschiedene Metriken zum Messen von Abhängigkeiten in Bezug auf eine Klassen-Kategorie. Eine Kategorie definiert er als Gruppe zusammenhängender Klassen, die gemeinsam benutzt werden. Diese Definition kann somit auf Pakete (Namensräume) oder auf Assemblies (Projekte) angewendet werden. Als erste Metrik stellt Martin \emph{Afferent Couplings} (hinführende Kupplungen $Ca(k)$) einer Kategorie $k$ als Anzahl der Klassen vor, die nicht in der Kategorie sind und eine Abhängigkeit von Klassen in der Kategorie haben. Daraus ergibt sich Formel \ref{eq:afferentcouplings}.
\begin{equation}
	Ca(k) = \sum_{\displaystyle c_o \in Cs \setminus Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_o, c_i) \in dG \mid c_i \in Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:afferentcouplings}
\end{equation}
\begin{eqnarray*}
Cs&=&\text{Menge aller Klassen im System}\\
Cs(k)&=&\text{Menge aller Klassen in der Kategorie }k\\
dG&=&\text{Abhängigkeitsgraph des Systems}\\
\label{eq:afferentcouplingsagenda}
\end{eqnarray*}
Martin bezieht sich auf die Abhängigkeiten zwischen Kategorien. In Formel \ref{eq:afferentcouplings} und den folgenden Formeln wird der bereits aus Unterabschnitt \ref{subsec:perclass} bekannte Abhängigkeitsgraph $dG$ auf Klassen-Ebene verwendet um die Abhängigkeiten abzubilden. Die Kategorie-Grenze einer Kategorie $k$ wird in Bezug auf die Klassen-Abhängigkeiten durch die Funktion $Cs(k)$ bestimmt. Während Formel \ref{eq:afferentcouplings} alle Abhängigkeiten in Richtung der betrachteten Kategorie beschreibt, definiert Formel \ref{eq:efferentcouplings} alle Abhängigkeiten aus der Richtung der betrachteten Kategorie. Die Metrik \emph{Efferent Couplings} (wegführende Kupplungen $Ce(k)$) bezeichnet die Anzahl der Klassen innerhalb einer Kategorie $k$, die Abhängigkeiten zu Klassen außerhalb der Kategorie besitzen.
\begin{equation}
	Ce(k) = \sum_{\displaystyle c_i \in Cs(k)}
	\begin{cases}
		1, & \text{wenn }\exists \text{ }(c_i, c_o) \in dG \mid c_o \in Cs \setminus Cs(k)\\
		0, & \text{sonst}\\
	\end{cases}
\label{eq:efferentcouplings}
\end{equation}
Die Formeln \ref{eq:afferentcouplings} und \ref{eq:efferentcouplings} besitzen die gleiche Struktur und unterscheiden sich nur durch die Richtung der gesuchten Kante im Abhängigkeitsgraph $dG$ und der Menge der Klassen, die gezählt werden soll.
\paragraph{}
Mit der Anzahl der hinführenden und wegführenden Abhängigkeiten kann jetzt die Metrik \emph{Instability} (Instabilität $I(k)$) einer Kategorie $k$ wie in Formel \ref{eq:instability} bestimmt werden. Martin beschreibt diese Metrik als Maß dafür, wie sich die betrachtete Kategorie anpassen muss, wenn sich das restliche System ändert.
\begin{equation}
	I(k) = \frac{Ce(k)}{Ca(k) + Ce(k)}
\label{eq:instability}
\end{equation}
Eine Instabilität von 1.0 bedeutet maximale Instabilität und wird erreicht, wenn nur wegführende Abhängigkeiten vorhanden sind, also die Klassen innerhalb der Kategorie von Klassen außerhalb abhängig sind. Im Falle einer Änderung im restlichen System ist diese Kategorie sehr wahrscheinlich ebenfalls betroffen. Eine Instabilität von 0.0 bedeutet maximale Stabilität, da keine wegführenden Abhängigkeiten vorhanden sind und Abhängigkeiten nur von Klassen außerhalb der Kategorie zu Klassen in der Kategorie bestehen. Eine Änderung des restlichen Systems hätte also keinen Einfluss auf die betrachtete Kategorie. Instabilität kann nur bestimmt werden, wenn mindestens ein Abhängigkeit (wegführend oder hinführend) vorhanden ist.
\paragraph{}
Robert C. Martin erläutert in seinem Artikel zudem den Zusammenhang von Instabilität und Abstraktheit. Dafür schreibt er, dass Abhängigkeiten von instabilen Kategorien zu vermeiden sind. Da Kategorien mit abstrakten Klassen und Schnittstellen hinführende Abhängigkeit einer externen Klasse motivieren, empfiehlt er keine abstrakten Typen innerhalb einer instabilen Kategorie zu positionieren. Um den Grad der Abstraktheit $A(k)$ einer Kategorie $k$ zu bestimmen, hat Martin die Metrik \emph{Abstractness} als Verhältnis zwischen abstrakten Klassen und Schnittstellen zu konkreten Klassen beschrieben. Dieses Verhältnis kann mit Formel \ref{eq:abstractness} berechnet werden.
\begin{equation}
	A(k) = \frac{|aCs(k)|}{|Cs(kp)|}
\label{eq:abstractness}
\end{equation}
\begin{eqnarray*}
aCs(k)&=&\text{Menge der abstrakten Klassen und Schnittstellen in der Kategorie }k\\
\label{eq:abstractnessagenda}
\end{eqnarray*}
Genau wie bei der Instabilität liegt auch die Ausprägung der Abstraktheit zwischen 0.0 und 1.0. Eine Abstraktheit von 0.0 entspricht einer konkreten Kategorie ohne abstrakte Typen, während eine Abstraktheit von 1.0 für eine Kategorie mit ausschließlich abstrakten Typen steht.
\paragraph{}
Die Abstraktheit und die Instabilität können kombiniert werden. NDepend greift die Idee von Martin auf und trägt jede Assembly der betrachteten Projektumgebung in einem Diagramm ähnlich Abbildung \ref{fig:abstractnessinstability} entsprechend ein.
\begin{figure}[h]
	\centering
		\includegraphics[width=7cm]{images/abstractnessinstability.jpg}
	\caption{Schematische Darstellung des "`Abstraktheit und Instabilität"'-Diagramm in NDepend}
	\label{fig:abstractnessinstability}
\end{figure}
Robert C. Martin beschreibt eine Kategorie, die in der Haupt-Sequenz liegt, als ausgeglichen, da sie zum Teil erweiterbar und zum Teil stabil ist. Laut Martin sind die beiden Endpunkte der Haupt-Sequenz die optimalen Punkte. Nach seiner Erfahrung können nur ungefähr die Hälfte der Kategorien in einem System diese optimalen Positionen einnehmen. Die andere Hälfte sollte möglichst nah an der Haupt-Sequenz liegen, was durch eine weitere Metrik in Form einer Abstandsberechnung festgehalten werden könnte.


\section{CCD-Addin}
\label{sec:ccdaddin}
In Kapitel \ref{chap:requirements} wurde im Rahmen der Anforderungsanalyse der Anwendungsfall "`Clean Code Hilfe bekommen"' identifiziert. Das Visual Studio Addin \emph{CcdAddIn}\footnote[1]{"`CcdAddIn is a visual Studio Add-In that displays the CCD values according to your current CCD Grade"' \url{https://github.com/AlexZeitler/CcdAddIn}} von Alexander Zeitler versucht eine solche Hilfestellung in passiver Form zu geben. In Unterabschnitt \ref{subsec:cleancode} wurde die Idee von Clean Code bereits erläutert und auf das sieben-Grade-System von Ralf Westphal und Stefan Lieser \cite{CleanCodeDeveloper} eingegangen. Das Programm integriert sich in die IDE und zeigt zu jedem Grad die entsprechenden Prinzipien und Praktiken an, sodass der Entwickler immer an seinen aktuellen Grad und an die damit verbundenen "`Regeln"' erinnert wird. Jede Praktik und jedes Prinzip ist anklickbar, sodass das Addin weitere Informationen anzeigen kann. Leider zeigt das Addin die Informationen nur an und bietet sonst kein weitere Hilfestellung.

\subsection{Prinzipien}
\label{subsec:ccdprinciples}
In diesem Unterabschnitt werden die einzelnen Grade vorgestellt. Da der \emph{schwarze} Grad lediglich einer Interessenbekundung entspricht und der \emph{weiße} Grad das komplette Spektrum abdeckt, werden im Folgenden nur die verbleibenden fünf Grade erwähnt. Die folgenden Prinzipien wurden direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen.
\begin{description}
	\item[Rot] \emph{Don´t Repeat Yourself} (DRY), \emph{Keep it simple, stupid} (KISS), Vorsicht vor Optimierungen!, \emph{Favour Composition over Inheritance} (FCoI)
	\item[Orange] \emph{Single Level of Abstraction} (SLA), \emph{Single Responsibility Principle} (SRP), \emph{Separation of Concerns} (SoC), Source Code Konventionen
	\item[Gelb] \emph{Interface Segregation Principle} (ISP), \emph{Dependency Inversion Principle} (DIP), \emph{Liskov Substitution Principle} (LSP), \emph{Principle of Least Astonishment} (PLA), \emph{Information Hiding Principle} (IHP)
	\item[Grün] \emph{Open Closed Principle} (OCP), \emph{Tell, don´t ask} (TDA), \emph{Law of Demeter} (LD)
	\item[Blau] Entwurf und Implementation überlappen nicht, Implementation spiegelt Entwurf, \emph{You Ain´t Gonna Need It} (YAGNI)
\end{description}

\subsection{Praktiken}
\label{subsec:ccdpractices}
Neben den Prinzipien existieren zu jedem Grad auf Praktiken, die ebenfalls direkt von Westphal und Lieser \cite{CleanCodeDeveloper} übernommen wurden.
\begin{description}
	\item[Rot] die Pfadfinderregel beachten, \emph{Root Cause Analysis}, ein Versionskontrollsystem einsetzen, einfache Refaktorisierungsmuster anwenden, Täglich reflektieren
	\item[Orange] Issue Tracking, Automatisierte Integrationstests, Reviews, Lesen, Lesen, Lesen
	\item[Gelb] Automatisierte Unit Tests, Mockups (Testattrappen), Code Coverage Analyse, Teilnahme an Fachveranstaltungen, Komplexe Refaktorisierungen
	\item[Grün] Continuous Integration, Statische Codeanalyse (Metriken), \emph{Inversion of Control} (IOC) Container, Erfahrung weitergeben, Messen von Fehlern
	\item[Blau] Continuous Delivery, Iterative Entwicklung, Komponentenorientierung, Test first
\end{description}




\chapter{Technologie Evaluierung}
\label{chap:techeval}
Nachdem in Kapitel \ref{chap:requirements} die Anforderungen an die zu entwickelnde Visual Studio Erweiterung beschrieben wurden, werden in diesem Kapitel verschiedene Technologien in Betracht gezogen um ein Werkzeug zu entwickeln, das einen ähnlichen Funktionsumfang wie das in Kapitel \ref{chap:usus} beschrieben Usus-Plugin besitzt. Der Schwerpunkt in diesem Kapitel liegt auf der statischen Code-Analyse, die durchgeführt werden muss um Metriken und alles weitere Feedback zu berechnen. Zu diesem Zweck werden Möglichkeiten untersucht um Quellcode zu analysieren und um die Rohdaten zu ermitteln, die für die Berechnung der vorgestellten Metriken benötigt werden. Dieser Analyse-Schritt wird auch von Artur Wagner in seiner Ausarbeitung \cite{IntroStaticCodeAnalysis} auch mit den Analyse-Schritten eines Compilers verglichen. Allerdings ist es möglich eine statische Code-Analyse auch nach dem Kompilieren durchzuführen, indem das Kompilat betrachtet wird. Dies ist im Fall von Java und .NET möglich, da es sich bei dem erzeugten Format um eine Zwischensprache handelt, die erst unmittelbar vor dem Ausführen in Maschinensprache übersetzt wird. Die Technologien, die in diesem Kapitel behandelt werden, nutzen entweder den Quellcode oder das Compiler-Ergebnis um eine statische Code-Analyse durchzuführen.
\paragraph{}
Um die Technologien anhand ihrer Eignung zu evaluieren, wird die Bewertung nach verschiedenen Kriterien vorgenommen. Die Kriterien sind in Form von Fragen so formuliert, dass eine bejahende Antwort als positiv gilt. Die Kriterien sind nach Wichtigkeit absteigend sortiert.
\begin{enumerate} 
\item Können alle Informationen gesammelt werden, die benötigt werden um die von Usus berechneten Metriken zu berechnen?
\item Ist die Technologie allgemein verfügbar und kann als Bestandteil einer Anwendung veröffentlicht werden?
\item Ist die Technologie kostenfrei verwendbar?
\item Ist die Technologie einfach zu verwenden und kann leicht eingesetzt werden?
\item Unterstützt die Technologie alle Versionen der .NET Laufzeitumgebungen unter Windows?
\item Ist die Technologie unabhängig von anderen Laufzeitumgebungen und anderen externen Komponenten?
\item Kann die Technologie ein unvollständiges System verarbeiten, das Klassen und Pakete verwendet, die nicht im betrachteten System definiert sind?
\item Ist die Technologie in der Lage ein System zu analysieren, dass nicht nur mit C$\#$ entwickelt wurde sondern auch in VB.net?
\item Kann die Technologie mit dem kompilierten Quellcode, also der Assembly, arbeiten?
\item Kann die Technologie mit dem unkompilierten Quellcode arbeiten?
\end{enumerate}
Anhand dieser Kriterien können verschiedene Technologien, die in den folgenden Abschnitten beschrieben werden, evaluiert werden. Das Ergebnis wird abschließend im letzten Abschnitt dieses Kapitels in Form einer Zusammenfassung vorgestellt. Die Auswahl der betrachteten Technologien wurde abhängig vom subjektiven Bekanntheitsgrad eingeschränkt und ist nicht vollständig.


\section{FxCop}
\label{sec:fxcop}
Jason Kresowaty beschreibt \emph{FxCop} in seiner Ausarbeitung \cite{FxCopCustomRules} als Werkzeug zur statischen Code-Analyse für Assemblies, die mit C\#, VB.NET und allen anderen .NET-Sprachen entwickelt wurden. \emph{FxCop} analysiert die vom Compiler erzeugten Binärdateien in \emph{Common Intermediate Language} (CIL) und führt Regeln aus, die nach Problemen im Sinne von Verletzungen von Konventionen und Richtlinien suchen.

\subsection{Umgebung}
Die \emph{FxCop}-Technologie besteht aus zwei Teilen. Der erste Teil ist die \emph{Microsoft FxCop} Anwendung und der zweite Teil sind die Regeln, die genutzt werden um die statische Analyse zu nutzen. Microsoft veröffentlicht mit dem Programm eine Menge von Regeln, um Assemblies anhand den von Krzysztof Cwalina und Brad Abrams veröffentlichten Konventionen und Richtlinien \cite{FrameworkDesignGuidelines} zu untersuchen. Eine Regel, die eine Berechnung von Metriken zur späteren Verwendung durchführt ist nicht vorhanden. Es lassen sich allerdings eigene Regeln definieren, die \emph{FxCop} genauso ausführen kann, und mit der das Programm beliebig erweitert werden kann. Eine solche eigene Regel könnte alle notwendigen Informationen sammeln um ein Programm mit einem Usus-ähnlichen Funktionsumfang zu entwickeln. Kresowaty beschreibt in seiner Ausarbeitung \cite{FxCopCustomRules} wie so eine Regel erstellt werden kann. Regeln lassen sich auch automatisiert ausführen, wenn eine Analyse mit der grafischen Oberfläche, die in Abbildung \ref{fig:fxcoprunner} dargestellt ist, nicht sinnvoll ist. Abbildung \ref{fig:fxcopcmdrunner} zeigt die Kommandozeilenversion des \emph{FxCop} Runners.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/fxcoprunner.png}
	\caption{FxCop Runner}
	\label{fig:fxcoprunner}
\end{figure}
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/fxcopcmdrunner.png}
	\caption{FxCop Kommandozeilen Runner}
	\label{fig:fxcopcmdrunner}
\end{figure}
\paragraph{}
Eine \emph{FxCop} Regel entspricht einer Klassenbibliothek, die eine Regel-Klasse und eine Regel-Konfigurationsdatei enthält. Während \emph{FxCop} den Code analysiert, erzeugt es Instanzen der Regel-Klasse und nutzt diese um in der Codebasis Problemfälle zu finden. Problemfälle können dann von der Regel-Klasse in Problem-Listen eingetragen werden, die \emph{FxCop} entweder grafisch anzeigt oder in Form einer Report-Datei erzeugt. Zusätzlich können Problemfälle als kritisch gekennzeichnet und mit verschiedenen Texten und Beschreibungen versehen werden um eine möglichst detaillierte Beschreibung der Schwierigkeit zu ermöglichen. \emph{FxCop} ist also auf das Finden von Problemen und nicht auf objektive Datensammlung spezialisiert. Um eine Assembly möglichst schnell analysieren zu können, erzeugt \emph{FxCop} mehrere Instanzen einer Regel und führt diese in mehreren Threads parallel aus. Jason Kresowaty betont in seiner Ausarbeitung \cite{FxCopCustomRules}, dass sich die Regeln nicht Thread-sicher verhalten. Damit mit \emph{FxCop} weiterverwendbare Daten gesammelt werden können, müssen diese auf eine geeignete Weise exportiert werden. Entweder können diese Daten in Form von Zeichenketten als Probleme verpackt oder direkt an ein Ziel gespeichert werden. Diese beiden Lösungen sind umständlich und nicht intuitiv und werden von der Nebenläufigkeit von \emph{FxCop} noch erschwert.

\subsection{API}
Regeln für \emph{FxCop} können mit C$\#$ in Form einer Klassenbibliothek entwickelt, wie es Jason Kresowaty in seiner Ausarbeitung \cite{FxCopCustomRules} vorstellt, und als \emph{Dynamic Link Library} (DLL) von \emph{FxCop} verwendet werden. Dazu muss die DLL über eine spezielle Metadaten-Datei als eingebettete Ressource verfügen, die die Regel dem Runner bekanntmacht. Die Regel selbst wird in einer Klasse implementiert, die von einer abstrakten Regel-Oberklasse abgeleitet ist und somit Analyse-Methoden überladen kann. Mit diesen Methoden kann das Objektmodell der zu analysierenden Assembly untersucht werden. Alle Basisklassen und Klassen, die das Objektmodell repräsentieren befinden sich im Namensraum \texttt{Microsoft.FxCop.Sdk}. Das \emph{Application Programming Interface} (API) um \emph{FxCop}-Regeln zu programmieren enthält Teile die dem in das .NET-Framework integrierten \texttt{System.Reflection} API ähnlich sind. Beide enthalten Klassen um das Objektmodell zu repräsentieren.
\paragraph{}
Um Operationen von einer Datenstruktur zu trennen, beschreiben Erich Gamma, Richard Helm, Ralph E. Johnson und John Vlissidest das Besuchermuster (Visitor Pattern) in \cite{DesignPatterns}. Mit dem Besuchermuster ermöglicht die \emph{FxCop} API die gleiche Datenstruktur (Objektmodell) mit vielen Regeln (Besuchern) zu analysieren. In der Regel-Klasse, die von \texttt{BaseIntrospectionRule} abgeleitet ist können oberflächliche Besuchermethoden überladen werden. Diese oberflächlichen Methoden bestimmen, an welcher Stelle im Objektmodell eine weitere Überprüfung vorgenommen werden soll. Zum Beispiel wird die \texttt{Check(Member)}-Methode in Listing \ref{listing:fxcopapisample} für jedes Property oder Methode in jeder Klasse aufgerufen. Die \texttt{Check(TypeNode)}-Methode wird zusätzlich für jede Klasse oder Interface ausgeführt.
\begin{lstlisting}[caption={FxCop API Beipiele},label={listing:fxcopapisample}]
ProblemCollection Check(Member member) {...}
ProblemCollection Check(TypeNode type) {...}
void VisitMemberBinding(MemberBinding memberBinding) {...}
void VisitBranch(Branch branch) {...}
void VisitAssignmentStatement(AssignmentStatement assignment) {...}
\end{lstlisting}
Nachdem sich die Regel mit einer dieser oberflächlichen \texttt{Check}-Methoden an dem Kontrollfluss der Analyse beteiligt, kann eine tiefgehende Analyse von der oberflächlichen Stelle ausgehend erfolgen. Dazu wird ein weiterer Besucher beispielsweise vom Typ \texttt{BinaryReadOnlyVisitor} erstellt, der die aktuelle Stelle im Objektmodell detaillierter besuchen kann. In einer von Klasse, von \texttt{BinaryReadOnlyVisitor} abgeleiteten ist, können jetzt \texttt{Visit}-Methoden überladen werden, die ebenfalls in Listing \ref{listing:fxcopapisample} dargestellt sind. Beispielsweise kann in der Methode \texttt{VisitMemberBinding} jeder Methodenaufruf und mit \texttt{VisitAssignmentStatement} jede Zuweisung analysiert werden. Auf diese Weise und mit sämtlichen Parameter- und Rückgabetypen kann aus dem Objektmodell der für die zu berechnenden Metriken erforderliche Abhängigkeitsgraph erstellt werden. Die Anzahl der Anweisungen pro Methode kann entweder im Sinne der \emph{Common Intermediate Language} (CIL, die vom Compiler erzeugte Zwischensprache) oder im Sinne von einem \textit{FxCop} \texttt{Statement} erfolgen. Während die CIL-Anweisungen die C$\#$-Anweisungen sehr viel granulärer abbilden, entsprechen die FxCop-Anweisungen zusammengefassten CIL-Anweisungen. Eine Entsprechung der C$\#$-Anweisungen konnte ohne detaillierte Betrachtung der konkreten \texttt{Statement}-Typen nicht ermittelt werden. Die Anzahl der Zeilen kann dafür auf eine sehr einfach Weise bestimmt werden, da jedes \texttt{Statement} über einen \texttt{SourceContext} und dort über Start- und Endzeilennummern verfügt. Anhand der Liste aller Anweisungen kann die erste Zeile als kleinste Startzeile und die letzte als größte Endzeile gesucht und mittels der Differenz die Methodenlänge berechnet werden. Die zyklomatische Komplexität kann bestimmt werden, da jede Verzweigung im Code von der \texttt{VisitBranch}-Methode besucht wird.


\section{Common Compiler Infrastracture}
\label{sec:cci}
Die \emph{Common Compiler Infrastructure} (CCI) ist eine Sammlung von Bibliotheken, die Compiler-ähnliche Funktionen bereitstellen und von Microsoft Research entwickelt wurde \cite{CCI}. Auf Codeplex lässt sich die Komponente \textit{CCI Metadata} finden. Guy Smith beschreibt sie als Obermenge von \texttt{System.Reflection}, \texttt{System.Reflection.Emit} und \texttt{System.CodeDom}, also den Mechanismen des .NET-Framework, die zur Laufzeit Reflektion und Code-Erzeugung möglich machen \cite{CCIMetadata}. Smith beschreibt \textit{CCI Metadata} als Werkzeug, das mit den vom Compiler erzeugten CIL-Anweisungen arbeitet. Um einfacher mit Methoden zu arbeiten, stellt Smith mit \emph{CCI Code and AST Components} eine weitere Komponente vor \cite{CCICode}. \emph{CCI Code} erleichtert das Arbeiten mit Methoden, da es von den CIL-Anweisungen abstrahiert und Quellcode-ähnliche Bäume nutzt. Beide Komponenten sind unter der Microsoft Public License veröffentlicht. Die CCI wird in einer ähnlichen Variante unter anderem von dem Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} und FxCop aus Abschnitt \ref{sec:fxcop} genutzt. Die Assembly Microsoft.Cci.dll, die mit diesen Tools ausgeliefert wird, besitzt viele Funktionen nur intern oder von erlaubten Assemblies aufrufbar sind. Funktionen, die beispielsweise konkrete Methoden-Metriken berechnen, sind nur von Programmen aufrufbar, die in der CCI-Assembly aufgelistet sind, wie in Abbildung \ref{fig:cciinternalsvisible} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=14cm]{images/cciinternalsvisible.png}
	\caption{Micorsoft.Cci.dll \texttt{InternalsVisibleTo}-Attribute}
	\label{fig:cciinternalsvisible}
\end{figure}

\subsection{CCI Metadata}
\label{subsec:ccimetadata}
Im Gegensatz zu der \emph{FxCop} API kann eine .NET-Assembly mit CCI direkt untersucht werden, ohne das die Analyse in Form einer einschränkenden Regel parallelisiert erfolgt. CCI überlässt dem Verwender der Bibliothek ob und wie die Untersuchung stattfinden soll. Mit einem \texttt{PeReader.DefaultHost} können Assemblies eingelesen werden, die von CCI als PE-Dateien bezeichnet werden. PE-Dateien werden in der vorliegenden Master-Thesis wie folgt definiert.
\begin{definition}[Portable Executable]
Eine \emph{Portable Executable}-Datei (PE-Datei), also eine transportierbare und ausführbare Datei, ist das Ergebnis einer Kompilierung eines Visual Studio .NET-Projekts. Die Datei ist entweder eine Bibliothek (dll-Datei) oder eine direkt ausführbare Datei (exe-Datei).
\end{definition}
Zusätzlich kann die vom Compiler erzeugte pdb-Datei mit einem \texttt{PdbReader} importiert werden. Eine pdb-Datei wird hier wie folgt definiert.
\begin{definition}[Program Database]
Die \emph{Program Database}-Datei (pdb-Datei) enthält die Datei- und Zeilenzuordnung der kompilierten Typen und Funktionen in einer PE-Datei. Laut Microsoft \cite{PDBFile} enthält sie generell Debug- und Projekt-Information.
\end{definition}
Mit der \texttt{IAssembly.GetAllTypes()}-Methode können alle Typen ermittelt werden. Alle Methoden und Properties eines Typs, können mit \texttt{INamedTypeDefinition.Methods} bestimmt werden. Der Inhalt von Methoden und Properties kann in Form von CIL-Anweisungen genauer betrachtet werden. Diese Anweisungen lassen sich mit \texttt{IMethodBody.Operations} ermitteln. So lassen sich beispielsweise alle lokalen Variablen und Methodenaufrufe lokalisieren, um Abhängigkeiten der Methode zu anderen Typen zu finden. Die CIL-Anweisung eines Methodenaufrufs enthält immer auch den Typ, der das Aufrufziel darstellt. Zusammen mit Attributen, Parametern und Rückgabewerten kann der Abhängigkeitsgraph eines Typs ermittelt werden. Die zyklomatische Komplexität einer Methode kann ebenfalls über die CIL-Anweisungen bestimmt werden, was durch das Code Metrics Power Tool aus Unterabschnitt \ref{subsec:vscodemetricspowertool} sowie Steve Gilham \cite{CCperCIL} demonstriert wird. Um die Methodenlänge einer Funktion aus den CIL-Anweisungen zu ermitteln, kann auch hier die Funktionalität durch das Code Metrics Power Tool inspiriert werden. Wenn zu der .NET-Assembly zusätzlich eine pdb-Datei existiert, kann außerdem die Start- und Endzeile jeder Anweisung auf die Methode bezogen werden, ähnlich der Lösung für die \emph{FxCop} Regel.

\subsection{CCI Code and AST Components}
\label{subsec:ccicodeast}
Soweit wurden nur Funktionen von \emph{CCI Metadata} betrachtet. \emph{CCI Code and AST Components} erlaubt es das Quellcode-Modell einer Methode in Form eines abstrakten Syntax-Baums (AST) zu analysieren. Philip Newcomb beschreibt einen AST in seinem Tutorial über den AST Metamodel Standard \cite{ASTMetamodel}. In der vorliegenden Master-Thesis wird ein AST wie folgt definiert.
\begin{definition}[Abstrakter Syntax-Baum]
Ein abstrakter Syntax-Baum (engl. Abstract Syntax Tree) ist einer formale Repräsentation der syntaktischen Struktur einer Software auch innerhalb Methoden. Besonders in Methoden enthält der AST einen Knoten für jede Anweisung. Wenn diese Anweisung aus mehreren anderen Anweisungen besteht, besitzt der Knoten für diese Anweisungen entsprechende Unter-Knoten.
\end{definition} 
Um einen solchen Baum zu betrachten, können Besucher verwendet werden. Beispielsweise erlaubt eine Objekt vom Typ \texttt{CodeTraverser} jede strukturelle Stelle der Assembly mit überladbaren Methoden, von denen einige in Listing \ref{listing:ccicodeastsample} aufgeführt sind, zu besuchen.
\begin{lstlisting}[caption={\emph{CCI Code and AST Components} \texttt{CodeTraverser}-Methoden},label={listing:ccicodeastsample}]
TraverseChildren(IConditionalStatement conditionalStatement) {...}//if
TraverseChildren(IConditional conditional) {...}//bool expression
TraverseChildren(IForStatement forStatement) {...}
TraverseChildren(ISwitchStatement switchStatement) {...}
\end{lstlisting}
Für jede Stelle im Code leitet \texttt{CodeTraverser} den Aufruf an Objekte vom Typ \texttt{ICodeVisitor} weiter, und ermöglicht so einfache Erweiterungen auf mehrere Weisen vorzunehmen. \texttt{ICodeVisitor} besitzt für jede \texttt{Traverse}-Methode eine entsprechende \texttt{Visit}-Methode. Da \texttt{CodeTraverser} das Code-Modell von links nach rechts und "`Depth First"' besucht, können zwei Besucher registriert werden. Einer wird aufgerufen bevor ein Syntax-Element im Baum besucht wird und der andere wird aufgerufen nachdem der Besuch beendet ist. 
\paragraph{}
\emph{CCI Code and AST Components} ermöglicht das syntaktische besuchen von Sprachelementen, indem von CIL abstrahiert wird. Es existieren Besucher-Methoden für alle Sprachelemente, die aus C$\#$ 4.0 bekannt sind, wie beispielsweise Lambda-Ausdrücke, Generics, Attribute und vielen mehr. Die herunterladbare \textit{CCI Code and AST Components} Visual Studio Solution enthält ein Beispiel (PeToTextViaCodeModel), das sämtliche Strukturelemente einer dll- oder exe-Datei besucht und wieder C$\#$-Quelltext erzeugt. Das Ergebnis entspricht Code, der dem Original sehr ähnlich ist und an professionelle Decompiler erinnert. Die CCI erlaubt es außerdem eine geladene Assembly zu verändern und anschließend wieder zu exportieren.


\section{NRefactory}
\label{sec:nrefactory}
Auch in der Mono-Welt existieren Werkzeuge für Compiler-ähnliche Funktionen. Das Team hinter Mono beschreibt Mono als Implementierung des .NET-Frameworks für Windows, Linux, Mac OS und verschiedene mobile Plattformen \cite{Mono}. In diesem Umfeld ist \textit{NRefactory} Teil der freien .NET-Entwicklungsumgebung SharpDevelop\footnote[1]{"`The Open Source Development Environment for .NET"' \url{http://www.icsharpcode.net/OpenSource/SD/}} und arbeitet im Gegensatz zur CCI und FxCop nicht nur auf Assembly-Ebene, sondern hauptsächlich mit Quellcode.

\subsection{AST aus Quellcode}
Mit \emph{NRefactory} ist es möglich einen AST aus C$\#$-Quelltext zu erzeugen. Unterstützung für VB.net ist nach Angaben in der Funktionsbeschreibung der Bibliothek \cite{NRefacRepo} noch nicht implementiert. Anschließend können AST-Besucher als direkte Implementierung der \texttt{IAstVisitor}-Schnittstelle oder als Ableitung von \texttt{DepthFirstAstVisitor} erstellt werden und mit dem abstrakten Syntax-Baum arbeiten. Listing \ref{listing:nrefacastsample} zeigt einige wenige Methoden, die in \texttt{IAstVisitor} definiert sind.
\begin{lstlisting}[caption={\emph{NRefactory} \texttt{IAstVisitor}-Methoden},label={listing:nrefacastsample}]
VisitIfElseStatement(IfElseStatement ifElseStatement) {...}
VisitBinaryOperatorExpression(BinaryOperatorExpression expression) {...}
VisitPrimitiveExpression(PrimitiveExpression expression) {...}
VisitNewLine(NewLineNode newLineNode) {...}
VisitInvocationExpression(InvocationExpression expression) {...}
\end{lstlisting}
Mit einem solchen Besucher können strukturelle Code-Elemente wie if-Anweisungen sehr gut besucht werden, was die Berechnung der zyklomatischen Komplexität ermöglicht, ohne kompiliern zu müssen. Wie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben, brauchen dafür nur alle Entscheidungsstellen besucht und aufsummiert werden. Die Methodenlänge kann ebenfalls einfach bestimmt werden. Es ist möglich entweder alle Statements oder alle Zeilenumbrüche zu besuchen und aufzusummieren. Der AST kann auch verändert und anschließend neuer Code erzeugt werden. Allerdings kann der Abhängigkeitsgraph nicht durch die alleinige Erzeugung des AST erstellt werden.

\subsection{Mono.Cecil}
\emph{NRefactory} ordnet Methodenaufrufe in Form von \texttt{InvocationExpression}-Objekten erst dann der definierenden Stelle zu, wenn alle Typen und Methoden im AST mit einem \texttt{CSharpAstResolver} komplett aufgelöst werden. Dazu verwendet \emph{NRefactory} die \emph{Mono.Cecil}-Bibliothek, die Jean-Baptiste Evain als API zum Erzeugen, Analysieren und Verändern von .NET-Assemblies beschreibt \cite{MonoCecil}. Die Assemblies, in denen sich die Typen befinden auf die der Code zugreift, werden von \emph{Mono.Cecil} geladen. Listing \ref{listing:nrefacastresolvercreation} zeigt wie ein \texttt{CSharpAstResolver}-Objekt zur Auflösung des abstrakten Syntaxbaums erzeugt werden kann.
\begin{lstlisting}[caption={\emph{NRefactory} Erzeugung von \texttt{CSharpAstResolver}},label={listing:nrefacastresolvercreation}]
CSharpAstResolver CreateResolver(CompilationUnit parsed, params Type[] types)
{
    IProjectContent project = new CSharpProjectContent();
    CSharpParsedFile file = parsed.ToTypeSystem();
    project = project.UpdateProjectContent(null, file);
    project = project.AddAssemblyReferences(LoadAssemblies(types));
    return new CSharpAstResolver(project.CreateCompilation(), parsed, file);
}
\end{lstlisting}
Der Code orientiert sich an dem Demo Beispiel von Daniel Grunwald in dem \emph{NRefactory}-Repository \cite{NRefacRepo}. Das übergebene \texttt{CompilationUnit}-Objekt ist der Wurzelknoten eines \textit{NRefactory}-AST, der aus Quellcode-Fragment erstellt wurde. Dieser AST wird für die Typ-Zuordnung vorbereitet und gemeinsam mit allen anderen Assemblies, die für die Auflösung von externen Typen verwendet werden sollen, in Form eines \texttt{CSharpProjectContent}-Objekts zusammengefasst. Um diese Assemblies zu finden, wird jede durch einen in ihr enthaltenen, nicht weiter relevanten Typ identifiziert. Für die Erzeugung des \texttt{CSharpAstResolver}-Objekts, wird der unvorbereitete AST, der vorbereitete AST und das Kompilat des \texttt{CSharpProjectContent}-Objekts übergeben. Die eigentliche Auflösung wird dann über einen Aufruf der \texttt{CSharpAstResolver.ApplyNavigator}-Methode synchron durchgeführt. Diese Funktion erwartet ein \texttt{IResolveVisitorNavigator}-Objekt und teilt diesem alle aufgelösten Details zu allen Knoten im AST mit. Ähnlich wie die CCI erlaubt auch \emph{Mono.Cecil} das manuelle Einlesen von Assemblies und \emph{Program Database}-Dateien um diese anhand der CIL-Anweisungen zu analysieren. Assemblies und pdb-Dateien können verändert und gespeichert werden.


\section{Codename "`Roslyn"'}
\label{sec:roslyn}
Karen Ng, Matt Warren, Peter Golde und Anders Hejlsberg beschreiben in ihrem Dokument \cite{RoslynOverview} ein Projekt um den C$\#$- und den VB.net-Compiler als Dienst zur Verfügung zu stellen. Sie beschreiben das Problem, dass Compiler viel isoliertes und ungeteiltes Wissen über die zu kompilierende Sprache besitzten. Dieses Wissen ist auch für andere Anwendungen, wie beispielsweise Entwicklungsumgebungen, Refactoring-Werkzeuge und Code-Analyse-Tools von bedeutung. Momentan müssen diese Programme das Wissen der Compiler neu erfinden und Teile des Compilers neu implementieren. Im Rahmen des Projekt \emph{Roslyn} sollen die Compiler ihr Wissen teilen können. Dazu werden sie als Dienste zur Verfügung gestellt und bieten APIs an. Diese APIs können dann von sämtlichen Code-orientierten Werkzeugen genutzt werden. Kirill Osenkov stellt in seinem Blog-Post \cite{RoslynCTPIntro} die CTP\footnote[1]{"`Microsoft Roslyn October 2011 CTP"' \url{http://msdn.com/roslyn}} (Community Technology Preview) von \emph{Roslyn} vor und erwähnt ein weiteres Ziel. Die bisherigen Compiler sollen in einer Sprache, die auf der CLR (Common Language Runtime) ausgeführt wird, neu geschrieben werden. Auf diese Weise soll das Team hinter Visual Studio schneller und bessere Features entwickeln können.

\subsection{Schichten}
In dem Dokument \cite{RoslynOverview} beschreiben Hejlsberg und co die traditionelle Compiler Pipeline der .net-Umgebung. Die \emph{Roslyn}-Compiler werden diese Pipeline ebenfalls haben. Ein Parser erzeugt einen Syntax-Baum anhand der Grammatik der Sprache. Darauf folgt die Deklarierungsphase. In dieser Phase werden die Deklarierungen im Code zusammen mit importierten Metadaten in Form von benannten Einheiten, sogenannten Symbols, erstellt. Danach folgt die Binder-Phase, in der Typen im Syntax Baum den Symbols zugeordnet werden. In der letzten Phase wird alle vom Compiler angesammelte Information in Form von CIL-Anweisungen in eine Assembly-Datei exportiert. Project \emph{Roslyn} bietet für jede dieser Phasen eine entsprechende API im Rahmen einer Compiler API Schicht, die auf der Compiler Pipeline aufbaut. Auf diese Compiler API Schicht setzt \emph{Roslyn} noch eine Language Service Schicht, die mit dem Objektmodell der Compiler Phasen arbeitet und beispielsweise Refactorings unterstützt.
\paragraph{}
Hejlsberg und co unterscheiden noch zwischen verschiedenen Architekturschichten, die getrennt von den oben beschrieben Schichten über der Compiler Pipeline beschrieben werden. Die Compiler APIs erlauben den Zugriff auf das syntaktische und semantische Objektmodell, das durch die Compiler Pipeline zur Verfügung gestellt wird. Die nächste Schicht ist die Scripting API. Sie bietet eine Umgebung für das Ausführen von Code-Schnippseln in Form von Ausdrücken und Anweisungen. Mit dieser Umgebung kann ein REPL (Read Eval Print Loop) realisiert werden. Die Workspace API stellt die nächste Schicht dar und ermöglicht eine Analyse auf der Basis von kompletten Visual Studio Solutions. Die letzte Schicht ist die Services API. Sie ist die einzige, die eine Abhängigkeit von Visual Studio hat. Sämtliche Funktionen wie Visual Studio \emph{IntelliSense}, Refactorings und Fomratierungsfunktionen befinden sich in dieser Schicht.

\subsection{Syntax Tree}
\label{subsec:roslynsyntaxtree}
In diesem Unterabschnitt werden die Möglichkeiten beschrieben, wie der Syntax-Baum der Compiler API verwendet werden kann. Interessant ist zu sehen, dass \emph{Roslyn} im Gegensatz zu \emph{NRefactory} die Datenstruktur nicht als abstrakten Syntax-Baum bezeichnet, sondern lediglich als Syntax-Baum. Philip Newcomb beschreibt in seiner Präsentation über den "`AST Metamodel Standard"' \cite{ASTMetamodel} den Unterschied als Nähe zum tatsächlichen Quellcode. Der Syntax Tree von \emph{Roslyn} orientiert sich sehr am Quellcode. Hejlsberg und co legen in ihrem Dokument \cite{RoslynOverview} besonderen Wert auf die Vollständigkeit des Baums, in dem jedes Leerzeichen und sogar synatktische Fehler Bestandteil des Syntax-Baum sind.
\paragraph{}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt die Erzeugung eines Syntax-Baum aus einem Quellcode-Ausschnitt, der in der Variable \texttt{sourceText} enthalten ist. Ähnlich wie \emph{NRefactory} bietet auch \emph{Roslyn} die Möglichkeit den Baum mit LINQ-Abfragen zu analysieren, da \texttt{DescendentNodes} ein \texttt{IEnumerable} zurückliefert. LINQ\footnote[1]{Mehr über "`LINQ (Language-Integrated Query, sprachintegrierte Abfrage)"' \url{http://msdn.microsoft.com/de-de/library/bb397926.aspx}} ist ein Sprachkonstrukt, das es erlaubt mit Keywords wie beispielsweise \texttt{from}, \texttt{where} und \texttt{select} SQL-ähnliche Abfragen direkt in C$\#$ oder VB.net zu schreiben.
\begin{lstlisting}[caption={Erzeugung eines Syntax Tree mit der \emph{Rosyln} Compiler API},label={listing:roslynsyntaxtreecreation}]
SyntaxTree tree = SyntaxTree.ParseCompilationUnit(sourceText);
var methods = tree.Root.DescendentNodes().OfType<MethodDeclarationSyntax>();
...
var ifs = method.DescendentNodes().OfType<IfStatementSyntax>();
var invocations = method.DescendentNodes().OfType<InvocationExpressionSyntax>();
\end{lstlisting}
Listing \ref{listing:roslynsyntaxtreecreation} zeigt ebenfalls wie alle Methoden, die in \texttt{sourceText} deklariert werden gefunden werden. In jeder dieser Methoden kann anschließend nach \texttt{if}-Anweisungen und ähnlichen Entscheidungsträgern gesucht werden, um die zyklomatische Komplexität, wie sie in Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} beschrieben wurde, auszurechnen. Um die Typen zu finden, von denen eine Methode abhängig ist, können neben sämtlichen Variablen alle Methodenaufrufe gefunden werden. Daraus kann anschließend der Abhängigkeitsgraph bestimmt werden. Ähnlich zu \emph{NRefactory} kann auch für den \emph{Roslyn}-Baum ein Besucher als Ableitung von \texttt{SyntaxWalker} erstellt werden. Über entsprechende Überladungen kann dann auf alle Knoten im Syntax-Baum reagiert werden. Leerzeichen, Zeilenumbrüche und andere Elemente, die keine nicht syntaktische Relevanz haben, sind im Baum in Form von \texttt{Trivia}-Objekten vorhanden und lassen sich ebenfalls finden. Eine Manipulation des Code-Baums ist auch möglich indem ein neuer Baum erzeugt wird. Bestehende Bäume sind laut Hejlsberg und co unveränderlich.

\subsection{Semantik}
\label{subsec:roslynsemanticmodel}
In diesem Unterabschnitt wird beschrieben, wie die Compiler API die Semantik von Code verwaltet. Nach der Erzeugung der syntaktischen Repräsentation von Code, dem Syntax Tree, werden beispielsweise die Methodenaufrufe nicht automatisch der Stelle zugeordnet, die sie deklarieren. Ähnlich wie bei \emph{NRefactory} wird dazu eine Auflösung benötigt, die den Baum mit den Symbols verbindet. Listing \ref{listing:rosylnsemanticmodelcreation} zeigt wie ein Syntax-Baum kompiliert werden kann. Durch die Kompilierung werden alle Verweise, die sich wie im Beispiel auf die \texttt{mscorlib} (Bibliothek der Basistypen wie \texttt{object}, \texttt{string}, \texttt{DateTime}, usw) beziehen, aufgelöst.
\begin{lstlisting}[caption={Erzeugung eines semantischen Modells aus Syntax-Bäumen},label={listing:rosylnsemanticmodelcreation}]
Compilation compilation = Compilation.Create(name)
				.AddReferences(mscorlib)
				.AddSyntaxTrees(tree);
SemanticModel semanticModel = compilation.GetSemanticModel(tree);
\end{lstlisting}
Das Kompilieren findet im Speicher statt und das Ergebnis wird nicht in Form einer Assembly in eine Datei geschrieben. Aus dem Kompilat kann das semantische Modell erzeugt werden. Dieses Modell kann anschließend genutzt werden um zu sämtlichen syntaktischen Elementen im Syntax Tree semantische Eigenschaften zu erhalten.
\begin{lstlisting}[caption={Ermitteln der semantischen Information eines Methodenaufrufs},label={listing:roslynsemanticmodelusage}]
SemanticInfo invocationSymbols = semanticModel.GetSemanticInfo(invocation);
string typeName = invocationSymbols.Symbol.ContainingType.Name;
\end{lstlisting}
Dafür kann die \texttt{GetSemanticInfo}-Methode mit dem entsprechenden Element aufgerufen werden, wie in Lisiting \ref{listing:roslynsemanticmodelusage} dargestellt. Das semantische Modell enthält alle Symbols des Kompilats und nicht nur die, die für die Auflösung der Typen benötigt werden die im Syntax-Baum deklariert wurden. Wenn also über alle Typen im semantischen Modell iteriert wird, werden nicht nur die Typen aus dem Baum, sondern auch alle Typen aller Referenz-Assemblies, betrachtet.

\subsection{Workspace}
In diesem Unterabschnitt werden die Möglichkeiten der Compiler API in Bezug auf die Analyse von ganzen Visual Stuido Solutions beschrieben. Eine Solution ist eine Datei, die es Visual Studio ermöglicht mehrere Projekte mit mehreren Quellcode-Dateien zu verwalten und zu kompilieren. In einer Solution sind in der Regel alle Abhängigkeiten der beinhalteten Projekte entweder durch andere beinhaltete Projekte oder durch Referenz-Assemblies auflösbar. Die \emph{Roslyn} Services API erlaubt es im Kontext einer laufenden Visual Studio Instanz einen sogenannten Workspace zu verwenden, der die Visual Studio Umgebung Repräsentiert und den Syntax-Baum ändert, sobald der Quellcode ändert. Ein Workspace kann auch ohne Abhängigkeit von Visual Studio erzeugt werden, indem die Solution-Datei direkt geladen wird, wie in Listing \ref{listing:roslynsolutionworkspacecreation} zu sehen ist.
\begin{lstlisting}[caption={Erzeugung eines Workspace aus einer Visual Studio Solution-Datei},label={listing:roslynsolutionworkspacecreation}]
IWorkspace workSpace = Workspace.LoadSolution(solutionFile);
ISolution solution = ws.CurrentSolution;
...
SyntaxTree tree = document.GetSyntaxTree();
SemanticModel semantic = document.GetSemanticModel();
\end{lstlisting}
In einem \texttt{ISolution}-Objekt kann über alle enthaltenen Projekte iteriert werden. In jedem Projekt können alle Dokumente als \texttt{IDocument}-Objekte betrachtet werden. Zu jedem Dokument kann der zugehörige Syntax-Baum und das semantische Modell bestimmt werden. Da die Workspace-Repräsentation das Erzeugen und Kompilieren der Dateien übernimmt, kann die Code-Analyse direkt auf Solution-Ebene erfolgen, indem das Syntax-Baum und das semantische Modell wie in den Unterabschnitten \ref{subsec:roslynsyntaxtree} und \ref{subsec:roslynsemanticmodel} beschrieben wurde.


\section{Zusammenfassung}
In den oberen Abschnitten wurden die vier Technologien \emph{FxCop}, CCI, \emph{NRefactory} und Projekt \emph{Roslyn} kurz vorgestellt. Zu jeder Technologie wurden Eigenheiten und Besonderheiten beschrieben, die sich mehr oder weniger auf die Eignung der Technologie in Bezug auf ein Usus-ähnliches Programm für .NET auswirken. Abbildung \ref{fig:techevalsummary} visualisiert die sich daraus ergebenen bewerteten Verbindungen zwischen den Technologien und den Eingangs festgelegten Fragen.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/techevalsummary.png}
	\caption{Tabellarisches Ergebnis der Technologie Evaluierung}
	\label{fig:techevalsummary}
\end{figure}
Es ist zu sehen, dass die für die Berechnung der Metriken erforderlichen Informationen von allen untersuchten Lösungen ermittelt werden können. Bei zwei Lösungen allerdings mit Vorbedingung.
\paragraph{}
Zuerst wurde in Abschnitt \ref{sec:fxcop} \emph{FxCop} betrachtet. Diese Technologie wird im Rahmen der Evaluierung als nicht tauglich bewertet. Der Grund dieser Entscheidung ist auf die Umgebung zurückzuführen. Die eigentliche Code-Analyse wird von einer eigenen speziellen Regel durchgeführt, die im Kontext der \emph{FxCop} Runner-Anwendung ausgeführt wird. Dadurch wird die Kommunikation zwischen Regel und aufrufendem Programm erschwert was zu einer größeren Distanz zwischen Informationssammlung und Informationsaufbereitung führt.
\paragraph{}
Anschließend wurde in Abschnitt \ref{sec:cci} die \emph{Common Compiler Infrastructure} (CCI) betrachtet. Im Rahmen der Evaluierung wird diese Technologie als sehr geeignet erachtet. Als einzigen Nachteil wurde festgestellt, dass CCI mit Assemblies und CIL-Anweisungen arbeitet und daher keinen direkten Bezug zu dem Original-Quellcode hat. Da das zu analysierende Programm in Form einer Assembly vorliegen muss, wurden alle Abhängigkeiten bereits zur Kompilierzeit aufgelöst und Ziele von Methodenaufrufen bestimmt. CCI kann diese auslesen und brauch nicht selbst zu kompilieren.
\paragraph{}
Weiter wurde in Abschnitt \ref{sec:nrefactory} \emph{NRefactory} untersucht. Diese Technologie wird in der Evaluierung als geeignet angesehen. Die Besonderheit von \emph{NRefactory} ist, dass diese Bibliothek Unterstützung für die Analyse von Quelltext bietet (zumindest für C$\#$, VB.net kommt wahrscheinlich bald dazu). Diese Form der Analyse hat einige Einschränkungen. Beispielsweise kann das tatsächliche Aufrufziel eines Methodenaufrufs durch die alleinige Betrachtung von Quelltext nicht ermittelt werden. Dafür muss \emph{NRefactory} kompilieren, was dann nur in einer vollständigen Umgebung möglich ist. Um mit Assemblies zu arbeiten wird \emph{Mono.Cecil} genutzt, das hier in Verbindung mit \emph{NRefactory} gesehen wird. Während der Evaluierung wurden die Möglichkeiten der Assembly-Analyse mithilfe von CCI als umfangreicher festgestellt.
\paragraph{}
Abschließend wurde in Abschnitt \ref{sec:roslyn} das Projekt mit dem Codenamen \emph{Roslyn} vorgestellt. Im dieser Evaluierung wurde diese Technologie als nicht geeignet bewertet. Diese Entscheidung wurde aufgrund der Tatsache getroffen, dass \emph{Roslyn} noch nicht offiziell verfügbar ist sondern derzeitig nur als CTP bezogen werden kann (was sich nach dieser Master-Thesis wahrscheinlich bald ändert). Weiterhin ist die Installation der \emph{Roslyn} Umgebung erforderlich. Langfristig ist diese Technologie die bessere Lösung, da sie direkt von Microsoft kommt und im Gegensatz zu \emph{NRefactory} wesentlich umfangreichere Möglichkeiten, wie beispielsweise die Workspace API, bietet. \emph{Roslyn} arbeitet mit Quellcode und muss zur Auflösung von Methodenaufrufen ebenfalls kompilieren was wieder nur in einer vollständigen Umgebung funktioniert. Dank der Workspace API wird diese aber automatisch verwaltet.
\paragraph{}
Zusammenfassend ist zu sagen, das die \emph{Common Compiler Infrastructure} (CCI) derzeitig die beste Möglichkeit darstellt eine statische Code-Analyse, oder besser gesagt Assembly-Analyse durchzuführen. Sollte die Analyse von reinem Quellcode in einem Sonderfall erforderlich werden, kann eine Kombination mit \emph{NRefactory} genutzt werden. Sobald Projekt \emph{Roslyn} allerdings einen offiziellen Zustand erreicht, sollte eine mögliche Technologieersetzung möglich sein. Bis dahin unterstützt die Tatsache, dass \emph{FxCop} und andere Programme ebenfalls die CCI verwenden, diese Entscheidung.




\chapter{Usus.net}
\label{chap:ususnet}
Nachdem das Usus-Plugin für Java einfach \emph{Usus} heißt, wird die Visual Studio Erweiterung, die in der vorliegenden Master-Thesis entwickelt wird, im weiteren Verlauf als \emph{Usus.net} bezeichnet. Die Architektur von Usus.net, das in Abschnitt \ref{sec:architecture} noch grob als System bezeichnet wurde, besteht aus drei Teilen, die in Abbildung \ref{fig:architecture2} abgebildet sind.
\begin{figure}[h]
	\centering
		\includegraphics[width=8cm]{images/architektur2.jpg}
	\caption{Architektur von Usus.net}
	\label{fig:architecture2}
\end{figure}
\texttt{Usus.net} als Visual Studio Erweiterung verwendet Oberflächen-Elemente, die in einer Bibliothek zusammengefasst und unabhängig von Visual Studio sind. Die Oberflächen sind Bestandteil der Bibliothek \texttt{Usus.net.View}. Diese verwendet eine weitere Bibliothek, die den allgemeinen Funktionsumfang von Usus darstellt: \texttt{Usus.net.Core} übernimmt die statische Code-Analyse von Assemblies, die Bewertung der Metriken und die Hotspot-Analyse. Diese Bibliothek kann sowohl über die Kommandozeile bedient werden, als auch in andere Anwendungen integriert werden. In diesem Kapitel wird Usus.net aus der Perspektive von \texttt{Usus.net.Core} vorgestellt. Dafür wird die konkrete Berechnung der Metriken mit der \emph{Common Compiler Infrastructure} beschrieben, sowie auf das zugrunde liegende Objektmodell eingegangen. Das Objektmodell dient dazu die Ergebnisse der Analyse weiter zu verarbeiten. Abschließend wird das Usus.net Verifikations-Framework vorgestellt, mit dem \texttt{Usus.net.Core} selbst getestet wurde.


\section{Metrikberechnung}
\label{sec:metriccalc}
In diesem Abschnitt wird vorgestellt, wie die Usus-Metriken aus Abschnitt \ref{sec:metrics} von Usus.net berechnet werden. In Abschnitt \ref{sec:cci} wurde erklärt das CCI Assemblies analysiert. Deswegen beginnt auch die Berechnung der Metriken mit einem Pfad zu einer \emph{Portable Executable}-Datei, wie sie in Unterabschnitt \ref{subsec:ccimetadata} definiert wurde. Abbildung \ref{fig:metriccalc} zeigt die Klassen, die an der Berechnung beteiligt sind. Alle diese Klassen befinden sich im Namespace \texttt{andrena.Usus.net.Core.Metrics}.
\begin{figure}[h]
	\centering
		\includegraphics[width=17cm]{images/metriccalc.jpg}
	\caption{Klassen, die an der Metrikberechnung von Usus.net beteiligt sind}
	\label{fig:metriccalc}
\end{figure}
Ein \texttt{AssemblyVisitor}-Objekt ist in der Lage eine PE-Datei einzulesen und definierte Typen und Methoden zu lokalisieren. Dies ist mit \emph{CCI Metadata} möglich. \texttt{MetricCollector} erbt die Analyse-Funktionalität von \texttt{AssemblyVisitor} und berechnet für die gefundenen Typen und Methoden die Metriken, die ohne den Kontext berechenbar sind. Für Methoden sind dies \emph{zyklomatische Komplexität}, \emph{Anzahl der Anweisungen}, \emph{Anzahl der tatsächlichen Codezeilen}, \emph{Anzahl der logischen Codezeilen} und \emph{Abhängigkeiten von Typen}. Als Klassenmetriken sind \emph{Anzahl der nicht-statischen öffentlichen Felder}, \emph{Anzahl der Methoden} und \emph{direkte Abhängigkeiten von Typen} kontextfrei. Alle weiteren Metriken sind nur dann berechenbar, wenn die kontextfreien Metriken vollständig bestimmt wurden. So lassen sich beispielsweise die \emph{interessanten direkten Typ-Abhängigkeiten} einer Klasse erst ermitteln, wenn alle selbst-deklarierten Typen im System bekannt sind. Das gleiche gilt für die \emph{zyklischen Abhängigkeiten von Namensräumen}, die nur in einem vollständigen Graph der Namensräume gefunden werden können. Diese kontext-sensitiven Metriken werden von Usus.net im Rahmen einer nachträglichen Bearbeitung der Metriken berechnet. Dazu wird zum einen die Klasse \texttt{PostProcessTypeDependencies} verwendet, die aus allen interessanten Abhängigkeiten den Abhängigkeitsbaum erzeugt um anschließend die kumulierte Komponentenabhängigkeit zu bestimmen. Zum anderen wird die Klasse \texttt{PostProcessNamespaceDependencies} genutzt um aus dem Abhängigkeitsbaum der Typen einen Abhängigkeitsbaum der Namespaces zu erstellen, der dann genutzt werden kann um die zyklischen Abhängigkeiten der Namespaces zu suchen.
\paragraph{}
Für jede zu bestimmende Metrik existiert eine Klasse, die die Berechnung durchführen kann. Alle Ergebnisse werden in einem \texttt{MetricsReport}-Objekt gesammelt und in Form eines Berichts im \texttt{MetricCollector}-Objekt hinterlegt. Der Aufrufer kann diesen Bericht jederzeit einsehen. Abschnitt \ref{sec:ususobjectmodel} beschreibt diesen Bericht als Bestandteil des Objektmodells ausführlicher, während Listing \ref{listing:ususnetcoreusage} einen vereinfachten Codeausschnitt aus \texttt{Usus.net.Console} zeigt, der die statische Code-Analyse durchführt und sämtliche Metriken aller Methoden einfach auf der Console ausgibt.
\begin{lstlisting}[caption={Aufruf der Code-Analyse von \texttt{Usus.net.Core} in \texttt{Usus.net.Console}},label={listing:ususnetcoreusage}]
var metrics = Analyze.PortableExecutable(assemblyToAnalyze);
//alternativ: Analyze.Me();
foreach (var method in metrics.Methods) {
	Console.WriteLine("Signature: " + method.Signature);
	Console.WriteLine("CyclomaticComplexity: " + method.CyclomaticComplexity);
	...
}
\end{lstlisting}
Nachdem die Infrastruktur der Metrikberechnung hiermit beschrieben wurde, werden in den folgenden Unterabschnitten die konkreten Berechnungen der einzelnen Metriken vorgestellt.

\subsection{Zyklomatische Komplexität}
Die zyklomatische Komplexität einer Methode gibt an, wie viele unterschiedliche Ablaufpfade durch eine Methode existieren. In Unter-Unterabschnitt \ref{subsubsec:cyclomaticcomplexity} wurde diese Metrik ausführlicher erklärt. In Usus.net kann die Berechnung auf zwei verschiedene Arten durchgeführt werden. Zum einen kann ausschließlich \emph{CCI Metadata} verwendet und alle CIL-Anweisungen die eine Entscheidung treffen aufsummiert werden. Die Klasse \texttt{CyclomaticComplexityOfIl} implementiert diesbezüglich eine einfache Abwandlung des Algorithmus, der unter anderem von Steve Gilham vorgestellt wurde \cite{CCperCIL} und laut ihm angeblich auch in frühen Versionen von NDepend (Abschnitt \ref{sec:ndepend}) verwendet wurde. Die andere Variante, die in Usus.net standardmäßig verwendet wird, nutzt \emph{CCI Code and AST Components}. Die Klasse \texttt{CyclomaticComplexityOfAst} erzeugt ein spezielles Besucher-Objekt vom Typ \texttt{CyclomaticComplexityCalculator}, das den aus dem Methodenrumpf erzeugten abstrakten Syntaxbaum besucht. Die Erzeugung des AST aus der Methoden-Definition übernimmt CCI. Listing \ref{listing:cyclomaticcomplexityofast} zeigt den Code der die zyklomatische Komplexität in \texttt{Usus.net.Core} bestimmt.
\begin{lstlisting}[caption={Statement-Analyse zur Bestimmung der zyklomatischen Komplexität},label={listing:cyclomaticcomplexityofast}]
var methodBody = method.Decompile(pdb, host);
var cyclomaticComplexityCalculator = new CyclomaticComplexityCalculator();
cyclomaticComplexityCalculator.Traverse(methodBody.Statements());
var result = cyclomaticComplexityCalculator.Result;
\end{lstlisting}
Das \texttt{CyclomaticComplexityCalculator}-Objekt erbt die Funktionalität, sämtliche Anweisungen (engl. Statements) in einem Methodenrumpf zu besuchen, von \texttt{CodeTraverser}, einer Klasse in der CCI. Jede Bedingung, jede \texttt{if}-, \texttt{while}-, \texttt{for}-, \texttt{case}- und \texttt{catch}-Anweisung erhöht einen anfangs mit 1 initiierten Zähler. Obwohl \texttt{CodeTraverser} auch eine Behandlungsroutine für \texttt{foreach}-Anweisungen anbietet, ist die CCI momentan nicht in der Lage diese als solche erfolgreich zu erkennen. Dies hat zur Folge, das \texttt{foreach}-Anweisungen, die vom Compiler in \texttt{while}/\texttt{if}/\texttt{finally}-Anweisungen übersetzt werden, auch also solche erkannt werden. Durch das \texttt{while} und das \texttt{if} entstehen also zwei Stellen, die eine Entscheidung treffen, während im Quellcode mit \texttt{foreach} nur eine erkennbar ist. Die in Usus.net berechnete zyklomatische Komplexität einer Methode entspricht also der Komplexität, die der Compiler generiert und nicht der, die durch den Quellcode suggeriert wird.

\subsection{Methodenlänge}
\label{subsec:methodlength}
Die Länge einer Methode sagt etwas darüber aus, wie viele Dinge diese Methode ausführt. Eine kurze Methode ist einfacher zu verstehen und zu verändern als eine lange. In Unter-Unterabschnitt \ref{subsubsec:methodlength} wurde diese Metrik und ihre Varianten genauer beschrieben. Usus.net bestimmt drei verschiedene Methodenlängen.
\paragraph{}
Als sehr nachvollziehbare Längenangabe wird wohl die Anzahl der Codezeilen gesehen, die Logik enthalten. Dieser Wert wird von der Klasse \texttt{NumberOfLogicalLines} bestimmt und ausschließlicher Verwendung von \emph{CCI Metadata}. Alle CIL-Anweisungen, außer leeren Anweisungen (\texttt{Nop}), Block-Verlassen-Anweisungen (\texttt{Leave.S}) und Methoden-Rückgabe-Anweisungen (\texttt{Ret}) werden dabei betrachtet. Listing \ref{listing:numberoflogicallines} zeigt den Code, der die Codezeilen der betroffenen CIL-Anweisungen (Operationen) findet, doppelte Werte entfernt und deren Anzahl bestimmt.
\begin{lstlisting}[caption={Operation-Analyse zur Bestimmung der Anzahl der logischen Codezeilen},label={listing:numberoflogicallines}]
var locations = method.LocatedOperations(pdb);
var result = locations.GetAllStartLinesOfInterestingOpCodes().Distinct().Count();
\end{lstlisting}
Die Zuordnung der Codezeilen des Quelltexts vor der Kompilierung zu den CIL-Anweisungen danach kann nur durchgeführt werden, wenn zu der zu analysierenden PE-Datei eine pdb-Datei existiert. Wie in Unterabschnitt \ref{subsec:ccimetadata} definiert, beinhaltet die pdb-Datei die erforderlichen Zeilenangaben. Die CCI unterstützt die Analyse dieser Dateien ebenfalls mithilfe der Klasse \texttt{PdbReader}. Sollte keine pdb-Datei zur Verfügung stehen, bestimmt Usus.net den Ergebniswert der \texttt{NumberOfLogicalLines}-Metrik mit -1.
\paragraph{}
Standardmässig verwendet Usus.net die Anzahl der logischen Codezeilen als Methodenlänge. Sollte deren Bestimmung aufgrund einer fehlenden pdb-Datei nicht möglich sein, wird die Anzahl der Anweisungen verwendet. Die Klasse \texttt{NumberOfStatements} verwendet \emph{CCI Code and AST Components} um den Methodenrumpf zu dekompilieren und einen AST zu erzeugen. Dieser kann anschließend analysiert und sämtliche Anweisungen besucht werden. Dieses Vorgehen ist vergleichbar mit der Bestimmung der zyklomatischen Komplexität. Listing \ref{listing:numberofstatements} zeigt wie dafür ein \texttt{StatementCollector}-Objekt verwendet wird.
\begin{lstlisting}[caption={Statement-Analyse zur Bestimmung der Anzahl der Anweisungen},label={listing:numberofstatements}]
var methodBody = method.Decompile(pdb, host);
var statementCollector = new StatementCollector(pdb);
statementCollector.Traverse(methodBody.Statements());
var result = return statementCollector.Result.Count();
\end{lstlisting}
Neben der Anzahl der Anweisungen kann Usus.net auch die Anzahl der CIL-Anweisungen, den sogenannten Operationen, bestimmen. Dafür wird kein AST erzeugt, sodass nur die \emph{CCI Metadata}-Infrastruktur benötigt wird. Allerdings besteht eine Methode aus einer Vielzahl von Operationen, die keinen direkten Zusammenhang mit dem Quellcode vor dem Kompilieren erkennen lassen.
\paragraph{}
Als dritte Möglichkeit die Methodenlänge zu bestimmen, kann Usus.net die Anzahl der tatsächlichen Zeilen einer Methode ausrechnen. Genau wie bei der Anzahl der logischen Codezeilen ist hierfür \emph{CCI Metadata} sowie eine pdb-Datei erforderlich. In der Klasse \texttt{NumberOfRealLines} werden die Zeilen aller Operationen eines Methodenrumpfs ermittelt. Durch die Differenz der ersten und letzten Zeile kann die Anzahl der Zeilenumbrüche bestimmt werden. Listing \ref{listing:numberofreallines} zeigt diese Berechnung.
\begin{lstlisting}[caption={Operation-Analyse zur Bestimmung der Anzahl der tatsächlichen Zeilen},label={listing:numberofreallines}]
var locations = method.LocatedOperations(pdb);
var firstLine = locations.GetAllValidLines(l => l.EndLine).Min();
var lastLine = locations.GetAllValidLines(l => l.EndLine).Max();
var result = Math.Max(0, lastLine - firstLine - 1);
\end{lstlisting}
Wenn die pdb-Datei nicht existiert, wird der Wert der \texttt{NumberOfRealLines}-Metrik auf -1 gesetzt.

\subsection{Kumulierte Komponentenabhängigkeit}
\label{subsec:ccdcode}
Die Anzahl aller Klassen, von denen eine Klasse im objektorientierten Sinne (siehe Unterabschnitt \ref{subsec:oo}) direkt und indirekt abhängig ist, ist auch als kumulierte Komponentenabhängigkeit (CCD) bekannt. Diese Metrik wurde bereits ausführlich in Unter-Unterabschnitt \ref{subsubsec:ccd} vorgestellt. Damit die direkten Abhängigkeiten einer Klasse bestimmt werden können müssen zunächst die direkten Klassenabhängigkeiten pro Methoden ermittelt werden. Jede Verwendung eines Typs innerhalb der Methodensignatur sowie dem Methodenrumpf muss erkannt werden. Usus.net verwendet dazu die Klasse \texttt{TypeDependencies}. Mithilfer der \emph{CCI Metadata}-Infrastruktur werden die CIL-Anweisungen der Methode nach Referenzen auf Typen untersucht. Die dabei verwendeten Strategien sind in Listing \ref{listing:typedependencies1} zu sehen. Die Ergebnisse dieser Strategien werden in einer Liste konsolidiert, wobei doppelte Vorkommen ignoriert werden.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Klassenabhängigkeiten einer Methode},label={listing:typedependencies1}]
var dependenciesOfMethod = Enumerable.Empty<string>()
		.Union(TypeDependenciesOfSignature.Of(method))
		.Union(TypeDependenciesOfVariables.Of(method))
		.Union(TypeDependenciesOfCallOperations.Of(method))
		.Union(TypeDependenciesOfNewOperations.Of(method))
		.Union(TypeDependenciesOfCatches.Of(method))
		.Union(TypeDependenciesOfTypeMentions.Of(method));
\end{lstlisting}
Die Variable \texttt{method} enthält eine Referenz auf ein Objekt vom Typ \texttt{IMethodDefinition}, welches in \emph{CCI Metadata} definiert ist. Nachdem zu jeder Methode alle Abhängigkeiten bestimmt wurden, können die Abhängigkeiten einer Klasse einfach ermittelt werden, wie in Listing \ref{listing:typedependencies2} dargestellt.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Klassenabhängigkeiten einer Klasse},label={listing:typedependencies2}]
var dependenciesOfType = Enumerable.Empty<string>()
		.Union(type.FullName().Return())
		.Union(GetMethodTypes(methods))
		.Union(GetFieldTypes(type.Fields))
		.Union(GetAncestorTypes(type))
		.Union(GetGenericConstraints(type));
\end{lstlisting}
Dazu werden die Abhängigkeitslisten der Methoden zusammengefasst und mit den Typen der Felder, den Typen der Oberklassen und den Typen eventueller generischer Einschränkungen kombiniert. Eine Klasse ist auch von sich selbst abhängig. Diese Konsolidierung der Listen erfolgt in der Klasse \texttt{DirectDependencies}. Doppelte Vorkommen eines Typen werden wieder ignoriert. Die Variable \texttt{type} enthält eine Referenz auf ein Objekt vom Typ \texttt{INamedTypeDefinition}, welches in \emph{CCI Metadata} definiert ist. \texttt{methods} enthält eine Sequenz von \texttt{MethodMetricsReport}-Objekten, die den Methoden der Klasse in \texttt{type} zugeordnet sind.
\paragraph{}
Um Typen wie \texttt{object}, \texttt{string} und \texttt{int}, die in der Base Class Library (BCL) des .NET-Frameworks definiert sind zu ignorieren, brauchen nur die interessanten Typen betrachtet werden. Dies sind Klassen, die in der analysierten Assembly selbst deklariert und definiert wurden. Dieser Filter ist in der Klasse \texttt{InterestingDirectDependencies} definiert. Da zu diesem Zeitpunkt alle deklarierten Typen des Systems bereits bekannt sein müssen, kann der Filter erst im Rahmen der nachträglichen Bearbeitung durch die \texttt{PostProcessTypeDependencies}-Klasse angewendet werden. Jeder in der Assembly deklarierte Typ ist anschließend nur noch von anderen in der Assembly deklarierten Typen abhängig. Aus diesem Netz der Abhängigkeiten erzeugt Usus.net mithilfe der QuickGraph\footnote[1]{QuickGraph: "`Generic Graph Data Structures and Algorithms for .NET"' \url{http://quickgraph.codeplex.com/}} Bibliothek einen Abhängigkeitsgraphen auf Typ-Ebene. Um jetzt alle direkten und indirekten Abhängigkeiten einer Klasse \texttt{type} zu bestimmen, kann wie Unter-Unterabschnitt \ref{subsubsec:ccd} hergeleitet der Algorithmus \emph{Depth First Search} verwendet werden, um die Erreichbarkeitsmenge des Knoten von \texttt{type} zu finden. Wie in Listing \ref{listing:cumulatedcomponentdependency} dargestellt, ist die kumulierte Komponentenabhängigkeit einer Klasse \texttt{type} die Anzahl der nicht vom Compiler erzeugten Typen, in der Erreichbarkeitsmenge von \texttt{type}.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der kumulierten Komponentenabhängigkeit},label={listing:cumulatedcomponentdependency}]
var result = typeGraph.Reach(type).Vertices
		      .Count(t => !t.CompilerGenerated);
\end{lstlisting}
Die Implementierung der \texttt{Reach}-Funktion verwendet die \texttt{DepthFirstSearchAlgorithm<T, Edge<T>>}-Klasse von QuickGraph und setzt den Startknoten auf $type$. Zusätzlich wird die Suche abgebrochen, nachdem die Erreichbarkeitsmenge des Startknotens gefunden wird.

\subsection{Klassengröße}
Die Klassengröße gehört zu den Metriken die kontextfrei bestimmt werden können. In Unter-Unterabschnitt \ref{subsubsec:classsize} wurde die Klassengröße in Usus als Anzahl der Methoden festgelegt. Die API der \emph{CCI Metadata} erlaubt eine bedingte Aufsummierung aller Methoden in einer Typ-Definiton, wie in Listing \ref{listing:numberofmethods} gezeigt.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der Anzahl der Methoden},label={listing:numberofmethods}]
var result = type.Methods.Count(m => !m.IsDefaultCtor());
\end{lstlisting}
Da jeder nicht-statische Typ immer einen Default-Konstruktor enthält, wird dieser in der Klassengröße nicht berücksichtigt. Neben Konstruktoren erzeugt der .NET-Compiler auch aus Properties, Indexern und Events Methoden.

\subsection{Nicht-statische öffentliche Felder}
Die Anzahl der öffentlichen Felder, die nicht statisch sind, kann ebenfalls im Rahmen der kontextfreien Bestimmung der Klassenmetriken ermittelt werden. Diese Metrik wurde bereits in Unter-Unterabschnitt \ref{subsubsec:nonstaticpublicfields} vorgestellt. Listing \ref{listing:nonstaticpublicfields} zeigt diese bedingte Aufsummierung der Felder einer Klasse.
\begin{lstlisting}[caption={Typen-Analyse zur Bestimmung der nicht-statischen öffentlichen Felder},label={listing:nonstaticpublicfields}]
var result = type.Fields.Count(f => !f.IsStatic 
	     && f.Visibility == TypeMemberVisibility.Public);
\end{lstlisting}
Auch hier ermöglicht die API der \emph{CCI Metadata} eine Iteration über alle Felder einer Typ-Definition.

\subsection{Namespaces mit zyklischen Abhängigkeiten}
\label{subsec:namespaceswithcyclicdependencies}
Die einzige Metrik die Usus.net für Namespaces bestimmt, ist die Anzahl der zyklischen Abhängigkeiten. In Unter-Unterabschnitt \ref{subsubsec:packetswithcyclicdependencies} wurde hergeleitet, das dafür der Algorithmus \textit{Strongly Connected Components} verwendet werden kann. Die Berechnung setzt also den vollständigen Abhängigkeitsgraphen auf Namespace-Ebene voraus. Der Abhängigkeitsgraph auf Typen-Ebene wurde von Usus.net bereits für die Berechnung der kumulierten Komponentenabhängigkeit in \ref{subsec:ccdcode} erstellt. Aus diesem Graph kann der Namespace-Graph reduziert werden. Damit ist offensichtlich, das auch diese Metrik im Rahmen der nachträglichen Bearbeitung kontextabhängig bestimmt wird. Die Klasse \texttt{PostProcessNamespaceDependencies} führt die nötigen Berechnungen durch, indem zuerst der Abhängigkeitsgraph auf Namespace-Ebene erstellt wird. Danach werden die Kreise ermittelt und den entsprechenden Namespaces zugewiesen.
\subsubsection{Namespace-Graph}
Die Erstellung des Graphen aller Namespaces geschieht wie in Listing \ref{listing:namespacegraphcreation} dargestellt.
\begin{lstlisting}[caption={Erzeugung des Abhängigkeitsgraphen auf Namespace-Ebene},label={listing:namespacegraphcreation}]
namespaceGraph = metrics.GraphOfTypes.Cast(t => t.AsNamespaceWithTypes());
foreach (var namespaceGroup in namespaceGraph.Vertices
	.GroupBy(n => n.Itself.Name)) {
	namespaceGraph.Reduce(
		namespaceGroup.AsNamespaceWithTypes(), 
		namespaceGroup);
}
\end{lstlisting}
Der Abhängigkeitsgraph auf Klassen-Ebene vom Typ \texttt{MutableGraph<TypeMetricsReport>} wird zunächst in einen neuen Graphen vom Typ \texttt{MutableGraph<NamespaceMetricsWithTypeMetrics>} überführt. Dies ist notwendig, da Knoten im nächsten Schritt zusammengefasst werden und alle Knoten in einem Graph den gleichen Knotentyp haben müssen. Jeder \texttt{TypeMetricsReport}-Knoten wird zu einen \texttt{NamespaceMetricsWithTypeMetrics}-Knoten umgestaltet. Das Ergebnis dieser \texttt{Cast}-Operation ist also ein identischer Graph mit einem unterschiedlichen Knotentyp. Anschließend können alle Knoten, die den gleichen Namespace (\texttt{n.Itself.Name}) besitzen zusammengefasst werden. Alle diese gruppierten Knoten (Typen) des gleichen Namespace können dann mit der \texttt{Reduce}-Operation des Graphen zu einem einzigen Knoten zusammengefasst werden, der alle Typen des Namespace repräsentiert. Der erste Parameter von \texttt{Reduce} ist der neue Knoten, der die Knoten in der Menge, die als zweiter Parameter übergeben wird, ersetzen soll. Selbstverständlich müssen alle Kanten zwischen Knoten außerhalb und Knoten innerhalb der zu reduzierenden Menge zu Kanten zwischen dem neuen Knoten und den Knoten außerhalb der reduzierten Menge umgestaltet werden. In der QuickGraph Bibliothek konnte kein Algorithmus gefunden werden, der diesen Reduktionsvorgang komplett übernimmt. QuickGraph bietet lediglich die \texttt{MergeVertex}-Operation an, die es erlaubt einen einzigen Knoten aufzulösen und die Knoten seiner eingehenden Kanten mit den Knoten seiner ausgehenden Kanten zu verbinden. Auf dieser Basis kann der Algorithmus in Listing \ref{listing:vertexreduction}, der in der vorliegenden Master-Thesis als \textit{Vertex Reduction} bezeichnet wird, aufgebaut werden.
\begin{lstlisting}[caption={\textit{Vertex Reduction} - Reduktion von Knotenmengen in einem Digraph},label={listing:vertexreduction}]
graph.AddVertex(reducedVertex);
foreach (var vertex in vertices) {
	graph.AddEdge(new Edge<T>(reducedVertex, vertex));
	graph.AddEdge(new Edge<T>(vertex, reducedVertex));
	graph.MergeVertex(vertex, (s, t) => new Edge<T>(s, t));
}
\end{lstlisting}
Der erste Parameter dieses Algorithmus ist der neue Knoten, der eine Menge an anderen Knoten zusammenfassen soll und in \texttt{reducedVertex} vorliegt. Der zweite Parameter des Algorithmus sind die Knoten, die zusammengefasst werden sollen, welche als Menge von Knoten in \texttt{vertices} vorliegen. Der neue Knoten wird in den Graph eingefügt und mit allen Knoten, die er ersetzen soll, \textit{stark} verbunden. Anschließend können alle Knoten, die ersetzt werden sollen mithilfe der \texttt{MergeVertex}-Operation aufgelöst werden. Durch die beidseitigen Verbindungen der aufzulösenden Knoten mit dem neuen Knoten werden alle Kanten der alten Knoten auf den neuen Knoten umgebogen. Abbildung \ref{fig:vertexreduction} zeigt die schematische Funktionsweise des Algorithmus \textit{Vertex Reduction} an einem Beispiel.
\begin{figure}[h]
	\centering
		\includegraphics[width=15cm]{images/vertexreduction.jpg}
	\caption{Schematische Darstellung der Funktionsweise des \textit{Vertex Reduction}-Algorithmus}
	\label{fig:vertexreduction}
\end{figure}
Die beiden mittleren Knoten sollen zu einem zusammengefasst werden, ohne das die Kanten verloren gehen. Diese Graphenreduktion, wie sie für die Erstellung des Abhängigkeitsgraph auf Namespace-Ebene erforderlich ist, kann mit der wiederholten Anwendung des \textit{Vertex Reduction}-Algorithmus erreicht werden. Bei jeder Anwendung wird dem Graph ein neuer \texttt{NamespaceMetricsWithTypeMetrics}-Knoten hinzugefügt, der alle \texttt{NamespaceMetricsWithTypeMetrics}-Knoten des gleichen Namespace ersetzt. Sobald der Algorithmus für alle Gruppen von Typen, die sich im gleichen Namespace befinden angewendet wurde, ist der Abhängigkeitsgraph auf Namespace-Ebene vollständig.
\subsubsection{Namespace-Kreise}
Die QuickGraph Bibliothek bietet eine Implementierung des Algorithmus zur Erkennung der starken Zusammenhangskomponenten. Die Methode \texttt{StronglyConnectedComponents} kann dazu auf dem QuickGraph-Graphen vom Typ \texttt{BidirectionalGraph<V, Edge<V>>} aufrufen werden. Das Ergebnis ist eine Zuordnung von Knoten \texttt{V} zu der eindeutigen Identifikationsnummer der \textit{Strongly Connected Component} in Form eines \texttt{IDictionary<V, int>}-Objekts. Um die Kreise den Knoten die sie enthalten zuordnen zu können, ist eine Zuordnung von Knoten zu einer Menge von Knoten (dem Kreis) erforderlich. Tabelle \ref{tab:sccfunctionalcomp} zeigt die Transformation der ursprünglichen Zuordnung um die gewünschte Abbildung von Knoten auf Knotenmenge zu erhalten. IE\textless{}$V$\textgreater{} steht für eine Sequenz von Objekten vom Typ $V$ und ist eine Abkürzung des Typen \texttt{IEnumerable<V>}. Die Transformation hat einen einmaligen Aufwand von $O(n)$, da die initiale Abbildung einmal vollständig invertiert werden muss.
\begin{table}
\centering
\begin{array}[t]{ l r c l l}
(1) & V & \rightarrow & int & \text{Ergebnis der \texttt{StronglyConnectedComponents}-Methode}\\
(2) & int & \rightarrow & IE<V> & \text{Umkehrung der Abbildung (1)}\\
(3) & V \rightarrow int & \rightarrow & int \rightarrow IE<V> & \text{Funktionale Komposition von (1) und (2)}\\
(4) & V & \rightarrow & IE<V> & \text{Reduktion der funktionalen Komposition (3)}\\
\end{array}
\caption{Abbildung von Knoten zu starker Zusammenhangskomponente zu anderen Knoten}
\label{tab:sccfunctionalcomp}
\end{table}
Diese neue Abbildung wird in einem Objekt vom Typ \texttt{StronglyConntectedComponents} gekapselt. Um die Anzahl der zyklischen Abhängigkeiten eines konkreten Namespace zu ermitteln muss die Methode \texttt{StronglyConntectedComponents}-Methode auf dem Abhängigkeitsgraph auf Namespace-Ebene aufgerufen werden. Auf das Ergebnis kann die in Tabelle \ref{tab:sccfunctionalcomp} gezeigte Transformation angewendet werden um ein \texttt{StronglyConntectedComponents<NamespaceMetricsWithTypeMetrics>}-Objekt zu erhalten. Dieses Objekt kann jederzeit nach allen oder speziellen Kreisen gefragt werden. Die zyklischen Abhängigkeiten eines Namespace werden in der nachträglichen Bearbeitung der Metriken von der Klasse \texttt{CyclicDependencies} bestimmt. Listing \ref{listing:namespacedependencies} zeigt wie das Objekt, dass die starken Zusammenhangskomponenten repräsentiert (also das Kompositions-Ergebnis aus Tabelle \ref{tab:sccfunctionalcomp}) nach dem Kreis gefragt wird, auf dem sich der Knoten des Namespace \texttt{namespaceWithTypes} befindet.
\begin{lstlisting}[caption={Namespace-Analyse zur Bestimmung der zyklischen Abhängigkeiten},label={listing:namespacedependencies}]
var result = from n in cycles.OfVertex(namespaceWithTypes).Vertices
	     select n.Itself;
\end{lstlisting}
Nachdem alle Namespaces Informationen über die Kreise, auf denen sie sich eventuell befinden, erhalten haben, ist die nachträgliche Bearbeitung der Metrik-Analyse beendet. Das vollständige MetrikReport-Objekt steht dem Aufrufer der Analysemethoden der \texttt{Analyze}-Klasse zur Verfügung.


\section{Objektmodell}
\label{sec:ususobjectmodel}
Im vorherigen Abschnitt wurde die Berechnung der Metriken ausführlich beschrieben. Dieser Abschnitt stellt das Objektmodell des Metrikberichts näher vor. Alle Klassen dieses Modells befinden sich im Namespace \texttt{andrena.Usus.net.Core.Reports}. Abbildung \ref{fig:metriccalc} zeigt, dass das zentrale Datenobjekt \texttt{MetricsReport} ist. Wie in Abschnitt \ref{sec:metriccalc} beschrieben, wird dieses Objekt zunächst mit den Daten befüllt, die das \texttt{MetricsCollector}-Objekt sammelt. Anschließend werden im Rahmen der nachträglichen Bearbeitung weitere Berechnungen vorgenommen um auch die kontextabhängigen Metriken zu bestimmen. Diese komplette Metrik-Analyse wird durch die statischen Methoden der \texttt{Analyze}-Klasse gestartet. Diese Methoden liefern das \texttt{MetricsReport}-Objekt als Ergebnis an den Aufrufer zurück. In diesem Abschnitt wird genau dieses Objekt genauer betrachtet. Abbildung \ref{fig:metricsreport} zeigt alle Klassen, aus denen dieser Bericht besteht.
\begin{figure}[h]
	\centering
		\includegraphics[width=17cm]{images/metricsreport.jpg}
	\caption{Objektmodell und Klassen des vollständigen Metrikberichts}
	\label{fig:metricsreport}
\end{figure}

\subsection{Methodenberichte}
Der Metrikbericht besteht aus mehreren Methodenberichten. Diese \texttt{MethodMetricsReport}-Objekte enthalten alle relevanten Daten und Metriken jeder im System gefundenen Methode. Die eindeutige Zuordnung von Methode zu Methodenbericht ist über die Eigenschaft \texttt{Signature} möglich. Die Signatur einer Methode macht sie im System eindeutig, da neben Methodenname auch Typ- und Namespace-Name, sowie vollständige Namen des Rückgabetypen und aller Parametertypen enthalten sind. Neben der Menge aller Methodenberichte kann der Bericht zu einer bestimmten Methode in \texttt{MetricsReport} auch gesucht werden. Dazu existieren mehrere Extension Methods\footnote[1]{Mehr über Extension Methods: "`add methods to existing types"' \url{http://msdn.microsoft.com/en-us/library/bb383977.aspx}}, die wie in Listing \ref{listing:methodpropertysearch} dargestellt, benutzt werden können. Die Variable \texttt{metrics} enthält die Referenz zu dem \texttt{MetricsReport}-Objekt. Methodenberichte sind vom Typ \texttt{MethodMetricsReport} und lassen sich zum einen über die \texttt{Signature}-Eigenschaft der Methode finden, wie Zeile 2 zeigt. Wenn die zu suchende Methode im Scope ist (also in der Assembly deklariert ist, die den Code ausführt), kann sie wie in Zeile 4 auch über einen \texttt{Expression}-Ausdruck angegeben werden. Microsoft beschreibt dieses Konzept in Verbindung mit den in C$\#$ integrierten Lambda-Ausdrücken in einem eigenen Artikel in der MSDN Library \cite{MSDNExpressions}. Dadurch bleibt die Methodenreferenz, im Gegensatz zur Verwendung von Strings, Ziel von automatisierten Refactorings. Eine dritte Möglichkeit erlaubt das Suchen von Methodenberichten per \texttt{MethodInfo}-Objekt aus dem .NET Framework.
\begin{lstlisting}[caption={Methoden- und Property-Suche in einem \texttt{MetricsReport}-Objekt},label={listing:methodpropertysearch}]
//Methoden
methodMetrics = metrics.ForMethod(
  "System.Void andrena.Usus.net.Console.Analyzer.AnalyzeFile(System.String)");
methodMetrics = metrics.ForMethod(() => AnalyzeFile(null));
//Properties
propertyMetrics = metrics.ForProperty(() => Name);
methodMetrics = metrics.ForMethod(
  "System.String andrena.Usus.net.Console.Analyzer.Name.get()");
\end{lstlisting}
Das gleiche gilt auch für Properties. Da der C$\#$-Compiler den \texttt{get}- und \texttt{set}-Teil eines Properties als Methoden kompiliert, werden diese ebenfalls auf \texttt{MethodMetricsReport}-Objekte abgebildet. Wie in Zeile 6 in Listing \ref{listing:methodpropertysearch} gezeigt, lassen sich Properties auch über einen \texttt{Expression}-Ausdruck suchen. Das resultierende \texttt{PropertyMetricsReport}-Objekt ist einfach eine Zusammenfassung zweier \texttt{MethodMetricsReport}-Objekte, nämlich eins für den \texttt{get}- und eins für den \texttt{set}-Teil des Properties. Diese \texttt{MethodMetricsReport}-Objekte der Properties lassen sich aber auch direkt über die Signatur finden, wie Zeile 7 zeigt.

\subsection{Klassenberichte}
Da die Methoden, zu denen \texttt{MetricsReport} die Methodenberichte enthält, in einer Klasse deklariert sind, existiert auch ein Bericht für eben diese Klasse. Die Abbildung von Klasse zu Methode ist im Usus.net Objektmodell als Abbildung von \texttt{TypeMetricsReport}-Objekt zu \texttt{MethodeMetricsReport}-Objekten realisiert. Der Codeausschnitt in Listing \ref{listing:classmethodsearch} zeigt in Zeile 4 wie mithilfe der \texttt{MethodsOfType}-Methode alle Methodenberichte, die zu einem Klassenbericht gehören, ermittelt werden können.
\begin{lstlisting}[caption={Klassen- und Methoden-Suche in einem \texttt{MetricsReport}-Objekt},label={listing:classmethodsearch}]
typeMetrics = metrics.ForType<Analyzer>();
typeMetrics = metrics.ForType(typeof(Analyzer));
typeMetrics = metrics.ForType("andrena.Usus.net.Console.Analyzer");
foreach (var methodMetrics in metrics.MethodsOfType(typeMetrics)) {...}
\end{lstlisting}
Die Variable \texttt{metrics} enthält wieder die Referenz zu dem \texttt{MetricsReport}-Objekt. Zeile 1 und 2 zeigen wie der Klassenbericht für einen Typ gesucht werden kann, der in der Assembly liegt, die den Code ausführt. Der Klassenname kann damit weiterhin von automatisierten Refactorings erreicht werden. In Zeile 3 wird der Bericht anhand der \texttt{Fullname}-Eigenschaft des Klassenberichts gesucht. Diese Eigenschaft enthält den Namespace, den Klassennamen sowie eventuelle generische Parameter und ist damit eindeutig.
\paragraph{}
Die Metriken auf Klassenebene, die im \texttt{TypeMetricsReport} enthalten sind, beinhalten auch die Menge aller direkten Abhängigkeiten. In Unterabschnitt \ref{subsec:ccdcode} wurde beschrieben, dass daraus ein Abhängigkeitsgraph auf Klassenebene erstellt wird. Dieser Klassengraph steht anschließend in einem schreibgeschützten Format im \texttt{MetricsReport}-Objekt zur Verfügung. Der nach außen sichtbare Typ des Graphen ist \texttt{IGraph<TypeMetricsReport>}, also ein \texttt{IGraph<V>} mit Knoten vom Typ \texttt{TypeMetricsReport}. Neben der Liste von Knoten besteht der Graph auch aus einer Liste von Kanten zwischen diesen Knoten. Eine Kante ist vom Typ \texttt{Tuple<TypeMetricsReport, TypeMetricsReport>}. Das erste Element in diesem Tuple stellt die Quelle, das zweite das Ziel der Verbindung dar. Beide Listen sind schreibgeschützt, sodass der Graph nicht ohne weiteres von außen verändert werden kann. Intern verwendet Usus.net den Typ \texttt{MutableGraph<V>}, der das \texttt{IGraph<V>}-Interface implementiert. Dieser Typ ist nicht mehr schreibgeschützt und erlaubt einige weitere Operationen. Beispielsweise lassen sich Kreise ermitteln, Erreichbarkeitsmengen bestimmen und Knoten reduzieren. Der Graph ist Bestandteil des Metrikberichts um eine Abbildung der Beziehungen zwischen den Klassen zu haben.

\subsection{Namespace-Berichte}
Neben den Methoden- und Klassenberichte enthält das \texttt{MetricsReport}-Objekt auch Namespace-Berichte vom Typ \texttt{NamespaceMetricsReport}. Diese Objekte enthalten im Vergleich zu den anderen Berichten vom Typ \texttt{TypeMetricsReport} und \texttt{MethodMetricsReport} nur wenige Informationen. Doch auch Namensräume haben einen eindeutigen Namen. Diese \texttt{Name}-Eigenschaft des Berichts wird für die Suche verwendet, wie Listing \ref{listing:namespaceclasssearch} in Zeile 1 zeigt.
\begin{lstlisting}[caption={Namespace- und Klassen-Suche in einem \texttt{MetricsReport}-Objekt},label={listing:namespaceclasssearch}]
namespaceMetrics = metrics.ForNamespace("andrena.Usus.net.Console");
foreach (var typeMetrics in metrics.TypesOfNamespace(namespaceMetrics)) {...}
\end{lstlisting}
Da Namespaces mehrere Klassen enthalten lässt sich diese Zuordnung auch unter den Berichten auflösen. Die Schleife in Zeile 2 iteriert über alle Klassenberichte eines Namespace-Berichts, indem die \texttt{TypesOfNamespace}-Methode verwendet wird.
\paragraph{}
Neben dem Abhängigkeitsgraphen auf Klassenebene steht auch der Abhängigkeitsgraph auf Namespace-Ebene zur Verfügung. In Unterabschnitt \ref{subsec:namespaceswithcyclicdependencies} wurde beschrieben, wie dieser Graph aus dem Klassengraph erzeugt wird. Der Namespace-Graph besteht aus Kanten zwischen Knoten vom Typ \texttt{IGraph<NamespaceMetricsReport>}. Im Gegensatz zum Graph auf Typ Ebene verwendet Usus.net intern keinen Graphen vom Typ \texttt{MutableGraph<NamespaceMetricsReport>} sondern einen Graphen, dessen Knoten vom Typ \texttt{NamespaceMetricsWithTypeMetrics} sind. Dies ist der Fall, da der Namespace-Graph aus dem Graph mit Klassenberichten als Knoten erzeugt wird. Um trotzdem einen schreibgeschützten Graphen vom Typ \texttt{IGraph<NamespaceMetricsReport>} zur Verfügung stellen zu können, ohne das ein neuer Graphen erzeugt werden muss, verwendet Usus.net eine Projektion des Knotentypen. Für diese Projektion wird ein Objekt vom Typ \texttt{GraphSurrogate<V, R>} verwendet, der das Interface \texttt{IGraph<V>} implementiert und einen Objekt vom Typ \texttt{IGraph<R>} kapselt. Die Knoten- und Kantenliste in diesem Typ werden über die Projektion von $R \rightarrow V$ also an den Zieltyp angepasst. Über diesen Adapter ist es möglich einen Graphen mit Knoten vom Typ \texttt{NamespaceMetricsWithTypeMetrics} als Graphen mit Knoten vom Typ \texttt{NamespaceMetricsReport} zu behandeln. Dies ist allerdings nur möglich, wenn es Abbildung von $R$ nach $V$ existiert. Da ein \texttt{NamespaceMetricsWithTypeMetrics}-Objekt den eigentlichen Namespace-Bericht sowie alle Klassenberichte in diesem Namespace enthält, ist die Abbildung einfach zu realisieren.


\section{Metrikgewichtung}
Nachdem in den vorherigen beiden Abschnitten beschrieben wurde, wie die Berechnung der Metriken funktioniert und in welcher Struktur das Ergebnis präsentiert wird, beschäftigt sich dieser Abschnitt mit der Weiterverarbeitung dieser Ergebnisse. Usus verwendet die Metriken beispielsweise für die in Unterabschnitt \ref{subsec:ususcockpit} vorgestellte Cockpit-Ansicht und in der in Unterabschnitt \ref{subsec:usushotspots} betrachteten Hotspots-Ansicht. Für diese beiden Ansichten werden die ermittelten Metriken gewichtet, mit Schwellwerten verglichen und Mittelwerte gebildet. Wie dies geschieht, wurde bereits in Unterabschnitt \ref{subsec:allprojectsmetrics} ausführlich beschrieben. Die im folgenden vorgestellten Klassen befinden sich alle im Namespace \texttt{andrena.Usus.net.Core.Hotspots}.

\subsection{Hotspots}
\label{subsec:hotspots}
Hotspots sind Methoden, Klassen und Namespaces dessen Metriken über einer Schwelle liegen. Usus.net kann diese Hotspots in Form eines \texttt{MetricsHotspots}-Objekts aus einem \texttt{MetricsReport}-Objekt bestimmen. Listing \ref{listing:hotspots} zeigt dies in Zeile 1. Die Variable \texttt{metrics} enthält wieder eine Referenz zu einem \texttt{MetricsReport}-Objekt. Anschließend können alle Berichte der Methoden, Klassen und Namespaces ermittelt werden, dessen Metriken über den Schwellen liegen, die in Unterabschnitt \ref{subsec:allprojectsmetrics} erwähnt wurden.
\begin{lstlisting}[caption={Methoden-, Klassen- und Namespace-Hotspots in einem \texttt{MetricsReport}-Objekt},label={listing:hotspots}]
MetricsHotspots hotspots = metrics.Hotspots();
methodHotspots = hotspots.OfMethodLength();
classHotspots = hotspots.OfClassSize();
classHotspots = hotspots.OfCumulativeComponentDependency();
classHotspots = hotspots.OfNumberOfNonStaticPublicFields();
namespaceHotspots = hotspots.OfNamespacesInCycle();
\end{lstlisting}
Wenn wie beispielsweise in Zeile 2 alle \texttt{MethodMetricsReport}-Objekte bestimmt werden, dessen \texttt{MethodLength}-Eigenschaft über der definierten Schwelle liegt, iteriert Usus.net über alle Methoden im \texttt{MetricsReport}-Objekt. Dabei werden nur Berichte zurückgegeben, dessen Methodenlänge über dem Ergebnis der Schwellwertfunktion für Methodenlängen liegen. Die Schwellwerte der Metriken müssen nicht konstant sein. Der Schwellwert kann sich auch abhängig von der Projektgröße ändern, wie es beispielweise bei der durchschnittlichen kumulierten Komponentenabhängigkeit ACD der Fall ist (siehe Unter-Unterabschnitt \ref{subsubsec:acd}). Daher verwendet Usus.net das Konzept einer Schwellwertfunktion. Alle Schwellwertfunktionen können bei Bedarf auch zur Laufzeit geändert werden. Dafür lässt sich das \texttt{RatingFunctionLimits}-Objekt, welches die Funktionen definiert, über die statische Eigenschaft \texttt{RatingFunctions.Limits} erreichen. Listing \ref{listing:limitfunctions} zeigt die Deklaration und Definition der Schwellwertfunktionen für Methodenlänge und kumulierte Komponentenabhängigkeit mit Lambda-Ausdrücken. Die Formel der Schwellwertfunktion \texttt{CumulativeComponentDependency} entspricht der bereits beschriebenen Formel \ref{eq:averagecomponentdependency4}.
\begin{lstlisting}[caption={Schwellwertfunktionen sind abhängig von Daten eines \texttt{MetricsReport}-Objekts},label={listing:limitfunctions}]
//Deklarationen
Func<CommonReportKnowledge, int> MethodLength { get; set; }
Func<CommonReportKnowledge, int> CumulativeComponentDependency { get; set; }
...
//Definitionen
MethodLength = ck => 9;
CumulativeComponentDependency = ck => ck.NumberOfClasses * 
	(1.5 / Math.Pow(2, (Math.Log(ck.NumberOfClasses) / Math.Log(5))));
...
\end{lstlisting}
Alle Schwellwertfunktionen sind Abbildungen von einem \texttt{CommonReportKnowledge}-Objekt auf eine Ganzzahl. \texttt{CommonReportKnowledge} ist Teil des Objektmodells des vollständigen Metrikberichts und wurde bereits in Abbildung \ref{fig:metricsreport} gezeigt. Dieses Objekt enthält einige allgemeine Daten der Metrik-Analyse wie beispielsweise die Anzahl der analysierten Klassen und Namespaces.

\subsection{Statistiken}
\label{subsec:statistics}
Die Unterscheidung zwischen Metrik und Statistik der Metrik wurde bereits in Unterabschnitt \ref{subsec:staticcodeanalysis} definiert. Die Theorie, also wie diese Statistiken in Usus entstehen und berechnet werden können, wurde in Unterabschnitt \ref{subsec:allprojectsmetrics} vorgestellt. In Usus.net lassen sich die gleichen Werte über ein \texttt{RatedMetrics}-Objekt bestimmen, welches wie in Listing \ref{listing:statistics} in Zeile 1 gezeigt, über die \texttt{Rate}-Methode erzeugt werden kann. Die Variable \texttt{metrics} enthält wieder eine Referenz eines \texttt{MetricsReport}-Objekts.
\begin{lstlisting}[caption={Statistiken aller Berichte in einem \texttt{MetricsReport}-Objekt},label={listing:statistics}]
RatedMetrics statistics = metrics.Rate();
double acd = statistics.AverageComponentDependency;
double acs = statistics.AverageRatedClassSize;
double acc = statistics.AverageRatedCyclomaticComplexity;
double aml = statistics.AverageRatedMethodLength;
double anf = statistics.AverageRatedNumberOfNonStaticPublicFields;
double ncn = statistics.NamespacesWithCyclicDependencies;
\end{lstlisting}
Diese Statistiken entstehen durch eine Gewichtung der Methoden-, Klassen und Namespace-Berichte, die anschließend gezählt oder gemittelt werden. Die Berichte können auch unabhängig von einander gewichtet werden. Die \texttt{Rate}-Methode existiert für die einzelnen Berichte ebenfalls und erzeugt Objekte vom Typ \texttt{RatedMethodMetrics} für Methoden, \texttt{RatedTypeMetrics} für Klassen und \texttt{RatedNamespaceMetrics} für Namespaces. Tatsächlich ruft Usus.net diese Methode für jeden Bericht auf und speichert die dadurch erzeugten Objekte in einem \texttt{RatedMetrics}-Objekt. Dort können dann die Mittelwerte der einzelnen gewichteten Metriken als projektübergreifende Statistiken bestimmt werden. Sämtliche Gewichtungsfunktionen implementieren die Formeln aus Unterabschnitt \ref{subsec:allprojectsmetrics} und sind in der Klasse \texttt{RatingFunctions} definiert.
\begin{lstlisting}[caption={Statistik-Berechnung in einem \texttt{RatedMetrics}-Objekt},label={listing:statisticscalc}]
AverageRatedMethodLength = RatedMethods.AverageAny(m => m.RatedMethodLength);
AverageComponentDependency = 
	RatedTypes.AverageAny(m => m.CumulativeComponentDependency) 
	/ metrics.CommonKnowledge.NumberOfClasses;
NamespacesWithCyclicDependencies = 
	RatedNamespaces.CountAny(m => m.IsInCycle) 
	/ metrics.CommonKnowledge.NumberOfNamespaces;
\end{lstlisting}
Listing \ref{listing:statisticscalc} zeigt die Berechnung der durchschnittlichen Methodenlänge in Zeile 1, der durchschnittlichen kumulierten Komponentenabhängigkeit in den Zeilen 2 bis 4 sowie der Anzahl der Namespaces mit zyklischen Abhängigkeiten in den Zeilen 5 bis 7. Obwohl die Berechnungen einfach lesbar sind, ist der Aufwand zur Bestimmung jeder Statistik $O(n)$. Für jede Statistik müssen alle Methoden oder Klassen-Berichte, die die Metrik enthalten, berücksichtigt werden.

\subsection{Ignorierbares}
In Unterabschnitt \ref{subsec:statistics} wurde beschrieben, dass alle Methodenberichte berücksichtigt werden müssen, wenn eine Methoden-Metrik-Statistik bestimmt werden soll. Allerdings existieren in einer Assembly Methoden, die keinen keine relevanten Metriken enthalten. Alle Methoden und Klassen, die vom Compiler erzeugt wurden, also durch ein \texttt{[CompilerGenerated]}-Attribut gekennzeichnet sind, werden von Usus.net in der Berechnung der Statistiken und der Hotspots ignoriert. Da diese Methoden und Klassen im Quellcode nicht offensichtlich sind, würde ein Hotspot an einer solchen Stelle den Entwickler auf etwas nicht nachvollziehbares hinweisen.
\paragraph{}
Beispielsweise erzeugt der Compiler aus einem \texttt{yield return}-Statement eine Klasse, die den Zustand der Methode verwaltet. Die erzeugte Logik ist kein Hotspot und sollte die Statistik auch nicht beeinflussen, da ein daraus resultierender Komplexitätsanstieg nicht nachvollziehbar ist. Ein weiteres Beispiel sind anonyme Methoden. Die durch einen Lambda-Ausdruck erzeugte Klasse wird teilweise ignoriert. Lambda-Ausdrücke sind Funktionen, die in Form von \texttt{()=>}\{\} geschrieben und wie Objekte behandelt werden können. Microsoft beschreibt diese Funktions-Objekte in der MSDN Library \cite{MSDNExpressions}. In einem Lambda-Ausdruck können die Variablen, die sich zum Zeitpunkt der Definition im Scope befinden verwendet werden. Wenn der Lamdba-Ausdruck dann als Objekt weitergegeben wird, behält dieser weiterhin den Scope der Definition. Dies ist möglich, da der .NET-Compiler eine Klasse generiert, die eine generierte Methode enthält. Diese generierte Methode enthält die Logik des Lambda-Ausdrucks. Externe Variablen, die von diesem Ausdruck verwendet werden, werden vom Compiler ebenfalls in der generierten Klasse deklariert und nicht wie erwartet in der Klasse die den Lambda-Ausdruck definiert. Diese erzeugt lediglich ein Objekt der generierten Klasse um die Variablen definieren zu können. Dank der in Unterabschnitt \ref{subsec:ccicodeast} beschriebenen Bibliothek \emph{CCI Code and AST Components} ist Usus.net in der Lage, die Logik des Lambda-Ausdrucks in der Methode zu finden, die den Ausdruck definiert und nicht nur in der Methode, die ihn nach dem Kompilieren enthält. Dadurch werden die zyklomatische Komplexität und die Methodenlänge der definierenden Methode unter Berücksichtigung der Logik des Lambda-Ausdrucks korrekt berechnet. Die Metriken der erzeugten Klasse werden ignoriert, da diese wieder die Statistiken nicht nachvollziehbar beeinflussen würden.
\paragraph{}
Außerdem betrachtet Usus.net nur Methoden, die einen nicht leeren Methodenrumpf besitzen. Abstrakte Methoden und Methoden-Deklarationen in Interfaces haben offensichtlich eine Methodenlänge und zyklomatische Komplexität von 0. Sie werden ebenfalls nicht in die Berechnung der Statistiken miteinbezogen, da sie das Ergebnis verfälschen. Eine Methoden-Deklaration ist weder gut noch schlecht, würde aber als sehr gute Methode die Statistik ungewollt verbessern. Die Methoden- und Klassenberichte im Usus.net Objektmodell aus Abschnitt \ref{sec:ususobjectmodel} bieten die Eigenschaften \texttt{CompilerGenerated} und \texttt{OnlyDeclaration} an, um die ignorierbaren Methoden und Klassen zu finden. Das in Abschnitt \ref{sec:eclipseusus} vorgestellte Usus-Plugin für Eclipse nimmt diese Unterscheidung nicht vor und behandelt abstrakte Methoden und Interface-Deklarationen wie normale Methoden, was zu einer trügerischen Verbesserung der Statistiken führt, wenn viele Interfaces und abstrakte Methoden vorhanden sind.


\section{Metrikverteilung}
\label{sec:distributions}
Im Namespace \texttt{andrena.Usus.net.Core.Math} existiert die Klasse \texttt{Distributions}. In dieser Klassen sind mehrere Extensions Methods definiert, die Verteilungen von Methoden- und Klassen-Metriken bestimmen können. Listing \ref{listing:methodtypedistributions} zeigt, wie diese Methoden verwendet werden können.
\begin{lstlisting}[caption={Verteilungen von Methoden- und Klassen-Berichten erstellen},label={listing:methodtypedistributions}]
IHistogram css = Metrics.TypeDistribution(t => t.ClassSize);
IHistogram ccs = Metrics.MethodDistribution(m => m.CyclomaticComplexity);
\end{lstlisting}
Die Variable \texttt{Metrics} enthält eine Referenz auf ein \texttt{MetricsReport}-Objekt. Die Verteilung besteht aus einem \texttt{Histogram}-Objekt und weiteren Verteilungsinformationen. Diese \texttt{Histogram}-Klasse bekommt über den Konstruktor eine Sequenz von \texttt{int}-Werten übergeben, aus denen sie das Histogramm erstellt. Das Histogramm ist eine einfache Abbildung von den diskreten Werten der Sequenz zu der absoluten Häufigkeit des Auftretens des entsprechenden Werts. Diese Zuordnung kann auch in einem Koordinatensystem angezeigt werden kann. Auf der x-Achse werden die diskreten Werte der Sequenz dargestellt, während die absoluten Häufigkeiten des Auftretens auf der y-Achse angezeigt wird. Dadurch wird ersichtlich, wie oft ein bestimmter Wert in der Sequenz enthalten ist. Die \texttt{Histogram}-Klasse verwendet Funktionalität der öffentlichen Bibliothek Math.NET\footnote[1]{Math.NET Numerics "`numerical library"' \url{http://mathnetnumerics.codeplex.com/}} um die Zuordnung aus der Sequenz zu erzeugen. Diese Erzeugung ist in Listing \ref{listing:distributioncreation} dargestellt.
\begin{lstlisting}[caption={Histogramm-Erzeugung mit Math.NET},label={listing:distributioncreation}]
var maxValue = data.Max();
for (int i = 0; i <= maxValue; i++)
	histogram.AddBucket(new Bucket(-0.5 + i, 0.5 + i));
histogram.AddData(data.Select(d => d * 1.0));
\end{lstlisting}
Die Variable \texttt{data} enthält die erwähnte Sequenz von Ganzzahlen (\texttt{IEnumerable<int>}), die über den Konstruktor übergeben wird. Usus.net unterstützt nur Histogramme mit positiven Werten. Ein fertiges Histogramm kann in Form eines \texttt{IHistogram}-Objekts weitergegeben und analysiert werden. Die Werte der x-Achse können mithilfe der Eigenschaft \texttt{BinCount} auf 0 bis \texttt{BinCount}-1 bestimmt werden. Um den y-Wert, also die absolute Häufigkeit zu einem x-Wert zu bestimmen, kann die Methode \texttt{ElementsInBin(x)} mit dem x-Wert als Parameter aufgerufen werden.
\paragraph{}
Usus.net nutzt Mechanismen um das Histogramm zu analysieren und speichert die Ergebnisse in Form von \texttt{IFittingReport}-Objekten ebenfalls in dem \texttt{Distribution}-Objekt. Das Interface \texttt{IFittingReport} definiert die beiden Properties \texttt{Parameter} und \texttt{Error}, welche von einer konkreten Verteilungsfunktion zur Verfügung gestellt werden können. In der aktuellen Version von Usus.net wird nur die geometrische Verteilung unterstützt. Die Klasse \texttt{Distribution} hat dafür das \texttt{GeometricalFit}-Property. Dieses Property liefert ein \texttt{GeometricalDistributionFitting}-Objekt, welches als \texttt{Parameter} das $\lambda$ der geometrischen Verteilung aus Formel \ref{eq:gdistribution} zurückgibt. Um diese Parameter der Verteilungen zu bestimmen, berechnet Usus.net statistische Kennzahlen (beispielsweise den Mittelwert) der Histogramm-Sequenz wieder mithilfe der Math.NET-Bibliothek. Wie diese Analyse des Histogramms und die Annäherung der Verteilungsfunktionen genau funktioniert, ist in Unterabschnitt \ref{subsec:histogramapproximation} beschrieben. Sobald der Parameter einer Verteilung bestimmt wurde, kann auch der Fehler dieser Verteilung berechnet und über das \texttt{Error}-Property veröffentlicht werden. Anhand des Fehlers können unterschiedliche Approximationen des Histogramms verglichen werden. Da Usus.net momentan nur eine Verteilung unterstützt, ist der Vergleich der Fehler noch nicht relevant. Wie der Fehler ermittelt werden könnte, wird in Unterabschnitt \ref{subsec:histogramerror} behandelt.


\section{Testen}
Nachdem in den vorherigen Abschnitten die Metrik-Analyse, das Objektmodell sowie die Statistiken von Usus.net erläutert wurden, beschäftigt sich dieser Abschnitt mit einer Möglichkeit Metriken mit Quellcode zu verbinden. \texttt{Usus.net.Core} stellt dafür eine Infrastruktur zur Verfügung, die in dieser Master-Thesis als \emph{Verification Framework} bezeichnet wird. Das Verification Framework befindet sich im Namespace \texttt{andrena.Usus.net.Core.Verification} und besteht aus einer Menge an Attributen, mit denen Methoden und Klassen dekoriert werden können. Diese Attribute beschreiben Erwartungen in Form von Metriken an die betroffene Methode oder Klasse, wie in Listing \ref{listing:expectedmetrics} gezeigt.
\begin{lstlisting}[caption={Metrik-Erwartungswerte für Methoden und Klassen per Attribut definieren},label={listing:expectedmetrics}]
[ExpectDirectDependency("System.Exception")]
class ClassWithOneMethod
{
	[ExpectCyclomaticComplexity(1)]
	public void MethodWithNothing(Exception e) {}
}
\end{lstlisting}
Diese Erwartungen können mithilfe der Methoden der Klasse \texttt{Verify} überprüft werden, was in Listing \ref{listing:expectedverification} zu sehen ist. Dazu ist ein \texttt{MetricReport}-Objekt erforderlich, welches auf einfache Weise mit \texttt{Analyse.Me()} ermittelt werden kann.
\begin{lstlisting}[caption={Verifikation der Metrik-Erwartungswerte für Methoden und Klassen},label={listing:expectedverification}]
Verify.MethodsWith<ExpectCyclomaticComplexityAttribute>(metrics);
Verify.TypesWith<ExpectDirectDependencyAttribute>(metrics);
...
\end{lstlisting}
Bei der Verifikation werden dann alle Methoden und Klassen in der aktuellen Assembly ermittelt, die mit einem solchen Attribut dekoriert sind. Für diese werden anhand der Signatur oder dem Klassennamen die entsprechenden Berichte gesucht. Anschließend werden die Erwartungswerte, die über die Konstruktoren der Attribute angegeben werden, mit den tatsächlichen Metriken verglichen. Im Falle einer Abweichung wird eine \texttt{VerificationException} geworfen. Auf diese Weise können Metriken erzwungen werden. Dadurch kann erreicht werden, dass eine Methode oder Klasse Bedingungen an die eigene Implementierung stellt, die auf Metrik-Basis formuliert werden können. Eine unabsichtliche Verletzung dieser Bedingungen wird dann sofort offensichtlich. Außerdem sind die erwarteten Metriken bereits im Quellcode sichtbar.
\paragraph{}
Usus.net nutzt das Verification Framework um die eigene Metrikberechnung und das Objektmodell zu testen. So bestehen die Integrationstests von \texttt{Usus.net.Core} aus beispielhaften Klassen, dessen tatsächliche Metriken künstlich erzeugt und mit den erwarteten Werten der Attribute verglichen werden. Sind die Werte nicht kongruent schlagen die Testfälle fehl und ein eventueller Fehler in der Metrikberechnung wurde gefunden. Entsprechen die tatsächlichen Metriken den Werten in den Attributen, laufen die Tests erfolgreich durch und bestätigen so die Berechnungen der Metriken. Ein weiterer Anwendungsfall ist ein Konzept, das in dieser Master-Thesis als \emph{Metrics Meta Testing} bezeichnet wird. Damit sind Testfälle gemeint, die die Metriken von Testfällen testen. Zum Beispiel schreibt Roy Osherove in seinem Buch \cite{ArtOfUnitTesting}, dass Testmethoden keine Logik enthalten sollen. Keine Logik bedeutet keine entscheidungstreffenden Anweisungen wie beispielsweise \texttt{if} oder \texttt{while} zu verwenden. Eine solche Anforderung an Tests kann einfach mit einem \texttt{[ExpectCyclomaticComplexity(1)]}-Attribut an allen Tests sichergestellt werden. Eine spezielle Testmethode erzeugt dann das \texttt{MetricsReport}-Objekt des Testprojekts mit \texttt{Analyze.Me()} und ruft die entsprechende Methode auf der \texttt{Verify}-Klasse auf. Dieser spezielle Testfall testet also, ob alle Testmethoden mit dem Attribut auch wirklich nur einen Ablaufpfad enthalten. Ein anderes Beispiel wäre die Sicherstellung, dass kein Testfall von einem bestimmten Objekt der Implementierung abhängig ist. Dafür kann die Testklasse um das Attribut \texttt{[ExpectNoDirectDependency("...")]} mit dem vollständigen Klassennamen erweitert werden. Eine spezielle Testmethode würde wieder die entsprechende Methode der \texttt{Verify}-Klasse aufrufen und fehlschlagen, sobald eine Methode in der Klasse von dem Typ in dem Attribut abhängig ist. Das Verification Framework dient also dazu die Metriken, die eigentlich implizit im Code existieren, offen zu legen und einen Fehler zu erzeugen wenn die Implementierung nicht mit den erwarteten Metriken übereinstimmt. Der Entwickler bekommt so die Gelegenheit über ein eventuell fehlerhaftes Verhalten der Implementierung zu reflektieren und ein ansonsten verstecktes Problem schnell zu beheben.




\chapter{Usus.net als Visual Studio Erweiterung}
Abbildung \ref{fig:architecture2} zeigt die Verwendung der in Kapitel \ref{chap:ususnet} beschrieben Funktionen der \texttt{Usus.net.Core}-Komponente. \texttt{Usus.net.Core} steht als Bibliothek in Form einer Assembly zur Verfügung und wird von der Bibliothek \texttt{Usus.net.View} genutzt. Diese Bibliothek enthält alle grafischen Oberflächen von Usus.net und wird von der \texttt{Usus.net}-Komponente in Form einer Visual Studio Erweiterung verwendet. Die Erweiterung stellt dann nur noch die Fenster-Infrastruktur für die Usus.net-Oberflächen zur Verfügung. Usus.net ist kein Addin im Sinne von Unterabschnitt \ref{subsec:visualstudio}, sondern eine Erweiterung. In diesem Kapitel werden zunächst die Steuerelemente von \texttt{Usus.net.View} vorgestellt. Anschließend wird auf die Integration mit Visual Studio eingegangen.


\section{Oberflächen}
\label{sec:ususnetviews}
Die Oberfläche von Usus.net besteht genau wie das Usus für Eclipse (Kapitel \ref{chap:usus}) aus mehreren grafischen Benutzeroberflächen. Alle diese Oberflächen bieten besondere Sichten auf eine gemeinsame Datenquelle. Der Metrikbericht aus Abschnitt \ref{sec:ususobjectmodel} ist als Ergebnis der statischen Code-Analyse aus Abschnitt \ref{sec:metriccalc} das zentrale Objekt. Sobald dieses Objekt vom Typ \texttt{MetricsReport} zur Verfügung steht, müssen sich alle Sichten aktualisieren und die Daten des neuen Berichts verwenden. In diesem Abschnitt wird zunächst die Infrastruktur beschrieben, die es den Usus.net Oberflächen erlaubt eine gemeinsame Datenquelle zu verwenden. Anschließend werden die Implementierungen der Ansichten beschrieben, die bereits für das Usus für Eclipse vorgestellt wurden.

\subsection{Hubs}
\label{subsec:ususnethubs}
Usus.net besteht aus mehreren Fenstern mit einer gemeinsamen Datenquelle. Jedes Fenster enthält ein Steuerelement vom Typ \texttt{UserControl}\footnote[1]{Mehr über Windows Presentation Foundation \url{http://msdn.microsoft.com/de-de/library/ms754130.aspx}}. Um alle diese Steuerelemente mit einem zentralen Objekt zu verknüpfen, bietet die Bibliothek \texttt{Usus.net.View} die Klasse \texttt{ViewHub} an, welche nur in Form einer einzigen Instanz existieren kann. Die Ansichten \texttt{Cockpit}, \texttt{Hotspots}, \texttt{Distribution} und \texttt{CleanCode} werden von der \texttt{ViewFactory} in Kombination mit den entsprechenden ViewModels erzeugt. Das \texttt{ViewHub}-Objekt wird dabei bei den ViewModels bekannt gemacht. Diese können sich dann für die Events \texttt{AnalysisStarted} und \texttt{MetricsReady} registrieren. Ein Aufruf der \texttt{TryStartAnalysis}-Methode mit einer Liste an Assembly-Pfaden startet die statische Code-Analyse und teilt allen registrierten Objekten das neue Ergebnis-Objekt vom Typ \texttt{MetricsReport} mit. In Abbildung \ref{fig:viewhub} sind die Beziehungen zwischen den Views und den ViewModels in Bezug auf die Hub-Infratstuktur verdeutlicht. Die Oberflächen besitzen eigene ViewModels und implementieren damit das MVVM-Muster, welches Josh Smith in seinem Artikel \cite{WPFMVVM} ausführlich beschreibt.
\begin{figure}[h]
	\centering
		\includegraphics[width=17cm]{images/viewhub.jpg}
	\caption{Oberflächen und \emph{ViewModels} in Verbindung zum \texttt{ViewHub}-Objekt}
	\label{fig:viewhub}
\end{figure}
Nachdem die Steuerelemente erzeugt wurden, erreichen die Events \texttt{AnalysisStarted} und \texttt{MetricsReady} des einen \texttt{ViewHub}-Objekts die ViewModels aller Oberflächen in Usus.net. In der \texttt{TryStartAnalysis}-Methode wird sichergestellt, dass eine Analyse nur dann gestartet werden kann, wenn sie nicht schon läuft. Wie die Analyse dann gestartet wird, ist in Listing \ref{listing:startanalysis} zu sehen.
\begin{lstlisting}[caption={Start der statischen Code-Analyse in der \texttt{TryStartAnalysis}-Methode},label={listing:startanalysis}]
AnalysisStarted();
ThreadPool.QueueUserWorkItem((c) =>
{
	MetricsReport metrics = Analyze.PortableExecutable(files.ToArray());
	MetricsReady(metrics);
});
\end{lstlisting}
Zu Beginn wird das Event \texttt{AnalysisStarted} gefeuert. Alles weitere findet asynchron in einem eigenen Thread statt, der über den \texttt{ThreadPool} erzeugt wird. Dadurch muss der Aufrufer der \texttt{TryStartAnalysis}-Methode nicht warten, da die Analyse im Hintergrund ausgeführt wird. Die Klasse \texttt{Analyse} ist bereits aus Abschnitt \ref{sec:metriccalc} bekannt. Sobald der Bericht vom Typ \texttt{MetricsReport} erzeugt wurde, wird dieser über das Event \texttt{MetricsReady} an alle ViewModels übergeben. Diese müssen sich beim Anzeigen der Daten des Berichts nur noch darum kümmern, dass sie die Daten mit dem Thread der Oberfläche synchronisieren. Die grafischen Steuerelemente und die Factory befinden sich im Namespace \texttt{andrena.Usus.net.View}. Die Hub-Infrastruktur befindet sich in \texttt{andrena.Usus.net.View.Hub}. Die ViewModels der Oberflächen sind im Namespace \texttt{andrena.Usus.net.View.ViewModels} zu finden.

\subsection{Cockpit}
Das Fenster mit den am weitesten aggregierte Metriken ist \emph{Usus.net Cockpit}. Nach dem Vorbild aus Unterabschnitt \ref{subsec:ususcockpit} enthält die Oberfläche eine einfache Tabelle und zeigt alle Statistiken an, die bereits in Unterabschnitt \ref{subsec:statistics} vorgestellt wurden. Abbildung \ref{fig:ususnet_cockpit} zeigt das Cockpit-Steuerelement als Fenster in Visual Studio.
\begin{figure}[h]
	\centering
		\includegraphics[width=14cm]{images/ususnet_cockpit.png}
	\caption{Usus.net Cockpit-Fenster}
	\label{fig:ususnet_cockpit}
\end{figure}
Dieses Fenster verhält sich wie alle anderen Fenster und kann in Visual Studio beliebig angedockt werden. Das ViewModel reagiert auf einen verfügbaren Metrikbericht, indem es die Einträge der Tabelle durch neue Einträge für die Statistiken ersetzt. Als Tabelle wird ein \texttt{DataGrid}-Objekt verwendet. Neben der Anzahl der Hotspots wird zu jeder Metrik die Verteilungsinformation angezeigt, die ausführlicher in Abschnitt \ref{sec:histogramanalysis} beschrieben wird. Außerdem ist mit einem Blick ersichtlich wie viele relevante Codezeilen die analysierte Codebasis enthält. Abschnitt \ref{subsec:rloc} beschreibt wie sich dieser Wert zusammensetzt.

\subsection{Info}
\label{subsec:ususnetinfo}
Das nächste Usus.net Fenster entspricht dem Usus Info-Fenster aus Unterabschnitt \ref{subsec:ususinfo}. Dieses Fenster zeigt die Metriken einer Methode an in Verbindung mit der Klasse an. Im Gegensatz zu der Eclipse Variante, lässt sich dieses Fenster nicht mit dem Shortcut \texttt{Ctrl-U} öffnen. Usus.net platziert einen kleinen Button rechts neben jeder Methodendeklaration, wie in Abbildung \ref{fig:ususnet_info} dargestellt.
\begin{figure}[h]
	\centering
		\includegraphics[width=13cm]{images/ususnet_info.png}
	\caption{Usus.net Info-Fenster}
	\label{fig:ususnet_info}
\end{figure}
Ein einfacher Mausklick öffnet das Usus.net Info-Fenster und zeigt die Metriken der entsprechenden Methode an. Die Metriken der Klasse sind ebenfalls sichtbar. Wie der Button im Code-Editor angezeigt wird ist in Unterabschnitt \ref{subsec:editoradornment} beschrieben. Der Button erscheint nur neben Methoden und nicht neben Properties oder Klassen. Daher lässt sich das Info-Fenster auch nur für Methoden öffnen. Dies ist ausreichend, da die Klassen-Metriken ja ebenfalls angezeigt werden. Das Info-Fenster in der Eclipse Variante lässt sich zusätzlich auch für Klassen direkt öffnen. Wenn der Entwickler auf den Button klickt, werden die Zeilennummer sowie der Name der Datei an das ViewModel des Info-Fensters übertragen. Beide Informationen kommen dort in Form eines \texttt{LineLocation}-Objekts an. Obwohl die Editor-Buttons und das Fenster in separaten Erweiterungsprojekten implementiert sind, ist diese Übertragung über das in Unterabschnitt \ref{subsec:vsmenus} beschriebene Event-System möglich. Um den Methoden- und Klassenbericht zu einer Datei und Zeile zu ermitteln, wird die Klasse \texttt{CurrentMethodInfoCalculator} verwendet. Jeder Methodenbericht erhält durch die Metrikberechnung aus Abschnitt \ref{sec:metriccalc} die Zeilen-Informationen der pdb-Datei in Form eines \texttt{SourceCodeLocation}-Objekts. Usus.net kann dadurch anhand der Zeilennummer und dem Dateipfad des geklickten Button den entsprechenden Methodenbericht finden und dessen Metriken anzeigen.

\subsection{Hotspots}
\label{subsec:ususnethotspots}
Abbildung \ref{fig:ususnet_hotspots} zeigt alle Hotspots in der Codebasis.
\begin{figure}[h]
	\centering
		\includegraphics[width=14cm]{images/ususnet_hotspots.png}
	\caption{Usus.net Hotspots-Fenster}
	\label{fig:ususnet_hotspots}
\end{figure}
Wie die Oberfläche in Unterabschnitt \ref{subsec:usushotspots}, lassen sich zu jeder Metrik genau die Methoden, Klassen und Namespaces anzeigen, dessen Metriken über den definierten Schwellen aus Abschnitt \ref{sec:metrics} liegen. Dazu wird die API verwendet, die bereits in Unterabschnitt \ref{subsec:hotspots} vorgestellt wurde. Diese Problemfälle sind nach Metrik gruppiert und lassen sich über den Reiter der entsprechenden Metrik anzeigen. Mit einen Doppelklick auf einen Methoden- oder Klassen-Hotspot springt Visual Studio an die Problemstelle im Quellcode. Dies ist möglich, da alle Methodenberichte ja ein \texttt{SourceCodeLocation}-Objekt beinhalten. Das ViewModel von \emph{Usus.net Hotspots} verwendet das Interface \texttt{IJumpToSource}, um an beliebige Zeilen von beliebigen Dateien zu springen. Auf Visual Studio Seite implementiert das Fenster, dass das Hotspots-Element enthält, dieses Interface. Wie eine Zeile in einer Visual Studio Erweiterung abgesprungen werden kann, beschreibt Unterabschnitt \ref{subsec:vsrowjumps}. Listing \ref{listing:jumptomethod} zeigt den Sprung von der Seite des Hostspots-ViewModel.
\begin{lstlisting}[caption={Zu der Methode eines \texttt{MethodMetricsReport}-Objekt springen},label={listing:jumptomethod}]
if (Report.SourceLocation.IsAvailable)
	jumper.JumpToFileLocation(
		Report.SourceLocation.Filename,
		Report.SourceLocation.Line, true);
\end{lstlisting}
Die Variable \texttt{Report} enthält eine Referenz auf das \texttt{MethodMetricsReport}-Objekt eines Hotspots. Der letzte Parameter des Methodenaufrufs gibt an, dass die entsprechende Zeile selektiert werden soll und damit schneller sichtbar wird. Die pdb-Datei einer Assembly enthält keine Zeileninformationen für Klassen. Um per Doppelklick zu einem Klassen-Hotspot zu springen, ermittelt das ViewModel die erste Methode dieser Klasse und springt zu dieser.

\subsection{Histogramm}
\label{subsec:ususnethostigram}
Abbildung \ref{fig:ususnet_histogram} zeigt die Häufigkeitsverteilungen aller Berichte des Objektmodells aus Abschnitt \ref{sec:ususobjectmodel} in Bezug auf die Metriken an.
\begin{figure}[h]
	\centering
		\includegraphics[width=14cm]{images/ususnet_histogram.png}
	\caption{Usus.net Histogramm-Fenster}
	\label{fig:ususnet_histogram}
\end{figure}
Ähnlich wie das Hotspots-Fenster, ist auch das Verteilungs-Fenster in Registerkarten eingeteilt. Um die Histogramme zu bestimmen, werden die Funktionen verwendet, die bereits in Abschnitt \ref{sec:distributions} vorgestellt wurden. Diese Verteilungen können anschließend angezeigt werden. Dazu verwendet Usus.net das Spalten-Diagramm des WPF Toolkits\footnote[1]{Windows Presentation Foundation Toolkit \url{http://wpf.codeplex.com/releases/view/40535}}. Usus.net versucht die Histogramme zu interpretieren, was in Abschnitt \ref{sec:histogramanalysis} beschrieben wird. Das Ergebnis dieser Interpretation wird am rechten oberen Rand angezeigt.

\subsection{Class Graph \& Package Graph}
In Unterabschnitt \ref{subsec:ususgraphs} wurde vorgestellt, wie Usus für Eclipse die Abhängigkeitsgraphen auf Klassen- und Package-Ebene visualisiert. Usus.net erstellt diese Graphen ebenfalls und veröffentlicht sie als Teil des Objektmodells, wie in Abschnitt \ref{sec:ususobjectmodel} beschrieben. Eine grafische Visualisierung dieser Graphen in Form eines Fensters in Visual Studio wird von Usus.net noch nicht unterstützt. Dieses Fenster kann im Rahmen dieser Master-Thesis aus Zeitgründen leider nicht mehr implementiert werden.

\subsection{Clean Code Grade}
Ein Usus.net Fenster, das es nicht in der Eclipse Version gibt, ist \emph{Usus.net CleanClode}. Damit ist Alexander Zeitler's Idee die Clean Code Grade von Ralf Westphal und Stefan Lieser \cite{CleanCodeDeveloper} immer direkt in der IDE zu sehen, in Usus.net integriert. Zeitlers Idee wurde bereits in Abschnitt \ref{sec:ccdaddin} vorgestellt. Abbildung \ref{fig:ususnet_cleancode} zeigt die Liste, mit den verschiedenen Graden.
\begin{figure}[h]
	\centering
		\includegraphics[width=12cm]{images/ususnet_cleancode.png}
	\caption{Usus.net Clean Code Grade-Fenster}
	\label{fig:ususnet_cleancode}
\end{figure}
Zu jedem Grad werden die Prinzipien (Unterabschnitt \ref{subsec:ccdprinciples}) und Parktiken (Unterabschnitt \ref{subsec:ccdpractices}) als Hyperlinks aufgelistet. Über diese Hyperlinks lassen sich die Internetseiten von Westphal und Lieser öffnen, die ausführliche Beschreibungen der Grade enthalten. 


\section{Visual Studio Integration}
Nachdem alle Oberflächen von Usus.net beschrieben wurden, beschäftigt sich dieser Abschnitt mit der tatsächlichen Integration der Views in Visual Studio. Jede Oberfläche erhält ein eigenes Visual Studio-Fenster, welches beliebig in der IDE verschoben, angedockt und angepasst werden kann. Diese Fenster sind alle in separaten Projekten vom Typ \emph{VsPackage} implementiert. Die fünf Fenster-Projekte sind \texttt{Usus.net.Cockpit} (1), \texttt{Usus.net.Current} (2), \texttt{Usus.net.Hotspots} (3), \texttt{Usus.net.Distributions} (4) und \texttt{Usus.net.CleanCode} (5). Zusätzlich verwendet das Info-Fenster (\texttt{Usus.net.Current}) Buttons direkt neben dem Quellcode im Visual Studio Editor. Diese Buttons sind in dem \emph{Editor Adornment}-Projekt \texttt{Usus.net.EditorAdornment} (6) definiert. Das Projekt \texttt{Usus.net.Menus} (7) ist ein weiteres \emph{VsPackage}, welches das Usus.net-Menü in die Menüleiste von Visual Studio integriert. Alle diese sieben Erweiterungsprojekte werden vom dem \emph{VsPackage}-Projekt \texttt{Usus.net} (0) zusammengefasst. Dieses Projekt enthält keinen Quellcode und erzeugt auch keine eigene Assembly. Das \texttt{Usus.net}-Projekt erzeugt die VSIX-Datei der kompletten Usus.net-Erweiterung. Eine VSIX-Datei ist eine ZIP-Datei, welche alle benötigten Assemblies und das Erweiterungsmanifest enthält. Im Folgenden werden die allgemeinen Implementierungsdetails der Usus.net-Fenster vorgestellt. Dabei wird beschrieben, wie diese Fenster auf das Build-Ereignis in Visual Studio reagieren können. Weiterhin wird die Integration aller Erweiterungsprojekte in einen einzigen Menüpunkt behandelt, der außerdem eine Kommunikation zwischen den Fenstern ermöglicht. Abschließend wird gezeigt wie Erweiterungen an beliebige Codezeilen springen und wie diese Codezeilen grafische Elemente darstellen können.

\subsection{Events}
\label{subsec:vsievents}
Um auf Ereignisse in Visual Studio zu reagieren, wird eine Referenz auf das \texttt{DTE2}-Objekt benötigt. Laut Microsoft ist dieses Objekt, als Bestandteil des \texttt{EnvDTE}-Namespace, Teil der COM\footnote[1]{Mehr über COM: "`What is COM?"' \url{http://www.microsoft.com/com/default.mspx}}-Bibliothek, die für die Automatisierung von Visual Studio verwendet werden kann \cite{MSDNDTE2}. Listing \ref{listing:getdte2} zeigt, wie eine Referenz zu diesem Objekt erstellt werden kann. Dafür muss dieser Code innerhalb einer Klasse die von \texttt{ToolWindowPane} erbt ausgeführt werden, sodass sich \texttt{base} auf ein Objekt vom Typ \texttt{WindowPane} bezieht.
\begin{lstlisting}[caption={Zentrales Visual Studio Objekt \texttt{DTE2} erhalten},label={listing:getdte2}]
EnvDTE80.DTE2 dt2 = base.GetService(typeof(SDTE)) as EnvDTE80.DTE2;
\end{lstlisting}
Sobald eine Referenz zu dem \texttt{DTE2}-Objekt verfügbar ist, kann die aktuelle Solution in der Visual Studio Instanz mit \texttt{dt2.Solution} ermittelt werden. Über dieses \texttt{Solution}-Objekt können dann alle Projekte in dieser Solution bestimmt werden. Mit \texttt{dt2.Events} kann außerdem ein Objekt erhalten werden, über welches Eventhandler für sämtliche Ereignisse definiert werden können. Für Usus.net ist das Ereignis \texttt{dt2.Events.BuildEvents.OnBuildDone} das wichtigste, da die statische Code-Analyse nach einem erfolgreichen Kompiliervorgang gestartet werden soll. Ob der Build erfolgreich war kann mit \texttt{dt2.Solution.SolutionBuild.LastBuildInfo} ermittelt werden.

\subsection{Fenster}
Ein Visual Studio Fenster ist eine Klasse, die von \texttt{ToolWindowPane} erbt. Alle Fenster von Usus.net sollen auf das Build-Ereignis reagieren, alle Projekte der aktuellen Solution und deren erzeugte Assemblies bestimmen können. Um diese Logik für alle Usus.net Fenster wiederverwenden zu können, stellt Usus.net einige Oberklassen zur Verfügung, die die benötigten Funktionen bereitstellen. Diese Klassen befinden sich im Namespace \texttt{andrena.Usus.net.ExtensionHelper}.
\begin{figure}[h]
	\centering
		\includegraphics[width=16cm]{images/windows.jpg}
	\caption{Usus.net Fenster-Oberklassen}
	\label{fig:windows}
\end{figure}
Abbildung \ref{fig:windows} zeigt, dass die oberste Klasse \texttt{DtAwareToolWindow} ist. Diese Klasse erbt von \texttt{ToolWindowPane} und stellt das in Unterabschnitt \ref{subsec:vsievents} beschriebene \texttt{DT2}-Objekt zur Verfügung. \texttt{SolutionAwareToolWindowPane} erbt von \texttt{DtAwareToolWindow} und nutzt das dort verfügbare Automatisierungsobjekt um eine Referenz auf die aktuelle Solution, sowie alle Projekte dieser Solution zu ermitteln. Da die Projekt-Objekte alle als COM-Objekte vorliegen, werden diese in einfache Objekte vom Typ \texttt{Project} konvertiert. Die Klasse \texttt{SolutionEventsAwareToolWindowPane} erbt von \texttt{SolutionAwareToolWindowPane} und verwendet die COM-Objekte der Oberklassen um Ereignisse in Visual Studio verfügbar zu machen. Diese Ereignisse wurden bereits in Unterabschnitt \ref{subsec:vsievents} erwähnt. Alle Klassen die von dieser Klasse ableiten, können damit informiert werden, wenn der Entwickler einen Speicher- oder Kompiliervorgang ausführt. Zusätzlich können alle betroffenen Projekte dieses Kompiliervorgangs bestimmt werden. Um über die tatsächlich erzeugten Assembly-Dateien im Falle eines Builds benachrichtigt werden zu können, erbt die Klasse \texttt{BuildAwareToolWindowPane} abschließend von \texttt{SolutionEventsAwareToolWindowPane}. Diese Klasse stellt ein Ereignis zur Verfügung, welches nur nach einem erfolgreichen Kompilieren ausgeführt wird, und welchem eine Liste an Dateipfaden übergeben wird. Diese Liste enthält zu jedem Projekt die aktuellste Assembly. Wenn ein Projekt keine Assembly-Datei erzeugt, wird es ignoriert. Die aktuellste Assembly wird von der Methode \texttt{LatestOutputAssembly} der Klasse \texttt{Project} gefunden. Auf diese Weise wird sichergestellt, dass immer der aktuellste Build berücksichtigt wird, unabhängig ob die Dateien im \emph{build}- oder \emph{debug}-Verzeichnis erstellt werden.
\paragraph{}
Die in Abschnitt \ref{sec:ususnetviews} vorgestellten Oberflächen von Usus.net sind also Fenster-Klassen vom Typ \texttt{BuildAwareToolWindowPane}. Diese Fenster erzeugen in ihren Konstruktoren die entsprechenden ViewModels, registrieren sich für das \texttt{BuildSuccessfull}-Ereignis und leiten dessen Dateipfad-Liste an die \texttt{TryStartAnalysis}-Methode der Hub-Infrastruktur aus Unterabschnitt \ref{subsec:ususnethubs} weiter. Alle Fenster werden also über die Build-Vorgänge informiert und benachrichtigen die \texttt{ViewHub}-Instanz. Listing \ref{listing:ususnetwindowsetup} zeigt diese Initialisierung exemplarisch im Konstruktor des Cockpit-Fenster.
\begin{lstlisting}[caption={Initialisierung eines Usus.net-Fenster},label={listing:ususnetwindowsetup}]
BuildSuccessfull += files => ViewHub.Instance.TryStartAnalysis(files);
base.Content = ViewFactory.CreateCockpit(ViewHub.Instance);
\end{lstlisting}
Usus.net ist als Erweiterung im Sinne von Unterabschnitt \ref{subsec:visualstudio} implementiert. Dadurch können alle Usus.net-Fenster als separate Projekte mit der Projektvorlage \emph{VSPackage} realisiert werden. In einem speziellen Container-Projekt werden alle Usus.net \emph{VSPackage}-Projekte dann zu einer VSIX-Datei zusammengefasst werden.

\subsection{Menüpunkt}
\label{subsec:vsmenus}
Standardmäßig werden alle selbsterstellten Visual Studio Tool Windows unter \texttt{View / Other Windows} aufgeführt. Für Usus.net sollen die in Abschnitt \ref{sec:ususnetviews} beschriebenen Fenster aber einen besonderen Stellenwert genießen. Microsoft beschreibt in der MSDN Library wie ein solcher Menüpunkt in Form eines \emph{VSPackage}-Projekts implementiert werde kann \cite{MSDNMenuBar}. Abbildung \ref{fig:ususnet_menu} zeigt diesen Menüeintrag direkt in Visual Studio.
\begin{figure}[h]
	\centering
		\includegraphics[width=7cm]{images/ususnet_menu.png}
	\caption{Usus.net Menüpunkt in der Menüleiste von Visual Studio}
	\label{fig:ususnet_menu}
\end{figure}
Um die einzelnen Fenster zu öffnen muss das \emph{VSPackage} des Fensters erst gestartet werden. Dies ist der Fall, da Visual Studio Erweiterungen erst dann gestartet werden, wenn sie das erste Mal durch den Entwickler verwendet werden. Microsoft beschreibt in der MSDN Library wie ein Paket manuell gestartet werden kann \cite{MSDNForcePackageLoad}. Sobald das Paket des Fensters gestartet wurde, kann dieses Fenster angezeigt werden. Um das Anzeigen von Usus.net-Fenstern zu vereinfachen, steht die Klasse \texttt{UsusNetWindow} im Namensraum \texttt{andrena.Usus.net.ExtensionHelper} zur Verfügung. Diese Klasse enthält für jedes Usus.net-Fenster die eindeutige Identifikationsnummer des dazugehörigen \emph{VSPackage} in Form einer GUID\footnote[1]{Mehr über GUIDs: "`Guid Structure"' \url{http://msdn.microsoft.com/en-us/library/system.guid.aspx}}. Listing \ref{listing:ususnetdisplaywindows} zeigt wie anhand dieser Identifikationsnummer das Paket geladen werden kann.
\begin{lstlisting}[caption={Anzeigen eines Usus.net-Fenster},label={listing:ususnetdisplaywindows}]
Guid PackageToBeLoadedGuid = new Guid(guid);
shell.LoadPackage(ref PackageToBeLoadedGuid, out package);
GlobalEventManager.Instance.FireEvent(guid, parameter);
\end{lstlisting}
Nachdem das Paket des Fensters in Zeile 2 geladen wurde, kann das Fenster in Visual Studio geöffnet werden. Dazu verwendet Usus.net ein Objekt vom Typ \texttt{GlobalEventManager}. Sobald das Paket eines Fensters geladen wird, registriert es eine Ereignisbehandlung bei der einzigen Instanz der \texttt{GlobalEventManager}-Klasse. Es ist eine Konvention in Usus.net, dass das Paket dafür seine GUID als Trigger verwendet. Die Ereignisbehandlung kann dann mit der GUID des \emph{VSPackage} ausgeführt werden, was in Listing \ref{listing:ususnetdisplaywindows} in Zeile 3 zu sehen ist. Listing \ref{listing:ususnetdisplaywindowsevent} zeigt exemplarisch wie das Paket des Usus.net Cockpit-Fenster die Ereignisbehandlung zum Anzeigen des Fensters registriert.
\begin{lstlisting}[caption={Registrierung des Anzeigen-Ereignis beim \texttt{GlobalEventManager}-Objekt},label={listing:ususnetdisplaywindowsevent}]
GlobalEventManager.Instance.RegisterEvent(
	UsusNetWindow.Cockpit,
	p => ShowToolWindow(null, null));
\end{lstlisting}
Alle \emph{VSPackage}-Projekte, die zur der einen VSIX-Datei zusammengefasst werden, teilen sich also die gleiche Instanz des \texttt{GlobalEventManager}-Objekts. Dadurch können Fenster und Menüs über Paketgrenzen hinweg kommunizieren indem Ereignisse definiert und ausgeführt werden. Dies ist die einzige Möglichkeit der Fenster-Menü-Kommunikation im Kontext von Usus.net.

\subsection{Zeilensprünge}
\label{subsec:vsrowjumps}
In Unterabschnitt \ref{subsec:ususnethotspots} wurde das Hotspots-Fenster vorgestellt. Nach einem Doppelklick auf einen Hotspot soll Visual Studio zu der entsprechenden Methode oder Klasse springen. Listing \ref{listing:openfilejumprow} zeigt, wie Visual Studio mithilfe des in Unterabschnitt \ref{subsec:vsievents} vorgestellten \texttt{DTE2}-Objekts eine Datei öffnen und zu einer Zeile in dieser Datei springen kann. Das \texttt{DTE2-Objekt} wird durch das \texttt{MasterObjekt}-Property der Klasse \texttt{DtAwareToolWindow} ermittelt.
\begin{lstlisting}[caption={Datei öffnen und an Zeile springen},label={listing:openfilejumprow}]
MasterObjekt.ItemOperations.OpenFile(fileName, 
	EnvDTE.Constants.vsViewKindTextView);
var file = MasterObjekt.ActiveDocument.Selection as EnvDTE.TextSelection;
file.GotoLine(fileLine, selectLine);
\end{lstlisting}
Dieser Code befindet sich in der \texttt{DtAwareToolWindow}-Klasse und lässt sich über die Methode \texttt{OpenFileAtLine} aufrufen. Die Variable \texttt{fileName} enthält den vollständigen Pfad der zu öffnenden Datei und die Variable \texttt{fileLine} die Zeilennummer der zu markierenden Zeile. Ob der Code in der Zeile tatsächlich markiert werden soll, kann über den Parameter \texttt{selectLine} festgelegt werden. Sollte Visual Studio das Dokument bereits geöffnet haben, bringt es dies bei Bedarf in den Vordergrund und springt nur zu der betroffenen Zeile.

\subsection{Editor Adornment}
\label{subsec:editoradornment}
In Unterabschnitt \ref{subsec:ususnetinfo} wurde beschrieben, dass das Info-Fenster von Usus.net über Buttons aufgerufen wird, die sich direkt neben den Methodensignaturen befinden. Das Erweiterungsmodell von Visual Studio unterstützt das Zeichnen von beliebigen WPF-Elementen im Code-Editor. Über die Projektvorlage \emph{Editor Adornment} (Editor Verzierung) kann eine Erweiterung erstellt werden, welche auf die aktuell sichtbaren Codezeilen reagieren kann. In dem von der Projektvorlage generierten Code existiert die Methode \texttt{CreateVisuals}, die einen Parameter vom Typ \texttt{ITextViewLine} übergeben bekommt. In dieser Methode kann die Logik implementiert werden, die ein grafisches Element in der übergebenen Zeile anzeigt. Im Fall von Usus.net ist dies ein kleiner Button, der in der Klasse \texttt{CodeTag} implementiert ist. Dieser Button wird nur neben einer Methodensignatur dargestellt. Usus.net stellt dies durch einen regulären Ausdruck sicher.
\begin{lstlisting}[caption={Muster einer gültigen Methodensignatur in C$\#$},label={listing:methodregex1}]
^{0}{1} {1}\\((((out |ref |this |params )?{1} {2})?(,[ ]?(out |ref |params )?
{1} {2})*)\\)\$
\end{lstlisting}
Dieser Ausdruck besteht aus vier Komponenten. Die erste Komponente ist in Listing \ref{listing:methodregex1} zu sehen und stellt eine Form dar, die die anderen drei Komponenten mehrfach wiederverwendet. \{0\} ist der Platzhalter für die zweite Komponente, während \{1\} für die dritte und \{2\} für die vierte Komponente steht.
\begin{lstlisting}[caption={Muster einer gültigen Zugriffseinschränkung in C$\#$},label={listing:methodregex2}]
(private |protected |public |internal )?(static |virtual new |virtual |new 
|override |override sealed )?
\end{lstlisting}
Listing \ref{listing:methodregex2} zeigt die zweite Komponente des regulären Ausdrucks, welche die Sichtbarkeit einer Methode beschreibt. Die dritte Komponente beschreibt die Syntax eines Typen und die vierte beschreibt einen Variablennamen. Beide Ausdrücke sind in Listing \ref{listing:methodregex3} abgebildet.
\begin{lstlisting}[caption={Muster eines gültigen Klassen- und Parameternamen in C$\#$},label={listing:methodregex3}]
Klassenname:	([_a-zA-Z]+[\\._a-zA-Z0-9\\[\\]]*(<.*>)?)
Parametername:	([_a-zA-Z]+[_a-zA-Z0-9]*([ ]?=[ ]?[^,<> ]*)?)
\end{lstlisting}
Zusammengesetzt entsteht ein Ausdruck, der nahezu alle gültigen Methodensignaturen zuverlässig erkennen kann und gleichzeitig weitgehend immun gegenüber Fehlern bleibt. Eine 100\%ige Korrektheit wurde nicht angestrebt und würde im zeitlichen Rahmen dieser Master-Thesis auch nicht erstellt werden können. Arrays, generische Typen, Standardwerte und automatische Arrays werden aber alle korrekt erkannt. Die Erkennung der Methoden wurde mit Unit Tests spezifiziert und getestet.
\paragraph{}
Wenn eine Methode als solche erkannt wurde, wird die Zeilennummer und der Pfad der Code-Datei ermittelt und innerhalb des Buttons gespeichert. Beide Informationen sind erforderlich um eine Methodensignatur der Quellcode-Datei mit einem Methodenbericht des Usus.net-Objektmodells zu verbinden. Usus.net kann diese Zuordnung noch nicht anhand der Signatur vornehmen. Die Signatur, die durch Analyse der Assembly mittels \emph{CCI Metadata} bestimmt werden kann, besteht aus voll-qualifizierten Namen und unterscheidet sich im schlimmsten Falle zu sehr von der Signatur die im Quelltext steht. Obwohl ein Ähnlichkeitsvergleich prinzipiell möglich ist, würde dies doch den zeitlichen Rahmen dieser Master-Thesis sprengen. Idealerweise könnte dazu der reguläre Ausdruck aus Listing \ref{listing:methodregex1}, \ref{listing:methodregex2} und \ref{listing:methodregex3} mit einer leichten Anpassung verwendet werden. Wenn eine pdb-Dateil vorhanden ist, funktioniert der zeilenbasierte Ansatz allerdings auch sehr gut. Da die Buttons ja sowieso nur in Visual Studio zu sehen sind und Visual Studio auch die Kompilierung des Codes vornimmt, wird eine solche pdb-Datei auch immer erzeugt. Listing \ref{listing:getlinenr} zeigt, wie in einer \emph{Editor Adornment}-Erweiterung die aktuelle Zeilennummer ermittelt werden kann.
\begin{lstlisting}[caption={Bestimmung der tatsächlichen Zeilennummer eines \texttt{ITextViewLine}-Objekts},label={listing:getlinenr}]
int lineNumber = _view.TextSnapshot
		.GetLineNumberFromPosition(line.Start.Position) + 1;
\end{lstlisting}
Die Variable \texttt{line} enthält das Objekt vom Typ \texttt{ITextViewLine}. Die Variable \texttt{\_view} enthält eine Referenz auf ein \texttt{IWpfTextView}-Objekt. Listing \ref{listing:getfile} zeigt wie zusätzlich noch der Pfad der aktuellen Datei ermittelt werden kann. Es ist zu beachten, dass dafür die Zeile nicht erforderlich ist. Visual Studio kann den Dateinamen allein anhand des \texttt{IWpfTextView}-Objekts bestimmen.
\begin{lstlisting}[caption={Bestimmung des Datei-Pfads eines \texttt{IWpfTextView}-Objekts},label={listing:getfile}]
ITextDocument document;
string filePath = string.Empty;
if (_view != null && _view.TextDataModel.DocumentBuffer.Properties
		.TryGetProperty(typeof(ITextDocument), out document))
	string filePath = document.FilePath;
\end{lstlisting}
Nachdem jede Methodensignatur eine Kompination aus Zeilennummer und Dateinamen zugewiesen bekommen hat, ist der Button bereit aus das Klick-Ereignis zu reagieren. Sobald der Entwickler auf den Button klickt, wird die Zeileninformation verpackt und über die Event-Infrastruktur aus Unterabschnitt \ref{subsec:vsmenus} an das \emph{VsPackage} geschickt, welches das Info-Fenster enthält und daraufhin anzeigt.
\begin{lstlisting}[caption={Öffnen des Info-Fensters mit einem \texttt{LineLocation}-Objekt},label={listing:sendlineandfiletoinfo}]
GlobalEventManager.Instance.FireEvent(UsusNetWindow.Current, 
	new LineLocation { Line = lineNumber, File = filePath });
\end{lstlisting}
Listing \ref{listing:sendlineandfiletoinfo} zeigt wie ein Methodensignatur-Button seine Daten an das Info-Fenster aus Unterabschnitt \ref{subsec:ususnetinfo} sendet. \texttt{UsusNetWindow.Current} enthält die GUID des Info-Fensters, sodass standardmäßig die Fenster-Öffnen-Ereginisbehandlung ausgeführt wird. Diese Behandlung wird auch von dem Menüpunkt verwendet. Im Gegensatz zu dem Menüpunkt, öffnet der Button das Fenster mit einem Parameter. Die Behandlung auf der Seite des Fensters muss also unabhängig davon funktionieren, ob eine Zeilen-Information übergeben wird oder nicht.




\chapter{Clean Code Unterstützung}
\textcolor[rgb]{1,0,0}{todo}


\section{Histogramm-Analyse}
\label{sec:histogramanalysis}
In Abschnitt \ref{sec:distributions} wurde beschrieben, das Usus.net Histogramme für alle Metriken erstellen kann. Dieser Abschnitt beschäftigt sich mit der Analyse ebendieser Metrik-Histogramme und wie die Metriken tatsächliche verteilt sind. Nach einer ersten Überlegung folgen beispielsweise Methodenlängen einer Exponentialverteilung. "`Kurz"' ist das Erste, was Robert C. Martin über Methoden schreibt \cite{CleanCode}. In einem Softwaresystem, das mit dieser Einstellung bezüglich Clean Code entwickelt wurde, wird also sehr viele sehr kurze Methoden haben, viele kurze und wenig lange Methoden. Die Methodenlänge nimmt also exponentiell ab und diese Entwicklung sollte auch im Histogramm der Methodenlängen zu sehen sein. Die Funktion der Exponentialverteilung ist laut Eric W. Weisstein wie in Formel \ref{eq:edistribution} definiert \cite{ExponentialDist}.
\begin{equation}
f_\lambda(x) = 
	\begin{cases}
		\lambda e^{-\lambda x}&x>=0\\
		0&x<0\\
	\end{cases}
\label{eq:edistribution}
\end{equation}
Da alle Metriken ganzen Zahlen sind (es gibt keine Methodenlänge mit 1,5 logischen Zeilen), enthalten auch die Metrik-Histogramme nur diskrete Werte auf der x-Achse. Für die analytische Annäherung einer Verteilungsfunktion empfiehlt sich daher auch die Verwendung einer diskreten Verteilung. Laut Eric W. Weisstein ist das diskrete Gegenstück der kontinuierlichen Exponentialverteilung die geometrische Verteilung \cite{GeometricsDist}. Die Funktion der geometrische Verteilung ist in Formel \ref{eq:gdistribution} zu sehen.
\begin{equation}
f_\lambda(x) = 
	\begin{cases}
		\lambda (1 - \lambda)^{x-1}&0 < x \wedge x <= 1  \\
		0&\text{sonst}\\
	\end{cases}
\label{eq:gdistribution}
\end{equation}
Beide Funktionen sind von dem Parameter $\lambda$ abhängig. Die eigentliche Histogramm-Analyse besteht darin, diesen Parameter so zu bestimmen, dass die Funktionen das Histogramm möglichst genau beschreibt.

\subsection{Approximation}
\label{subsec:histogramapproximation}
Eine Methode das $\lambda$ zu berechnen ist die Maximum Likelyhood-Methode, die Weisstein ebenfalls in seinem MathWorld-Eintrag beschreibt \cite{MaximumLikelihood}. Mit dieser Methode kann eine Schätzer-Funktion errechnet werden, die in Abhängigkeit der Werte des Histogramms den Parameter $\lambda$ bestimmt. Sigbert Klinke, Patrick Lehmann, Bernd Rönz, Sibylle Schmerbach und Olga Zlatkin-Troitschanskaia haben den Schätzer für die Exponentialverteilung bereits bestimmt \cite{MLExponentialDist}. Den Schätzer der geometrischen Verteilung wurde von Künzer, Meister und Nebe berechnet \cite{MLGeometricsDist}. Beide Schätzer-Funktion sind identisch und abhängig von der Histogramm-Sequenz. Formel \ref{eq:edistributionml} zeigt diese Rechenvorschrift zur Bestimmung des $\lambda$-Parameters.
\begin{equation}
\lambda = \frac{n}{\sum_{i=1}^n x_i} = \frac{1}{\bar{x}}
\label{eq:edistributionml}
\end{equation}
Der Parameter $\lambda$ der Exponentialverteilung entspricht also dem reziproken Mittelwert. Je mehr kurze Methoden der Quellcode enthält, dest niedriger ist der Mittelwert. Für ein großes $\lambda$ ist der Mittelwert klein und umgekehrt. Auf das Histogramm bezogen bedeutet ein großes $\lambda$, dass die Exponentialfunktion der Verteilung schnell fällt (sehr viele kurze und sehr wenige lange Methoden). Abbildung \ref{fig:edist} zeigt die wünschenswerte Verteilung in rot und die weniger optimale in blau. Das Schaubild geht von einer Stichprobe mit 100 Werten aus, beispielsweise Methodenlängen.
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/edist.png}
	\caption{Exponentialverteilung für großes und kleines $\lambda$}
	\label{fig:edist}
\end{figure}
Die Funktion der geometrischen Verteilung verhält sich genauso, da sie den gleichen Maximum Likelihood-Schätzer wie die Exponentialverteilung hat. Abbildung \ref{fig:gdist} zeigt wieder die wünschenswerte Verteilung in rot und die weniger optimale in blau. Auch hier besteht die Stichprobe aus 100 Werten.
\begin{figure}[h]
	\centering
		\includegraphics[width=11cm]{images/gdist.png}
	\caption{Geometrische Verteilung für großes und kleines $\lambda$}
	\label{fig:gdist}
\end{figure}
Obwohl die Exponentialverteilung und die geometrische Verteilung nicht identisch sind, kann der Parameter, von dem beide abhängig sind auf die gleiche Art berechnet werden. Das Ergebnis verhält sich in beiden Verteilungen vergleichbar. Im Kontext der Software-Metriken gilt: je größer das $\lambda$, desto extremer entspricht der Code dem Clean Code Paradigma von Robert C. Martin. Martin befürwortet sehr einfache und sehr kurze Methoden, sowie Klassen mit sehr wenig Abhängigkeiten \cite{CleanCode}.
\paragraph{}
Usus.net berechnet den $\lambda$-Parameter in der Klasse \texttt{GeometricalDistributionFitting} nach Formel \ref{eq:edistributionml}. Die Komponenten, die für diese Berechnung zuständig sind, wurden bereits in Abschnitt \ref{sec:distributions} vorgestellt. Das Ergebnis kann anschließend in der Histogramm-Oberfläche aus Unterabschnitt \ref{subsec:ususnethostigram} angezeigt werden. Abbildung \ref{fig:ususnet_histogram} zeigt beispielsweise die Verteilung der Klassengrößen einer Beispielanwendung. In Kapitel \ref{chap:inaction} werden konkretere Beispiele betrachtet und mit Usus.net analysiert.

\subsection{Fehler}
\label{subsec:histogramerror}
Da das Histogramm durch eine stetige Funktion angenähert wird, ist es sehr wahrscheinlich, dass die Funktion mit dem bestimmten Parameter nicht exakt durch die Punkte des Histogramms läuft. Diese Abweichung kann laut Eric W. Weisstein mit den Chi-Squared Test ermittelt werden \cite{ChiSquared}. Formel \ref{eq:chisquaredtest} zeigt dieses Maß der Abweichung.
\begin{equation}
\chi^2 = \sum_{i=1}^n \frac{(x_i - f(x_i))^2}{f(x_i)}
\label{eq:chisquaredtest}
\end{equation}
Da das $\lambda$ der geometrischen Verteilung bekannt ist, kann die Funktion $f(x_i)$ durch die Funktion $f_\lambda(x_i)$ aus Formel \ref{eq:gdistribution} ersetzt werden. Das berechnete Ergebnis kann über den \texttt{Error}-Parameter des \texttt{GeometricalDistributionFitting}-Objekts zurückgegeben werden. Die Implementierung dieser Fehlerfunktion ist in der aktuellen Version von Usus.net noch nicht enthalten. Sobald Usus.net die Bestimmung von verschiedenen Verteilungen unterstützt, kann mithilfe des Fehlers die Verteilungsfunktion bestimmt werden, die das Histogramm am Besten (mit dem geringsten Fehler) annähert. Aufgrund der dadurch bestimmten wahrscheinlichsten Verteilung könnte eine bessere Aussage über die Metriken im betroffenen Softwaresystem getroffen werden. Diese weiteren Verteilungen könnten eventuell die Poisson-Verteilung und die Pareto-Verteilung sein. Eine weiterführende theoretische Analyse kann im zeitlichen Rahmen dieser Master-Thesis nicht vorgenommen werden.


\section{Andrena Software Qualitäts Index}
Theoretisch interpretieren Entwickler kleinere Metriken in der Regel als bessere Metriken, obwohl bessere Metriken nicht automatisch besseren Code beschreiben. In Bezug auf die Methodenlänge ist Robert C. Martin in seinem Buch sehr deutlich und verteidigt kurze Methoden \cite{CleanCode}. Ein Softwaresystem, welches evolutionär gewachsen ist, enthält leider nicht nur kurze Methoden sondern auch zunehmend längere. Eine Metrik-Interpretation über die Verteilung, wie in Abschnitt \ref{sec:histogramanalysis} beschrieben, kann dann sehr schnell an Aussagekraft verlieren. Die Gewichtung der Metriken, die in Usus für Eclipse und Usus.net vorgenommen und in Abschnitt \ref{sec:metrics} beschrieben wird, versucht die Interpretation trotzdem zu ermöglichen. Deswegen zeigt das Cockpit-Fenster der beiden Usus-Versionen auch nicht die Rohmetriken an. Die Metrikgewichtung von Usus geht auf das andrena-interne Werkzeug Isis zurück. Isis erlaubt es ungewichtete Metriken, die von einem anderen Tool erstellt wurden, zu importieren und zu bewerten. Das Ergebnis ist der von andrena sogenannte "`Softwarequalitätsindex"' (SQI), welcher in dem Manuskript von Dr. Eberhard Kuhn ausführlich beschrieben wird \cite{IsisSQI}.

\subsection{SQI Parameter}
Der von Isis berechnete Softwarequalitätsindex ist von mehreren Metriken abhängig. Im Folgenden werden diese Metriken in der vorliegenden Master-Thesis so definiert, wie sie Kuhn in seinem Manuskript ebenfalls verwendet.
\begin{definition}[Testabdeckung] Testabdeckung ist der prozentuale Anteil allen Quellcodes, der durch automatisierte Tests abgedeckt wird.
\end{definition}
\begin{definition}[Pakete in Zyklen] \emph{Pakete in Zyklen} ist die Anzahl aller Namespaces, die Teil eines Namespace-Zyklus sind.
\end{definition}
\begin{definition}[Komplizierte Methoden] \emph{Komplizierte Methoden} ist die Anzahl aller Methoden, deren zyklomatische Komplexität den Schwellwert 5 übersteigen.
\end{definition}
\begin{definition}[Average Component Dependency] \emph{ACD} ist der gemittelte CCD-Wert aller Klassen und gibt an, wie viel Prozent aller Klassen von jeder Klasse direkt oder indirekt abhängig ist.
\end{definition}
\begin{definition}[Große Klassen] \emph{Große Klassen} ist die Anzahl aller Klassen, die mehr als 20 Methoden haben.
\end{definition}
\begin{definition}[Große Methoden] \emph{Große Methoden} ist die Anzahl aller Methoden, die mehr als 15 Codezeilen enthalten.
\end{definition}
\begin{definition}[Compiler-Warnungen] \emph{Compiler-Warnungen} ist die Anzahl der Warnungen, die der Compiler beim Kompilieren anzeigt.
\end{definition}
Nachdem diese Metriken durch ein Tool bestimmt wurden, berechnet Isis für jede Metrik $m$, bis auf die Testabdeckung, das Softwarequalitätsniveau. Die Berechnungsvorschrift ist in Formel \ref{eq:sqniveau} dargestellt. Das Software Qualitätsniveau der Testabdeckung ist die Testabdeckung selber.
\begin{equation}
SQNiveau(m) = \frac{100}{1,5^{\Big(\displaystyle \frac{RelativeGroeße(m)}{Zweidrittelkonstante(m)}\Big)}}
\label{eq:sqniveau}
\end{equation}
Isis rechnet nicht mit den Rohwerten der Metriken, sondern verwendet dessen relative Größe. Diese relative Größe wird zusätzlich noch mit einem Faktor gewichtet, den Kuhn "`Zweidrittelkonstante"' nennt. Tabelle \ref{tab:sqniveaufactors} zeigt diese Faktoren.
\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.5}
\rowcolors{1}{}{shadethmcolor}
\begin{tabular}{ l | c | c }
	Metrik $m$ & $RelativeGroeße(m)$ & $Zweidrittelkonstante(m)$ \\
	\hline
	Pakete in Zyklen & $\frac{\displaystyle m}{Anzahl Packages}$ & $\frac{1}{15}$ \\
	Komplizierte Methoden & $\frac{\displaystyle m}{Anzahl Methoden}$ & $\frac{1}{50}$ \\
	Average Component Dependency & 1 & $100 \times Anzahl Klassen^{-1/3}$ \\
	Große Klassen & $\frac{\displaystyle m}{Anzahl Klassen}$ & $\frac{1}{25}$ \\
	Große Methoden & $\frac{\displaystyle m}{Anzahl Methoden}$ & $\frac{1}{25}$ \\
	Compiler-Warnungen & $\frac{\displaystyle m}{Anzahl Klassen}$ & $\frac{1}{50}$ \\
\end{tabular}
\caption{Relative Größen und Zweidrittelkonstanten aller Isis-Metriken}
\label{tab:sqniveaufactors}
\end{table}
Wie die Zweidrittelkonstanten zustande kommen beschreiben Andreas Leidig und Nicole Rauch in ihrem technischen Artikel \cite{Isis}. Um den Softwarequalitätsniveau gegenüber monolithischen Extremen robuster zu machen, kann der von Kuhn beschriebenen "`Monolithkorrekturfaktor"' angewendet werden. Als Beispiel beschreibt Kuhn, dass eine zweifelhafte Verbesserung der Metriken erreicht werden könnte, indem alle Klassen in einem einzigen Paket oder alle Methoden in einer einzigen Klasse platziert werden. Diese Fälle sollen durch den Monolithkorrekturfaktor berücksichtigt werden. Die Testabdeckung und die Compiler-Warnungen sind von dieser Korrektur nicht betroffen. Formel \ref{eq:sqifmk} zeigt wie dieser Faktor zu jeder Metrik bestimmt werden kann.
\begin{equation}
f_{mk}(m) = \frac{1}{1,5^{\Big(\displaystyle \frac{MittlereGroeße(m)}{Zweidrittelkonstante_{fmk}(m)}\Big)^3}}
\label{eq:sqifmk}
\end{equation}
Isis verwendet an dieser Stelle wieder eine Zweidrittelkonstante aus Tabelle \ref{tab:sqniveaufmkfactors}, um die Gewichtung des Korrekturfaktors zu regulieren. Die Größe des Systems ist ebenfalls von Bedeutung und wird in Form der Anzahl aller relevanten Codezeilen (RLOC) verwendet. Wie Usus.net diese Codezeilen ermitteln kann ist in Unterabschnitt \ref{subsec:rloc} beschrieben.
\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.5}
\rowcolors{1}{}{shadethmcolor}
\begin{tabular}{ l | c | c }
	Metrik $m$ & Mittlere Größe & Zweidrittelkonstante$_{fmk}$ \\
	\hline
	Pakete in Zyklen & $\frac{\displaystyle RLOC}{Anzahl Packages}$ & 3000 \\
	Komplizierte Methoden & $\frac{\displaystyle RLOC}{Anzahl Methoden}$ & 15 \\
	Average Component Dependency & $\frac{\displaystyle RLOC}{Anzahl Klassen}$ & 200 \\
	Große Klassen & $\frac{\displaystyle RLOC}{Anzahl Klassen}$ & 200 \\
	Große Methoden & $\frac{\displaystyle RLOC}{Anzahl Methoden}$ & 15 \\
\end{tabular}
\caption{Zweidrittelkonstanten$_{fmk}$ der Isis-Monolithkorrekturfaktoren}
\label{tab:sqniveaufmkfactors}
\end{table}
Dieser Faktor $f_{mk}$ wird, wie in Formel \ref{eq:sqniveaufmk} gezeigt, mit Softwarequalitätsniveau multipliziert, um ein korrigiertes Softwarequalitätsniveau zu erhalten.
\begin{equation}
SQNiveau_{fmk}(m) = SQNiveau(m) \times f_{mk}(m)
\label{eq:sqniveaufmk}
\end{equation}
Nachdem die endgültigen Softwarequalitätsniveaus aller Metriken bekannt sind, können diese Aufsummiert werden. Diese Summe ist in Formel \ref{eq:sqisum} dargestellt.
\begin{equation}
SQI = \sum_{m \in M} SQNiveau_{fmk}(m) \times Gewicht(m) \times 0,1
\label{eq:sqisum}
\end{equation}
Isis nimmt dabei eine abschließende Gewichtung anhand Tabelle \ref{tab:sqiweights} vor.
\begin{table}[htb]
\centering
\rowcolors{1}{}{shadethmcolor}
\begin{tabular}{ l | c }
	Metrik $m$ & Gewicht \\
	\hline
	Testabdeckung & 2,28 \\
	Pakete in Zyklen & 1,93 \\
	Komplizierte Methoden & 1,75 \\
	Average Component Dependency & 1,58 \\
	Große Klassen & 1,05 \\
	Große Methoden & 1,05 \\
	Compiler-Warnungen & 0,36 \\
\end{tabular}
\caption{SQI Gewichte}
\label{tab:sqiweights}
\end{table}
In diesem Unterabschnitt wurden die Parameter beschrieben, mit denen Isis den Softwarequalitätsindex berechnet. Die nachfolgenden Unterabschnitte beschäftigen sich mit der Berechnung des SQI durch wie Usus.net.

\subsection{Relevante Code-Zeilen}
\label{subsec:rloc}
ISIS verwendet eine einheitliche Größe für Codebasen, nämlich RLOC (engl. Relevant Lines Of Code). Die Anzahl aller Codezeilen in allen Code-Dokumenten ohne Kommentare und ohne Klammern werden dabei berücksichtigt. Der Wert wird in dem \texttt{CommonReportKnowledge}-Objekt des Metrikberichts gespeichert (siehe Abschnitt \ref{sec:ususobjectmodel}). \emph{CCI Metadata} erlaubt es die Zeileninformationen der CIL-Anweisungen innerhalb einer Methoden mithilfe der \texttt{PeReader}-Klasse zu bestimmen. In Unterabschnitt \ref{subsec:methodlength} wurde beschrieben, dass Usus.net auf diese Weise auch die Methodenlänge eine Methode berechnet. Die Zeileninformationen von Methoden- und Klassendefinitionen können über das \texttt{PeReader}-Objekt nicht ermittelt werden. \emph{CCI Metadata} kann die Anzahl der relevanten Codezeilen also nicht direkt aus einer Assembly bestimmen. Aus diesem Grund versucht Usus.net den RLOC-Wert auszurechnen. Die Methodenlänge bildet dabei die Grundlage. Für jede Methode im \texttt{MetricsReport}-Objekt addiert Usus.net die Methodenlänge sowie eine weitere Zeile (Methodendefiniton) zu dem \texttt{RelevantLinesOfCode}-Property in dem \texttt{CommonReportKnowledge}-Objekt. Für jede Klasse wird dieses Property um zwei weitere Zeilen erhöht, welche für die Klassendefinition sowie die Namespace-Zugehörigkeit stehen. Mehrzeilige Methodensignaturen und Klassendefinitionen werden also trotzdem mit nur jeweils einer Zeile gerechnet. Die \texttt{using}-Angaben am Anfang jeder Quellcode-Datei werden ignoriert.

\subsection{Usus.net Berechnung}
Testabdeckung wird noch nicht ermittelt

Compiler-Warnungen werden noch nicht ermittelt

Oberfläche gibt es noch nicht

Klassen gibt es auch noch nicht

\textcolor[rgb]{1,0,0}{todo}


\section{Metrik-Veränderung}
\textcolor[rgb]{1,0,0}{todo}




\chapter{In Aktion}
\label{chap:inaction}
\textcolor[rgb]{1,0,0}{todo}


\section{Metrik-Vergleich}
Stimmen die Werte, die Usus.net bestimmt mit denen der anderen Werkzeuge überein? Eclipse Usus, FxCop, Code Metrics PowerTool
\textcolor[rgb]{1,0,0}{todo}


\section{Usus.net Performance}
Wie schnell arbeitet Usus.net im Vergleich zu anderen Werkzeugen? Wird Zeit gespart, da kein Kontextswitch erforderlich ist und das Tool in die IDE integriert ist?
\textcolor[rgb]{1,0,0}{todo}


\section{Fallbeispiel Andrena-Kurs}
\textcolor[rgb]{1,0,0}{todo}




\chapter{Zusammenfassung}
\textcolor[rgb]{1,0,0}{todo}
Use Cases erfüllt, bla bla
Graphen Visualisierung weggelassen




\chapter{Ausblick}
\textcolor[rgb]{1,0,0}{todo}
automatische Refaktorings, bla bla








\bibliography{masterthesis}
\bibliographystyle{alpha}

\end{document}
